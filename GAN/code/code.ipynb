{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n",
      "Found 60000 images\n",
      "Epoch [1/20] Batch 0/938 Loss D: 0.7414, Loss G: 0.6043\n",
      "Epoch [1/20] Batch 10/938 Loss D: 0.4739, Loss G: 0.7594\n",
      "Epoch [1/20] Batch 20/938 Loss D: 0.3420, Loss G: 1.0037\n",
      "Epoch [1/20] Batch 30/938 Loss D: 0.2948, Loss G: 1.0997\n",
      "Epoch [1/20] Batch 40/938 Loss D: 0.2482, Loss G: 1.2733\n",
      "Epoch [1/20] Batch 50/938 Loss D: 0.1630, Loss G: 1.7457\n",
      "Epoch [1/20] Batch 60/938 Loss D: 0.1667, Loss G: 1.7947\n",
      "Epoch [1/20] Batch 70/938 Loss D: 0.1200, Loss G: 2.1831\n",
      "Epoch [1/20] Batch 80/938 Loss D: 0.1160, Loss G: 2.1231\n",
      "Epoch [1/20] Batch 90/938 Loss D: 0.1043, Loss G: 2.3175\n",
      "Epoch [1/20] Batch 100/938 Loss D: 0.0600, Loss G: 2.9524\n",
      "Epoch [1/20] Batch 110/938 Loss D: 0.0581, Loss G: 2.9725\n",
      "Epoch [1/20] Batch 120/938 Loss D: 0.1040, Loss G: 2.1085\n",
      "Epoch [1/20] Batch 130/938 Loss D: 0.0882, Loss G: 2.3104\n",
      "Epoch [1/20] Batch 140/938 Loss D: 0.0768, Loss G: 2.7449\n",
      "Epoch [1/20] Batch 150/938 Loss D: 0.0617, Loss G: 2.8921\n",
      "Epoch [1/20] Batch 160/938 Loss D: 0.0566, Loss G: 2.9160\n",
      "Epoch [1/20] Batch 170/938 Loss D: 0.0600, Loss G: 2.7795\n",
      "Epoch [1/20] Batch 180/938 Loss D: 0.0931, Loss G: 2.1969\n",
      "Epoch [1/20] Batch 190/938 Loss D: 0.0592, Loss G: 2.7722\n",
      "Epoch [1/20] Batch 200/938 Loss D: 0.0333, Loss G: 3.5755\n",
      "Epoch [1/20] Batch 210/938 Loss D: 0.0263, Loss G: 3.7951\n",
      "Epoch [1/20] Batch 220/938 Loss D: 0.0337, Loss G: 3.2667\n",
      "Epoch [1/20] Batch 230/938 Loss D: 0.0315, Loss G: 3.3930\n",
      "Epoch [1/20] Batch 240/938 Loss D: 0.0271, Loss G: 3.6413\n",
      "Epoch [1/20] Batch 250/938 Loss D: 0.0289, Loss G: 3.4363\n",
      "Epoch [1/20] Batch 260/938 Loss D: 0.0271, Loss G: 3.5026\n",
      "Epoch [1/20] Batch 270/938 Loss D: 0.0236, Loss G: 3.8669\n",
      "Epoch [1/20] Batch 280/938 Loss D: 0.0229, Loss G: 3.8426\n",
      "Epoch [1/20] Batch 290/938 Loss D: 0.0251, Loss G: 3.7340\n",
      "Epoch [1/20] Batch 300/938 Loss D: 0.0190, Loss G: 3.9826\n",
      "Epoch [1/20] Batch 310/938 Loss D: 0.0156, Loss G: 4.3216\n",
      "Epoch [1/20] Batch 320/938 Loss D: 0.0193, Loss G: 4.0328\n",
      "Epoch [1/20] Batch 330/938 Loss D: 0.0390, Loss G: 3.0449\n",
      "Epoch [1/20] Batch 340/938 Loss D: 0.0286, Loss G: 3.6039\n",
      "Epoch [1/20] Batch 350/938 Loss D: 0.0170, Loss G: 4.5010\n",
      "Epoch [1/20] Batch 360/938 Loss D: 0.0117, Loss G: 4.7318\n",
      "Epoch [1/20] Batch 370/938 Loss D: 0.0184, Loss G: 4.5203\n",
      "Epoch [1/20] Batch 380/938 Loss D: 0.0150, Loss G: 4.1149\n",
      "Epoch [1/20] Batch 390/938 Loss D: 0.0155, Loss G: 4.0682\n",
      "Epoch [1/20] Batch 400/938 Loss D: 0.0131, Loss G: 4.2152\n",
      "Epoch [1/20] Batch 410/938 Loss D: 0.0211, Loss G: 3.6335\n",
      "Epoch [1/20] Batch 420/938 Loss D: 0.0128, Loss G: 4.3783\n",
      "Epoch [1/20] Batch 430/938 Loss D: 0.0144, Loss G: 4.4095\n",
      "Epoch [1/20] Batch 440/938 Loss D: 0.0604, Loss G: 2.7525\n",
      "Epoch [1/20] Batch 450/938 Loss D: 0.0728, Loss G: 2.9995\n",
      "Epoch [1/20] Batch 460/938 Loss D: 0.0308, Loss G: 4.5330\n",
      "Epoch [1/20] Batch 470/938 Loss D: 0.0215, Loss G: 3.9563\n",
      "Epoch [1/20] Batch 480/938 Loss D: 0.0290, Loss G: 3.5863\n",
      "Epoch [1/20] Batch 490/938 Loss D: 0.0133, Loss G: 4.5140\n",
      "Epoch [1/20] Batch 500/938 Loss D: 0.0144, Loss G: 4.5377\n",
      "Epoch [1/20] Batch 510/938 Loss D: 0.0233, Loss G: 3.7287\n",
      "Epoch [1/20] Batch 520/938 Loss D: 0.0108, Loss G: 4.7551\n",
      "Epoch [1/20] Batch 530/938 Loss D: 0.0082, Loss G: 5.1812\n",
      "Epoch [1/20] Batch 540/938 Loss D: 0.0129, Loss G: 4.4610\n",
      "Epoch [1/20] Batch 550/938 Loss D: 0.0108, Loss G: 4.6822\n",
      "Epoch [1/20] Batch 560/938 Loss D: 0.0076, Loss G: 5.1541\n",
      "Epoch [1/20] Batch 570/938 Loss D: 0.0080, Loss G: 5.1552\n",
      "Epoch [1/20] Batch 580/938 Loss D: 0.0087, Loss G: 4.8107\n",
      "Epoch [1/20] Batch 590/938 Loss D: 0.0099, Loss G: 4.3842\n",
      "Epoch [1/20] Batch 600/938 Loss D: 0.0133, Loss G: 4.1469\n",
      "Epoch [1/20] Batch 610/938 Loss D: 0.0163, Loss G: 3.9832\n",
      "Epoch [1/20] Batch 620/938 Loss D: 0.0307, Loss G: 3.6679\n",
      "Epoch [1/20] Batch 630/938 Loss D: 0.0332, Loss G: 3.8432\n",
      "Epoch [1/20] Batch 640/938 Loss D: 0.1062, Loss G: 2.6962\n",
      "Epoch [1/20] Batch 650/938 Loss D: 0.0534, Loss G: 4.3104\n",
      "Epoch [1/20] Batch 660/938 Loss D: 0.0330, Loss G: 4.2508\n",
      "Epoch [1/20] Batch 670/938 Loss D: 0.0581, Loss G: 3.0902\n",
      "Epoch [1/20] Batch 680/938 Loss D: 0.0398, Loss G: 3.6626\n",
      "Epoch [1/20] Batch 690/938 Loss D: 0.0548, Loss G: 3.3826\n",
      "Epoch [1/20] Batch 700/938 Loss D: 0.0378, Loss G: 4.0268\n",
      "Epoch [1/20] Batch 710/938 Loss D: 0.0552, Loss G: 3.2065\n",
      "Epoch [1/20] Batch 720/938 Loss D: 0.0337, Loss G: 4.2488\n",
      "Epoch [1/20] Batch 730/938 Loss D: 0.0259, Loss G: 4.5839\n",
      "Epoch [1/20] Batch 740/938 Loss D: 0.0149, Loss G: 4.3990\n",
      "Epoch [1/20] Batch 750/938 Loss D: 0.0162, Loss G: 4.4508\n",
      "Epoch [1/20] Batch 760/938 Loss D: 0.0148, Loss G: 4.3224\n",
      "Epoch [1/20] Batch 770/938 Loss D: 0.0199, Loss G: 4.0726\n",
      "Epoch [1/20] Batch 780/938 Loss D: 0.0199, Loss G: 4.0793\n",
      "Epoch [1/20] Batch 790/938 Loss D: 0.0198, Loss G: 4.0692\n",
      "Epoch [1/20] Batch 800/938 Loss D: 0.0210, Loss G: 4.4565\n",
      "Epoch [1/20] Batch 810/938 Loss D: 0.0223, Loss G: 4.1724\n",
      "Epoch [1/20] Batch 820/938 Loss D: 0.0355, Loss G: 3.6103\n",
      "Epoch [1/20] Batch 830/938 Loss D: 0.0513, Loss G: 3.6174\n",
      "Epoch [1/20] Batch 840/938 Loss D: 0.0605, Loss G: 3.4000\n",
      "Epoch [1/20] Batch 850/938 Loss D: 0.0424, Loss G: 4.0949\n",
      "Epoch [1/20] Batch 860/938 Loss D: 0.0240, Loss G: 4.2466\n",
      "Epoch [1/20] Batch 870/938 Loss D: 0.0183, Loss G: 4.1819\n",
      "Epoch [1/20] Batch 880/938 Loss D: 0.0158, Loss G: 4.4471\n",
      "Epoch [1/20] Batch 890/938 Loss D: 0.0149, Loss G: 4.6551\n",
      "Epoch [1/20] Batch 900/938 Loss D: 0.0119, Loss G: 4.6416\n",
      "Epoch [1/20] Batch 910/938 Loss D: 0.0117, Loss G: 4.5739\n",
      "Epoch [1/20] Batch 920/938 Loss D: 0.0180, Loss G: 4.2247\n",
      "Epoch [1/20] Batch 930/938 Loss D: 0.0159, Loss G: 4.5041\n",
      "Epoch [2/20] Batch 0/938 Loss D: 0.0129, Loss G: 4.5875\n",
      "Epoch [2/20] Batch 10/938 Loss D: 0.0121, Loss G: 4.5361\n",
      "Epoch [2/20] Batch 20/938 Loss D: 0.0171, Loss G: 4.4988\n",
      "Epoch [2/20] Batch 30/938 Loss D: 0.0113, Loss G: 4.8306\n",
      "Epoch [2/20] Batch 40/938 Loss D: 0.0110, Loss G: 5.0077\n",
      "Epoch [2/20] Batch 50/938 Loss D: 0.0178, Loss G: 4.2383\n",
      "Epoch [2/20] Batch 60/938 Loss D: 0.0342, Loss G: 3.5437\n",
      "Epoch [2/20] Batch 70/938 Loss D: 0.0344, Loss G: 4.0934\n",
      "Epoch [2/20] Batch 80/938 Loss D: 0.0228, Loss G: 4.7394\n",
      "Epoch [2/20] Batch 90/938 Loss D: 0.0156, Loss G: 4.6174\n",
      "Epoch [2/20] Batch 100/938 Loss D: 0.0193, Loss G: 4.5446\n",
      "Epoch [2/20] Batch 110/938 Loss D: 0.0110, Loss G: 4.7046\n",
      "Epoch [2/20] Batch 120/938 Loss D: 0.0109, Loss G: 4.9751\n",
      "Epoch [2/20] Batch 130/938 Loss D: 0.0088, Loss G: 5.0231\n",
      "Epoch [2/20] Batch 140/938 Loss D: 0.0096, Loss G: 4.8431\n",
      "Epoch [2/20] Batch 150/938 Loss D: 0.0103, Loss G: 4.8544\n",
      "Epoch [2/20] Batch 160/938 Loss D: 0.0088, Loss G: 4.9452\n",
      "Epoch [2/20] Batch 170/938 Loss D: 0.0116, Loss G: 4.5373\n",
      "Epoch [2/20] Batch 180/938 Loss D: 0.0157, Loss G: 4.5777\n",
      "Epoch [2/20] Batch 190/938 Loss D: 0.0191, Loss G: 4.5506\n",
      "Epoch [2/20] Batch 200/938 Loss D: 0.0124, Loss G: 4.8149\n",
      "Epoch [2/20] Batch 210/938 Loss D: 0.0104, Loss G: 4.8127\n",
      "Epoch [2/20] Batch 220/938 Loss D: 0.0090, Loss G: 5.0034\n",
      "Epoch [2/20] Batch 230/938 Loss D: 0.0086, Loss G: 4.8380\n",
      "Epoch [2/20] Batch 240/938 Loss D: 0.0117, Loss G: 4.8097\n",
      "Epoch [2/20] Batch 250/938 Loss D: 0.0109, Loss G: 4.6720\n",
      "Epoch [2/20] Batch 260/938 Loss D: 0.0135, Loss G: 4.8240\n",
      "Epoch [2/20] Batch 270/938 Loss D: 0.0103, Loss G: 5.0670\n",
      "Epoch [2/20] Batch 280/938 Loss D: 0.0101, Loss G: 4.9962\n",
      "Epoch [2/20] Batch 290/938 Loss D: 0.0097, Loss G: 4.8462\n",
      "Epoch [2/20] Batch 300/938 Loss D: 0.0147, Loss G: 4.5801\n",
      "Epoch [2/20] Batch 310/938 Loss D: 0.0224, Loss G: 4.2420\n",
      "Epoch [2/20] Batch 320/938 Loss D: 0.0265, Loss G: 4.1618\n",
      "Epoch [2/20] Batch 330/938 Loss D: 0.0281, Loss G: 4.1064\n",
      "Epoch [2/20] Batch 340/938 Loss D: 0.0330, Loss G: 3.9213\n",
      "Epoch [2/20] Batch 350/938 Loss D: 0.0515, Loss G: 3.8826\n",
      "Epoch [2/20] Batch 360/938 Loss D: 0.0442, Loss G: 4.1170\n",
      "Epoch [2/20] Batch 370/938 Loss D: 0.0994, Loss G: 3.1061\n",
      "Epoch [2/20] Batch 380/938 Loss D: 0.1513, Loss G: 2.9013\n",
      "Epoch [2/20] Batch 390/938 Loss D: 0.0677, Loss G: 3.4176\n",
      "Epoch [2/20] Batch 400/938 Loss D: 0.0425, Loss G: 3.8745\n",
      "Epoch [2/20] Batch 410/938 Loss D: 0.0275, Loss G: 4.1652\n",
      "Epoch [2/20] Batch 420/938 Loss D: 0.0295, Loss G: 3.9898\n",
      "Epoch [2/20] Batch 430/938 Loss D: 0.0524, Loss G: 3.7437\n",
      "Epoch [2/20] Batch 440/938 Loss D: 0.1761, Loss G: 2.5492\n",
      "Epoch [2/20] Batch 450/938 Loss D: 0.0969, Loss G: 2.7890\n",
      "Epoch [2/20] Batch 460/938 Loss D: 0.0743, Loss G: 3.0219\n",
      "Epoch [2/20] Batch 470/938 Loss D: 0.1945, Loss G: 2.3268\n",
      "Epoch [2/20] Batch 480/938 Loss D: 0.1922, Loss G: 2.2992\n",
      "Epoch [2/20] Batch 490/938 Loss D: 0.0815, Loss G: 3.2130\n",
      "Epoch [2/20] Batch 500/938 Loss D: 0.0945, Loss G: 2.7483\n",
      "Epoch [2/20] Batch 510/938 Loss D: 0.2222, Loss G: 2.0617\n",
      "Epoch [2/20] Batch 520/938 Loss D: 0.1539, Loss G: 2.4802\n",
      "Epoch [2/20] Batch 530/938 Loss D: 0.1555, Loss G: 2.5485\n",
      "Epoch [2/20] Batch 540/938 Loss D: 0.1102, Loss G: 2.6409\n",
      "Epoch [2/20] Batch 550/938 Loss D: 0.1251, Loss G: 2.4509\n",
      "Epoch [2/20] Batch 560/938 Loss D: 0.2609, Loss G: 2.0208\n",
      "Epoch [2/20] Batch 570/938 Loss D: 0.1992, Loss G: 2.2055\n",
      "Epoch [2/20] Batch 580/938 Loss D: 0.1610, Loss G: 2.4334\n",
      "Epoch [2/20] Batch 590/938 Loss D: 0.0881, Loss G: 2.9160\n",
      "Epoch [2/20] Batch 600/938 Loss D: 0.1199, Loss G: 2.5976\n",
      "Epoch [2/20] Batch 610/938 Loss D: 0.2061, Loss G: 1.9831\n",
      "Epoch [2/20] Batch 620/938 Loss D: 0.1638, Loss G: 2.2653\n",
      "Epoch [2/20] Batch 630/938 Loss D: 0.1497, Loss G: 2.4005\n",
      "Epoch [2/20] Batch 640/938 Loss D: 0.2877, Loss G: 2.0127\n",
      "Epoch [2/20] Batch 650/938 Loss D: 0.1766, Loss G: 2.2894\n",
      "Epoch [2/20] Batch 660/938 Loss D: 0.1458, Loss G: 2.7882\n",
      "Epoch [2/20] Batch 670/938 Loss D: 0.2063, Loss G: 2.2906\n",
      "Epoch [2/20] Batch 680/938 Loss D: 0.2252, Loss G: 2.4402\n",
      "Epoch [2/20] Batch 690/938 Loss D: 0.2282, Loss G: 2.3908\n",
      "Epoch [2/20] Batch 700/938 Loss D: 0.1574, Loss G: 2.4270\n",
      "Epoch [2/20] Batch 710/938 Loss D: 0.2446, Loss G: 2.0436\n",
      "Epoch [2/20] Batch 720/938 Loss D: 0.2000, Loss G: 2.1049\n",
      "Epoch [2/20] Batch 730/938 Loss D: 0.1521, Loss G: 2.6019\n",
      "Epoch [2/20] Batch 740/938 Loss D: 0.2162, Loss G: 2.0595\n",
      "Epoch [2/20] Batch 750/938 Loss D: 0.2240, Loss G: 2.0995\n",
      "Epoch [2/20] Batch 760/938 Loss D: 0.2199, Loss G: 2.0629\n",
      "Epoch [2/20] Batch 770/938 Loss D: 0.1399, Loss G: 2.3370\n",
      "Epoch [2/20] Batch 780/938 Loss D: 0.1691, Loss G: 2.3521\n",
      "Epoch [2/20] Batch 790/938 Loss D: 0.2269, Loss G: 2.0476\n",
      "Epoch [2/20] Batch 800/938 Loss D: 0.2507, Loss G: 2.1543\n",
      "Epoch [2/20] Batch 810/938 Loss D: 0.2744, Loss G: 2.0772\n",
      "Epoch [2/20] Batch 820/938 Loss D: 0.2420, Loss G: 2.1135\n",
      "Epoch [2/20] Batch 830/938 Loss D: 0.2101, Loss G: 2.4097\n",
      "Epoch [2/20] Batch 840/938 Loss D: 0.2255, Loss G: 2.0616\n",
      "Epoch [2/20] Batch 850/938 Loss D: 0.1860, Loss G: 2.2698\n",
      "Epoch [2/20] Batch 860/938 Loss D: 0.1570, Loss G: 2.2471\n",
      "Epoch [2/20] Batch 870/938 Loss D: 0.3016, Loss G: 1.8210\n",
      "Epoch [2/20] Batch 880/938 Loss D: 0.3176, Loss G: 1.6476\n",
      "Epoch [2/20] Batch 890/938 Loss D: 0.2656, Loss G: 2.0323\n",
      "Epoch [2/20] Batch 900/938 Loss D: 0.1723, Loss G: 2.2559\n",
      "Epoch [2/20] Batch 910/938 Loss D: 0.2880, Loss G: 1.5517\n",
      "Epoch [2/20] Batch 920/938 Loss D: 0.2774, Loss G: 1.5183\n",
      "Epoch [2/20] Batch 930/938 Loss D: 0.1940, Loss G: 2.0407\n",
      "Epoch [3/20] Batch 0/938 Loss D: 0.2035, Loss G: 1.7694\n",
      "Epoch [3/20] Batch 10/938 Loss D: 0.2097, Loss G: 1.9583\n",
      "Epoch [3/20] Batch 20/938 Loss D: 0.1889, Loss G: 2.1291\n",
      "Epoch [3/20] Batch 30/938 Loss D: 0.3117, Loss G: 1.7592\n",
      "Epoch [3/20] Batch 40/938 Loss D: 0.2678, Loss G: 1.6460\n",
      "Epoch [3/20] Batch 50/938 Loss D: 0.2005, Loss G: 1.9294\n",
      "Epoch [3/20] Batch 60/938 Loss D: 0.2505, Loss G: 1.7485\n",
      "Epoch [3/20] Batch 70/938 Loss D: 0.1901, Loss G: 2.0185\n",
      "Epoch [3/20] Batch 80/938 Loss D: 0.3134, Loss G: 1.4959\n",
      "Epoch [3/20] Batch 90/938 Loss D: 0.2249, Loss G: 1.9283\n",
      "Epoch [3/20] Batch 100/938 Loss D: 0.2820, Loss G: 1.5325\n",
      "Epoch [3/20] Batch 110/938 Loss D: 0.1836, Loss G: 2.0590\n",
      "Epoch [3/20] Batch 120/938 Loss D: 0.1945, Loss G: 2.1069\n",
      "Epoch [3/20] Batch 130/938 Loss D: 0.2396, Loss G: 2.1027\n",
      "Epoch [3/20] Batch 140/938 Loss D: 0.4054, Loss G: 1.5872\n",
      "Epoch [3/20] Batch 150/938 Loss D: 0.2631, Loss G: 1.7110\n",
      "Epoch [3/20] Batch 160/938 Loss D: 0.2977, Loss G: 1.6032\n",
      "Epoch [3/20] Batch 170/938 Loss D: 0.2447, Loss G: 1.8243\n",
      "Epoch [3/20] Batch 180/938 Loss D: 0.2555, Loss G: 1.7935\n",
      "Epoch [3/20] Batch 190/938 Loss D: 0.2827, Loss G: 1.9915\n",
      "Epoch [3/20] Batch 200/938 Loss D: 0.2625, Loss G: 2.1029\n",
      "Epoch [3/20] Batch 210/938 Loss D: 0.2515, Loss G: 1.8217\n",
      "Epoch [3/20] Batch 220/938 Loss D: 0.2395, Loss G: 1.7921\n",
      "Epoch [3/20] Batch 230/938 Loss D: 0.3003, Loss G: 1.6107\n",
      "Epoch [3/20] Batch 240/938 Loss D: 0.2100, Loss G: 2.0989\n",
      "Epoch [3/20] Batch 250/938 Loss D: 0.2555, Loss G: 1.5572\n",
      "Epoch [3/20] Batch 260/938 Loss D: 0.2468, Loss G: 1.5988\n",
      "Epoch [3/20] Batch 270/938 Loss D: 0.2507, Loss G: 1.7780\n",
      "Epoch [3/20] Batch 280/938 Loss D: 0.2959, Loss G: 1.7024\n",
      "Epoch [3/20] Batch 290/938 Loss D: 0.1813, Loss G: 2.4347\n",
      "Epoch [3/20] Batch 300/938 Loss D: 0.2539, Loss G: 1.7847\n",
      "Epoch [3/20] Batch 310/938 Loss D: 0.3469, Loss G: 1.5569\n",
      "Epoch [3/20] Batch 320/938 Loss D: 0.2438, Loss G: 2.0180\n",
      "Epoch [3/20] Batch 330/938 Loss D: 0.3378, Loss G: 1.7386\n",
      "Epoch [3/20] Batch 340/938 Loss D: 0.3091, Loss G: 1.6196\n",
      "Epoch [3/20] Batch 350/938 Loss D: 0.2849, Loss G: 1.7721\n",
      "Epoch [3/20] Batch 360/938 Loss D: 0.2456, Loss G: 1.8033\n",
      "Epoch [3/20] Batch 370/938 Loss D: 0.3901, Loss G: 1.8030\n",
      "Epoch [3/20] Batch 380/938 Loss D: 0.2206, Loss G: 2.0397\n",
      "Epoch [3/20] Batch 390/938 Loss D: 0.2816, Loss G: 1.3971\n",
      "Epoch [3/20] Batch 400/938 Loss D: 0.2525, Loss G: 1.5685\n",
      "Epoch [3/20] Batch 410/938 Loss D: 0.2954, Loss G: 1.5824\n",
      "Epoch [3/20] Batch 420/938 Loss D: 0.3076, Loss G: 1.6934\n",
      "Epoch [3/20] Batch 430/938 Loss D: 0.2898, Loss G: 1.5810\n",
      "Epoch [3/20] Batch 440/938 Loss D: 0.2674, Loss G: 1.6710\n",
      "Epoch [3/20] Batch 450/938 Loss D: 0.2840, Loss G: 1.8321\n",
      "Epoch [3/20] Batch 460/938 Loss D: 0.2731, Loss G: 1.6367\n",
      "Epoch [3/20] Batch 470/938 Loss D: 0.2736, Loss G: 1.9222\n",
      "Epoch [3/20] Batch 480/938 Loss D: 0.2102, Loss G: 2.0030\n",
      "Epoch [3/20] Batch 490/938 Loss D: 0.2571, Loss G: 1.6573\n",
      "Epoch [3/20] Batch 500/938 Loss D: 0.2750, Loss G: 1.6459\n",
      "Epoch [3/20] Batch 510/938 Loss D: 0.3195, Loss G: 1.4449\n",
      "Epoch [3/20] Batch 520/938 Loss D: 0.2854, Loss G: 1.5936\n",
      "Epoch [3/20] Batch 530/938 Loss D: 0.2961, Loss G: 1.5992\n",
      "Epoch [3/20] Batch 540/938 Loss D: 0.2686, Loss G: 1.9839\n",
      "Epoch [3/20] Batch 550/938 Loss D: 0.2236, Loss G: 1.8562\n",
      "Epoch [3/20] Batch 560/938 Loss D: 0.2809, Loss G: 1.5540\n",
      "Epoch [3/20] Batch 570/938 Loss D: 0.3011, Loss G: 1.8887\n",
      "Epoch [3/20] Batch 580/938 Loss D: 0.4377, Loss G: 1.4960\n",
      "Epoch [3/20] Batch 590/938 Loss D: 0.2849, Loss G: 2.1050\n",
      "Epoch [3/20] Batch 600/938 Loss D: 0.2100, Loss G: 1.9810\n",
      "Epoch [3/20] Batch 610/938 Loss D: 0.2867, Loss G: 1.8641\n",
      "Epoch [3/20] Batch 620/938 Loss D: 0.1842, Loss G: 2.0649\n",
      "Epoch [3/20] Batch 630/938 Loss D: 0.2570, Loss G: 1.5597\n",
      "Epoch [3/20] Batch 640/938 Loss D: 0.2404, Loss G: 1.6500\n",
      "Epoch [3/20] Batch 650/938 Loss D: 0.2741, Loss G: 1.5288\n",
      "Epoch [3/20] Batch 660/938 Loss D: 0.3076, Loss G: 1.4380\n",
      "Epoch [3/20] Batch 670/938 Loss D: 0.2231, Loss G: 1.6339\n",
      "Epoch [3/20] Batch 680/938 Loss D: 0.2710, Loss G: 1.8925\n",
      "Epoch [3/20] Batch 690/938 Loss D: 0.2665, Loss G: 1.9026\n",
      "Epoch [3/20] Batch 700/938 Loss D: 0.3249, Loss G: 1.4317\n",
      "Epoch [3/20] Batch 710/938 Loss D: 0.2673, Loss G: 1.5212\n",
      "Epoch [3/20] Batch 720/938 Loss D: 0.2770, Loss G: 1.7719\n",
      "Epoch [3/20] Batch 730/938 Loss D: 0.2716, Loss G: 1.9504\n",
      "Epoch [3/20] Batch 740/938 Loss D: 0.2211, Loss G: 1.8269\n",
      "Epoch [3/20] Batch 750/938 Loss D: 0.2749, Loss G: 1.5241\n",
      "Epoch [3/20] Batch 760/938 Loss D: 0.2707, Loss G: 1.7552\n",
      "Epoch [3/20] Batch 770/938 Loss D: 0.3707, Loss G: 1.4814\n",
      "Epoch [3/20] Batch 780/938 Loss D: 0.2217, Loss G: 1.8890\n",
      "Epoch [3/20] Batch 790/938 Loss D: 0.2862, Loss G: 1.4341\n",
      "Epoch [3/20] Batch 800/938 Loss D: 0.2963, Loss G: 1.3768\n",
      "Epoch [3/20] Batch 810/938 Loss D: 0.2272, Loss G: 1.7103\n",
      "Epoch [3/20] Batch 820/938 Loss D: 0.3337, Loss G: 1.3314\n",
      "Epoch [3/20] Batch 830/938 Loss D: 0.1940, Loss G: 1.8985\n",
      "Epoch [3/20] Batch 840/938 Loss D: 0.3004, Loss G: 1.4913\n",
      "Epoch [3/20] Batch 850/938 Loss D: 0.3120, Loss G: 1.5583\n",
      "Epoch [3/20] Batch 860/938 Loss D: 0.3423, Loss G: 1.3652\n",
      "Epoch [3/20] Batch 870/938 Loss D: 0.3200, Loss G: 1.2363\n",
      "Epoch [3/20] Batch 880/938 Loss D: 0.2941, Loss G: 1.6294\n",
      "Epoch [3/20] Batch 890/938 Loss D: 0.4240, Loss G: 1.2607\n",
      "Epoch [3/20] Batch 900/938 Loss D: 0.2542, Loss G: 2.0689\n",
      "Epoch [3/20] Batch 910/938 Loss D: 0.2479, Loss G: 1.8087\n",
      "Epoch [3/20] Batch 920/938 Loss D: 0.3358, Loss G: 1.2981\n",
      "Epoch [3/20] Batch 930/938 Loss D: 0.2571, Loss G: 1.7210\n",
      "Epoch [4/20] Batch 0/938 Loss D: 0.4245, Loss G: 1.3149\n",
      "Epoch [4/20] Batch 10/938 Loss D: 0.3341, Loss G: 1.4483\n",
      "Epoch [4/20] Batch 20/938 Loss D: 0.3117, Loss G: 1.4938\n",
      "Epoch [4/20] Batch 30/938 Loss D: 0.3537, Loss G: 1.4981\n",
      "Epoch [4/20] Batch 40/938 Loss D: 0.3098, Loss G: 1.8079\n",
      "Epoch [4/20] Batch 50/938 Loss D: 0.3009, Loss G: 1.5046\n",
      "Epoch [4/20] Batch 60/938 Loss D: 0.1952, Loss G: 2.0643\n",
      "Epoch [4/20] Batch 70/938 Loss D: 0.4058, Loss G: 1.1313\n",
      "Epoch [4/20] Batch 80/938 Loss D: 0.3168, Loss G: 1.4889\n",
      "Epoch [4/20] Batch 90/938 Loss D: 0.3448, Loss G: 1.5475\n",
      "Epoch [4/20] Batch 100/938 Loss D: 0.3313, Loss G: 1.7323\n",
      "Epoch [4/20] Batch 110/938 Loss D: 0.2409, Loss G: 1.9200\n",
      "Epoch [4/20] Batch 120/938 Loss D: 0.3603, Loss G: 1.3206\n",
      "Epoch [4/20] Batch 130/938 Loss D: 0.3573, Loss G: 1.7912\n",
      "Epoch [4/20] Batch 140/938 Loss D: 0.3039, Loss G: 1.7949\n",
      "Epoch [4/20] Batch 150/938 Loss D: 0.3163, Loss G: 1.6213\n",
      "Epoch [4/20] Batch 160/938 Loss D: 0.2740, Loss G: 1.6387\n",
      "Epoch [4/20] Batch 170/938 Loss D: 0.3914, Loss G: 1.2367\n",
      "Epoch [4/20] Batch 180/938 Loss D: 0.2598, Loss G: 1.9055\n",
      "Epoch [4/20] Batch 190/938 Loss D: 0.3887, Loss G: 1.3098\n",
      "Epoch [4/20] Batch 200/938 Loss D: 0.2599, Loss G: 1.9511\n",
      "Epoch [4/20] Batch 210/938 Loss D: 0.2783, Loss G: 1.7701\n",
      "Epoch [4/20] Batch 220/938 Loss D: 0.3661, Loss G: 1.3259\n",
      "Epoch [4/20] Batch 230/938 Loss D: 0.2188, Loss G: 1.5987\n",
      "Epoch [4/20] Batch 240/938 Loss D: 0.3834, Loss G: 1.1292\n",
      "Epoch [4/20] Batch 250/938 Loss D: 0.2503, Loss G: 1.7642\n",
      "Epoch [4/20] Batch 260/938 Loss D: 0.2791, Loss G: 1.5156\n",
      "Epoch [4/20] Batch 270/938 Loss D: 0.3244, Loss G: 1.5723\n",
      "Epoch [4/20] Batch 280/938 Loss D: 0.2524, Loss G: 1.8812\n",
      "Epoch [4/20] Batch 290/938 Loss D: 0.2759, Loss G: 1.6673\n",
      "Epoch [4/20] Batch 300/938 Loss D: 0.2965, Loss G: 1.7928\n",
      "Epoch [4/20] Batch 310/938 Loss D: 0.3898, Loss G: 1.3857\n",
      "Epoch [4/20] Batch 320/938 Loss D: 0.3151, Loss G: 1.5556\n",
      "Epoch [4/20] Batch 330/938 Loss D: 0.2907, Loss G: 1.5949\n",
      "Epoch [4/20] Batch 340/938 Loss D: 0.2975, Loss G: 1.3241\n",
      "Epoch [4/20] Batch 350/938 Loss D: 0.2834, Loss G: 1.4533\n",
      "Epoch [4/20] Batch 360/938 Loss D: 0.3183, Loss G: 1.6505\n",
      "Epoch [4/20] Batch 370/938 Loss D: 0.3027, Loss G: 1.7159\n",
      "Epoch [4/20] Batch 380/938 Loss D: 0.2812, Loss G: 1.4534\n",
      "Epoch [4/20] Batch 390/938 Loss D: 0.3036, Loss G: 1.5380\n",
      "Epoch [4/20] Batch 400/938 Loss D: 0.2718, Loss G: 1.8791\n",
      "Epoch [4/20] Batch 410/938 Loss D: 0.2771, Loss G: 1.7493\n",
      "Epoch [4/20] Batch 420/938 Loss D: 0.3065, Loss G: 1.4340\n",
      "Epoch [4/20] Batch 430/938 Loss D: 0.2526, Loss G: 1.5804\n",
      "Epoch [4/20] Batch 440/938 Loss D: 0.3788, Loss G: 1.3497\n",
      "Epoch [4/20] Batch 450/938 Loss D: 0.3171, Loss G: 1.6204\n",
      "Epoch [4/20] Batch 460/938 Loss D: 0.3152, Loss G: 1.4219\n",
      "Epoch [4/20] Batch 470/938 Loss D: 0.3997, Loss G: 1.1405\n",
      "Epoch [4/20] Batch 480/938 Loss D: 0.2341, Loss G: 1.7243\n",
      "Epoch [4/20] Batch 490/938 Loss D: 0.3119, Loss G: 1.4166\n",
      "Epoch [4/20] Batch 500/938 Loss D: 0.3321, Loss G: 1.5989\n",
      "Epoch [4/20] Batch 510/938 Loss D: 0.3009, Loss G: 1.3336\n",
      "Epoch [4/20] Batch 520/938 Loss D: 0.2506, Loss G: 1.3838\n",
      "Epoch [4/20] Batch 530/938 Loss D: 0.2507, Loss G: 1.6197\n",
      "Epoch [4/20] Batch 540/938 Loss D: 0.4469, Loss G: 1.0417\n",
      "Epoch [4/20] Batch 550/938 Loss D: 0.2184, Loss G: 1.9825\n",
      "Epoch [4/20] Batch 560/938 Loss D: 0.3797, Loss G: 1.1072\n",
      "Epoch [4/20] Batch 570/938 Loss D: 0.3509, Loss G: 1.3633\n",
      "Epoch [4/20] Batch 580/938 Loss D: 0.2751, Loss G: 1.6100\n",
      "Epoch [4/20] Batch 590/938 Loss D: 0.3070, Loss G: 1.3861\n",
      "Epoch [4/20] Batch 600/938 Loss D: 0.2817, Loss G: 1.4644\n",
      "Epoch [4/20] Batch 610/938 Loss D: 0.3297, Loss G: 1.3329\n",
      "Epoch [4/20] Batch 620/938 Loss D: 0.3153, Loss G: 1.5738\n",
      "Epoch [4/20] Batch 630/938 Loss D: 0.2969, Loss G: 2.0676\n",
      "Epoch [4/20] Batch 640/938 Loss D: 0.2871, Loss G: 1.4483\n",
      "Epoch [4/20] Batch 650/938 Loss D: 0.3440, Loss G: 1.3285\n",
      "Epoch [4/20] Batch 660/938 Loss D: 0.3603, Loss G: 1.4422\n",
      "Epoch [4/20] Batch 670/938 Loss D: 0.3254, Loss G: 1.4141\n",
      "Epoch [4/20] Batch 680/938 Loss D: 0.3396, Loss G: 1.4979\n",
      "Epoch [4/20] Batch 690/938 Loss D: 0.3736, Loss G: 1.0815\n",
      "Epoch [4/20] Batch 700/938 Loss D: 0.3397, Loss G: 1.3847\n",
      "Epoch [4/20] Batch 710/938 Loss D: 0.2508, Loss G: 1.8091\n",
      "Epoch [4/20] Batch 720/938 Loss D: 0.3128, Loss G: 1.4592\n",
      "Epoch [4/20] Batch 730/938 Loss D: 0.2918, Loss G: 1.4781\n",
      "Epoch [4/20] Batch 740/938 Loss D: 0.3274, Loss G: 1.4847\n",
      "Epoch [4/20] Batch 750/938 Loss D: 0.2944, Loss G: 1.4019\n",
      "Epoch [4/20] Batch 760/938 Loss D: 0.3236, Loss G: 1.6170\n",
      "Epoch [4/20] Batch 770/938 Loss D: 0.5220, Loss G: 1.2775\n",
      "Epoch [4/20] Batch 780/938 Loss D: 0.2734, Loss G: 1.5104\n",
      "Epoch [4/20] Batch 790/938 Loss D: 0.3424, Loss G: 1.7255\n",
      "Epoch [4/20] Batch 800/938 Loss D: 0.3792, Loss G: 1.3454\n",
      "Epoch [4/20] Batch 810/938 Loss D: 0.3591, Loss G: 1.3539\n",
      "Epoch [4/20] Batch 820/938 Loss D: 0.3490, Loss G: 1.4232\n",
      "Epoch [4/20] Batch 830/938 Loss D: 0.3490, Loss G: 1.4251\n",
      "Epoch [4/20] Batch 840/938 Loss D: 0.3296, Loss G: 1.5565\n",
      "Epoch [4/20] Batch 850/938 Loss D: 0.4241, Loss G: 1.2359\n",
      "Epoch [4/20] Batch 860/938 Loss D: 0.3846, Loss G: 1.4512\n",
      "Epoch [4/20] Batch 870/938 Loss D: 0.2508, Loss G: 1.6551\n",
      "Epoch [4/20] Batch 880/938 Loss D: 0.4060, Loss G: 1.2714\n",
      "Epoch [4/20] Batch 890/938 Loss D: 0.2953, Loss G: 1.6491\n",
      "Epoch [4/20] Batch 900/938 Loss D: 0.2453, Loss G: 1.7933\n",
      "Epoch [4/20] Batch 910/938 Loss D: 0.3586, Loss G: 1.2431\n",
      "Epoch [4/20] Batch 920/938 Loss D: 0.3146, Loss G: 1.4995\n",
      "Epoch [4/20] Batch 930/938 Loss D: 0.2956, Loss G: 1.6711\n",
      "Epoch [5/20] Batch 0/938 Loss D: 0.3880, Loss G: 1.2861\n",
      "Epoch [5/20] Batch 10/938 Loss D: 0.3183, Loss G: 1.3206\n",
      "Epoch [5/20] Batch 20/938 Loss D: 0.3412, Loss G: 1.1834\n",
      "Epoch [5/20] Batch 30/938 Loss D: 0.3375, Loss G: 1.6816\n",
      "Epoch [5/20] Batch 40/938 Loss D: 0.3326, Loss G: 1.5198\n",
      "Epoch [5/20] Batch 50/938 Loss D: 0.4713, Loss G: 1.1866\n",
      "Epoch [5/20] Batch 60/938 Loss D: 0.3562, Loss G: 1.6645\n",
      "Epoch [5/20] Batch 70/938 Loss D: 0.4075, Loss G: 1.1949\n",
      "Epoch [5/20] Batch 80/938 Loss D: 0.3069, Loss G: 1.5649\n",
      "Epoch [5/20] Batch 90/938 Loss D: 0.3908, Loss G: 1.3877\n",
      "Epoch [5/20] Batch 100/938 Loss D: 0.4126, Loss G: 1.3512\n",
      "Epoch [5/20] Batch 110/938 Loss D: 0.3635, Loss G: 1.5702\n",
      "Epoch [5/20] Batch 120/938 Loss D: 0.4267, Loss G: 1.3831\n",
      "Epoch [5/20] Batch 130/938 Loss D: 0.4039, Loss G: 1.3877\n",
      "Epoch [5/20] Batch 140/938 Loss D: 0.2991, Loss G: 1.6124\n",
      "Epoch [5/20] Batch 150/938 Loss D: 0.4329, Loss G: 1.2480\n",
      "Epoch [5/20] Batch 160/938 Loss D: 0.3372, Loss G: 1.3292\n",
      "Epoch [5/20] Batch 170/938 Loss D: 0.3648, Loss G: 1.4088\n",
      "Epoch [5/20] Batch 180/938 Loss D: 0.3876, Loss G: 1.2852\n",
      "Epoch [5/20] Batch 190/938 Loss D: 0.3641, Loss G: 1.4883\n",
      "Epoch [5/20] Batch 200/938 Loss D: 0.3204, Loss G: 1.4588\n",
      "Epoch [5/20] Batch 210/938 Loss D: 0.4262, Loss G: 1.1978\n",
      "Epoch [5/20] Batch 220/938 Loss D: 0.2874, Loss G: 1.3999\n",
      "Epoch [5/20] Batch 230/938 Loss D: 0.3557, Loss G: 1.3949\n",
      "Epoch [5/20] Batch 240/938 Loss D: 0.4120, Loss G: 1.4197\n",
      "Epoch [5/20] Batch 250/938 Loss D: 0.2749, Loss G: 1.6067\n",
      "Epoch [5/20] Batch 260/938 Loss D: 0.4240, Loss G: 1.0467\n",
      "Epoch [5/20] Batch 270/938 Loss D: 0.2999, Loss G: 1.4368\n",
      "Epoch [5/20] Batch 280/938 Loss D: 0.4675, Loss G: 1.1528\n",
      "Epoch [5/20] Batch 290/938 Loss D: 0.4311, Loss G: 1.5139\n",
      "Epoch [5/20] Batch 300/938 Loss D: 0.3243, Loss G: 1.7501\n",
      "Epoch [5/20] Batch 310/938 Loss D: 0.3083, Loss G: 1.5936\n",
      "Epoch [5/20] Batch 320/938 Loss D: 0.4049, Loss G: 1.3539\n",
      "Epoch [5/20] Batch 330/938 Loss D: 0.3659, Loss G: 1.6003\n",
      "Epoch [5/20] Batch 340/938 Loss D: 0.3778, Loss G: 1.5766\n",
      "Epoch [5/20] Batch 350/938 Loss D: 0.4615, Loss G: 1.4274\n",
      "Epoch [5/20] Batch 360/938 Loss D: 0.3113, Loss G: 1.6856\n",
      "Epoch [5/20] Batch 370/938 Loss D: 0.3304, Loss G: 1.6824\n",
      "Epoch [5/20] Batch 380/938 Loss D: 0.2981, Loss G: 1.7074\n",
      "Epoch [5/20] Batch 390/938 Loss D: 0.2987, Loss G: 1.4183\n",
      "Epoch [5/20] Batch 400/938 Loss D: 0.3808, Loss G: 1.3005\n",
      "Epoch [5/20] Batch 410/938 Loss D: 0.3492, Loss G: 1.5368\n",
      "Epoch [5/20] Batch 420/938 Loss D: 0.4003, Loss G: 1.4889\n",
      "Epoch [5/20] Batch 430/938 Loss D: 0.4356, Loss G: 1.4747\n",
      "Epoch [5/20] Batch 440/938 Loss D: 0.3058, Loss G: 1.7601\n",
      "Epoch [5/20] Batch 450/938 Loss D: 0.4793, Loss G: 1.2849\n",
      "Epoch [5/20] Batch 460/938 Loss D: 0.4499, Loss G: 1.4156\n",
      "Epoch [5/20] Batch 470/938 Loss D: 0.3053, Loss G: 1.4848\n",
      "Epoch [5/20] Batch 480/938 Loss D: 0.3395, Loss G: 1.5062\n",
      "Epoch [5/20] Batch 490/938 Loss D: 0.4201, Loss G: 1.3400\n",
      "Epoch [5/20] Batch 500/938 Loss D: 0.4141, Loss G: 1.2150\n",
      "Epoch [5/20] Batch 510/938 Loss D: 0.4639, Loss G: 1.0625\n",
      "Epoch [5/20] Batch 520/938 Loss D: 0.3536, Loss G: 1.6510\n",
      "Epoch [5/20] Batch 530/938 Loss D: 0.3348, Loss G: 1.7581\n",
      "Epoch [5/20] Batch 540/938 Loss D: 0.3786, Loss G: 1.4263\n",
      "Epoch [5/20] Batch 550/938 Loss D: 0.3787, Loss G: 1.8001\n",
      "Epoch [5/20] Batch 560/938 Loss D: 0.3617, Loss G: 1.5286\n",
      "Epoch [5/20] Batch 570/938 Loss D: 0.3850, Loss G: 1.3331\n",
      "Epoch [5/20] Batch 580/938 Loss D: 0.3601, Loss G: 1.4885\n",
      "Epoch [5/20] Batch 590/938 Loss D: 0.3958, Loss G: 1.3122\n",
      "Epoch [5/20] Batch 600/938 Loss D: 0.4647, Loss G: 1.3646\n",
      "Epoch [5/20] Batch 610/938 Loss D: 0.3845, Loss G: 1.6868\n",
      "Epoch [5/20] Batch 620/938 Loss D: 0.3627, Loss G: 1.5401\n",
      "Epoch [5/20] Batch 630/938 Loss D: 0.4626, Loss G: 1.2891\n",
      "Epoch [5/20] Batch 640/938 Loss D: 0.4864, Loss G: 1.6781\n",
      "Epoch [5/20] Batch 650/938 Loss D: 0.4562, Loss G: 1.3445\n",
      "Epoch [5/20] Batch 660/938 Loss D: 0.3691, Loss G: 1.5345\n",
      "Epoch [5/20] Batch 670/938 Loss D: 0.2894, Loss G: 1.6543\n",
      "Epoch [5/20] Batch 680/938 Loss D: 0.5027, Loss G: 1.1722\n",
      "Epoch [5/20] Batch 690/938 Loss D: 0.3579, Loss G: 1.8523\n",
      "Epoch [5/20] Batch 700/938 Loss D: 0.4182, Loss G: 1.4881\n",
      "Epoch [5/20] Batch 710/938 Loss D: 0.5136, Loss G: 1.1701\n",
      "Epoch [5/20] Batch 720/938 Loss D: 0.3760, Loss G: 1.3553\n",
      "Epoch [5/20] Batch 730/938 Loss D: 0.3260, Loss G: 1.6060\n",
      "Epoch [5/20] Batch 740/938 Loss D: 0.3975, Loss G: 1.2739\n",
      "Epoch [5/20] Batch 750/938 Loss D: 0.3201, Loss G: 1.5397\n",
      "Epoch [5/20] Batch 760/938 Loss D: 0.3505, Loss G: 1.5827\n",
      "Epoch [5/20] Batch 770/938 Loss D: 0.4650, Loss G: 1.4085\n",
      "Epoch [5/20] Batch 780/938 Loss D: 0.3776, Loss G: 1.3486\n",
      "Epoch [5/20] Batch 790/938 Loss D: 0.3149, Loss G: 1.5201\n",
      "Epoch [5/20] Batch 800/938 Loss D: 0.3604, Loss G: 1.4475\n",
      "Epoch [5/20] Batch 810/938 Loss D: 0.3520, Loss G: 1.6053\n",
      "Epoch [5/20] Batch 820/938 Loss D: 0.4175, Loss G: 1.7142\n",
      "Epoch [5/20] Batch 830/938 Loss D: 0.3983, Loss G: 1.4211\n",
      "Epoch [5/20] Batch 840/938 Loss D: 0.4272, Loss G: 1.4402\n",
      "Epoch [5/20] Batch 850/938 Loss D: 0.3045, Loss G: 1.6257\n",
      "Epoch [5/20] Batch 860/938 Loss D: 0.3293, Loss G: 1.5748\n",
      "Epoch [5/20] Batch 870/938 Loss D: 0.3690, Loss G: 1.5364\n",
      "Epoch [5/20] Batch 880/938 Loss D: 0.3311, Loss G: 1.6582\n",
      "Epoch [5/20] Batch 890/938 Loss D: 0.4398, Loss G: 1.3757\n",
      "Epoch [5/20] Batch 900/938 Loss D: 0.4513, Loss G: 1.2229\n",
      "Epoch [5/20] Batch 910/938 Loss D: 0.4097, Loss G: 1.3505\n",
      "Epoch [5/20] Batch 920/938 Loss D: 0.4269, Loss G: 1.2915\n",
      "Epoch [5/20] Batch 930/938 Loss D: 0.2880, Loss G: 1.7870\n",
      "Epoch [6/20] Batch 0/938 Loss D: 0.3749, Loss G: 1.3231\n",
      "Epoch [6/20] Batch 10/938 Loss D: 0.3428, Loss G: 1.5966\n",
      "Epoch [6/20] Batch 20/938 Loss D: 0.5467, Loss G: 1.3140\n",
      "Epoch [6/20] Batch 30/938 Loss D: 0.4135, Loss G: 1.2989\n",
      "Epoch [6/20] Batch 40/938 Loss D: 0.3054, Loss G: 1.6221\n",
      "Epoch [6/20] Batch 50/938 Loss D: 0.3068, Loss G: 1.4900\n",
      "Epoch [6/20] Batch 60/938 Loss D: 0.4721, Loss G: 1.2016\n",
      "Epoch [6/20] Batch 70/938 Loss D: 0.5012, Loss G: 1.1758\n",
      "Epoch [6/20] Batch 80/938 Loss D: 0.4813, Loss G: 1.3129\n",
      "Epoch [6/20] Batch 90/938 Loss D: 0.2923, Loss G: 1.6327\n",
      "Epoch [6/20] Batch 100/938 Loss D: 0.3030, Loss G: 1.9317\n",
      "Epoch [6/20] Batch 110/938 Loss D: 0.3206, Loss G: 1.6767\n",
      "Epoch [6/20] Batch 120/938 Loss D: 0.4607, Loss G: 1.2092\n",
      "Epoch [6/20] Batch 130/938 Loss D: 0.5234, Loss G: 1.3864\n",
      "Epoch [6/20] Batch 140/938 Loss D: 0.4166, Loss G: 1.3829\n",
      "Epoch [6/20] Batch 150/938 Loss D: 0.4011, Loss G: 1.4874\n",
      "Epoch [6/20] Batch 160/938 Loss D: 0.4323, Loss G: 1.3767\n",
      "Epoch [6/20] Batch 170/938 Loss D: 0.3630, Loss G: 1.4502\n",
      "Epoch [6/20] Batch 180/938 Loss D: 0.4494, Loss G: 1.1648\n",
      "Epoch [6/20] Batch 190/938 Loss D: 0.3324, Loss G: 1.4883\n",
      "Epoch [6/20] Batch 200/938 Loss D: 0.3136, Loss G: 1.4827\n",
      "Epoch [6/20] Batch 210/938 Loss D: 0.4582, Loss G: 1.2380\n",
      "Epoch [6/20] Batch 220/938 Loss D: 0.4630, Loss G: 1.3147\n",
      "Epoch [6/20] Batch 230/938 Loss D: 0.5116, Loss G: 1.2939\n",
      "Epoch [6/20] Batch 240/938 Loss D: 0.3692, Loss G: 1.4583\n",
      "Epoch [6/20] Batch 250/938 Loss D: 0.3964, Loss G: 1.3819\n",
      "Epoch [6/20] Batch 260/938 Loss D: 0.4505, Loss G: 1.3358\n",
      "Epoch [6/20] Batch 270/938 Loss D: 0.3712, Loss G: 1.5327\n",
      "Epoch [6/20] Batch 280/938 Loss D: 0.4608, Loss G: 1.2948\n",
      "Epoch [6/20] Batch 290/938 Loss D: 0.3596, Loss G: 1.3072\n",
      "Epoch [6/20] Batch 300/938 Loss D: 0.3846, Loss G: 1.3617\n",
      "Epoch [6/20] Batch 310/938 Loss D: 0.3874, Loss G: 1.3245\n",
      "Epoch [6/20] Batch 320/938 Loss D: 0.5700, Loss G: 1.1001\n",
      "Epoch [6/20] Batch 330/938 Loss D: 0.5130, Loss G: 1.4718\n",
      "Epoch [6/20] Batch 340/938 Loss D: 0.3852, Loss G: 1.4596\n",
      "Epoch [6/20] Batch 350/938 Loss D: 0.3480, Loss G: 1.4155\n",
      "Epoch [6/20] Batch 360/938 Loss D: 0.4666, Loss G: 1.3064\n",
      "Epoch [6/20] Batch 370/938 Loss D: 0.4115, Loss G: 1.2364\n",
      "Epoch [6/20] Batch 380/938 Loss D: 0.3603, Loss G: 1.4300\n",
      "Epoch [6/20] Batch 390/938 Loss D: 0.3699, Loss G: 1.4048\n",
      "Epoch [6/20] Batch 400/938 Loss D: 0.4501, Loss G: 1.2238\n",
      "Epoch [6/20] Batch 410/938 Loss D: 0.4596, Loss G: 1.0390\n",
      "Epoch [6/20] Batch 420/938 Loss D: 0.4167, Loss G: 1.2978\n",
      "Epoch [6/20] Batch 430/938 Loss D: 0.4668, Loss G: 1.4172\n",
      "Epoch [6/20] Batch 440/938 Loss D: 0.4002, Loss G: 1.4105\n",
      "Epoch [6/20] Batch 450/938 Loss D: 0.3485, Loss G: 1.4445\n",
      "Epoch [6/20] Batch 460/938 Loss D: 0.3148, Loss G: 1.5085\n",
      "Epoch [6/20] Batch 470/938 Loss D: 0.3987, Loss G: 1.3767\n",
      "Epoch [6/20] Batch 480/938 Loss D: 0.4523, Loss G: 1.2010\n",
      "Epoch [6/20] Batch 490/938 Loss D: 0.4039, Loss G: 1.4829\n",
      "Epoch [6/20] Batch 500/938 Loss D: 0.4720, Loss G: 1.5012\n",
      "Epoch [6/20] Batch 510/938 Loss D: 0.3860, Loss G: 1.4624\n",
      "Epoch [6/20] Batch 520/938 Loss D: 0.4462, Loss G: 1.2142\n",
      "Epoch [6/20] Batch 530/938 Loss D: 0.4484, Loss G: 1.3272\n",
      "Epoch [6/20] Batch 540/938 Loss D: 0.4516, Loss G: 1.2547\n",
      "Epoch [6/20] Batch 550/938 Loss D: 0.3490, Loss G: 1.3714\n",
      "Epoch [6/20] Batch 560/938 Loss D: 0.3713, Loss G: 1.4556\n",
      "Epoch [6/20] Batch 570/938 Loss D: 0.3778, Loss G: 1.3542\n",
      "Epoch [6/20] Batch 580/938 Loss D: 0.3470, Loss G: 1.4667\n",
      "Epoch [6/20] Batch 590/938 Loss D: 0.3462, Loss G: 1.5549\n",
      "Epoch [6/20] Batch 600/938 Loss D: 0.3880, Loss G: 1.2396\n",
      "Epoch [6/20] Batch 610/938 Loss D: 0.4582, Loss G: 1.3907\n",
      "Epoch [6/20] Batch 620/938 Loss D: 0.4806, Loss G: 1.2351\n",
      "Epoch [6/20] Batch 630/938 Loss D: 0.3773, Loss G: 1.1431\n",
      "Epoch [6/20] Batch 640/938 Loss D: 0.3412, Loss G: 1.5759\n",
      "Epoch [6/20] Batch 650/938 Loss D: 0.3362, Loss G: 1.5447\n",
      "Epoch [6/20] Batch 660/938 Loss D: 0.4708, Loss G: 1.1925\n",
      "Epoch [6/20] Batch 670/938 Loss D: 0.3816, Loss G: 1.5505\n",
      "Epoch [6/20] Batch 680/938 Loss D: 0.3946, Loss G: 1.6023\n",
      "Epoch [6/20] Batch 690/938 Loss D: 0.3923, Loss G: 1.2688\n",
      "Epoch [6/20] Batch 700/938 Loss D: 0.4219, Loss G: 1.2719\n",
      "Epoch [6/20] Batch 710/938 Loss D: 0.4483, Loss G: 1.3451\n",
      "Epoch [6/20] Batch 720/938 Loss D: 0.3419, Loss G: 1.6503\n",
      "Epoch [6/20] Batch 730/938 Loss D: 0.3416, Loss G: 1.4217\n",
      "Epoch [6/20] Batch 740/938 Loss D: 0.4031, Loss G: 1.2767\n",
      "Epoch [6/20] Batch 750/938 Loss D: 0.3829, Loss G: 1.3181\n",
      "Epoch [6/20] Batch 760/938 Loss D: 0.4311, Loss G: 1.2095\n",
      "Epoch [6/20] Batch 770/938 Loss D: 0.4001, Loss G: 1.4440\n",
      "Epoch [6/20] Batch 780/938 Loss D: 0.3350, Loss G: 1.4930\n",
      "Epoch [6/20] Batch 790/938 Loss D: 0.3478, Loss G: 1.4428\n",
      "Epoch [6/20] Batch 800/938 Loss D: 0.3805, Loss G: 1.2573\n",
      "Epoch [6/20] Batch 810/938 Loss D: 0.4186, Loss G: 1.4164\n",
      "Epoch [6/20] Batch 820/938 Loss D: 0.3718, Loss G: 1.4552\n",
      "Epoch [6/20] Batch 830/938 Loss D: 0.3712, Loss G: 1.2511\n",
      "Epoch [6/20] Batch 840/938 Loss D: 0.3702, Loss G: 1.2525\n",
      "Epoch [6/20] Batch 850/938 Loss D: 0.4600, Loss G: 1.2685\n",
      "Epoch [6/20] Batch 860/938 Loss D: 0.4485, Loss G: 1.2782\n",
      "Epoch [6/20] Batch 870/938 Loss D: 0.4322, Loss G: 1.2514\n",
      "Epoch [6/20] Batch 880/938 Loss D: 0.3895, Loss G: 1.4956\n",
      "Epoch [6/20] Batch 890/938 Loss D: 0.4215, Loss G: 1.5854\n",
      "Epoch [6/20] Batch 900/938 Loss D: 0.3742, Loss G: 1.3282\n",
      "Epoch [6/20] Batch 910/938 Loss D: 0.3999, Loss G: 1.2312\n",
      "Epoch [6/20] Batch 920/938 Loss D: 0.3380, Loss G: 1.5320\n",
      "Epoch [6/20] Batch 930/938 Loss D: 0.3594, Loss G: 1.4455\n",
      "Epoch [7/20] Batch 0/938 Loss D: 0.3617, Loss G: 1.4414\n",
      "Epoch [7/20] Batch 10/938 Loss D: 0.4360, Loss G: 1.3305\n",
      "Epoch [7/20] Batch 20/938 Loss D: 0.4143, Loss G: 1.2542\n",
      "Epoch [7/20] Batch 30/938 Loss D: 0.3744, Loss G: 1.2184\n",
      "Epoch [7/20] Batch 40/938 Loss D: 0.3665, Loss G: 1.6302\n",
      "Epoch [7/20] Batch 50/938 Loss D: 0.3407, Loss G: 1.4461\n",
      "Epoch [7/20] Batch 60/938 Loss D: 0.3516, Loss G: 1.4074\n",
      "Epoch [7/20] Batch 70/938 Loss D: 0.3504, Loss G: 1.3811\n",
      "Epoch [7/20] Batch 80/938 Loss D: 0.4290, Loss G: 1.2188\n",
      "Epoch [7/20] Batch 90/938 Loss D: 0.4109, Loss G: 1.4158\n",
      "Epoch [7/20] Batch 100/938 Loss D: 0.4013, Loss G: 1.3007\n",
      "Epoch [7/20] Batch 110/938 Loss D: 0.3931, Loss G: 1.2245\n",
      "Epoch [7/20] Batch 120/938 Loss D: 0.3276, Loss G: 1.6865\n",
      "Epoch [7/20] Batch 130/938 Loss D: 0.3677, Loss G: 1.4533\n",
      "Epoch [7/20] Batch 140/938 Loss D: 0.3730, Loss G: 1.3333\n",
      "Epoch [7/20] Batch 150/938 Loss D: 0.4131, Loss G: 1.3735\n",
      "Epoch [7/20] Batch 160/938 Loss D: 0.3756, Loss G: 1.3102\n",
      "Epoch [7/20] Batch 170/938 Loss D: 0.3649, Loss G: 1.3519\n",
      "Epoch [7/20] Batch 180/938 Loss D: 0.4106, Loss G: 1.4186\n",
      "Epoch [7/20] Batch 190/938 Loss D: 0.4290, Loss G: 1.3038\n",
      "Epoch [7/20] Batch 200/938 Loss D: 0.4092, Loss G: 1.4355\n",
      "Epoch [7/20] Batch 210/938 Loss D: 0.4469, Loss G: 1.2283\n",
      "Epoch [7/20] Batch 220/938 Loss D: 0.3417, Loss G: 1.3189\n",
      "Epoch [7/20] Batch 230/938 Loss D: 0.2963, Loss G: 1.5563\n",
      "Epoch [7/20] Batch 240/938 Loss D: 0.3673, Loss G: 1.4075\n",
      "Epoch [7/20] Batch 250/938 Loss D: 0.3641, Loss G: 1.2736\n",
      "Epoch [7/20] Batch 260/938 Loss D: 0.3993, Loss G: 1.2871\n",
      "Epoch [7/20] Batch 270/938 Loss D: 0.3912, Loss G: 1.5010\n",
      "Epoch [7/20] Batch 280/938 Loss D: 0.4487, Loss G: 1.1630\n",
      "Epoch [7/20] Batch 290/938 Loss D: 0.4055, Loss G: 1.3000\n",
      "Epoch [7/20] Batch 300/938 Loss D: 0.3771, Loss G: 1.3946\n",
      "Epoch [7/20] Batch 310/938 Loss D: 0.3921, Loss G: 1.4198\n",
      "Epoch [7/20] Batch 320/938 Loss D: 0.3500, Loss G: 1.3253\n",
      "Epoch [7/20] Batch 330/938 Loss D: 0.3442, Loss G: 1.3510\n",
      "Epoch [7/20] Batch 340/938 Loss D: 0.3606, Loss G: 1.5032\n",
      "Epoch [7/20] Batch 350/938 Loss D: 0.3880, Loss G: 1.2954\n",
      "Epoch [7/20] Batch 360/938 Loss D: 0.3734, Loss G: 1.5657\n",
      "Epoch [7/20] Batch 370/938 Loss D: 0.4069, Loss G: 1.3585\n",
      "Epoch [7/20] Batch 380/938 Loss D: 0.3265, Loss G: 1.5015\n",
      "Epoch [7/20] Batch 390/938 Loss D: 0.4202, Loss G: 1.2977\n",
      "Epoch [7/20] Batch 400/938 Loss D: 0.3581, Loss G: 1.3736\n",
      "Epoch [7/20] Batch 410/938 Loss D: 0.4755, Loss G: 1.2436\n",
      "Epoch [7/20] Batch 420/938 Loss D: 0.4199, Loss G: 1.5534\n",
      "Epoch [7/20] Batch 430/938 Loss D: 0.3312, Loss G: 1.4574\n",
      "Epoch [7/20] Batch 440/938 Loss D: 0.3786, Loss G: 1.2700\n",
      "Epoch [7/20] Batch 450/938 Loss D: 0.3730, Loss G: 1.4633\n",
      "Epoch [7/20] Batch 460/938 Loss D: 0.3782, Loss G: 1.3043\n",
      "Epoch [7/20] Batch 470/938 Loss D: 0.3483, Loss G: 1.3148\n",
      "Epoch [7/20] Batch 480/938 Loss D: 0.4179, Loss G: 1.4705\n",
      "Epoch [7/20] Batch 490/938 Loss D: 0.3389, Loss G: 1.5331\n",
      "Epoch [7/20] Batch 500/938 Loss D: 0.3704, Loss G: 1.5159\n",
      "Epoch [7/20] Batch 510/938 Loss D: 0.3600, Loss G: 1.3461\n",
      "Epoch [7/20] Batch 520/938 Loss D: 0.3526, Loss G: 1.3344\n",
      "Epoch [7/20] Batch 530/938 Loss D: 0.4507, Loss G: 1.2875\n",
      "Epoch [7/20] Batch 540/938 Loss D: 0.3973, Loss G: 1.4888\n",
      "Epoch [7/20] Batch 550/938 Loss D: 0.3493, Loss G: 1.4414\n",
      "Epoch [7/20] Batch 560/938 Loss D: 0.3279, Loss G: 1.5259\n",
      "Epoch [7/20] Batch 570/938 Loss D: 0.3780, Loss G: 1.3256\n",
      "Epoch [7/20] Batch 580/938 Loss D: 0.3712, Loss G: 1.4005\n",
      "Epoch [7/20] Batch 590/938 Loss D: 0.3599, Loss G: 1.3991\n",
      "Epoch [7/20] Batch 600/938 Loss D: 0.3579, Loss G: 1.4425\n",
      "Epoch [7/20] Batch 610/938 Loss D: 0.4000, Loss G: 1.2966\n",
      "Epoch [7/20] Batch 620/938 Loss D: 0.3865, Loss G: 1.3440\n",
      "Epoch [7/20] Batch 630/938 Loss D: 0.3675, Loss G: 1.3635\n",
      "Epoch [7/20] Batch 640/938 Loss D: 0.3627, Loss G: 1.4306\n",
      "Epoch [7/20] Batch 650/938 Loss D: 0.2898, Loss G: 1.7954\n",
      "Epoch [7/20] Batch 660/938 Loss D: 0.4034, Loss G: 1.3214\n",
      "Epoch [7/20] Batch 670/938 Loss D: 0.3284, Loss G: 1.5065\n",
      "Epoch [7/20] Batch 680/938 Loss D: 0.4138, Loss G: 1.3478\n",
      "Epoch [7/20] Batch 690/938 Loss D: 0.3393, Loss G: 1.4853\n",
      "Epoch [7/20] Batch 700/938 Loss D: 0.3945, Loss G: 1.4012\n",
      "Epoch [7/20] Batch 710/938 Loss D: 0.4309, Loss G: 1.3412\n",
      "Epoch [7/20] Batch 720/938 Loss D: 0.3515, Loss G: 1.5726\n",
      "Epoch [7/20] Batch 730/938 Loss D: 0.3521, Loss G: 1.6097\n",
      "Epoch [7/20] Batch 740/938 Loss D: 0.3779, Loss G: 1.4115\n",
      "Epoch [7/20] Batch 750/938 Loss D: 0.3900, Loss G: 1.4093\n",
      "Epoch [7/20] Batch 760/938 Loss D: 0.3775, Loss G: 1.4084\n",
      "Epoch [7/20] Batch 770/938 Loss D: 0.3326, Loss G: 1.3740\n",
      "Epoch [7/20] Batch 780/938 Loss D: 0.3949, Loss G: 1.4135\n",
      "Epoch [7/20] Batch 790/938 Loss D: 0.3742, Loss G: 1.3677\n",
      "Epoch [7/20] Batch 800/938 Loss D: 0.4004, Loss G: 1.3831\n",
      "Epoch [7/20] Batch 810/938 Loss D: 0.3639, Loss G: 1.3447\n",
      "Epoch [7/20] Batch 820/938 Loss D: 0.4275, Loss G: 1.3748\n",
      "Epoch [7/20] Batch 830/938 Loss D: 0.3591, Loss G: 1.5730\n",
      "Epoch [7/20] Batch 840/938 Loss D: 0.3310, Loss G: 1.6450\n",
      "Epoch [7/20] Batch 850/938 Loss D: 0.3802, Loss G: 1.4737\n",
      "Epoch [7/20] Batch 860/938 Loss D: 0.3231, Loss G: 1.4558\n",
      "Epoch [7/20] Batch 870/938 Loss D: 0.3638, Loss G: 1.3198\n",
      "Epoch [7/20] Batch 880/938 Loss D: 0.4542, Loss G: 1.2083\n",
      "Epoch [7/20] Batch 890/938 Loss D: 0.4154, Loss G: 1.4152\n",
      "Epoch [7/20] Batch 900/938 Loss D: 0.3758, Loss G: 1.4250\n",
      "Epoch [7/20] Batch 910/938 Loss D: 0.4391, Loss G: 1.2797\n",
      "Epoch [7/20] Batch 920/938 Loss D: 0.3459, Loss G: 1.3890\n",
      "Epoch [7/20] Batch 930/938 Loss D: 0.2723, Loss G: 1.6925\n",
      "Epoch [8/20] Batch 0/938 Loss D: 0.3357, Loss G: 1.5011\n",
      "Epoch [8/20] Batch 10/938 Loss D: 0.3311, Loss G: 1.5230\n",
      "Epoch [8/20] Batch 20/938 Loss D: 0.4135, Loss G: 1.3107\n",
      "Epoch [8/20] Batch 30/938 Loss D: 0.3685, Loss G: 1.3042\n",
      "Epoch [8/20] Batch 40/938 Loss D: 0.3284, Loss G: 1.4906\n",
      "Epoch [8/20] Batch 50/938 Loss D: 0.3088, Loss G: 1.4801\n",
      "Epoch [8/20] Batch 60/938 Loss D: 0.3885, Loss G: 1.4120\n",
      "Epoch [8/20] Batch 70/938 Loss D: 0.3368, Loss G: 1.5176\n",
      "Epoch [8/20] Batch 80/938 Loss D: 0.3151, Loss G: 1.5786\n",
      "Epoch [8/20] Batch 90/938 Loss D: 0.3910, Loss G: 1.3207\n",
      "Epoch [8/20] Batch 100/938 Loss D: 0.4265, Loss G: 1.4331\n",
      "Epoch [8/20] Batch 110/938 Loss D: 0.3827, Loss G: 1.4426\n",
      "Epoch [8/20] Batch 120/938 Loss D: 0.3763, Loss G: 1.1846\n",
      "Epoch [8/20] Batch 130/938 Loss D: 0.4050, Loss G: 1.2408\n",
      "Epoch [8/20] Batch 140/938 Loss D: 0.3947, Loss G: 1.4303\n",
      "Epoch [8/20] Batch 150/938 Loss D: 0.3455, Loss G: 1.5105\n",
      "Epoch [8/20] Batch 160/938 Loss D: 0.3437, Loss G: 1.5426\n",
      "Epoch [8/20] Batch 170/938 Loss D: 0.3274, Loss G: 1.4427\n",
      "Epoch [8/20] Batch 180/938 Loss D: 0.4182, Loss G: 1.2209\n",
      "Epoch [8/20] Batch 190/938 Loss D: 0.4627, Loss G: 1.2196\n",
      "Epoch [8/20] Batch 200/938 Loss D: 0.4006, Loss G: 1.5271\n",
      "Epoch [8/20] Batch 210/938 Loss D: 0.3698, Loss G: 1.3584\n",
      "Epoch [8/20] Batch 220/938 Loss D: 0.4038, Loss G: 1.4778\n",
      "Epoch [8/20] Batch 230/938 Loss D: 0.4227, Loss G: 1.4728\n",
      "Epoch [8/20] Batch 240/938 Loss D: 0.3200, Loss G: 1.5711\n",
      "Epoch [8/20] Batch 250/938 Loss D: 0.3124, Loss G: 1.5692\n",
      "Epoch [8/20] Batch 260/938 Loss D: 0.3416, Loss G: 1.2654\n",
      "Epoch [8/20] Batch 270/938 Loss D: 0.4248, Loss G: 1.3940\n",
      "Epoch [8/20] Batch 280/938 Loss D: 0.4166, Loss G: 1.4133\n",
      "Epoch [8/20] Batch 290/938 Loss D: 0.3339, Loss G: 1.3230\n",
      "Epoch [8/20] Batch 300/938 Loss D: 0.3850, Loss G: 1.3689\n",
      "Epoch [8/20] Batch 310/938 Loss D: 0.3846, Loss G: 1.4765\n",
      "Epoch [8/20] Batch 320/938 Loss D: 0.3567, Loss G: 1.6384\n",
      "Epoch [8/20] Batch 330/938 Loss D: 0.3218, Loss G: 1.4615\n",
      "Epoch [8/20] Batch 340/938 Loss D: 0.3875, Loss G: 1.4674\n",
      "Epoch [8/20] Batch 350/938 Loss D: 0.4199, Loss G: 1.3218\n",
      "Epoch [8/20] Batch 360/938 Loss D: 0.3552, Loss G: 1.3787\n",
      "Epoch [8/20] Batch 370/938 Loss D: 0.3182, Loss G: 1.5280\n",
      "Epoch [8/20] Batch 380/938 Loss D: 0.3312, Loss G: 1.3965\n",
      "Epoch [8/20] Batch 390/938 Loss D: 0.4021, Loss G: 1.4413\n",
      "Epoch [8/20] Batch 400/938 Loss D: 0.3861, Loss G: 1.4259\n",
      "Epoch [8/20] Batch 410/938 Loss D: 0.2889, Loss G: 1.5582\n",
      "Epoch [8/20] Batch 420/938 Loss D: 0.3271, Loss G: 1.5268\n",
      "Epoch [8/20] Batch 430/938 Loss D: 0.4677, Loss G: 1.3126\n",
      "Epoch [8/20] Batch 440/938 Loss D: 0.3411, Loss G: 1.3914\n",
      "Epoch [8/20] Batch 450/938 Loss D: 0.3663, Loss G: 1.3511\n",
      "Epoch [8/20] Batch 460/938 Loss D: 0.4169, Loss G: 1.4630\n",
      "Epoch [8/20] Batch 470/938 Loss D: 0.3710, Loss G: 1.2820\n",
      "Epoch [8/20] Batch 480/938 Loss D: 0.3326, Loss G: 1.7308\n",
      "Epoch [8/20] Batch 490/938 Loss D: 0.3710, Loss G: 1.6837\n",
      "Epoch [8/20] Batch 500/938 Loss D: 0.3109, Loss G: 1.5635\n",
      "Epoch [8/20] Batch 510/938 Loss D: 0.3363, Loss G: 1.4617\n",
      "Epoch [8/20] Batch 520/938 Loss D: 0.3762, Loss G: 1.2741\n",
      "Epoch [8/20] Batch 530/938 Loss D: 0.3017, Loss G: 1.4471\n",
      "Epoch [8/20] Batch 540/938 Loss D: 0.3817, Loss G: 1.4152\n",
      "Epoch [8/20] Batch 550/938 Loss D: 0.3511, Loss G: 1.5076\n",
      "Epoch [8/20] Batch 560/938 Loss D: 0.2699, Loss G: 1.6604\n",
      "Epoch [8/20] Batch 570/938 Loss D: 0.2902, Loss G: 1.5247\n",
      "Epoch [8/20] Batch 580/938 Loss D: 0.3813, Loss G: 1.3822\n",
      "Epoch [8/20] Batch 590/938 Loss D: 0.4158, Loss G: 1.2369\n",
      "Epoch [8/20] Batch 600/938 Loss D: 0.4516, Loss G: 1.3950\n",
      "Epoch [8/20] Batch 610/938 Loss D: 0.3776, Loss G: 1.4211\n",
      "Epoch [8/20] Batch 620/938 Loss D: 0.4412, Loss G: 1.3313\n",
      "Epoch [8/20] Batch 630/938 Loss D: 0.4681, Loss G: 1.1864\n",
      "Epoch [8/20] Batch 640/938 Loss D: 0.3221, Loss G: 1.5866\n",
      "Epoch [8/20] Batch 650/938 Loss D: 0.3387, Loss G: 1.4223\n",
      "Epoch [8/20] Batch 660/938 Loss D: 0.3806, Loss G: 1.3065\n",
      "Epoch [8/20] Batch 670/938 Loss D: 0.3288, Loss G: 1.4711\n",
      "Epoch [8/20] Batch 680/938 Loss D: 0.3726, Loss G: 1.1931\n",
      "Epoch [8/20] Batch 690/938 Loss D: 0.4368, Loss G: 1.0649\n",
      "Epoch [8/20] Batch 700/938 Loss D: 0.3925, Loss G: 1.3554\n",
      "Epoch [8/20] Batch 710/938 Loss D: 0.4026, Loss G: 1.4221\n",
      "Epoch [8/20] Batch 720/938 Loss D: 0.3129, Loss G: 1.6006\n",
      "Epoch [8/20] Batch 730/938 Loss D: 0.3750, Loss G: 1.3195\n",
      "Epoch [8/20] Batch 740/938 Loss D: 0.2937, Loss G: 1.5509\n",
      "Epoch [8/20] Batch 750/938 Loss D: 0.3203, Loss G: 1.5593\n",
      "Epoch [8/20] Batch 760/938 Loss D: 0.4197, Loss G: 1.2850\n",
      "Epoch [8/20] Batch 770/938 Loss D: 0.4349, Loss G: 1.3871\n",
      "Epoch [8/20] Batch 780/938 Loss D: 0.4043, Loss G: 1.4485\n",
      "Epoch [8/20] Batch 790/938 Loss D: 0.3193, Loss G: 1.6657\n",
      "Epoch [8/20] Batch 800/938 Loss D: 0.4080, Loss G: 1.4251\n",
      "Epoch [8/20] Batch 810/938 Loss D: 0.3717, Loss G: 1.3899\n",
      "Epoch [8/20] Batch 820/938 Loss D: 0.3372, Loss G: 1.5737\n",
      "Epoch [8/20] Batch 830/938 Loss D: 0.3297, Loss G: 1.4321\n",
      "Epoch [8/20] Batch 840/938 Loss D: 0.3579, Loss G: 1.3982\n",
      "Epoch [8/20] Batch 850/938 Loss D: 0.3920, Loss G: 1.6050\n",
      "Epoch [8/20] Batch 860/938 Loss D: 0.3859, Loss G: 1.4328\n",
      "Epoch [8/20] Batch 870/938 Loss D: 0.3579, Loss G: 1.4176\n",
      "Epoch [8/20] Batch 880/938 Loss D: 0.3889, Loss G: 1.2787\n",
      "Epoch [8/20] Batch 890/938 Loss D: 0.3444, Loss G: 1.5578\n",
      "Epoch [8/20] Batch 900/938 Loss D: 0.3359, Loss G: 1.4104\n",
      "Epoch [8/20] Batch 910/938 Loss D: 0.3744, Loss G: 1.5079\n",
      "Epoch [8/20] Batch 920/938 Loss D: 0.3905, Loss G: 1.4001\n",
      "Epoch [8/20] Batch 930/938 Loss D: 0.4040, Loss G: 1.2925\n",
      "Epoch [9/20] Batch 0/938 Loss D: 0.4317, Loss G: 1.3133\n",
      "Epoch [9/20] Batch 10/938 Loss D: 0.4362, Loss G: 1.4170\n",
      "Epoch [9/20] Batch 20/938 Loss D: 0.3774, Loss G: 1.3065\n",
      "Epoch [9/20] Batch 30/938 Loss D: 0.2995, Loss G: 1.6442\n",
      "Epoch [9/20] Batch 40/938 Loss D: 0.2958, Loss G: 1.5332\n",
      "Epoch [9/20] Batch 50/938 Loss D: 0.3674, Loss G: 1.4136\n",
      "Epoch [9/20] Batch 60/938 Loss D: 0.3584, Loss G: 1.4288\n",
      "Epoch [9/20] Batch 70/938 Loss D: 0.4007, Loss G: 1.3475\n",
      "Epoch [9/20] Batch 80/938 Loss D: 0.3997, Loss G: 1.2930\n",
      "Epoch [9/20] Batch 90/938 Loss D: 0.3637, Loss G: 1.3956\n",
      "Epoch [9/20] Batch 100/938 Loss D: 0.3372, Loss G: 1.4672\n",
      "Epoch [9/20] Batch 110/938 Loss D: 0.3273, Loss G: 1.5672\n",
      "Epoch [9/20] Batch 120/938 Loss D: 0.3275, Loss G: 1.5993\n",
      "Epoch [9/20] Batch 130/938 Loss D: 0.3637, Loss G: 1.3679\n",
      "Epoch [9/20] Batch 140/938 Loss D: 0.3310, Loss G: 1.5295\n",
      "Epoch [9/20] Batch 150/938 Loss D: 0.4034, Loss G: 1.4884\n",
      "Epoch [9/20] Batch 160/938 Loss D: 0.3404, Loss G: 1.4235\n",
      "Epoch [9/20] Batch 170/938 Loss D: 0.3755, Loss G: 1.3889\n",
      "Epoch [9/20] Batch 180/938 Loss D: 0.3454, Loss G: 1.4688\n",
      "Epoch [9/20] Batch 190/938 Loss D: 0.3233, Loss G: 1.5806\n",
      "Epoch [9/20] Batch 200/938 Loss D: 0.3802, Loss G: 1.4844\n",
      "Epoch [9/20] Batch 210/938 Loss D: 0.3520, Loss G: 1.3747\n",
      "Epoch [9/20] Batch 220/938 Loss D: 0.4207, Loss G: 1.2515\n",
      "Epoch [9/20] Batch 230/938 Loss D: 0.3182, Loss G: 1.6485\n",
      "Epoch [9/20] Batch 240/938 Loss D: 0.3742, Loss G: 1.2893\n",
      "Epoch [9/20] Batch 250/938 Loss D: 0.3786, Loss G: 1.2888\n",
      "Epoch [9/20] Batch 260/938 Loss D: 0.3486, Loss G: 1.5523\n",
      "Epoch [9/20] Batch 270/938 Loss D: 0.3894, Loss G: 1.2558\n",
      "Epoch [9/20] Batch 280/938 Loss D: 0.3776, Loss G: 1.2591\n",
      "Epoch [9/20] Batch 290/938 Loss D: 0.3274, Loss G: 1.4658\n",
      "Epoch [9/20] Batch 300/938 Loss D: 0.3563, Loss G: 1.5625\n",
      "Epoch [9/20] Batch 310/938 Loss D: 0.3842, Loss G: 1.3374\n",
      "Epoch [9/20] Batch 320/938 Loss D: 0.3742, Loss G: 1.2340\n",
      "Epoch [9/20] Batch 330/938 Loss D: 0.3876, Loss G: 1.5340\n",
      "Epoch [9/20] Batch 340/938 Loss D: 0.3432, Loss G: 1.4573\n",
      "Epoch [9/20] Batch 350/938 Loss D: 0.3497, Loss G: 1.3557\n",
      "Epoch [9/20] Batch 360/938 Loss D: 0.4592, Loss G: 1.2136\n",
      "Epoch [9/20] Batch 370/938 Loss D: 0.3693, Loss G: 1.4888\n",
      "Epoch [9/20] Batch 380/938 Loss D: 0.3378, Loss G: 1.3694\n",
      "Epoch [9/20] Batch 390/938 Loss D: 0.3366, Loss G: 1.4628\n",
      "Epoch [9/20] Batch 400/938 Loss D: 0.4075, Loss G: 1.4081\n",
      "Epoch [9/20] Batch 410/938 Loss D: 0.3180, Loss G: 1.6043\n",
      "Epoch [9/20] Batch 420/938 Loss D: 0.3533, Loss G: 1.3642\n",
      "Epoch [9/20] Batch 430/938 Loss D: 0.3442, Loss G: 1.4407\n",
      "Epoch [9/20] Batch 440/938 Loss D: 0.3970, Loss G: 1.4733\n",
      "Epoch [9/20] Batch 450/938 Loss D: 0.3040, Loss G: 1.5301\n",
      "Epoch [9/20] Batch 460/938 Loss D: 0.3659, Loss G: 1.4212\n",
      "Epoch [9/20] Batch 470/938 Loss D: 0.4106, Loss G: 1.3716\n",
      "Epoch [9/20] Batch 480/938 Loss D: 0.3917, Loss G: 1.2833\n",
      "Epoch [9/20] Batch 490/938 Loss D: 0.3554, Loss G: 1.4425\n",
      "Epoch [9/20] Batch 500/938 Loss D: 0.3530, Loss G: 1.4700\n",
      "Epoch [9/20] Batch 510/938 Loss D: 0.3299, Loss G: 1.6144\n",
      "Epoch [9/20] Batch 520/938 Loss D: 0.3507, Loss G: 1.4552\n",
      "Epoch [9/20] Batch 530/938 Loss D: 0.3333, Loss G: 1.6615\n",
      "Epoch [9/20] Batch 540/938 Loss D: 0.3573, Loss G: 1.4849\n",
      "Epoch [9/20] Batch 550/938 Loss D: 0.3684, Loss G: 1.3204\n",
      "Epoch [9/20] Batch 560/938 Loss D: 0.3912, Loss G: 1.2840\n",
      "Epoch [9/20] Batch 570/938 Loss D: 0.3967, Loss G: 1.4460\n",
      "Epoch [9/20] Batch 580/938 Loss D: 0.4427, Loss G: 1.4610\n",
      "Epoch [9/20] Batch 590/938 Loss D: 0.2995, Loss G: 1.5024\n",
      "Epoch [9/20] Batch 600/938 Loss D: 0.3357, Loss G: 1.4563\n",
      "Epoch [9/20] Batch 610/938 Loss D: 0.3364, Loss G: 1.5867\n",
      "Epoch [9/20] Batch 620/938 Loss D: 0.4033, Loss G: 1.1940\n",
      "Epoch [9/20] Batch 630/938 Loss D: 0.4391, Loss G: 1.3232\n",
      "Epoch [9/20] Batch 640/938 Loss D: 0.3406, Loss G: 1.4894\n",
      "Epoch [9/20] Batch 650/938 Loss D: 0.3749, Loss G: 1.3740\n",
      "Epoch [9/20] Batch 660/938 Loss D: 0.3437, Loss G: 1.3754\n",
      "Epoch [9/20] Batch 670/938 Loss D: 0.3446, Loss G: 1.4670\n",
      "Epoch [9/20] Batch 680/938 Loss D: 0.3985, Loss G: 1.4359\n",
      "Epoch [9/20] Batch 690/938 Loss D: 0.4098, Loss G: 1.3475\n",
      "Epoch [9/20] Batch 700/938 Loss D: 0.3892, Loss G: 1.4269\n",
      "Epoch [9/20] Batch 710/938 Loss D: 0.3528, Loss G: 1.4625\n",
      "Epoch [9/20] Batch 720/938 Loss D: 0.3053, Loss G: 1.4302\n",
      "Epoch [9/20] Batch 730/938 Loss D: 0.3464, Loss G: 1.3662\n",
      "Epoch [9/20] Batch 740/938 Loss D: 0.3603, Loss G: 1.4850\n",
      "Epoch [9/20] Batch 750/938 Loss D: 0.3408, Loss G: 1.6443\n",
      "Epoch [9/20] Batch 760/938 Loss D: 0.3616, Loss G: 1.2716\n",
      "Epoch [9/20] Batch 770/938 Loss D: 0.3193, Loss G: 1.4950\n",
      "Epoch [9/20] Batch 780/938 Loss D: 0.3064, Loss G: 1.7647\n",
      "Epoch [9/20] Batch 790/938 Loss D: 0.3944, Loss G: 1.3960\n",
      "Epoch [9/20] Batch 800/938 Loss D: 0.3566, Loss G: 1.4178\n",
      "Epoch [9/20] Batch 810/938 Loss D: 0.3675, Loss G: 1.4632\n",
      "Epoch [9/20] Batch 820/938 Loss D: 0.3918, Loss G: 1.4970\n",
      "Epoch [9/20] Batch 830/938 Loss D: 0.3927, Loss G: 1.3772\n",
      "Epoch [9/20] Batch 840/938 Loss D: 0.3821, Loss G: 1.4202\n",
      "Epoch [9/20] Batch 850/938 Loss D: 0.3756, Loss G: 1.4472\n",
      "Epoch [9/20] Batch 860/938 Loss D: 0.3150, Loss G: 1.4791\n",
      "Epoch [9/20] Batch 870/938 Loss D: 0.3491, Loss G: 1.5044\n",
      "Epoch [9/20] Batch 880/938 Loss D: 0.3465, Loss G: 1.5065\n",
      "Epoch [9/20] Batch 890/938 Loss D: 0.3676, Loss G: 1.3796\n",
      "Epoch [9/20] Batch 900/938 Loss D: 0.4076, Loss G: 1.1839\n",
      "Epoch [9/20] Batch 910/938 Loss D: 0.3708, Loss G: 1.4577\n",
      "Epoch [9/20] Batch 920/938 Loss D: 0.3704, Loss G: 1.4719\n",
      "Epoch [9/20] Batch 930/938 Loss D: 0.3512, Loss G: 1.4250\n",
      "Epoch [10/20] Batch 0/938 Loss D: 0.3277, Loss G: 1.6620\n",
      "Epoch [10/20] Batch 10/938 Loss D: 0.3597, Loss G: 1.5144\n",
      "Epoch [10/20] Batch 20/938 Loss D: 0.3237, Loss G: 1.5362\n",
      "Epoch [10/20] Batch 30/938 Loss D: 0.4612, Loss G: 1.3283\n",
      "Epoch [10/20] Batch 40/938 Loss D: 0.3408, Loss G: 1.5147\n",
      "Epoch [10/20] Batch 50/938 Loss D: 0.4084, Loss G: 1.2547\n",
      "Epoch [10/20] Batch 60/938 Loss D: 0.3672, Loss G: 1.2644\n",
      "Epoch [10/20] Batch 70/938 Loss D: 0.3460, Loss G: 1.3732\n",
      "Epoch [10/20] Batch 80/938 Loss D: 0.3792, Loss G: 1.3300\n",
      "Epoch [10/20] Batch 90/938 Loss D: 0.3523, Loss G: 1.4369\n",
      "Epoch [10/20] Batch 100/938 Loss D: 0.3592, Loss G: 1.2856\n",
      "Epoch [10/20] Batch 110/938 Loss D: 0.4598, Loss G: 1.6023\n",
      "Epoch [10/20] Batch 120/938 Loss D: 0.3486, Loss G: 1.7075\n",
      "Epoch [10/20] Batch 130/938 Loss D: 0.4431, Loss G: 1.5609\n",
      "Epoch [10/20] Batch 140/938 Loss D: 0.3754, Loss G: 1.4328\n",
      "Epoch [10/20] Batch 150/938 Loss D: 0.3752, Loss G: 1.4748\n",
      "Epoch [10/20] Batch 160/938 Loss D: 0.3561, Loss G: 1.4352\n",
      "Epoch [10/20] Batch 170/938 Loss D: 0.3467, Loss G: 1.3481\n",
      "Epoch [10/20] Batch 180/938 Loss D: 0.3615, Loss G: 1.4624\n",
      "Epoch [10/20] Batch 190/938 Loss D: 0.4479, Loss G: 1.3556\n",
      "Epoch [10/20] Batch 200/938 Loss D: 0.3478, Loss G: 1.3738\n",
      "Epoch [10/20] Batch 210/938 Loss D: 0.3647, Loss G: 1.1899\n",
      "Epoch [10/20] Batch 220/938 Loss D: 0.3563, Loss G: 1.5074\n",
      "Epoch [10/20] Batch 230/938 Loss D: 0.4201, Loss G: 1.3116\n",
      "Epoch [10/20] Batch 240/938 Loss D: 0.3832, Loss G: 1.5174\n",
      "Epoch [10/20] Batch 250/938 Loss D: 0.3607, Loss G: 1.4070\n",
      "Epoch [10/20] Batch 260/938 Loss D: 0.3291, Loss G: 1.3971\n",
      "Epoch [10/20] Batch 270/938 Loss D: 0.3147, Loss G: 1.5038\n",
      "Epoch [10/20] Batch 280/938 Loss D: 0.3920, Loss G: 1.1859\n",
      "Epoch [10/20] Batch 290/938 Loss D: 0.3002, Loss G: 1.5494\n",
      "Epoch [10/20] Batch 300/938 Loss D: 0.3485, Loss G: 1.3967\n",
      "Epoch [10/20] Batch 310/938 Loss D: 0.3467, Loss G: 1.6142\n",
      "Epoch [10/20] Batch 320/938 Loss D: 0.3913, Loss G: 1.5179\n",
      "Epoch [10/20] Batch 330/938 Loss D: 0.3578, Loss G: 1.3532\n",
      "Epoch [10/20] Batch 340/938 Loss D: 0.3204, Loss G: 1.6099\n",
      "Epoch [10/20] Batch 350/938 Loss D: 0.3144, Loss G: 1.5730\n",
      "Epoch [10/20] Batch 360/938 Loss D: 0.3955, Loss G: 1.3606\n",
      "Epoch [10/20] Batch 370/938 Loss D: 0.3656, Loss G: 1.4648\n",
      "Epoch [10/20] Batch 380/938 Loss D: 0.3103, Loss G: 1.5152\n",
      "Epoch [10/20] Batch 390/938 Loss D: 0.3634, Loss G: 1.6720\n",
      "Epoch [10/20] Batch 400/938 Loss D: 0.3016, Loss G: 1.7307\n",
      "Epoch [10/20] Batch 410/938 Loss D: 0.3217, Loss G: 1.3734\n",
      "Epoch [10/20] Batch 420/938 Loss D: 0.3028, Loss G: 1.3858\n",
      "Epoch [10/20] Batch 430/938 Loss D: 0.3234, Loss G: 1.4661\n",
      "Epoch [10/20] Batch 440/938 Loss D: 0.3675, Loss G: 1.3787\n",
      "Epoch [10/20] Batch 450/938 Loss D: 0.3896, Loss G: 1.4895\n",
      "Epoch [10/20] Batch 460/938 Loss D: 0.3915, Loss G: 1.5034\n",
      "Epoch [10/20] Batch 470/938 Loss D: 0.3103, Loss G: 1.4583\n",
      "Epoch [10/20] Batch 480/938 Loss D: 0.3909, Loss G: 1.4154\n",
      "Epoch [10/20] Batch 490/938 Loss D: 0.3193, Loss G: 1.5266\n",
      "Epoch [10/20] Batch 500/938 Loss D: 0.3366, Loss G: 1.3316\n",
      "Epoch [10/20] Batch 510/938 Loss D: 0.3282, Loss G: 1.7253\n",
      "Epoch [10/20] Batch 520/938 Loss D: 0.3638, Loss G: 1.5258\n",
      "Epoch [10/20] Batch 530/938 Loss D: 0.3576, Loss G: 1.5277\n",
      "Epoch [10/20] Batch 540/938 Loss D: 0.3305, Loss G: 1.5502\n",
      "Epoch [10/20] Batch 550/938 Loss D: 0.3943, Loss G: 1.3424\n",
      "Epoch [10/20] Batch 560/938 Loss D: 0.3478, Loss G: 1.5818\n",
      "Epoch [10/20] Batch 570/938 Loss D: 0.3986, Loss G: 1.4182\n",
      "Epoch [10/20] Batch 580/938 Loss D: 0.3536, Loss G: 1.4550\n",
      "Epoch [10/20] Batch 590/938 Loss D: 0.3196, Loss G: 1.4587\n",
      "Epoch [10/20] Batch 600/938 Loss D: 0.3486, Loss G: 1.3499\n",
      "Epoch [10/20] Batch 610/938 Loss D: 0.3881, Loss G: 1.3777\n",
      "Epoch [10/20] Batch 620/938 Loss D: 0.3794, Loss G: 1.5707\n",
      "Epoch [10/20] Batch 630/938 Loss D: 0.3260, Loss G: 1.5782\n",
      "Epoch [10/20] Batch 640/938 Loss D: 0.3346, Loss G: 1.3633\n",
      "Epoch [10/20] Batch 650/938 Loss D: 0.3981, Loss G: 1.2903\n",
      "Epoch [10/20] Batch 660/938 Loss D: 0.4168, Loss G: 1.3271\n",
      "Epoch [10/20] Batch 670/938 Loss D: 0.3240, Loss G: 1.5910\n",
      "Epoch [10/20] Batch 680/938 Loss D: 0.3508, Loss G: 1.4516\n",
      "Epoch [10/20] Batch 690/938 Loss D: 0.3076, Loss G: 1.6687\n",
      "Epoch [10/20] Batch 700/938 Loss D: 0.3184, Loss G: 1.5542\n",
      "Epoch [10/20] Batch 710/938 Loss D: 0.3228, Loss G: 1.5766\n",
      "Epoch [10/20] Batch 720/938 Loss D: 0.3460, Loss G: 1.4994\n",
      "Epoch [10/20] Batch 730/938 Loss D: 0.3763, Loss G: 1.2798\n",
      "Epoch [10/20] Batch 740/938 Loss D: 0.3709, Loss G: 1.4150\n",
      "Epoch [10/20] Batch 750/938 Loss D: 0.3072, Loss G: 1.6157\n",
      "Epoch [10/20] Batch 760/938 Loss D: 0.3506, Loss G: 1.2550\n",
      "Epoch [10/20] Batch 770/938 Loss D: 0.3510, Loss G: 1.5257\n",
      "Epoch [10/20] Batch 780/938 Loss D: 0.3992, Loss G: 1.4192\n",
      "Epoch [10/20] Batch 790/938 Loss D: 0.3365, Loss G: 1.4835\n",
      "Epoch [10/20] Batch 800/938 Loss D: 0.3305, Loss G: 1.7612\n",
      "Epoch [10/20] Batch 810/938 Loss D: 0.3735, Loss G: 1.3701\n",
      "Epoch [10/20] Batch 820/938 Loss D: 0.3342, Loss G: 1.3356\n",
      "Epoch [10/20] Batch 830/938 Loss D: 0.3940, Loss G: 1.3302\n",
      "Epoch [10/20] Batch 840/938 Loss D: 0.3529, Loss G: 1.6033\n",
      "Epoch [10/20] Batch 850/938 Loss D: 0.3688, Loss G: 1.3445\n",
      "Epoch [10/20] Batch 860/938 Loss D: 0.3792, Loss G: 1.5928\n",
      "Epoch [10/20] Batch 870/938 Loss D: 0.3003, Loss G: 1.7365\n",
      "Epoch [10/20] Batch 880/938 Loss D: 0.2919, Loss G: 1.6214\n",
      "Epoch [10/20] Batch 890/938 Loss D: 0.3973, Loss G: 1.4728\n",
      "Epoch [10/20] Batch 900/938 Loss D: 0.3454, Loss G: 1.6104\n",
      "Epoch [10/20] Batch 910/938 Loss D: 0.3289, Loss G: 1.4837\n",
      "Epoch [10/20] Batch 920/938 Loss D: 0.3682, Loss G: 1.2969\n",
      "Epoch [10/20] Batch 930/938 Loss D: 0.3490, Loss G: 1.3149\n",
      "Epoch [11/20] Batch 0/938 Loss D: 0.3867, Loss G: 1.6231\n",
      "Epoch [11/20] Batch 10/938 Loss D: 0.3384, Loss G: 1.4388\n",
      "Epoch [11/20] Batch 20/938 Loss D: 0.3373, Loss G: 1.2929\n",
      "Epoch [11/20] Batch 30/938 Loss D: 0.3532, Loss G: 1.3191\n",
      "Epoch [11/20] Batch 40/938 Loss D: 0.3021, Loss G: 1.5316\n",
      "Epoch [11/20] Batch 50/938 Loss D: 0.3077, Loss G: 1.5407\n",
      "Epoch [11/20] Batch 60/938 Loss D: 0.3364, Loss G: 1.3453\n",
      "Epoch [11/20] Batch 70/938 Loss D: 0.3475, Loss G: 1.2896\n",
      "Epoch [11/20] Batch 80/938 Loss D: 0.3546, Loss G: 1.3093\n",
      "Epoch [11/20] Batch 90/938 Loss D: 0.3272, Loss G: 1.3236\n",
      "Epoch [11/20] Batch 100/938 Loss D: 0.3130, Loss G: 1.6240\n",
      "Epoch [11/20] Batch 110/938 Loss D: 0.3917, Loss G: 1.1610\n",
      "Epoch [11/20] Batch 120/938 Loss D: 0.3743, Loss G: 1.6074\n",
      "Epoch [11/20] Batch 130/938 Loss D: 0.3179, Loss G: 1.6142\n",
      "Epoch [11/20] Batch 140/938 Loss D: 0.3061, Loss G: 1.3828\n",
      "Epoch [11/20] Batch 150/938 Loss D: 0.4250, Loss G: 1.3003\n",
      "Epoch [11/20] Batch 160/938 Loss D: 0.3001, Loss G: 1.4103\n",
      "Epoch [11/20] Batch 170/938 Loss D: 0.3319, Loss G: 1.6209\n",
      "Epoch [11/20] Batch 180/938 Loss D: 0.3763, Loss G: 1.3031\n",
      "Epoch [11/20] Batch 190/938 Loss D: 0.3245, Loss G: 1.3111\n",
      "Epoch [11/20] Batch 200/938 Loss D: 0.3316, Loss G: 1.4149\n",
      "Epoch [11/20] Batch 210/938 Loss D: 0.2965, Loss G: 1.6015\n",
      "Epoch [11/20] Batch 220/938 Loss D: 0.3764, Loss G: 1.3352\n",
      "Epoch [11/20] Batch 230/938 Loss D: 0.3600, Loss G: 1.2582\n",
      "Epoch [11/20] Batch 240/938 Loss D: 0.3960, Loss G: 1.4050\n",
      "Epoch [11/20] Batch 250/938 Loss D: 0.4258, Loss G: 1.3637\n",
      "Epoch [11/20] Batch 260/938 Loss D: 0.3298, Loss G: 1.4337\n",
      "Epoch [11/20] Batch 270/938 Loss D: 0.3512, Loss G: 1.4252\n",
      "Epoch [11/20] Batch 280/938 Loss D: 0.3144, Loss G: 1.4635\n",
      "Epoch [11/20] Batch 290/938 Loss D: 0.3416, Loss G: 1.5451\n",
      "Epoch [11/20] Batch 300/938 Loss D: 0.3583, Loss G: 1.3546\n",
      "Epoch [11/20] Batch 310/938 Loss D: 0.3871, Loss G: 1.2577\n",
      "Epoch [11/20] Batch 320/938 Loss D: 0.3475, Loss G: 1.5316\n",
      "Epoch [11/20] Batch 330/938 Loss D: 0.3724, Loss G: 1.4111\n",
      "Epoch [11/20] Batch 340/938 Loss D: 0.3506, Loss G: 1.4286\n",
      "Epoch [11/20] Batch 350/938 Loss D: 0.3457, Loss G: 1.3025\n",
      "Epoch [11/20] Batch 360/938 Loss D: 0.3034, Loss G: 1.4497\n",
      "Epoch [11/20] Batch 370/938 Loss D: 0.3364, Loss G: 1.6402\n",
      "Epoch [11/20] Batch 380/938 Loss D: 0.3430, Loss G: 1.3752\n",
      "Epoch [11/20] Batch 390/938 Loss D: 0.3636, Loss G: 1.2965\n",
      "Epoch [11/20] Batch 400/938 Loss D: 0.3348, Loss G: 1.5597\n",
      "Epoch [11/20] Batch 410/938 Loss D: 0.3259, Loss G: 1.5941\n",
      "Epoch [11/20] Batch 420/938 Loss D: 0.3461, Loss G: 1.4483\n",
      "Epoch [11/20] Batch 430/938 Loss D: 0.3433, Loss G: 1.5500\n",
      "Epoch [11/20] Batch 440/938 Loss D: 0.3301, Loss G: 1.4502\n",
      "Epoch [11/20] Batch 450/938 Loss D: 0.3302, Loss G: 1.5250\n",
      "Epoch [11/20] Batch 460/938 Loss D: 0.4058, Loss G: 1.1897\n",
      "Epoch [11/20] Batch 470/938 Loss D: 0.3295, Loss G: 1.4548\n",
      "Epoch [11/20] Batch 480/938 Loss D: 0.3586, Loss G: 1.4744\n",
      "Epoch [11/20] Batch 490/938 Loss D: 0.3116, Loss G: 1.5619\n",
      "Epoch [11/20] Batch 500/938 Loss D: 0.3346, Loss G: 1.4634\n",
      "Epoch [11/20] Batch 510/938 Loss D: 0.3809, Loss G: 1.3358\n",
      "Epoch [11/20] Batch 520/938 Loss D: 0.3362, Loss G: 1.3695\n",
      "Epoch [11/20] Batch 530/938 Loss D: 0.3420, Loss G: 1.2950\n",
      "Epoch [11/20] Batch 540/938 Loss D: 0.3851, Loss G: 1.3093\n",
      "Epoch [11/20] Batch 550/938 Loss D: 0.3723, Loss G: 1.4835\n",
      "Epoch [11/20] Batch 560/938 Loss D: 0.3843, Loss G: 1.4323\n",
      "Epoch [11/20] Batch 570/938 Loss D: 0.4006, Loss G: 1.3009\n",
      "Epoch [11/20] Batch 580/938 Loss D: 0.3961, Loss G: 1.3823\n",
      "Epoch [11/20] Batch 590/938 Loss D: 0.4321, Loss G: 1.4946\n",
      "Epoch [11/20] Batch 600/938 Loss D: 0.3381, Loss G: 1.4580\n",
      "Epoch [11/20] Batch 610/938 Loss D: 0.3979, Loss G: 1.2915\n",
      "Epoch [11/20] Batch 620/938 Loss D: 0.3894, Loss G: 1.5336\n",
      "Epoch [11/20] Batch 630/938 Loss D: 0.3243, Loss G: 1.4501\n",
      "Epoch [11/20] Batch 640/938 Loss D: 0.3652, Loss G: 1.5673\n",
      "Epoch [11/20] Batch 650/938 Loss D: 0.3425, Loss G: 1.3653\n",
      "Epoch [11/20] Batch 660/938 Loss D: 0.3825, Loss G: 1.1861\n",
      "Epoch [11/20] Batch 670/938 Loss D: 0.3177, Loss G: 1.7388\n",
      "Epoch [11/20] Batch 680/938 Loss D: 0.3251, Loss G: 1.5769\n",
      "Epoch [11/20] Batch 690/938 Loss D: 0.4204, Loss G: 1.1921\n",
      "Epoch [11/20] Batch 700/938 Loss D: 0.3438, Loss G: 1.3290\n",
      "Epoch [11/20] Batch 710/938 Loss D: 0.3729, Loss G: 1.6183\n",
      "Epoch [11/20] Batch 720/938 Loss D: 0.3470, Loss G: 1.5402\n",
      "Epoch [11/20] Batch 730/938 Loss D: 0.2810, Loss G: 1.7002\n",
      "Epoch [11/20] Batch 740/938 Loss D: 0.3777, Loss G: 1.3554\n",
      "Epoch [11/20] Batch 750/938 Loss D: 0.3810, Loss G: 1.3523\n",
      "Epoch [11/20] Batch 760/938 Loss D: 0.3046, Loss G: 1.5703\n",
      "Epoch [11/20] Batch 770/938 Loss D: 0.3607, Loss G: 1.2661\n",
      "Epoch [11/20] Batch 780/938 Loss D: 0.3281, Loss G: 1.4687\n",
      "Epoch [11/20] Batch 790/938 Loss D: 0.3316, Loss G: 1.5971\n",
      "Epoch [11/20] Batch 800/938 Loss D: 0.3491, Loss G: 1.4286\n",
      "Epoch [11/20] Batch 810/938 Loss D: 0.3170, Loss G: 1.5624\n",
      "Epoch [11/20] Batch 820/938 Loss D: 0.2903, Loss G: 1.7800\n",
      "Epoch [11/20] Batch 830/938 Loss D: 0.3387, Loss G: 1.5766\n",
      "Epoch [11/20] Batch 840/938 Loss D: 0.3324, Loss G: 1.4549\n",
      "Epoch [11/20] Batch 850/938 Loss D: 0.3270, Loss G: 1.4839\n",
      "Epoch [11/20] Batch 860/938 Loss D: 0.3868, Loss G: 1.4576\n",
      "Epoch [11/20] Batch 870/938 Loss D: 0.3198, Loss G: 1.5297\n",
      "Epoch [11/20] Batch 880/938 Loss D: 0.3687, Loss G: 1.4669\n",
      "Epoch [11/20] Batch 890/938 Loss D: 0.3525, Loss G: 1.4261\n",
      "Epoch [11/20] Batch 900/938 Loss D: 0.3168, Loss G: 1.4807\n",
      "Epoch [11/20] Batch 910/938 Loss D: 0.3777, Loss G: 1.3765\n",
      "Epoch [11/20] Batch 920/938 Loss D: 0.3614, Loss G: 1.4036\n",
      "Epoch [11/20] Batch 930/938 Loss D: 0.3670, Loss G: 1.3100\n",
      "Epoch [12/20] Batch 0/938 Loss D: 0.2791, Loss G: 1.5926\n",
      "Epoch [12/20] Batch 10/938 Loss D: 0.3013, Loss G: 1.5662\n",
      "Epoch [12/20] Batch 20/938 Loss D: 0.3752, Loss G: 1.3508\n",
      "Epoch [12/20] Batch 30/938 Loss D: 0.3457, Loss G: 1.5928\n",
      "Epoch [12/20] Batch 40/938 Loss D: 0.2937, Loss G: 1.6178\n",
      "Epoch [12/20] Batch 50/938 Loss D: 0.3453, Loss G: 1.4597\n",
      "Epoch [12/20] Batch 60/938 Loss D: 0.4120, Loss G: 1.4067\n",
      "Epoch [12/20] Batch 70/938 Loss D: 0.3254, Loss G: 1.6045\n",
      "Epoch [12/20] Batch 80/938 Loss D: 0.3544, Loss G: 1.2676\n",
      "Epoch [12/20] Batch 90/938 Loss D: 0.2895, Loss G: 1.5402\n",
      "Epoch [12/20] Batch 100/938 Loss D: 0.2835, Loss G: 1.5998\n",
      "Epoch [12/20] Batch 110/938 Loss D: 0.3516, Loss G: 1.2898\n",
      "Epoch [12/20] Batch 120/938 Loss D: 0.3372, Loss G: 1.2879\n",
      "Epoch [12/20] Batch 130/938 Loss D: 0.3744, Loss G: 1.3551\n",
      "Epoch [12/20] Batch 140/938 Loss D: 0.3659, Loss G: 1.7470\n",
      "Epoch [12/20] Batch 150/938 Loss D: 0.3653, Loss G: 1.6662\n",
      "Epoch [12/20] Batch 160/938 Loss D: 0.3098, Loss G: 1.4869\n",
      "Epoch [12/20] Batch 170/938 Loss D: 0.3526, Loss G: 1.4109\n",
      "Epoch [12/20] Batch 180/938 Loss D: 0.2932, Loss G: 1.4002\n",
      "Epoch [12/20] Batch 190/938 Loss D: 0.3276, Loss G: 1.4023\n",
      "Epoch [12/20] Batch 200/938 Loss D: 0.3415, Loss G: 1.5343\n",
      "Epoch [12/20] Batch 210/938 Loss D: 0.3193, Loss G: 1.6052\n",
      "Epoch [12/20] Batch 220/938 Loss D: 0.3410, Loss G: 1.2521\n",
      "Epoch [12/20] Batch 230/938 Loss D: 0.2881, Loss G: 1.5862\n",
      "Epoch [12/20] Batch 240/938 Loss D: 0.3543, Loss G: 1.5497\n",
      "Epoch [12/20] Batch 250/938 Loss D: 0.3276, Loss G: 1.4890\n",
      "Epoch [12/20] Batch 260/938 Loss D: 0.3459, Loss G: 1.3922\n",
      "Epoch [12/20] Batch 270/938 Loss D: 0.3341, Loss G: 1.4707\n",
      "Epoch [12/20] Batch 280/938 Loss D: 0.2865, Loss G: 1.6044\n",
      "Epoch [12/20] Batch 290/938 Loss D: 0.3149, Loss G: 1.5395\n",
      "Epoch [12/20] Batch 300/938 Loss D: 0.3536, Loss G: 1.4192\n",
      "Epoch [12/20] Batch 310/938 Loss D: 0.3210, Loss G: 1.6055\n",
      "Epoch [12/20] Batch 320/938 Loss D: 0.3862, Loss G: 1.5150\n",
      "Epoch [12/20] Batch 330/938 Loss D: 0.3649, Loss G: 1.5354\n",
      "Epoch [12/20] Batch 340/938 Loss D: 0.3207, Loss G: 1.6116\n",
      "Epoch [12/20] Batch 350/938 Loss D: 0.3641, Loss G: 1.5372\n",
      "Epoch [12/20] Batch 360/938 Loss D: 0.2725, Loss G: 1.5308\n",
      "Epoch [12/20] Batch 370/938 Loss D: 0.3424, Loss G: 1.4557\n",
      "Epoch [12/20] Batch 380/938 Loss D: 0.3693, Loss G: 1.6309\n",
      "Epoch [12/20] Batch 390/938 Loss D: 0.2797, Loss G: 1.6715\n",
      "Epoch [12/20] Batch 400/938 Loss D: 0.3217, Loss G: 1.5331\n",
      "Epoch [12/20] Batch 410/938 Loss D: 0.3105, Loss G: 1.5723\n",
      "Epoch [12/20] Batch 420/938 Loss D: 0.3789, Loss G: 1.4925\n",
      "Epoch [12/20] Batch 430/938 Loss D: 0.3840, Loss G: 1.4149\n",
      "Epoch [12/20] Batch 440/938 Loss D: 0.3103, Loss G: 1.4303\n",
      "Epoch [12/20] Batch 450/938 Loss D: 0.3103, Loss G: 1.3379\n",
      "Epoch [12/20] Batch 460/938 Loss D: 0.3683, Loss G: 1.2424\n",
      "Epoch [12/20] Batch 470/938 Loss D: 0.3284, Loss G: 1.5606\n",
      "Epoch [12/20] Batch 480/938 Loss D: 0.3476, Loss G: 1.2856\n",
      "Epoch [12/20] Batch 490/938 Loss D: 0.2986, Loss G: 1.5478\n",
      "Epoch [12/20] Batch 500/938 Loss D: 0.3239, Loss G: 1.3336\n",
      "Epoch [12/20] Batch 510/938 Loss D: 0.3285, Loss G: 1.3907\n",
      "Epoch [12/20] Batch 520/938 Loss D: 0.3893, Loss G: 1.3445\n",
      "Epoch [12/20] Batch 530/938 Loss D: 0.2901, Loss G: 1.6529\n",
      "Epoch [12/20] Batch 540/938 Loss D: 0.3258, Loss G: 1.5139\n",
      "Epoch [12/20] Batch 550/938 Loss D: 0.3716, Loss G: 1.3024\n",
      "Epoch [12/20] Batch 560/938 Loss D: 0.3725, Loss G: 1.3880\n",
      "Epoch [12/20] Batch 570/938 Loss D: 0.3331, Loss G: 1.4758\n",
      "Epoch [12/20] Batch 580/938 Loss D: 0.3728, Loss G: 1.4816\n",
      "Epoch [12/20] Batch 590/938 Loss D: 0.3259, Loss G: 1.5268\n",
      "Epoch [12/20] Batch 600/938 Loss D: 0.3201, Loss G: 1.4371\n",
      "Epoch [12/20] Batch 610/938 Loss D: 0.3663, Loss G: 1.3508\n",
      "Epoch [12/20] Batch 620/938 Loss D: 0.3517, Loss G: 1.3709\n",
      "Epoch [12/20] Batch 630/938 Loss D: 0.3078, Loss G: 1.4870\n",
      "Epoch [12/20] Batch 640/938 Loss D: 0.3279, Loss G: 1.6636\n",
      "Epoch [12/20] Batch 650/938 Loss D: 0.3444, Loss G: 1.5208\n",
      "Epoch [12/20] Batch 660/938 Loss D: 0.4082, Loss G: 1.2974\n",
      "Epoch [12/20] Batch 670/938 Loss D: 0.3322, Loss G: 1.5223\n",
      "Epoch [12/20] Batch 680/938 Loss D: 0.3129, Loss G: 1.6292\n",
      "Epoch [12/20] Batch 690/938 Loss D: 0.3752, Loss G: 1.4504\n",
      "Epoch [12/20] Batch 700/938 Loss D: 0.3584, Loss G: 1.4123\n",
      "Epoch [12/20] Batch 710/938 Loss D: 0.2909, Loss G: 1.3930\n",
      "Epoch [12/20] Batch 720/938 Loss D: 0.3719, Loss G: 1.4880\n",
      "Epoch [12/20] Batch 730/938 Loss D: 0.2890, Loss G: 1.6461\n",
      "Epoch [12/20] Batch 740/938 Loss D: 0.3263, Loss G: 1.5091\n",
      "Epoch [12/20] Batch 750/938 Loss D: 0.3469, Loss G: 1.5236\n",
      "Epoch [12/20] Batch 760/938 Loss D: 0.3315, Loss G: 1.6233\n",
      "Epoch [12/20] Batch 770/938 Loss D: 0.3212, Loss G: 1.4545\n",
      "Epoch [12/20] Batch 780/938 Loss D: 0.3489, Loss G: 1.2712\n",
      "Epoch [12/20] Batch 790/938 Loss D: 0.3389, Loss G: 1.5334\n",
      "Epoch [12/20] Batch 800/938 Loss D: 0.3384, Loss G: 1.4107\n",
      "Epoch [12/20] Batch 810/938 Loss D: 0.4011, Loss G: 1.7519\n",
      "Epoch [12/20] Batch 820/938 Loss D: 0.3271, Loss G: 1.4073\n",
      "Epoch [12/20] Batch 830/938 Loss D: 0.3060, Loss G: 1.5874\n",
      "Epoch [12/20] Batch 840/938 Loss D: 0.3081, Loss G: 1.5443\n",
      "Epoch [12/20] Batch 850/938 Loss D: 0.3437, Loss G: 1.4595\n",
      "Epoch [12/20] Batch 860/938 Loss D: 0.3574, Loss G: 1.7529\n",
      "Epoch [12/20] Batch 870/938 Loss D: 0.2802, Loss G: 1.5802\n",
      "Epoch [12/20] Batch 880/938 Loss D: 0.3215, Loss G: 1.5273\n",
      "Epoch [12/20] Batch 890/938 Loss D: 0.3572, Loss G: 1.7114\n",
      "Epoch [12/20] Batch 900/938 Loss D: 0.3328, Loss G: 1.4174\n",
      "Epoch [12/20] Batch 910/938 Loss D: 0.3507, Loss G: 1.4030\n",
      "Epoch [12/20] Batch 920/938 Loss D: 0.2897, Loss G: 1.6305\n",
      "Epoch [12/20] Batch 930/938 Loss D: 0.3783, Loss G: 1.3084\n",
      "Epoch [13/20] Batch 0/938 Loss D: 0.3203, Loss G: 1.5639\n",
      "Epoch [13/20] Batch 10/938 Loss D: 0.3147, Loss G: 1.5086\n",
      "Epoch [13/20] Batch 20/938 Loss D: 0.3687, Loss G: 1.3405\n",
      "Epoch [13/20] Batch 30/938 Loss D: 0.3022, Loss G: 1.4307\n",
      "Epoch [13/20] Batch 40/938 Loss D: 0.3073, Loss G: 1.4964\n",
      "Epoch [13/20] Batch 50/938 Loss D: 0.3592, Loss G: 1.5167\n",
      "Epoch [13/20] Batch 60/938 Loss D: 0.3496, Loss G: 1.3595\n",
      "Epoch [13/20] Batch 70/938 Loss D: 0.3700, Loss G: 1.2249\n",
      "Epoch [13/20] Batch 80/938 Loss D: 0.3028, Loss G: 1.6030\n",
      "Epoch [13/20] Batch 90/938 Loss D: 0.2952, Loss G: 1.6157\n",
      "Epoch [13/20] Batch 100/938 Loss D: 0.3204, Loss G: 1.5361\n",
      "Epoch [13/20] Batch 110/938 Loss D: 0.3068, Loss G: 1.5187\n",
      "Epoch [13/20] Batch 120/938 Loss D: 0.3507, Loss G: 1.5646\n",
      "Epoch [13/20] Batch 130/938 Loss D: 0.2993, Loss G: 1.5190\n",
      "Epoch [13/20] Batch 140/938 Loss D: 0.3694, Loss G: 1.4745\n",
      "Epoch [13/20] Batch 150/938 Loss D: 0.3064, Loss G: 1.5690\n",
      "Epoch [13/20] Batch 160/938 Loss D: 0.3548, Loss G: 1.4237\n",
      "Epoch [13/20] Batch 170/938 Loss D: 0.3762, Loss G: 1.2735\n",
      "Epoch [13/20] Batch 180/938 Loss D: 0.3234, Loss G: 1.4015\n",
      "Epoch [13/20] Batch 190/938 Loss D: 0.3161, Loss G: 1.6787\n",
      "Epoch [13/20] Batch 200/938 Loss D: 0.3077, Loss G: 1.4382\n",
      "Epoch [13/20] Batch 210/938 Loss D: 0.3458, Loss G: 1.4491\n",
      "Epoch [13/20] Batch 220/938 Loss D: 0.3805, Loss G: 1.6612\n",
      "Epoch [13/20] Batch 230/938 Loss D: 0.3222, Loss G: 1.4858\n",
      "Epoch [13/20] Batch 240/938 Loss D: 0.3601, Loss G: 1.2799\n",
      "Epoch [13/20] Batch 250/938 Loss D: 0.3473, Loss G: 1.4215\n",
      "Epoch [13/20] Batch 260/938 Loss D: 0.3839, Loss G: 1.4201\n",
      "Epoch [13/20] Batch 270/938 Loss D: 0.2925, Loss G: 1.5663\n",
      "Epoch [13/20] Batch 280/938 Loss D: 0.3454, Loss G: 1.3911\n",
      "Epoch [13/20] Batch 290/938 Loss D: 0.3590, Loss G: 1.5963\n",
      "Epoch [13/20] Batch 300/938 Loss D: 0.3854, Loss G: 1.4171\n",
      "Epoch [13/20] Batch 310/938 Loss D: 0.3426, Loss G: 1.4110\n",
      "Epoch [13/20] Batch 320/938 Loss D: 0.3362, Loss G: 1.5084\n",
      "Epoch [13/20] Batch 330/938 Loss D: 0.3368, Loss G: 1.5261\n",
      "Epoch [13/20] Batch 340/938 Loss D: 0.3317, Loss G: 1.5274\n",
      "Epoch [13/20] Batch 350/938 Loss D: 0.3450, Loss G: 1.4943\n",
      "Epoch [13/20] Batch 360/938 Loss D: 0.3909, Loss G: 1.4703\n",
      "Epoch [13/20] Batch 370/938 Loss D: 0.3405, Loss G: 1.3802\n",
      "Epoch [13/20] Batch 380/938 Loss D: 0.3572, Loss G: 1.3606\n",
      "Epoch [13/20] Batch 390/938 Loss D: 0.3426, Loss G: 1.6070\n",
      "Epoch [13/20] Batch 400/938 Loss D: 0.2780, Loss G: 1.7259\n",
      "Epoch [13/20] Batch 410/938 Loss D: 0.3651, Loss G: 1.3224\n",
      "Epoch [13/20] Batch 420/938 Loss D: 0.3673, Loss G: 1.4730\n",
      "Epoch [13/20] Batch 430/938 Loss D: 0.2907, Loss G: 1.7639\n",
      "Epoch [13/20] Batch 440/938 Loss D: 0.3797, Loss G: 1.5049\n",
      "Epoch [13/20] Batch 450/938 Loss D: 0.3129, Loss G: 1.3701\n",
      "Epoch [13/20] Batch 460/938 Loss D: 0.3941, Loss G: 1.4652\n",
      "Epoch [13/20] Batch 470/938 Loss D: 0.3295, Loss G: 1.8255\n",
      "Epoch [13/20] Batch 480/938 Loss D: 0.2548, Loss G: 1.8149\n",
      "Epoch [13/20] Batch 490/938 Loss D: 0.3138, Loss G: 1.4129\n",
      "Epoch [13/20] Batch 500/938 Loss D: 0.3223, Loss G: 1.4009\n",
      "Epoch [13/20] Batch 510/938 Loss D: 0.3170, Loss G: 1.4796\n",
      "Epoch [13/20] Batch 520/938 Loss D: 0.3349, Loss G: 1.6174\n",
      "Epoch [13/20] Batch 530/938 Loss D: 0.3133, Loss G: 1.6589\n",
      "Epoch [13/20] Batch 540/938 Loss D: 0.3726, Loss G: 1.2019\n",
      "Epoch [13/20] Batch 550/938 Loss D: 0.2944, Loss G: 1.6734\n",
      "Epoch [13/20] Batch 560/938 Loss D: 0.2765, Loss G: 1.6658\n",
      "Epoch [13/20] Batch 570/938 Loss D: 0.3290, Loss G: 1.4002\n",
      "Epoch [13/20] Batch 580/938 Loss D: 0.2852, Loss G: 1.5296\n",
      "Epoch [13/20] Batch 590/938 Loss D: 0.3993, Loss G: 1.5613\n",
      "Epoch [13/20] Batch 600/938 Loss D: 0.4058, Loss G: 1.2859\n",
      "Epoch [13/20] Batch 610/938 Loss D: 0.2780, Loss G: 1.6703\n",
      "Epoch [13/20] Batch 620/938 Loss D: 0.3271, Loss G: 1.6818\n",
      "Epoch [13/20] Batch 630/938 Loss D: 0.2960, Loss G: 1.6668\n",
      "Epoch [13/20] Batch 640/938 Loss D: 0.3125, Loss G: 1.6269\n",
      "Epoch [13/20] Batch 650/938 Loss D: 0.3354, Loss G: 1.3413\n",
      "Epoch [13/20] Batch 660/938 Loss D: 0.3216, Loss G: 1.4567\n",
      "Epoch [13/20] Batch 670/938 Loss D: 0.3182, Loss G: 1.7251\n",
      "Epoch [13/20] Batch 680/938 Loss D: 0.3014, Loss G: 1.7063\n",
      "Epoch [13/20] Batch 690/938 Loss D: 0.3046, Loss G: 1.7453\n",
      "Epoch [13/20] Batch 700/938 Loss D: 0.3589, Loss G: 1.4063\n",
      "Epoch [13/20] Batch 710/938 Loss D: 0.3506, Loss G: 1.5329\n",
      "Epoch [13/20] Batch 720/938 Loss D: 0.3276, Loss G: 1.7362\n",
      "Epoch [13/20] Batch 730/938 Loss D: 0.3444, Loss G: 1.3642\n",
      "Epoch [13/20] Batch 740/938 Loss D: 0.3851, Loss G: 1.3104\n",
      "Epoch [13/20] Batch 750/938 Loss D: 0.3463, Loss G: 1.5558\n",
      "Epoch [13/20] Batch 760/938 Loss D: 0.3174, Loss G: 1.6077\n",
      "Epoch [13/20] Batch 770/938 Loss D: 0.3122, Loss G: 1.7966\n",
      "Epoch [13/20] Batch 780/938 Loss D: 0.3391, Loss G: 1.4339\n",
      "Epoch [13/20] Batch 790/938 Loss D: 0.2840, Loss G: 1.4947\n",
      "Epoch [13/20] Batch 800/938 Loss D: 0.2639, Loss G: 1.7154\n",
      "Epoch [13/20] Batch 810/938 Loss D: 0.3503, Loss G: 1.4496\n",
      "Epoch [13/20] Batch 820/938 Loss D: 0.3090, Loss G: 1.5403\n",
      "Epoch [13/20] Batch 830/938 Loss D: 0.3467, Loss G: 1.5772\n",
      "Epoch [13/20] Batch 840/938 Loss D: 0.3146, Loss G: 1.4650\n",
      "Epoch [13/20] Batch 850/938 Loss D: 0.4011, Loss G: 1.2968\n",
      "Epoch [13/20] Batch 860/938 Loss D: 0.3289, Loss G: 1.6545\n",
      "Epoch [13/20] Batch 870/938 Loss D: 0.3613, Loss G: 1.4755\n",
      "Epoch [13/20] Batch 880/938 Loss D: 0.3557, Loss G: 1.3844\n",
      "Epoch [13/20] Batch 890/938 Loss D: 0.3167, Loss G: 1.4683\n",
      "Epoch [13/20] Batch 900/938 Loss D: 0.3706, Loss G: 1.5677\n",
      "Epoch [13/20] Batch 910/938 Loss D: 0.2958, Loss G: 1.5148\n",
      "Epoch [13/20] Batch 920/938 Loss D: 0.3339, Loss G: 1.5483\n",
      "Epoch [13/20] Batch 930/938 Loss D: 0.3702, Loss G: 1.4847\n",
      "Epoch [14/20] Batch 0/938 Loss D: 0.3100, Loss G: 1.6457\n",
      "Epoch [14/20] Batch 10/938 Loss D: 0.3546, Loss G: 1.6787\n",
      "Epoch [14/20] Batch 20/938 Loss D: 0.2977, Loss G: 1.7011\n",
      "Epoch [14/20] Batch 30/938 Loss D: 0.2597, Loss G: 1.8077\n",
      "Epoch [14/20] Batch 40/938 Loss D: 0.3033, Loss G: 1.6592\n",
      "Epoch [14/20] Batch 50/938 Loss D: 0.3068, Loss G: 1.4902\n",
      "Epoch [14/20] Batch 60/938 Loss D: 0.3412, Loss G: 1.6144\n",
      "Epoch [14/20] Batch 70/938 Loss D: 0.3246, Loss G: 1.4821\n",
      "Epoch [14/20] Batch 80/938 Loss D: 0.3197, Loss G: 1.4295\n",
      "Epoch [14/20] Batch 90/938 Loss D: 0.3165, Loss G: 1.5314\n",
      "Epoch [14/20] Batch 100/938 Loss D: 0.3103, Loss G: 1.4953\n",
      "Epoch [14/20] Batch 110/938 Loss D: 0.2983, Loss G: 1.6581\n",
      "Epoch [14/20] Batch 120/938 Loss D: 0.3554, Loss G: 1.5570\n",
      "Epoch [14/20] Batch 130/938 Loss D: 0.3309, Loss G: 1.6117\n",
      "Epoch [14/20] Batch 140/938 Loss D: 0.3277, Loss G: 1.5699\n",
      "Epoch [14/20] Batch 150/938 Loss D: 0.3171, Loss G: 1.5961\n",
      "Epoch [14/20] Batch 160/938 Loss D: 0.3235, Loss G: 1.5300\n",
      "Epoch [14/20] Batch 170/938 Loss D: 0.2370, Loss G: 1.8531\n",
      "Epoch [14/20] Batch 180/938 Loss D: 0.4347, Loss G: 1.4184\n",
      "Epoch [14/20] Batch 190/938 Loss D: 0.3110, Loss G: 1.4301\n",
      "Epoch [14/20] Batch 200/938 Loss D: 0.4021, Loss G: 1.3084\n",
      "Epoch [14/20] Batch 210/938 Loss D: 0.3631, Loss G: 1.5653\n",
      "Epoch [14/20] Batch 220/938 Loss D: 0.3060, Loss G: 1.3868\n",
      "Epoch [14/20] Batch 230/938 Loss D: 0.2874, Loss G: 1.6019\n",
      "Epoch [14/20] Batch 240/938 Loss D: 0.2812, Loss G: 1.7205\n",
      "Epoch [14/20] Batch 250/938 Loss D: 0.3228, Loss G: 1.4280\n",
      "Epoch [14/20] Batch 260/938 Loss D: 0.3585, Loss G: 1.3945\n",
      "Epoch [14/20] Batch 270/938 Loss D: 0.3298, Loss G: 1.4802\n",
      "Epoch [14/20] Batch 280/938 Loss D: 0.2778, Loss G: 1.8000\n",
      "Epoch [14/20] Batch 290/938 Loss D: 0.3479, Loss G: 1.4383\n",
      "Epoch [14/20] Batch 300/938 Loss D: 0.3000, Loss G: 1.4146\n",
      "Epoch [14/20] Batch 310/938 Loss D: 0.3431, Loss G: 1.4575\n",
      "Epoch [14/20] Batch 320/938 Loss D: 0.3068, Loss G: 1.3895\n",
      "Epoch [14/20] Batch 330/938 Loss D: 0.3338, Loss G: 1.6661\n",
      "Epoch [14/20] Batch 340/938 Loss D: 0.3473, Loss G: 1.5325\n",
      "Epoch [14/20] Batch 350/938 Loss D: 0.2743, Loss G: 1.4786\n",
      "Epoch [14/20] Batch 360/938 Loss D: 0.3140, Loss G: 1.3969\n",
      "Epoch [14/20] Batch 370/938 Loss D: 0.3384, Loss G: 1.6543\n",
      "Epoch [14/20] Batch 380/938 Loss D: 0.3507, Loss G: 1.5275\n",
      "Epoch [14/20] Batch 390/938 Loss D: 0.3659, Loss G: 1.5507\n",
      "Epoch [14/20] Batch 400/938 Loss D: 0.3233, Loss G: 1.6665\n",
      "Epoch [14/20] Batch 410/938 Loss D: 0.3167, Loss G: 1.4942\n",
      "Epoch [14/20] Batch 420/938 Loss D: 0.4067, Loss G: 1.3935\n",
      "Epoch [14/20] Batch 430/938 Loss D: 0.3312, Loss G: 1.5058\n",
      "Epoch [14/20] Batch 440/938 Loss D: 0.3274, Loss G: 1.6470\n",
      "Epoch [14/20] Batch 450/938 Loss D: 0.3304, Loss G: 1.6153\n",
      "Epoch [14/20] Batch 460/938 Loss D: 0.3245, Loss G: 1.5565\n",
      "Epoch [14/20] Batch 470/938 Loss D: 0.3075, Loss G: 1.3695\n",
      "Epoch [14/20] Batch 480/938 Loss D: 0.3408, Loss G: 1.4796\n",
      "Epoch [14/20] Batch 490/938 Loss D: 0.3115, Loss G: 1.6843\n",
      "Epoch [14/20] Batch 500/938 Loss D: 0.3012, Loss G: 1.6869\n",
      "Epoch [14/20] Batch 510/938 Loss D: 0.2667, Loss G: 1.9367\n",
      "Epoch [14/20] Batch 520/938 Loss D: 0.2900, Loss G: 1.6691\n",
      "Epoch [14/20] Batch 530/938 Loss D: 0.3725, Loss G: 1.3856\n",
      "Epoch [14/20] Batch 540/938 Loss D: 0.3249, Loss G: 1.7478\n",
      "Epoch [14/20] Batch 550/938 Loss D: 0.3037, Loss G: 1.6047\n",
      "Epoch [14/20] Batch 560/938 Loss D: 0.3249, Loss G: 1.7211\n",
      "Epoch [14/20] Batch 570/938 Loss D: 0.3162, Loss G: 1.5864\n",
      "Epoch [14/20] Batch 580/938 Loss D: 0.2891, Loss G: 1.7384\n",
      "Epoch [14/20] Batch 590/938 Loss D: 0.3530, Loss G: 1.4965\n",
      "Epoch [14/20] Batch 600/938 Loss D: 0.3013, Loss G: 1.5832\n",
      "Epoch [14/20] Batch 610/938 Loss D: 0.2702, Loss G: 1.7547\n",
      "Epoch [14/20] Batch 620/938 Loss D: 0.2985, Loss G: 1.4422\n",
      "Epoch [14/20] Batch 630/938 Loss D: 0.2703, Loss G: 1.8144\n",
      "Epoch [14/20] Batch 640/938 Loss D: 0.3214, Loss G: 1.6369\n",
      "Epoch [14/20] Batch 650/938 Loss D: 0.3348, Loss G: 1.6086\n",
      "Epoch [14/20] Batch 660/938 Loss D: 0.2830, Loss G: 1.6883\n",
      "Epoch [14/20] Batch 670/938 Loss D: 0.3183, Loss G: 1.6501\n",
      "Epoch [14/20] Batch 680/938 Loss D: 0.3289, Loss G: 1.5983\n",
      "Epoch [14/20] Batch 690/938 Loss D: 0.3351, Loss G: 1.5358\n",
      "Epoch [14/20] Batch 700/938 Loss D: 0.2771, Loss G: 1.7538\n",
      "Epoch [14/20] Batch 710/938 Loss D: 0.3601, Loss G: 1.5686\n",
      "Epoch [14/20] Batch 720/938 Loss D: 0.3282, Loss G: 1.7677\n",
      "Epoch [14/20] Batch 730/938 Loss D: 0.3348, Loss G: 1.6934\n",
      "Epoch [14/20] Batch 740/938 Loss D: 0.2806, Loss G: 1.7696\n",
      "Epoch [14/20] Batch 750/938 Loss D: 0.2920, Loss G: 1.6751\n",
      "Epoch [14/20] Batch 760/938 Loss D: 0.3466, Loss G: 1.2819\n",
      "Epoch [14/20] Batch 770/938 Loss D: 0.3805, Loss G: 1.3457\n",
      "Epoch [14/20] Batch 780/938 Loss D: 0.3021, Loss G: 1.7878\n",
      "Epoch [14/20] Batch 790/938 Loss D: 0.2670, Loss G: 1.8993\n",
      "Epoch [14/20] Batch 800/938 Loss D: 0.3141, Loss G: 1.4535\n",
      "Epoch [14/20] Batch 810/938 Loss D: 0.2771, Loss G: 1.7016\n",
      "Epoch [14/20] Batch 820/938 Loss D: 0.3500, Loss G: 1.5292\n",
      "Epoch [14/20] Batch 830/938 Loss D: 0.2872, Loss G: 1.7992\n",
      "Epoch [14/20] Batch 840/938 Loss D: 0.3365, Loss G: 1.4793\n",
      "Epoch [14/20] Batch 850/938 Loss D: 0.3187, Loss G: 1.5005\n",
      "Epoch [14/20] Batch 860/938 Loss D: 0.3236, Loss G: 1.5979\n",
      "Epoch [14/20] Batch 870/938 Loss D: 0.2939, Loss G: 1.9232\n",
      "Epoch [14/20] Batch 880/938 Loss D: 0.3182, Loss G: 1.6865\n",
      "Epoch [14/20] Batch 890/938 Loss D: 0.3130, Loss G: 1.5364\n",
      "Epoch [14/20] Batch 900/938 Loss D: 0.3048, Loss G: 1.4985\n",
      "Epoch [14/20] Batch 910/938 Loss D: 0.3080, Loss G: 1.7319\n",
      "Epoch [14/20] Batch 920/938 Loss D: 0.3253, Loss G: 1.6010\n",
      "Epoch [14/20] Batch 930/938 Loss D: 0.3044, Loss G: 1.5933\n",
      "Epoch [15/20] Batch 0/938 Loss D: 0.2981, Loss G: 1.5953\n",
      "Epoch [15/20] Batch 10/938 Loss D: 0.3198, Loss G: 1.7786\n",
      "Epoch [15/20] Batch 20/938 Loss D: 0.3014, Loss G: 1.7175\n",
      "Epoch [15/20] Batch 30/938 Loss D: 0.3503, Loss G: 1.5263\n",
      "Epoch [15/20] Batch 40/938 Loss D: 0.3143, Loss G: 1.6369\n",
      "Epoch [15/20] Batch 50/938 Loss D: 0.3654, Loss G: 1.5059\n",
      "Epoch [15/20] Batch 60/938 Loss D: 0.3028, Loss G: 1.5241\n",
      "Epoch [15/20] Batch 70/938 Loss D: 0.3360, Loss G: 1.4980\n",
      "Epoch [15/20] Batch 80/938 Loss D: 0.4146, Loss G: 1.6491\n",
      "Epoch [15/20] Batch 90/938 Loss D: 0.2943, Loss G: 1.8674\n",
      "Epoch [15/20] Batch 100/938 Loss D: 0.4273, Loss G: 1.4966\n",
      "Epoch [15/20] Batch 110/938 Loss D: 0.3137, Loss G: 1.6695\n",
      "Epoch [15/20] Batch 120/938 Loss D: 0.3124, Loss G: 1.4830\n",
      "Epoch [15/20] Batch 130/938 Loss D: 0.3627, Loss G: 1.4216\n",
      "Epoch [15/20] Batch 140/938 Loss D: 0.3639, Loss G: 1.6394\n",
      "Epoch [15/20] Batch 150/938 Loss D: 0.3628, Loss G: 1.5411\n",
      "Epoch [15/20] Batch 160/938 Loss D: 0.3153, Loss G: 1.5907\n",
      "Epoch [15/20] Batch 170/938 Loss D: 0.2811, Loss G: 1.6134\n",
      "Epoch [15/20] Batch 180/938 Loss D: 0.3374, Loss G: 1.5500\n",
      "Epoch [15/20] Batch 190/938 Loss D: 0.2790, Loss G: 1.8319\n",
      "Epoch [15/20] Batch 200/938 Loss D: 0.3189, Loss G: 1.6364\n",
      "Epoch [15/20] Batch 210/938 Loss D: 0.3123, Loss G: 1.6357\n",
      "Epoch [15/20] Batch 220/938 Loss D: 0.2911, Loss G: 1.6259\n",
      "Epoch [15/20] Batch 230/938 Loss D: 0.3133, Loss G: 1.6016\n",
      "Epoch [15/20] Batch 240/938 Loss D: 0.2972, Loss G: 1.6463\n",
      "Epoch [15/20] Batch 250/938 Loss D: 0.3186, Loss G: 1.7085\n",
      "Epoch [15/20] Batch 260/938 Loss D: 0.3066, Loss G: 1.6198\n",
      "Epoch [15/20] Batch 270/938 Loss D: 0.3717, Loss G: 1.5370\n",
      "Epoch [15/20] Batch 280/938 Loss D: 0.3152, Loss G: 1.6416\n",
      "Epoch [15/20] Batch 290/938 Loss D: 0.2940, Loss G: 1.9772\n",
      "Epoch [15/20] Batch 300/938 Loss D: 0.3337, Loss G: 1.6120\n",
      "Epoch [15/20] Batch 310/938 Loss D: 0.2999, Loss G: 1.6140\n",
      "Epoch [15/20] Batch 320/938 Loss D: 0.3213, Loss G: 1.4744\n",
      "Epoch [15/20] Batch 330/938 Loss D: 0.2722, Loss G: 1.7215\n",
      "Epoch [15/20] Batch 340/938 Loss D: 0.2908, Loss G: 1.4559\n",
      "Epoch [15/20] Batch 350/938 Loss D: 0.3388, Loss G: 1.5944\n",
      "Epoch [15/20] Batch 360/938 Loss D: 0.2986, Loss G: 1.6862\n",
      "Epoch [15/20] Batch 370/938 Loss D: 0.3064, Loss G: 1.4475\n",
      "Epoch [15/20] Batch 380/938 Loss D: 0.3702, Loss G: 1.1477\n",
      "Epoch [15/20] Batch 390/938 Loss D: 0.3018, Loss G: 1.7279\n",
      "Epoch [15/20] Batch 400/938 Loss D: 0.3186, Loss G: 1.6289\n",
      "Epoch [15/20] Batch 410/938 Loss D: 0.3707, Loss G: 1.4889\n",
      "Epoch [15/20] Batch 420/938 Loss D: 0.2650, Loss G: 1.9185\n",
      "Epoch [15/20] Batch 430/938 Loss D: 0.3005, Loss G: 1.8552\n",
      "Epoch [15/20] Batch 440/938 Loss D: 0.3579, Loss G: 1.5017\n",
      "Epoch [15/20] Batch 450/938 Loss D: 0.3291, Loss G: 1.3348\n",
      "Epoch [15/20] Batch 460/938 Loss D: 0.3121, Loss G: 1.4695\n",
      "Epoch [15/20] Batch 470/938 Loss D: 0.3004, Loss G: 1.6377\n",
      "Epoch [15/20] Batch 480/938 Loss D: 0.2852, Loss G: 1.6243\n",
      "Epoch [15/20] Batch 490/938 Loss D: 0.3658, Loss G: 1.3236\n",
      "Epoch [15/20] Batch 500/938 Loss D: 0.3215, Loss G: 1.4935\n",
      "Epoch [15/20] Batch 510/938 Loss D: 0.3488, Loss G: 1.7789\n",
      "Epoch [15/20] Batch 520/938 Loss D: 0.2975, Loss G: 1.6913\n",
      "Epoch [15/20] Batch 530/938 Loss D: 0.3904, Loss G: 1.3445\n",
      "Epoch [15/20] Batch 540/938 Loss D: 0.3728, Loss G: 1.5190\n",
      "Epoch [15/20] Batch 550/938 Loss D: 0.2759, Loss G: 1.8111\n",
      "Epoch [15/20] Batch 560/938 Loss D: 0.3128, Loss G: 1.5599\n",
      "Epoch [15/20] Batch 570/938 Loss D: 0.2876, Loss G: 1.5670\n",
      "Epoch [15/20] Batch 580/938 Loss D: 0.3010, Loss G: 1.5878\n",
      "Epoch [15/20] Batch 590/938 Loss D: 0.2938, Loss G: 1.4831\n",
      "Epoch [15/20] Batch 600/938 Loss D: 0.3513, Loss G: 1.6648\n",
      "Epoch [15/20] Batch 610/938 Loss D: 0.2825, Loss G: 1.8285\n",
      "Epoch [15/20] Batch 620/938 Loss D: 0.3647, Loss G: 1.3201\n",
      "Epoch [15/20] Batch 630/938 Loss D: 0.3536, Loss G: 1.5679\n",
      "Epoch [15/20] Batch 640/938 Loss D: 0.3307, Loss G: 1.7666\n",
      "Epoch [15/20] Batch 650/938 Loss D: 0.3626, Loss G: 1.6787\n",
      "Epoch [15/20] Batch 660/938 Loss D: 0.4036, Loss G: 1.2427\n",
      "Epoch [15/20] Batch 670/938 Loss D: 0.2760, Loss G: 1.5867\n",
      "Epoch [15/20] Batch 680/938 Loss D: 0.2967, Loss G: 1.5618\n",
      "Epoch [15/20] Batch 690/938 Loss D: 0.2643, Loss G: 1.8871\n",
      "Epoch [15/20] Batch 700/938 Loss D: 0.3528, Loss G: 1.6716\n",
      "Epoch [15/20] Batch 710/938 Loss D: 0.3311, Loss G: 1.5205\n",
      "Epoch [15/20] Batch 720/938 Loss D: 0.2649, Loss G: 1.9308\n",
      "Epoch [15/20] Batch 730/938 Loss D: 0.3253, Loss G: 1.6273\n",
      "Epoch [15/20] Batch 740/938 Loss D: 0.3349, Loss G: 1.4189\n",
      "Epoch [15/20] Batch 750/938 Loss D: 0.3335, Loss G: 1.5736\n",
      "Epoch [15/20] Batch 760/938 Loss D: 0.3600, Loss G: 1.3936\n",
      "Epoch [15/20] Batch 770/938 Loss D: 0.2823, Loss G: 1.5285\n",
      "Epoch [15/20] Batch 780/938 Loss D: 0.3658, Loss G: 1.6108\n",
      "Epoch [15/20] Batch 790/938 Loss D: 0.2994, Loss G: 1.8248\n",
      "Epoch [15/20] Batch 800/938 Loss D: 0.3303, Loss G: 1.7350\n",
      "Epoch [15/20] Batch 810/938 Loss D: 0.3197, Loss G: 1.7694\n",
      "Epoch [15/20] Batch 820/938 Loss D: 0.3435, Loss G: 1.5341\n",
      "Epoch [15/20] Batch 830/938 Loss D: 0.2729, Loss G: 1.7238\n",
      "Epoch [15/20] Batch 840/938 Loss D: 0.3245, Loss G: 1.6624\n",
      "Epoch [15/20] Batch 850/938 Loss D: 0.3230, Loss G: 1.7405\n",
      "Epoch [15/20] Batch 860/938 Loss D: 0.2980, Loss G: 1.8033\n",
      "Epoch [15/20] Batch 870/938 Loss D: 0.4008, Loss G: 1.2196\n",
      "Epoch [15/20] Batch 880/938 Loss D: 0.2598, Loss G: 1.4841\n",
      "Epoch [15/20] Batch 890/938 Loss D: 0.2921, Loss G: 1.6790\n",
      "Epoch [15/20] Batch 900/938 Loss D: 0.3066, Loss G: 1.8259\n",
      "Epoch [15/20] Batch 910/938 Loss D: 0.3098, Loss G: 1.5934\n",
      "Epoch [15/20] Batch 920/938 Loss D: 0.2905, Loss G: 1.7514\n",
      "Epoch [15/20] Batch 930/938 Loss D: 0.2878, Loss G: 1.6820\n",
      "Epoch [16/20] Batch 0/938 Loss D: 0.3536, Loss G: 1.4747\n",
      "Epoch [16/20] Batch 10/938 Loss D: 0.2889, Loss G: 1.4307\n",
      "Epoch [16/20] Batch 20/938 Loss D: 0.3353, Loss G: 1.4303\n",
      "Epoch [16/20] Batch 30/938 Loss D: 0.3867, Loss G: 1.3890\n",
      "Epoch [16/20] Batch 40/938 Loss D: 0.3267, Loss G: 1.5251\n",
      "Epoch [16/20] Batch 50/938 Loss D: 0.2707, Loss G: 1.8144\n",
      "Epoch [16/20] Batch 60/938 Loss D: 0.3151, Loss G: 1.5954\n",
      "Epoch [16/20] Batch 70/938 Loss D: 0.4669, Loss G: 1.4265\n",
      "Epoch [16/20] Batch 80/938 Loss D: 0.2903, Loss G: 1.6848\n",
      "Epoch [16/20] Batch 90/938 Loss D: 0.3265, Loss G: 1.4182\n",
      "Epoch [16/20] Batch 100/938 Loss D: 0.2786, Loss G: 1.5032\n",
      "Epoch [16/20] Batch 110/938 Loss D: 0.3024, Loss G: 1.7220\n",
      "Epoch [16/20] Batch 120/938 Loss D: 0.3261, Loss G: 1.5341\n",
      "Epoch [16/20] Batch 130/938 Loss D: 0.3743, Loss G: 1.3556\n",
      "Epoch [16/20] Batch 140/938 Loss D: 0.2943, Loss G: 1.5948\n",
      "Epoch [16/20] Batch 150/938 Loss D: 0.3310, Loss G: 1.5736\n",
      "Epoch [16/20] Batch 160/938 Loss D: 0.2615, Loss G: 1.7200\n",
      "Epoch [16/20] Batch 170/938 Loss D: 0.3071, Loss G: 1.6843\n",
      "Epoch [16/20] Batch 180/938 Loss D: 0.3437, Loss G: 1.5496\n",
      "Epoch [16/20] Batch 190/938 Loss D: 0.2834, Loss G: 1.5173\n",
      "Epoch [16/20] Batch 200/938 Loss D: 0.3337, Loss G: 1.5435\n",
      "Epoch [16/20] Batch 210/938 Loss D: 0.3527, Loss G: 1.4585\n",
      "Epoch [16/20] Batch 220/938 Loss D: 0.3179, Loss G: 1.7304\n",
      "Epoch [16/20] Batch 230/938 Loss D: 0.2764, Loss G: 1.7987\n",
      "Epoch [16/20] Batch 240/938 Loss D: 0.2709, Loss G: 1.5540\n",
      "Epoch [16/20] Batch 250/938 Loss D: 0.3576, Loss G: 1.6118\n",
      "Epoch [16/20] Batch 260/938 Loss D: 0.2976, Loss G: 1.6996\n",
      "Epoch [16/20] Batch 270/938 Loss D: 0.3381, Loss G: 1.5879\n",
      "Epoch [16/20] Batch 280/938 Loss D: 0.3319, Loss G: 1.5708\n",
      "Epoch [16/20] Batch 290/938 Loss D: 0.2603, Loss G: 1.6627\n",
      "Epoch [16/20] Batch 300/938 Loss D: 0.2855, Loss G: 1.6391\n",
      "Epoch [16/20] Batch 310/938 Loss D: 0.2796, Loss G: 1.6233\n",
      "Epoch [16/20] Batch 320/938 Loss D: 0.3655, Loss G: 1.4568\n",
      "Epoch [16/20] Batch 330/938 Loss D: 0.2922, Loss G: 1.7163\n",
      "Epoch [16/20] Batch 340/938 Loss D: 0.4018, Loss G: 1.5120\n",
      "Epoch [16/20] Batch 350/938 Loss D: 0.3130, Loss G: 1.7475\n",
      "Epoch [16/20] Batch 360/938 Loss D: 0.3393, Loss G: 1.7364\n",
      "Epoch [16/20] Batch 370/938 Loss D: 0.3404, Loss G: 1.3800\n",
      "Epoch [16/20] Batch 380/938 Loss D: 0.3690, Loss G: 1.4856\n",
      "Epoch [16/20] Batch 390/938 Loss D: 0.3579, Loss G: 1.6757\n",
      "Epoch [16/20] Batch 400/938 Loss D: 0.3486, Loss G: 1.4514\n",
      "Epoch [16/20] Batch 410/938 Loss D: 0.3544, Loss G: 1.6823\n",
      "Epoch [16/20] Batch 420/938 Loss D: 0.3207, Loss G: 1.5313\n",
      "Epoch [16/20] Batch 430/938 Loss D: 0.3081, Loss G: 1.6060\n",
      "Epoch [16/20] Batch 440/938 Loss D: 0.2504, Loss G: 2.0224\n",
      "Epoch [16/20] Batch 450/938 Loss D: 0.2591, Loss G: 1.7746\n",
      "Epoch [16/20] Batch 460/938 Loss D: 0.2856, Loss G: 1.4076\n",
      "Epoch [16/20] Batch 470/938 Loss D: 0.3353, Loss G: 1.3341\n",
      "Epoch [16/20] Batch 480/938 Loss D: 0.3386, Loss G: 1.7055\n",
      "Epoch [16/20] Batch 490/938 Loss D: 0.2929, Loss G: 1.7185\n",
      "Epoch [16/20] Batch 500/938 Loss D: 0.3442, Loss G: 1.4718\n",
      "Epoch [16/20] Batch 510/938 Loss D: 0.2343, Loss G: 1.7463\n",
      "Epoch [16/20] Batch 520/938 Loss D: 0.2965, Loss G: 1.5232\n",
      "Epoch [16/20] Batch 530/938 Loss D: 0.2904, Loss G: 1.7742\n",
      "Epoch [16/20] Batch 540/938 Loss D: 0.3223, Loss G: 1.5303\n",
      "Epoch [16/20] Batch 550/938 Loss D: 0.2834, Loss G: 1.7762\n",
      "Epoch [16/20] Batch 560/938 Loss D: 0.2901, Loss G: 1.5676\n",
      "Epoch [16/20] Batch 570/938 Loss D: 0.2738, Loss G: 1.6600\n",
      "Epoch [16/20] Batch 580/938 Loss D: 0.3563, Loss G: 1.3799\n",
      "Epoch [16/20] Batch 590/938 Loss D: 0.3482, Loss G: 1.4243\n",
      "Epoch [16/20] Batch 600/938 Loss D: 0.3147, Loss G: 1.4289\n",
      "Epoch [16/20] Batch 610/938 Loss D: 0.2646, Loss G: 1.8789\n",
      "Epoch [16/20] Batch 620/938 Loss D: 0.2949, Loss G: 1.7332\n",
      "Epoch [16/20] Batch 630/938 Loss D: 0.3197, Loss G: 1.5807\n",
      "Epoch [16/20] Batch 640/938 Loss D: 0.3618, Loss G: 1.5644\n",
      "Epoch [16/20] Batch 650/938 Loss D: 0.2818, Loss G: 1.7484\n",
      "Epoch [16/20] Batch 660/938 Loss D: 0.3133, Loss G: 1.6046\n",
      "Epoch [16/20] Batch 670/938 Loss D: 0.2922, Loss G: 1.4891\n",
      "Epoch [16/20] Batch 680/938 Loss D: 0.2879, Loss G: 1.7394\n",
      "Epoch [16/20] Batch 690/938 Loss D: 0.3412, Loss G: 1.5078\n",
      "Epoch [16/20] Batch 700/938 Loss D: 0.2727, Loss G: 1.4930\n",
      "Epoch [16/20] Batch 710/938 Loss D: 0.2771, Loss G: 1.4358\n",
      "Epoch [16/20] Batch 720/938 Loss D: 0.3013, Loss G: 1.7754\n",
      "Epoch [16/20] Batch 730/938 Loss D: 0.3276, Loss G: 1.3701\n",
      "Epoch [16/20] Batch 740/938 Loss D: 0.2768, Loss G: 1.6509\n",
      "Epoch [16/20] Batch 750/938 Loss D: 0.3372, Loss G: 1.6649\n",
      "Epoch [16/20] Batch 760/938 Loss D: 0.3554, Loss G: 1.4124\n",
      "Epoch [16/20] Batch 770/938 Loss D: 0.3468, Loss G: 1.6175\n",
      "Epoch [16/20] Batch 780/938 Loss D: 0.3389, Loss G: 1.6871\n",
      "Epoch [16/20] Batch 790/938 Loss D: 0.2533, Loss G: 1.9518\n",
      "Epoch [16/20] Batch 800/938 Loss D: 0.3057, Loss G: 1.5786\n",
      "Epoch [16/20] Batch 810/938 Loss D: 0.2960, Loss G: 1.5927\n",
      "Epoch [16/20] Batch 820/938 Loss D: 0.2840, Loss G: 1.8828\n",
      "Epoch [16/20] Batch 830/938 Loss D: 0.2370, Loss G: 1.7669\n",
      "Epoch [16/20] Batch 840/938 Loss D: 0.3437, Loss G: 1.5480\n",
      "Epoch [16/20] Batch 850/938 Loss D: 0.3115, Loss G: 1.5123\n",
      "Epoch [16/20] Batch 860/938 Loss D: 0.3417, Loss G: 1.6688\n",
      "Epoch [16/20] Batch 870/938 Loss D: 0.3168, Loss G: 1.5022\n",
      "Epoch [16/20] Batch 880/938 Loss D: 0.3021, Loss G: 1.6763\n",
      "Epoch [16/20] Batch 890/938 Loss D: 0.3472, Loss G: 1.4130\n",
      "Epoch [16/20] Batch 900/938 Loss D: 0.2400, Loss G: 1.7098\n",
      "Epoch [16/20] Batch 910/938 Loss D: 0.2895, Loss G: 1.7107\n",
      "Epoch [16/20] Batch 920/938 Loss D: 0.2515, Loss G: 1.7764\n",
      "Epoch [16/20] Batch 930/938 Loss D: 0.3460, Loss G: 1.6918\n",
      "Epoch [17/20] Batch 0/938 Loss D: 0.3008, Loss G: 1.5839\n",
      "Epoch [17/20] Batch 10/938 Loss D: 0.3288, Loss G: 1.5377\n",
      "Epoch [17/20] Batch 20/938 Loss D: 0.3106, Loss G: 1.6637\n",
      "Epoch [17/20] Batch 30/938 Loss D: 0.3139, Loss G: 1.7016\n",
      "Epoch [17/20] Batch 40/938 Loss D: 0.2665, Loss G: 1.6867\n",
      "Epoch [17/20] Batch 50/938 Loss D: 0.2961, Loss G: 1.6076\n",
      "Epoch [17/20] Batch 60/938 Loss D: 0.2693, Loss G: 1.6739\n",
      "Epoch [17/20] Batch 70/938 Loss D: 0.3045, Loss G: 1.5406\n",
      "Epoch [17/20] Batch 80/938 Loss D: 0.3468, Loss G: 1.6414\n",
      "Epoch [17/20] Batch 90/938 Loss D: 0.2850, Loss G: 1.4223\n",
      "Epoch [17/20] Batch 100/938 Loss D: 0.2998, Loss G: 1.3502\n",
      "Epoch [17/20] Batch 110/938 Loss D: 0.3054, Loss G: 1.6359\n",
      "Epoch [17/20] Batch 120/938 Loss D: 0.2633, Loss G: 1.7511\n",
      "Epoch [17/20] Batch 130/938 Loss D: 0.2764, Loss G: 1.6510\n",
      "Epoch [17/20] Batch 140/938 Loss D: 0.3007, Loss G: 1.6329\n",
      "Epoch [17/20] Batch 150/938 Loss D: 0.4197, Loss G: 1.5442\n",
      "Epoch [17/20] Batch 160/938 Loss D: 0.3522, Loss G: 1.6121\n",
      "Epoch [17/20] Batch 170/938 Loss D: 0.3453, Loss G: 1.5668\n",
      "Epoch [17/20] Batch 180/938 Loss D: 0.3344, Loss G: 1.6056\n",
      "Epoch [17/20] Batch 190/938 Loss D: 0.3021, Loss G: 1.6844\n",
      "Epoch [17/20] Batch 200/938 Loss D: 0.2856, Loss G: 1.6296\n",
      "Epoch [17/20] Batch 210/938 Loss D: 0.3153, Loss G: 1.8534\n",
      "Epoch [17/20] Batch 220/938 Loss D: 0.2970, Loss G: 1.7165\n",
      "Epoch [17/20] Batch 230/938 Loss D: 0.3428, Loss G: 1.4814\n",
      "Epoch [17/20] Batch 240/938 Loss D: 0.3178, Loss G: 1.6242\n",
      "Epoch [17/20] Batch 250/938 Loss D: 0.2579, Loss G: 1.6931\n",
      "Epoch [17/20] Batch 260/938 Loss D: 0.2804, Loss G: 1.8034\n",
      "Epoch [17/20] Batch 270/938 Loss D: 0.3415, Loss G: 1.5315\n",
      "Epoch [17/20] Batch 280/938 Loss D: 0.2757, Loss G: 1.5631\n",
      "Epoch [17/20] Batch 290/938 Loss D: 0.3607, Loss G: 1.5287\n",
      "Epoch [17/20] Batch 300/938 Loss D: 0.3202, Loss G: 1.6341\n",
      "Epoch [17/20] Batch 310/938 Loss D: 0.3493, Loss G: 1.4384\n",
      "Epoch [17/20] Batch 320/938 Loss D: 0.2985, Loss G: 1.4644\n",
      "Epoch [17/20] Batch 330/938 Loss D: 0.4236, Loss G: 1.4704\n",
      "Epoch [17/20] Batch 340/938 Loss D: 0.3473, Loss G: 1.5949\n",
      "Epoch [17/20] Batch 350/938 Loss D: 0.2920, Loss G: 1.6246\n",
      "Epoch [17/20] Batch 360/938 Loss D: 0.3017, Loss G: 1.5954\n",
      "Epoch [17/20] Batch 370/938 Loss D: 0.2526, Loss G: 1.7153\n",
      "Epoch [17/20] Batch 380/938 Loss D: 0.3087, Loss G: 1.6164\n",
      "Epoch [17/20] Batch 390/938 Loss D: 0.2414, Loss G: 1.8205\n",
      "Epoch [17/20] Batch 400/938 Loss D: 0.3527, Loss G: 1.5080\n",
      "Epoch [17/20] Batch 410/938 Loss D: 0.2936, Loss G: 1.7552\n",
      "Epoch [17/20] Batch 420/938 Loss D: 0.2680, Loss G: 1.6674\n",
      "Epoch [17/20] Batch 430/938 Loss D: 0.3309, Loss G: 1.6978\n",
      "Epoch [17/20] Batch 440/938 Loss D: 0.2683, Loss G: 1.6653\n",
      "Epoch [17/20] Batch 450/938 Loss D: 0.2446, Loss G: 1.8508\n",
      "Epoch [17/20] Batch 460/938 Loss D: 0.2891, Loss G: 1.6729\n",
      "Epoch [17/20] Batch 470/938 Loss D: 0.3235, Loss G: 1.7215\n",
      "Epoch [17/20] Batch 480/938 Loss D: 0.3103, Loss G: 1.5530\n",
      "Epoch [17/20] Batch 490/938 Loss D: 0.2779, Loss G: 1.6899\n",
      "Epoch [17/20] Batch 500/938 Loss D: 0.2921, Loss G: 1.5253\n",
      "Epoch [17/20] Batch 510/938 Loss D: 0.2926, Loss G: 1.6845\n",
      "Epoch [17/20] Batch 520/938 Loss D: 0.3255, Loss G: 1.8239\n",
      "Epoch [17/20] Batch 530/938 Loss D: 0.2835, Loss G: 1.7477\n",
      "Epoch [17/20] Batch 540/938 Loss D: 0.3295, Loss G: 1.4045\n",
      "Epoch [17/20] Batch 550/938 Loss D: 0.3504, Loss G: 1.6072\n",
      "Epoch [17/20] Batch 560/938 Loss D: 0.3092, Loss G: 1.6435\n",
      "Epoch [17/20] Batch 570/938 Loss D: 0.3282, Loss G: 1.4776\n",
      "Epoch [17/20] Batch 580/938 Loss D: 0.2559, Loss G: 1.6744\n",
      "Epoch [17/20] Batch 590/938 Loss D: 0.2947, Loss G: 1.6069\n",
      "Epoch [17/20] Batch 600/938 Loss D: 0.3605, Loss G: 1.3470\n",
      "Epoch [17/20] Batch 610/938 Loss D: 0.2840, Loss G: 1.5945\n",
      "Epoch [17/20] Batch 620/938 Loss D: 0.2659, Loss G: 1.8180\n",
      "Epoch [17/20] Batch 630/938 Loss D: 0.2642, Loss G: 2.0017\n",
      "Epoch [17/20] Batch 640/938 Loss D: 0.2598, Loss G: 1.9157\n",
      "Epoch [17/20] Batch 650/938 Loss D: 0.3370, Loss G: 1.7247\n",
      "Epoch [17/20] Batch 660/938 Loss D: 0.2892, Loss G: 1.5186\n",
      "Epoch [17/20] Batch 670/938 Loss D: 0.3244, Loss G: 1.7003\n",
      "Epoch [17/20] Batch 680/938 Loss D: 0.2330, Loss G: 1.7537\n",
      "Epoch [17/20] Batch 690/938 Loss D: 0.2644, Loss G: 1.9208\n",
      "Epoch [17/20] Batch 700/938 Loss D: 0.3051, Loss G: 1.6771\n",
      "Epoch [17/20] Batch 710/938 Loss D: 0.3883, Loss G: 1.7765\n",
      "Epoch [17/20] Batch 720/938 Loss D: 0.2711, Loss G: 1.8873\n",
      "Epoch [17/20] Batch 730/938 Loss D: 0.2999, Loss G: 1.5643\n",
      "Epoch [17/20] Batch 740/938 Loss D: 0.3642, Loss G: 1.4794\n",
      "Epoch [17/20] Batch 750/938 Loss D: 0.2495, Loss G: 1.9085\n",
      "Epoch [17/20] Batch 760/938 Loss D: 0.2906, Loss G: 1.6967\n",
      "Epoch [17/20] Batch 770/938 Loss D: 0.3262, Loss G: 1.5586\n",
      "Epoch [17/20] Batch 780/938 Loss D: 0.3005, Loss G: 1.6850\n",
      "Epoch [17/20] Batch 790/938 Loss D: 0.3064, Loss G: 1.5447\n",
      "Epoch [17/20] Batch 800/938 Loss D: 0.3363, Loss G: 1.5822\n",
      "Epoch [17/20] Batch 810/938 Loss D: 0.3436, Loss G: 1.3663\n",
      "Epoch [17/20] Batch 820/938 Loss D: 0.2309, Loss G: 1.7688\n",
      "Epoch [17/20] Batch 830/938 Loss D: 0.3316, Loss G: 1.4447\n",
      "Epoch [17/20] Batch 840/938 Loss D: 0.3080, Loss G: 1.7309\n",
      "Epoch [17/20] Batch 850/938 Loss D: 0.2575, Loss G: 1.7413\n",
      "Epoch [17/20] Batch 860/938 Loss D: 0.3333, Loss G: 1.4412\n",
      "Epoch [17/20] Batch 870/938 Loss D: 0.3066, Loss G: 1.7196\n",
      "Epoch [17/20] Batch 880/938 Loss D: 0.2802, Loss G: 1.5274\n",
      "Epoch [17/20] Batch 890/938 Loss D: 0.2135, Loss G: 2.1508\n",
      "Epoch [17/20] Batch 900/938 Loss D: 0.2860, Loss G: 1.7953\n",
      "Epoch [17/20] Batch 910/938 Loss D: 0.3088, Loss G: 1.3932\n",
      "Epoch [17/20] Batch 920/938 Loss D: 0.3602, Loss G: 1.3488\n",
      "Epoch [17/20] Batch 930/938 Loss D: 0.2840, Loss G: 1.6172\n",
      "Epoch [18/20] Batch 0/938 Loss D: 0.2961, Loss G: 1.7486\n",
      "Epoch [18/20] Batch 10/938 Loss D: 0.2970, Loss G: 1.4658\n",
      "Epoch [18/20] Batch 20/938 Loss D: 0.2825, Loss G: 1.7334\n",
      "Epoch [18/20] Batch 30/938 Loss D: 0.3126, Loss G: 1.7770\n",
      "Epoch [18/20] Batch 40/938 Loss D: 0.2933, Loss G: 1.6914\n",
      "Epoch [18/20] Batch 50/938 Loss D: 0.3036, Loss G: 1.5841\n",
      "Epoch [18/20] Batch 60/938 Loss D: 0.2747, Loss G: 1.7346\n",
      "Epoch [18/20] Batch 70/938 Loss D: 0.2879, Loss G: 1.7189\n",
      "Epoch [18/20] Batch 80/938 Loss D: 0.2880, Loss G: 1.5976\n",
      "Epoch [18/20] Batch 90/938 Loss D: 0.3188, Loss G: 1.5572\n",
      "Epoch [18/20] Batch 100/938 Loss D: 0.2960, Loss G: 1.7457\n",
      "Epoch [18/20] Batch 110/938 Loss D: 0.2966, Loss G: 1.6528\n",
      "Epoch [18/20] Batch 120/938 Loss D: 0.3131, Loss G: 1.4326\n",
      "Epoch [18/20] Batch 130/938 Loss D: 0.2651, Loss G: 1.8700\n",
      "Epoch [18/20] Batch 140/938 Loss D: 0.3263, Loss G: 1.6038\n",
      "Epoch [18/20] Batch 150/938 Loss D: 0.3097, Loss G: 1.6349\n",
      "Epoch [18/20] Batch 160/938 Loss D: 0.2928, Loss G: 1.4680\n",
      "Epoch [18/20] Batch 170/938 Loss D: 0.3886, Loss G: 1.6420\n",
      "Epoch [18/20] Batch 180/938 Loss D: 0.3388, Loss G: 1.5565\n",
      "Epoch [18/20] Batch 190/938 Loss D: 0.2757, Loss G: 1.7953\n",
      "Epoch [18/20] Batch 200/938 Loss D: 0.3443, Loss G: 1.4517\n",
      "Epoch [18/20] Batch 210/938 Loss D: 0.2795, Loss G: 1.5291\n",
      "Epoch [18/20] Batch 220/938 Loss D: 0.3906, Loss G: 1.4957\n",
      "Epoch [18/20] Batch 230/938 Loss D: 0.2991, Loss G: 1.7504\n",
      "Epoch [18/20] Batch 240/938 Loss D: 0.2531, Loss G: 2.0614\n",
      "Epoch [18/20] Batch 250/938 Loss D: 0.2791, Loss G: 1.8738\n",
      "Epoch [18/20] Batch 260/938 Loss D: 0.2852, Loss G: 1.7378\n",
      "Epoch [18/20] Batch 270/938 Loss D: 0.3341, Loss G: 1.4483\n",
      "Epoch [18/20] Batch 280/938 Loss D: 0.2864, Loss G: 1.6258\n",
      "Epoch [18/20] Batch 290/938 Loss D: 0.2917, Loss G: 1.4597\n",
      "Epoch [18/20] Batch 300/938 Loss D: 0.3277, Loss G: 1.6900\n",
      "Epoch [18/20] Batch 310/938 Loss D: 0.2962, Loss G: 1.8280\n",
      "Epoch [18/20] Batch 320/938 Loss D: 0.3073, Loss G: 1.5638\n",
      "Epoch [18/20] Batch 330/938 Loss D: 0.2927, Loss G: 1.6567\n",
      "Epoch [18/20] Batch 340/938 Loss D: 0.2999, Loss G: 1.5345\n",
      "Epoch [18/20] Batch 350/938 Loss D: 0.3005, Loss G: 1.5321\n",
      "Epoch [18/20] Batch 360/938 Loss D: 0.3244, Loss G: 1.3285\n",
      "Epoch [18/20] Batch 370/938 Loss D: 0.3415, Loss G: 1.8565\n",
      "Epoch [18/20] Batch 380/938 Loss D: 0.3635, Loss G: 1.6679\n",
      "Epoch [18/20] Batch 390/938 Loss D: 0.3186, Loss G: 1.4789\n",
      "Epoch [18/20] Batch 400/938 Loss D: 0.3100, Loss G: 1.6802\n",
      "Epoch [18/20] Batch 410/938 Loss D: 0.2715, Loss G: 1.8090\n",
      "Epoch [18/20] Batch 420/938 Loss D: 0.2884, Loss G: 1.4399\n",
      "Epoch [18/20] Batch 430/938 Loss D: 0.2960, Loss G: 1.5079\n",
      "Epoch [18/20] Batch 440/938 Loss D: 0.2768, Loss G: 1.8457\n",
      "Epoch [18/20] Batch 450/938 Loss D: 0.2728, Loss G: 1.6221\n",
      "Epoch [18/20] Batch 460/938 Loss D: 0.3216, Loss G: 1.6504\n",
      "Epoch [18/20] Batch 470/938 Loss D: 0.3486, Loss G: 1.5333\n",
      "Epoch [18/20] Batch 480/938 Loss D: 0.2656, Loss G: 1.6901\n",
      "Epoch [18/20] Batch 490/938 Loss D: 0.3309, Loss G: 1.4362\n",
      "Epoch [18/20] Batch 500/938 Loss D: 0.2789, Loss G: 1.4822\n",
      "Epoch [18/20] Batch 510/938 Loss D: 0.2901, Loss G: 1.6218\n",
      "Epoch [18/20] Batch 520/938 Loss D: 0.2981, Loss G: 1.8256\n",
      "Epoch [18/20] Batch 530/938 Loss D: 0.3765, Loss G: 1.4160\n",
      "Epoch [18/20] Batch 540/938 Loss D: 0.2591, Loss G: 1.6430\n",
      "Epoch [18/20] Batch 550/938 Loss D: 0.3255, Loss G: 1.5714\n",
      "Epoch [18/20] Batch 560/938 Loss D: 0.3519, Loss G: 1.5521\n",
      "Epoch [18/20] Batch 570/938 Loss D: 0.3547, Loss G: 1.4403\n",
      "Epoch [18/20] Batch 580/938 Loss D: 0.3406, Loss G: 1.6952\n",
      "Epoch [18/20] Batch 590/938 Loss D: 0.3211, Loss G: 1.4734\n",
      "Epoch [18/20] Batch 600/938 Loss D: 0.2714, Loss G: 1.8452\n",
      "Epoch [18/20] Batch 610/938 Loss D: 0.3207, Loss G: 1.6309\n",
      "Epoch [18/20] Batch 620/938 Loss D: 0.2927, Loss G: 1.8544\n",
      "Epoch [18/20] Batch 630/938 Loss D: 0.2763, Loss G: 1.5908\n",
      "Epoch [18/20] Batch 640/938 Loss D: 0.2982, Loss G: 1.5325\n",
      "Epoch [18/20] Batch 650/938 Loss D: 0.3111, Loss G: 1.5527\n",
      "Epoch [18/20] Batch 660/938 Loss D: 0.2976, Loss G: 1.5037\n",
      "Epoch [18/20] Batch 670/938 Loss D: 0.3087, Loss G: 1.5103\n",
      "Epoch [18/20] Batch 680/938 Loss D: 0.3148, Loss G: 1.3875\n",
      "Epoch [18/20] Batch 690/938 Loss D: 0.2672, Loss G: 1.7454\n",
      "Epoch [18/20] Batch 700/938 Loss D: 0.2965, Loss G: 1.9057\n",
      "Epoch [18/20] Batch 710/938 Loss D: 0.3147, Loss G: 1.5672\n",
      "Epoch [18/20] Batch 720/938 Loss D: 0.3151, Loss G: 1.5579\n",
      "Epoch [18/20] Batch 730/938 Loss D: 0.3025, Loss G: 1.6194\n",
      "Epoch [18/20] Batch 740/938 Loss D: 0.2914, Loss G: 1.7689\n",
      "Epoch [18/20] Batch 750/938 Loss D: 0.2476, Loss G: 1.8832\n",
      "Epoch [18/20] Batch 760/938 Loss D: 0.2858, Loss G: 1.7037\n",
      "Epoch [18/20] Batch 770/938 Loss D: 0.2199, Loss G: 1.8978\n",
      "Epoch [18/20] Batch 780/938 Loss D: 0.3353, Loss G: 1.7650\n",
      "Epoch [18/20] Batch 790/938 Loss D: 0.3756, Loss G: 1.9383\n",
      "Epoch [18/20] Batch 800/938 Loss D: 0.2964, Loss G: 1.7741\n",
      "Epoch [18/20] Batch 810/938 Loss D: 0.2833, Loss G: 1.9854\n",
      "Epoch [18/20] Batch 820/938 Loss D: 0.3046, Loss G: 1.4212\n",
      "Epoch [18/20] Batch 830/938 Loss D: 0.2382, Loss G: 1.7454\n",
      "Epoch [18/20] Batch 840/938 Loss D: 0.2969, Loss G: 1.6828\n",
      "Epoch [18/20] Batch 850/938 Loss D: 0.3041, Loss G: 1.5855\n",
      "Epoch [18/20] Batch 860/938 Loss D: 0.3891, Loss G: 1.6584\n",
      "Epoch [18/20] Batch 870/938 Loss D: 0.2961, Loss G: 1.8011\n",
      "Epoch [18/20] Batch 880/938 Loss D: 0.3531, Loss G: 1.4645\n",
      "Epoch [18/20] Batch 890/938 Loss D: 0.3514, Loss G: 1.3812\n",
      "Epoch [18/20] Batch 900/938 Loss D: 0.3100, Loss G: 1.5292\n",
      "Epoch [18/20] Batch 910/938 Loss D: 0.3017, Loss G: 1.5905\n",
      "Epoch [18/20] Batch 920/938 Loss D: 0.3303, Loss G: 1.5422\n",
      "Epoch [18/20] Batch 930/938 Loss D: 0.3270, Loss G: 1.5985\n",
      "Epoch [19/20] Batch 0/938 Loss D: 0.2529, Loss G: 1.7589\n",
      "Epoch [19/20] Batch 10/938 Loss D: 0.2736, Loss G: 1.5834\n",
      "Epoch [19/20] Batch 20/938 Loss D: 0.2923, Loss G: 1.6072\n",
      "Epoch [19/20] Batch 30/938 Loss D: 0.3798, Loss G: 1.5960\n",
      "Epoch [19/20] Batch 40/938 Loss D: 0.2961, Loss G: 1.7408\n",
      "Epoch [19/20] Batch 50/938 Loss D: 0.3257, Loss G: 1.7286\n",
      "Epoch [19/20] Batch 60/938 Loss D: 0.2253, Loss G: 1.9421\n",
      "Epoch [19/20] Batch 70/938 Loss D: 0.3319, Loss G: 1.4308\n",
      "Epoch [19/20] Batch 80/938 Loss D: 0.2935, Loss G: 1.8023\n",
      "Epoch [19/20] Batch 90/938 Loss D: 0.2761, Loss G: 1.8714\n",
      "Epoch [19/20] Batch 100/938 Loss D: 0.3031, Loss G: 1.9305\n",
      "Epoch [19/20] Batch 110/938 Loss D: 0.3212, Loss G: 1.5122\n",
      "Epoch [19/20] Batch 120/938 Loss D: 0.2208, Loss G: 2.2352\n",
      "Epoch [19/20] Batch 130/938 Loss D: 0.2156, Loss G: 1.8127\n",
      "Epoch [19/20] Batch 140/938 Loss D: 0.2615, Loss G: 1.5214\n",
      "Epoch [19/20] Batch 150/938 Loss D: 0.3550, Loss G: 1.4012\n",
      "Epoch [19/20] Batch 160/938 Loss D: 0.3017, Loss G: 1.5889\n",
      "Epoch [19/20] Batch 170/938 Loss D: 0.4040, Loss G: 1.6413\n",
      "Epoch [19/20] Batch 180/938 Loss D: 0.2546, Loss G: 2.2830\n",
      "Epoch [19/20] Batch 190/938 Loss D: 0.3471, Loss G: 1.4281\n",
      "Epoch [19/20] Batch 200/938 Loss D: 0.2994, Loss G: 1.6366\n",
      "Epoch [19/20] Batch 210/938 Loss D: 0.2963, Loss G: 1.6568\n",
      "Epoch [19/20] Batch 220/938 Loss D: 0.2843, Loss G: 1.7115\n",
      "Epoch [19/20] Batch 230/938 Loss D: 0.2727, Loss G: 1.8803\n",
      "Epoch [19/20] Batch 240/938 Loss D: 0.2905, Loss G: 1.6169\n",
      "Epoch [19/20] Batch 250/938 Loss D: 0.3130, Loss G: 1.6805\n",
      "Epoch [19/20] Batch 260/938 Loss D: 0.2914, Loss G: 1.6917\n",
      "Epoch [19/20] Batch 270/938 Loss D: 0.2935, Loss G: 2.0165\n",
      "Epoch [19/20] Batch 280/938 Loss D: 0.3351, Loss G: 1.5566\n",
      "Epoch [19/20] Batch 290/938 Loss D: 0.3449, Loss G: 1.5749\n",
      "Epoch [19/20] Batch 300/938 Loss D: 0.3007, Loss G: 1.3758\n",
      "Epoch [19/20] Batch 310/938 Loss D: 0.2990, Loss G: 1.4497\n",
      "Epoch [19/20] Batch 320/938 Loss D: 0.3151, Loss G: 1.4889\n",
      "Epoch [19/20] Batch 330/938 Loss D: 0.3459, Loss G: 1.4601\n",
      "Epoch [19/20] Batch 340/938 Loss D: 0.3589, Loss G: 1.4759\n",
      "Epoch [19/20] Batch 350/938 Loss D: 0.2916, Loss G: 1.6099\n",
      "Epoch [19/20] Batch 360/938 Loss D: 0.3394, Loss G: 1.4840\n",
      "Epoch [19/20] Batch 370/938 Loss D: 0.2793, Loss G: 1.7113\n",
      "Epoch [19/20] Batch 380/938 Loss D: 0.3518, Loss G: 1.5625\n",
      "Epoch [19/20] Batch 390/938 Loss D: 0.2929, Loss G: 1.9048\n",
      "Epoch [19/20] Batch 400/938 Loss D: 0.3330, Loss G: 1.6603\n",
      "Epoch [19/20] Batch 410/938 Loss D: 0.3182, Loss G: 1.7883\n",
      "Epoch [19/20] Batch 420/938 Loss D: 0.2831, Loss G: 1.7421\n",
      "Epoch [19/20] Batch 430/938 Loss D: 0.3054, Loss G: 1.8755\n",
      "Epoch [19/20] Batch 440/938 Loss D: 0.3412, Loss G: 1.6519\n",
      "Epoch [19/20] Batch 450/938 Loss D: 0.3786, Loss G: 1.7205\n",
      "Epoch [19/20] Batch 460/938 Loss D: 0.3651, Loss G: 1.6867\n",
      "Epoch [19/20] Batch 470/938 Loss D: 0.2867, Loss G: 1.7899\n",
      "Epoch [19/20] Batch 480/938 Loss D: 0.2678, Loss G: 1.7292\n",
      "Epoch [19/20] Batch 490/938 Loss D: 0.3850, Loss G: 1.4657\n",
      "Epoch [19/20] Batch 500/938 Loss D: 0.2324, Loss G: 1.8836\n",
      "Epoch [19/20] Batch 510/938 Loss D: 0.2902, Loss G: 1.7865\n",
      "Epoch [19/20] Batch 520/938 Loss D: 0.3033, Loss G: 1.5534\n",
      "Epoch [19/20] Batch 530/938 Loss D: 0.3629, Loss G: 1.5068\n",
      "Epoch [19/20] Batch 540/938 Loss D: 0.3728, Loss G: 1.4897\n",
      "Epoch [19/20] Batch 550/938 Loss D: 0.2901, Loss G: 1.6307\n",
      "Epoch [19/20] Batch 560/938 Loss D: 0.3103, Loss G: 1.7290\n",
      "Epoch [19/20] Batch 570/938 Loss D: 0.2659, Loss G: 1.8061\n",
      "Epoch [19/20] Batch 580/938 Loss D: 0.2821, Loss G: 1.7170\n",
      "Epoch [19/20] Batch 590/938 Loss D: 0.2646, Loss G: 1.7731\n",
      "Epoch [19/20] Batch 600/938 Loss D: 0.3474, Loss G: 1.8525\n",
      "Epoch [19/20] Batch 610/938 Loss D: 0.2769, Loss G: 1.9070\n",
      "Epoch [19/20] Batch 620/938 Loss D: 0.2378, Loss G: 1.7464\n",
      "Epoch [19/20] Batch 630/938 Loss D: 0.2977, Loss G: 1.7445\n",
      "Epoch [19/20] Batch 640/938 Loss D: 0.2655, Loss G: 1.7625\n",
      "Epoch [19/20] Batch 650/938 Loss D: 0.2769, Loss G: 1.6288\n",
      "Epoch [19/20] Batch 660/938 Loss D: 0.2655, Loss G: 1.5513\n",
      "Epoch [19/20] Batch 670/938 Loss D: 0.3835, Loss G: 1.3799\n",
      "Epoch [19/20] Batch 680/938 Loss D: 0.3811, Loss G: 1.4454\n",
      "Epoch [19/20] Batch 690/938 Loss D: 0.3041, Loss G: 1.7990\n",
      "Epoch [19/20] Batch 700/938 Loss D: 0.2839, Loss G: 1.5253\n",
      "Epoch [19/20] Batch 710/938 Loss D: 0.3143, Loss G: 1.6398\n",
      "Epoch [19/20] Batch 720/938 Loss D: 0.2743, Loss G: 1.4727\n",
      "Epoch [19/20] Batch 730/938 Loss D: 0.2715, Loss G: 1.5312\n",
      "Epoch [19/20] Batch 740/938 Loss D: 0.3391, Loss G: 1.4475\n",
      "Epoch [19/20] Batch 750/938 Loss D: 0.3034, Loss G: 1.5520\n",
      "Epoch [19/20] Batch 760/938 Loss D: 0.3721, Loss G: 1.6346\n",
      "Epoch [19/20] Batch 770/938 Loss D: 0.3061, Loss G: 2.0981\n",
      "Epoch [19/20] Batch 780/938 Loss D: 0.3479, Loss G: 1.5433\n",
      "Epoch [19/20] Batch 790/938 Loss D: 0.2359, Loss G: 1.7288\n",
      "Epoch [19/20] Batch 800/938 Loss D: 0.3364, Loss G: 1.5119\n",
      "Epoch [19/20] Batch 810/938 Loss D: 0.2710, Loss G: 1.8334\n",
      "Epoch [19/20] Batch 820/938 Loss D: 0.2727, Loss G: 1.8989\n",
      "Epoch [19/20] Batch 830/938 Loss D: 0.3342, Loss G: 1.4884\n",
      "Epoch [19/20] Batch 840/938 Loss D: 0.2850, Loss G: 1.6974\n",
      "Epoch [19/20] Batch 850/938 Loss D: 0.3110, Loss G: 1.6015\n",
      "Epoch [19/20] Batch 860/938 Loss D: 0.3453, Loss G: 1.8825\n",
      "Epoch [19/20] Batch 870/938 Loss D: 0.2854, Loss G: 1.7555\n",
      "Epoch [19/20] Batch 880/938 Loss D: 0.3219, Loss G: 1.4857\n",
      "Epoch [19/20] Batch 890/938 Loss D: 0.3749, Loss G: 1.4266\n",
      "Epoch [19/20] Batch 900/938 Loss D: 0.3440, Loss G: 1.6130\n",
      "Epoch [19/20] Batch 910/938 Loss D: 0.2556, Loss G: 1.6954\n",
      "Epoch [19/20] Batch 920/938 Loss D: 0.2757, Loss G: 1.9660\n",
      "Epoch [19/20] Batch 930/938 Loss D: 0.2835, Loss G: 1.5215\n",
      "Epoch [20/20] Batch 0/938 Loss D: 0.2888, Loss G: 1.8369\n",
      "Epoch [20/20] Batch 10/938 Loss D: 0.3138, Loss G: 1.8550\n",
      "Epoch [20/20] Batch 20/938 Loss D: 0.3218, Loss G: 1.7043\n",
      "Epoch [20/20] Batch 30/938 Loss D: 0.2723, Loss G: 1.8142\n",
      "Epoch [20/20] Batch 40/938 Loss D: 0.2702, Loss G: 1.7172\n",
      "Epoch [20/20] Batch 50/938 Loss D: 0.2880, Loss G: 1.8633\n",
      "Epoch [20/20] Batch 60/938 Loss D: 0.2893, Loss G: 1.8666\n",
      "Epoch [20/20] Batch 70/938 Loss D: 0.3657, Loss G: 1.8286\n",
      "Epoch [20/20] Batch 80/938 Loss D: 0.2979, Loss G: 1.5042\n",
      "Epoch [20/20] Batch 90/938 Loss D: 0.2749, Loss G: 1.9210\n",
      "Epoch [20/20] Batch 100/938 Loss D: 0.3250, Loss G: 1.5647\n",
      "Epoch [20/20] Batch 110/938 Loss D: 0.2474, Loss G: 1.9100\n",
      "Epoch [20/20] Batch 120/938 Loss D: 0.2631, Loss G: 1.7253\n",
      "Epoch [20/20] Batch 130/938 Loss D: 0.3034, Loss G: 1.5347\n",
      "Epoch [20/20] Batch 140/938 Loss D: 0.2666, Loss G: 1.9437\n",
      "Epoch [20/20] Batch 150/938 Loss D: 0.3703, Loss G: 1.8606\n",
      "Epoch [20/20] Batch 160/938 Loss D: 0.2775, Loss G: 1.5775\n",
      "Epoch [20/20] Batch 170/938 Loss D: 0.2578, Loss G: 1.5878\n",
      "Epoch [20/20] Batch 180/938 Loss D: 0.2625, Loss G: 1.5609\n",
      "Epoch [20/20] Batch 190/938 Loss D: 0.2693, Loss G: 1.8833\n",
      "Epoch [20/20] Batch 200/938 Loss D: 0.3365, Loss G: 1.7016\n",
      "Epoch [20/20] Batch 210/938 Loss D: 0.2940, Loss G: 1.6982\n",
      "Epoch [20/20] Batch 220/938 Loss D: 0.2843, Loss G: 1.5499\n",
      "Epoch [20/20] Batch 230/938 Loss D: 0.2754, Loss G: 1.6933\n",
      "Epoch [20/20] Batch 240/938 Loss D: 0.2668, Loss G: 1.7806\n",
      "Epoch [20/20] Batch 250/938 Loss D: 0.3236, Loss G: 1.8074\n",
      "Epoch [20/20] Batch 260/938 Loss D: 0.3547, Loss G: 1.5777\n",
      "Epoch [20/20] Batch 270/938 Loss D: 0.3669, Loss G: 1.3879\n",
      "Epoch [20/20] Batch 280/938 Loss D: 0.2849, Loss G: 1.7587\n",
      "Epoch [20/20] Batch 290/938 Loss D: 0.3509, Loss G: 1.7609\n",
      "Epoch [20/20] Batch 300/938 Loss D: 0.2604, Loss G: 2.0721\n",
      "Epoch [20/20] Batch 310/938 Loss D: 0.3318, Loss G: 1.3911\n",
      "Epoch [20/20] Batch 320/938 Loss D: 0.2986, Loss G: 1.5380\n",
      "Epoch [20/20] Batch 330/938 Loss D: 0.3578, Loss G: 1.5160\n",
      "Epoch [20/20] Batch 340/938 Loss D: 0.3560, Loss G: 1.9122\n",
      "Epoch [20/20] Batch 350/938 Loss D: 0.3332, Loss G: 1.7652\n",
      "Epoch [20/20] Batch 360/938 Loss D: 0.2651, Loss G: 1.7210\n",
      "Epoch [20/20] Batch 370/938 Loss D: 0.2928, Loss G: 1.6558\n",
      "Epoch [20/20] Batch 380/938 Loss D: 0.2808, Loss G: 1.8904\n",
      "Epoch [20/20] Batch 390/938 Loss D: 0.2929, Loss G: 2.2540\n",
      "Epoch [20/20] Batch 400/938 Loss D: 0.2663, Loss G: 1.7301\n",
      "Epoch [20/20] Batch 410/938 Loss D: 0.3039, Loss G: 1.8507\n",
      "Epoch [20/20] Batch 420/938 Loss D: 0.3317, Loss G: 1.7275\n",
      "Epoch [20/20] Batch 430/938 Loss D: 0.2934, Loss G: 1.7963\n",
      "Epoch [20/20] Batch 440/938 Loss D: 0.3221, Loss G: 1.5092\n",
      "Epoch [20/20] Batch 450/938 Loss D: 0.3164, Loss G: 1.5517\n",
      "Epoch [20/20] Batch 460/938 Loss D: 0.3354, Loss G: 1.6360\n",
      "Epoch [20/20] Batch 470/938 Loss D: 0.2611, Loss G: 1.7009\n",
      "Epoch [20/20] Batch 480/938 Loss D: 0.2660, Loss G: 1.7396\n",
      "Epoch [20/20] Batch 490/938 Loss D: 0.2433, Loss G: 1.8442\n",
      "Epoch [20/20] Batch 500/938 Loss D: 0.3533, Loss G: 1.6915\n",
      "Epoch [20/20] Batch 510/938 Loss D: 0.3224, Loss G: 2.1114\n",
      "Epoch [20/20] Batch 520/938 Loss D: 0.3214, Loss G: 1.7262\n",
      "Epoch [20/20] Batch 530/938 Loss D: 0.2824, Loss G: 1.6826\n",
      "Epoch [20/20] Batch 540/938 Loss D: 0.2750, Loss G: 1.7905\n",
      "Epoch [20/20] Batch 550/938 Loss D: 0.2993, Loss G: 1.8352\n",
      "Epoch [20/20] Batch 560/938 Loss D: 0.2883, Loss G: 1.8546\n",
      "Epoch [20/20] Batch 570/938 Loss D: 0.3196, Loss G: 1.7499\n",
      "Epoch [20/20] Batch 580/938 Loss D: 0.2987, Loss G: 1.7319\n",
      "Epoch [20/20] Batch 590/938 Loss D: 0.2801, Loss G: 1.7197\n",
      "Epoch [20/20] Batch 600/938 Loss D: 0.2916, Loss G: 1.9455\n",
      "Epoch [20/20] Batch 610/938 Loss D: 0.3237, Loss G: 1.6229\n",
      "Epoch [20/20] Batch 620/938 Loss D: 0.2457, Loss G: 2.0746\n",
      "Epoch [20/20] Batch 630/938 Loss D: 0.2871, Loss G: 1.5100\n",
      "Epoch [20/20] Batch 640/938 Loss D: 0.3080, Loss G: 1.6246\n",
      "Epoch [20/20] Batch 650/938 Loss D: 0.2794, Loss G: 1.8663\n",
      "Epoch [20/20] Batch 660/938 Loss D: 0.3152, Loss G: 1.5566\n",
      "Epoch [20/20] Batch 670/938 Loss D: 0.2784, Loss G: 1.6822\n",
      "Epoch [20/20] Batch 680/938 Loss D: 0.2618, Loss G: 1.9962\n",
      "Epoch [20/20] Batch 690/938 Loss D: 0.2828, Loss G: 2.0615\n",
      "Epoch [20/20] Batch 700/938 Loss D: 0.2824, Loss G: 1.9064\n",
      "Epoch [20/20] Batch 710/938 Loss D: 0.3292, Loss G: 1.5294\n",
      "Epoch [20/20] Batch 720/938 Loss D: 0.2763, Loss G: 1.6143\n",
      "Epoch [20/20] Batch 730/938 Loss D: 0.2973, Loss G: 1.5568\n",
      "Epoch [20/20] Batch 740/938 Loss D: 0.3321, Loss G: 1.7346\n",
      "Epoch [20/20] Batch 750/938 Loss D: 0.3431, Loss G: 1.6103\n",
      "Epoch [20/20] Batch 760/938 Loss D: 0.2904, Loss G: 1.8613\n",
      "Epoch [20/20] Batch 770/938 Loss D: 0.3322, Loss G: 1.5426\n",
      "Epoch [20/20] Batch 780/938 Loss D: 0.2702, Loss G: 1.7889\n",
      "Epoch [20/20] Batch 790/938 Loss D: 0.3448, Loss G: 1.7554\n",
      "Epoch [20/20] Batch 800/938 Loss D: 0.3562, Loss G: 1.7791\n",
      "Epoch [20/20] Batch 810/938 Loss D: 0.3169, Loss G: 1.7414\n",
      "Epoch [20/20] Batch 820/938 Loss D: 0.3258, Loss G: 1.9392\n",
      "Epoch [20/20] Batch 830/938 Loss D: 0.3142, Loss G: 1.6843\n",
      "Epoch [20/20] Batch 840/938 Loss D: 0.2495, Loss G: 1.9023\n",
      "Epoch [20/20] Batch 850/938 Loss D: 0.2997, Loss G: 1.9370\n",
      "Epoch [20/20] Batch 860/938 Loss D: 0.2363, Loss G: 1.8780\n",
      "Epoch [20/20] Batch 870/938 Loss D: 0.3578, Loss G: 1.6891\n",
      "Epoch [20/20] Batch 880/938 Loss D: 0.3313, Loss G: 1.8793\n",
      "Epoch [20/20] Batch 890/938 Loss D: 0.2794, Loss G: 1.6767\n",
      "Epoch [20/20] Batch 900/938 Loss D: 0.2778, Loss G: 1.7302\n",
      "Epoch [20/20] Batch 910/938 Loss D: 0.2784, Loss G: 1.6811\n",
      "Epoch [20/20] Batch 920/938 Loss D: 0.2901, Loss G: 1.6904\n",
      "Epoch [20/20] Batch 930/938 Loss D: 0.2531, Loss G: 1.8121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir # data directory\n",
    "        self.transform = transform # 데이터 이미지 스케일 변환\n",
    "        self.image_paths = []\n",
    "\n",
    "        for i in range(10):\n",
    "            label_dir = os.path.join(root_dir, str(i))\n",
    "            for img_file in glob.glob(os.path.join(label_dir, '*.png')):\n",
    "                self.image_paths.append(img_file) # data 파일에 있는 이미지 파일 저장\n",
    "\n",
    "        print(f'Found {len(self.image_paths)} images')        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index): # 이미지 스케일 변환\n",
    "        img_path = self.image_paths[index]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=1, feature_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(z_dim, feature_g*4, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.InstanceNorm2d(feature_g*4)\n",
    "        self.r1 = nn.ReLU(True)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(feature_g*4, feature_g, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.InstanceNorm2d(feature_g)\n",
    "        self.r2 = nn.ReLU(True)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(feature_g, img_channels, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.t = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.r1(self.bn1(self.conv1(x)))\n",
    "        conv1_out = x  # 활성화 함수 출력 저장\n",
    "        x = self.r2(self.bn2(self.conv2(x)))\n",
    "        conv2_out = x  # 활성화 함수 출력 저장\n",
    "        x = self.t(self.conv3(x))\n",
    "        conv3_out = x  # 활성화 함수 출력 저장\n",
    "        return x, conv1_out, conv2_out, conv3_out\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_d=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(img_channels, feature_d, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(feature_d)\n",
    "        self.r1 = nn.LeakyReLU(True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(feature_d, feature_d*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(feature_d*4)\n",
    "        self.r2 = nn.ReLU(True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(feature_d*4, 1, kernel_size=3, stride=2, padding=0, bias=False)\n",
    "        self.t = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.r1(self.bn1(self.conv1(x)))\n",
    "        conv1_out = x  # 활성화 함수 출력 저장\n",
    "        x = self.r2(self.bn2(self.conv2(x)))\n",
    "        conv2_out = x  # 활성화 함수 출력 저장\n",
    "        x = self.t(self.conv3(x))\n",
    "        conv3_out = x  # 활성화 함수 출력 저장\n",
    "        return x, conv1_out, conv2_out, conv3_out\n",
    "\n",
    "\n",
    "data_dir = './data/train/'\n",
    "result_dir = './result/'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 4. 하이퍼파라미터 정의\n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "z_dim = 100\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 20  # 훈련 에포크 수\n",
    "\n",
    "print(f\"Using Device: {device}\")\n",
    "\n",
    "# 5. 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((16, 16)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# 6. 데이터셋 및 데이터로더 생성\n",
    "\n",
    "train_dataset = CustomMNISTDataset(root_dir=data_dir, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# 7. 모델 초기화\n",
    "\n",
    "gen = Generator(z_dim=z_dim, img_channels=1, feature_g=32).to(device)\n",
    "disc = Discriminator(img_channels=1, feature_d=32).to(device)\n",
    "\n",
    "# 8. 최적화 함수 및 손실 함수 정의\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "# 9. 생성된 이미지 시각화 함수 정의\n",
    "\n",
    "def show_generated_images(generator, num_images=64, epoch=0):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_images, z_dim, 1, 1).to(device)  # CNN은 4D 텐서 입력을 기대\n",
    "        fake_images, conv1_out, conv2_out, conv3_out = generator(noise)\n",
    "        \n",
    "        fake_images = fake_images.cpu()\n",
    "        grid = vutils.make_grid(fake_images, nrow=8, normalize=True)\n",
    "        plt.clf()\n",
    "        plt.imshow(grid.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Generated Images at Epoch {epoch}')\n",
    "        plt.savefig(f'{result_dir}image_normalnormal.png', pad_inches=0.1, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plt.show\n",
    "    generator.train()\n",
    "\n",
    "# 10. GAN 훈련 루프\n",
    "losses_g = []\n",
    "losses_d = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, real in enumerate(train_dataloader):\n",
    "        real = real.to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        ### (a) 판별자 훈련 (진짜 이미지)\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
    "        fake, conv1_out_gen, conv2_out_gen, conv3_out_gen = gen(noise)\n",
    "        \n",
    "        # 진짜 이미지(1) 판별\n",
    "        disc_real, conv1_out_disc_real, conv2_out_disc_real, conv3_out_disc_real = disc(real)\n",
    "        loss_disc_real = bce_loss(disc_real.view(-1), torch.ones_like(disc_real.view(-1)))\n",
    "\n",
    "        # 가짜 이미지(0) 판별\n",
    "        disc_fake, conv1_out_disc_fake, conv2_out_disc_fake, conv3_out_disc_fake = disc(fake.detach())\n",
    "        loss_disc_fake = bce_loss(disc_fake.view(-1), torch.zeros_like(disc_fake.view(-1)))\n",
    "        \n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        opt_disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### (b) 생성자 훈련 (가짜 이미지)\n",
    "        output, conv1_out_gen, conv2_out_gen, conv3_out_gen = disc(fake)\n",
    "        loss_gen = bce_loss(output.view(-1), torch.ones_like(output.view(-1)))\n",
    "        \n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        losses_g.append(loss_gen.item())\n",
    "        losses_d.append(loss_disc.item())\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Batch {batch_idx}/{len(train_dataloader)} \"\n",
    "                  f\"Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\")\n",
    "            show_generated_images(gen, num_images=16, epoch=epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n",
      "Found 60000 images\n",
      "Epoch [1/85] Batch 0/938 Loss D: 0.6839, Loss G: 0.7823\n",
      "Epoch [1/85] Batch 10/938 Loss D: 0.4286, Loss G: 1.0740\n",
      "Epoch [1/85] Batch 20/938 Loss D: 0.3256, Loss G: 1.8696\n",
      "Epoch [1/85] Batch 30/938 Loss D: 0.2234, Loss G: 2.2573\n",
      "Epoch [1/85] Batch 40/938 Loss D: 0.1040, Loss G: 2.9401\n",
      "Epoch [1/85] Batch 50/938 Loss D: 0.1247, Loss G: 2.3908\n",
      "Epoch [1/85] Batch 60/938 Loss D: 0.0557, Loss G: 3.3700\n",
      "Epoch [1/85] Batch 70/938 Loss D: 0.0665, Loss G: 3.2769\n",
      "Epoch [1/85] Batch 80/938 Loss D: 0.0705, Loss G: 4.1119\n",
      "Epoch [1/85] Batch 90/938 Loss D: 0.0565, Loss G: 3.1707\n",
      "Epoch [1/85] Batch 100/938 Loss D: 0.0540, Loss G: 3.5522\n",
      "Epoch [1/85] Batch 110/938 Loss D: 0.0924, Loss G: 2.9719\n",
      "Epoch [1/85] Batch 120/938 Loss D: 0.0371, Loss G: 4.5118\n",
      "Epoch [1/85] Batch 130/938 Loss D: 0.0288, Loss G: 4.0343\n",
      "Epoch [1/85] Batch 140/938 Loss D: 0.0212, Loss G: 4.1827\n",
      "Epoch [1/85] Batch 150/938 Loss D: 0.0189, Loss G: 4.1441\n",
      "Epoch [1/85] Batch 160/938 Loss D: 0.0346, Loss G: 3.5810\n",
      "Epoch [1/85] Batch 170/938 Loss D: 0.0220, Loss G: 4.0889\n",
      "Epoch [1/85] Batch 180/938 Loss D: 0.0483, Loss G: 3.2399\n",
      "Epoch [1/85] Batch 190/938 Loss D: 0.0500, Loss G: 4.0087\n",
      "Epoch [1/85] Batch 200/938 Loss D: 0.0547, Loss G: 3.5220\n",
      "Epoch [1/85] Batch 210/938 Loss D: 0.0750, Loss G: 3.5440\n",
      "Epoch [1/85] Batch 220/938 Loss D: 0.0288, Loss G: 4.1771\n",
      "Epoch [1/85] Batch 230/938 Loss D: 0.0190, Loss G: 4.6150\n",
      "Epoch [1/85] Batch 240/938 Loss D: 0.0088, Loss G: 5.3308\n",
      "Epoch [1/85] Batch 250/938 Loss D: 0.0098, Loss G: 4.9468\n",
      "Epoch [1/85] Batch 260/938 Loss D: 0.0161, Loss G: 4.4096\n",
      "Epoch [1/85] Batch 270/938 Loss D: 0.0163, Loss G: 4.4869\n",
      "Epoch [1/85] Batch 280/938 Loss D: 0.0164, Loss G: 4.8215\n",
      "Epoch [1/85] Batch 290/938 Loss D: 0.0212, Loss G: 4.1947\n",
      "Epoch [1/85] Batch 300/938 Loss D: 0.0216, Loss G: 4.4965\n",
      "Epoch [1/85] Batch 310/938 Loss D: 0.0215, Loss G: 4.4247\n",
      "Epoch [1/85] Batch 320/938 Loss D: 0.0168, Loss G: 4.6732\n",
      "Epoch [1/85] Batch 330/938 Loss D: 0.0131, Loss G: 4.9269\n",
      "Epoch [1/85] Batch 340/938 Loss D: 0.0114, Loss G: 4.6797\n",
      "Epoch [1/85] Batch 350/938 Loss D: 0.0173, Loss G: 4.6787\n",
      "Epoch [1/85] Batch 360/938 Loss D: 0.0160, Loss G: 4.6359\n",
      "Epoch [1/85] Batch 370/938 Loss D: 0.0126, Loss G: 5.0630\n",
      "Epoch [1/85] Batch 380/938 Loss D: 0.0169, Loss G: 4.8088\n",
      "Epoch [1/85] Batch 390/938 Loss D: 0.0243, Loss G: 4.7015\n",
      "Epoch [1/85] Batch 400/938 Loss D: 0.0493, Loss G: 4.0107\n",
      "Epoch [1/85] Batch 410/938 Loss D: 0.0401, Loss G: 4.3492\n",
      "Epoch [1/85] Batch 420/938 Loss D: 0.0392, Loss G: 3.9832\n",
      "Epoch [1/85] Batch 430/938 Loss D: 0.0340, Loss G: 4.3282\n",
      "Epoch [1/85] Batch 440/938 Loss D: 0.0233, Loss G: 4.1388\n",
      "Epoch [1/85] Batch 450/938 Loss D: 0.0430, Loss G: 4.6898\n",
      "Epoch [1/85] Batch 460/938 Loss D: 0.1258, Loss G: 3.7503\n",
      "Epoch [1/85] Batch 470/938 Loss D: 0.0438, Loss G: 4.0432\n",
      "Epoch [1/85] Batch 480/938 Loss D: 0.0680, Loss G: 3.4658\n",
      "Epoch [1/85] Batch 490/938 Loss D: 0.0821, Loss G: 3.3535\n",
      "Epoch [1/85] Batch 500/938 Loss D: 0.0925, Loss G: 3.4919\n",
      "Epoch [1/85] Batch 510/938 Loss D: 0.0630, Loss G: 3.7831\n",
      "Epoch [1/85] Batch 520/938 Loss D: 0.0547, Loss G: 4.0226\n",
      "Epoch [1/85] Batch 530/938 Loss D: 0.0474, Loss G: 4.1095\n",
      "Epoch [1/85] Batch 540/938 Loss D: 0.0442, Loss G: 4.5841\n",
      "Epoch [1/85] Batch 550/938 Loss D: 0.0579, Loss G: 4.2846\n",
      "Epoch [1/85] Batch 560/938 Loss D: 0.0505, Loss G: 4.1107\n",
      "Epoch [1/85] Batch 570/938 Loss D: 0.0383, Loss G: 4.2447\n",
      "Epoch [1/85] Batch 580/938 Loss D: 0.0208, Loss G: 4.2504\n",
      "Epoch [1/85] Batch 590/938 Loss D: 0.0400, Loss G: 3.9214\n",
      "Epoch [1/85] Batch 600/938 Loss D: 0.0919, Loss G: 3.4322\n",
      "Epoch [1/85] Batch 610/938 Loss D: 0.0503, Loss G: 4.1738\n",
      "Epoch [1/85] Batch 620/938 Loss D: 0.0450, Loss G: 4.2009\n",
      "Epoch [1/85] Batch 630/938 Loss D: 0.0483, Loss G: 3.8407\n",
      "Epoch [1/85] Batch 640/938 Loss D: 0.0497, Loss G: 3.5694\n",
      "Epoch [1/85] Batch 650/938 Loss D: 0.1565, Loss G: 3.1461\n",
      "Epoch [1/85] Batch 660/938 Loss D: 0.1391, Loss G: 2.8368\n",
      "Epoch [1/85] Batch 670/938 Loss D: 0.0700, Loss G: 3.3565\n",
      "Epoch [1/85] Batch 680/938 Loss D: 0.0816, Loss G: 3.1706\n",
      "Epoch [1/85] Batch 690/938 Loss D: 0.0934, Loss G: 3.4611\n",
      "Epoch [1/85] Batch 700/938 Loss D: 0.1055, Loss G: 3.6103\n",
      "Epoch [1/85] Batch 710/938 Loss D: 0.1242, Loss G: 3.0734\n",
      "Epoch [1/85] Batch 720/938 Loss D: 0.1583, Loss G: 2.3341\n",
      "Epoch [1/85] Batch 730/938 Loss D: 0.0667, Loss G: 3.5692\n",
      "Epoch [1/85] Batch 740/938 Loss D: 0.0663, Loss G: 3.4493\n",
      "Epoch [1/85] Batch 750/938 Loss D: 0.1826, Loss G: 2.7728\n",
      "Epoch [1/85] Batch 760/938 Loss D: 0.1405, Loss G: 2.6493\n",
      "Epoch [1/85] Batch 770/938 Loss D: 0.1760, Loss G: 2.1764\n",
      "Epoch [1/85] Batch 780/938 Loss D: 0.1550, Loss G: 2.7277\n",
      "Epoch [1/85] Batch 790/938 Loss D: 0.1350, Loss G: 3.1184\n",
      "Epoch [1/85] Batch 800/938 Loss D: 0.1447, Loss G: 3.2782\n",
      "Epoch [1/85] Batch 810/938 Loss D: 0.2284, Loss G: 2.7273\n",
      "Epoch [1/85] Batch 820/938 Loss D: 0.2985, Loss G: 1.9282\n",
      "Epoch [1/85] Batch 830/938 Loss D: 0.0635, Loss G: 3.1267\n",
      "Epoch [1/85] Batch 840/938 Loss D: 0.1217, Loss G: 3.6265\n",
      "Epoch [1/85] Batch 850/938 Loss D: 0.1547, Loss G: 3.1365\n",
      "Epoch [1/85] Batch 860/938 Loss D: 0.2287, Loss G: 2.8870\n",
      "Epoch [1/85] Batch 870/938 Loss D: 0.3774, Loss G: 1.5185\n",
      "Epoch [1/85] Batch 880/938 Loss D: 0.1522, Loss G: 2.8606\n",
      "Epoch [1/85] Batch 890/938 Loss D: 0.1942, Loss G: 2.9562\n",
      "Epoch [1/85] Batch 900/938 Loss D: 0.1407, Loss G: 3.0511\n",
      "Epoch [1/85] Batch 910/938 Loss D: 0.0866, Loss G: 3.2738\n",
      "Epoch [1/85] Batch 920/938 Loss D: 0.1014, Loss G: 3.3842\n",
      "Epoch [1/85] Batch 930/938 Loss D: 0.2770, Loss G: 2.0743\n",
      "Epoch [2/85] Batch 0/938 Loss D: 0.4589, Loss G: 1.5677\n",
      "Epoch [2/85] Batch 10/938 Loss D: 0.1445, Loss G: 2.7995\n",
      "Epoch [2/85] Batch 20/938 Loss D: 0.1798, Loss G: 2.4031\n",
      "Epoch [2/85] Batch 30/938 Loss D: 0.1974, Loss G: 2.2212\n",
      "Epoch [2/85] Batch 40/938 Loss D: 0.1994, Loss G: 2.2972\n",
      "Epoch [2/85] Batch 50/938 Loss D: 0.2055, Loss G: 2.3552\n",
      "Epoch [2/85] Batch 60/938 Loss D: 0.2131, Loss G: 2.4203\n",
      "Epoch [2/85] Batch 70/938 Loss D: 0.2308, Loss G: 2.6182\n",
      "Epoch [2/85] Batch 80/938 Loss D: 0.1791, Loss G: 3.0550\n",
      "Epoch [2/85] Batch 90/938 Loss D: 0.3255, Loss G: 2.4559\n",
      "Epoch [2/85] Batch 100/938 Loss D: 0.2314, Loss G: 2.3893\n",
      "Epoch [2/85] Batch 110/938 Loss D: 0.3075, Loss G: 2.4555\n",
      "Epoch [2/85] Batch 120/938 Loss D: 0.1340, Loss G: 3.1465\n",
      "Epoch [2/85] Batch 130/938 Loss D: 0.1423, Loss G: 2.6544\n",
      "Epoch [2/85] Batch 140/938 Loss D: 0.2090, Loss G: 2.6380\n",
      "Epoch [2/85] Batch 150/938 Loss D: 0.2299, Loss G: 2.5296\n",
      "Epoch [2/85] Batch 160/938 Loss D: 0.2505, Loss G: 1.9703\n",
      "Epoch [2/85] Batch 170/938 Loss D: 0.1089, Loss G: 2.4422\n",
      "Epoch [2/85] Batch 180/938 Loss D: 0.0919, Loss G: 2.7255\n",
      "Epoch [2/85] Batch 190/938 Loss D: 0.1645, Loss G: 2.4473\n",
      "Epoch [2/85] Batch 200/938 Loss D: 0.2430, Loss G: 2.3033\n",
      "Epoch [2/85] Batch 210/938 Loss D: 0.2227, Loss G: 2.1917\n",
      "Epoch [2/85] Batch 220/938 Loss D: 0.2533, Loss G: 2.1144\n",
      "Epoch [2/85] Batch 230/938 Loss D: 0.1701, Loss G: 2.3021\n",
      "Epoch [2/85] Batch 240/938 Loss D: 0.2490, Loss G: 2.4065\n",
      "Epoch [2/85] Batch 250/938 Loss D: 0.2693, Loss G: 2.0465\n",
      "Epoch [2/85] Batch 260/938 Loss D: 0.1588, Loss G: 2.5438\n",
      "Epoch [2/85] Batch 270/938 Loss D: 0.2200, Loss G: 1.9850\n",
      "Epoch [2/85] Batch 280/938 Loss D: 0.3716, Loss G: 1.9626\n",
      "Epoch [2/85] Batch 290/938 Loss D: 0.1892, Loss G: 2.4801\n",
      "Epoch [2/85] Batch 300/938 Loss D: 0.1359, Loss G: 2.5046\n",
      "Epoch [2/85] Batch 310/938 Loss D: 0.1272, Loss G: 3.7999\n",
      "Epoch [2/85] Batch 320/938 Loss D: 0.1722, Loss G: 3.1775\n",
      "Epoch [2/85] Batch 330/938 Loss D: 0.2654, Loss G: 2.2832\n",
      "Epoch [2/85] Batch 340/938 Loss D: 0.3440, Loss G: 2.3787\n",
      "Epoch [2/85] Batch 350/938 Loss D: 0.3592, Loss G: 1.9173\n",
      "Epoch [2/85] Batch 360/938 Loss D: 0.2470, Loss G: 1.9871\n",
      "Epoch [2/85] Batch 370/938 Loss D: 0.2259, Loss G: 1.9817\n",
      "Epoch [2/85] Batch 380/938 Loss D: 0.1314, Loss G: 2.5442\n",
      "Epoch [2/85] Batch 390/938 Loss D: 0.1816, Loss G: 2.9744\n",
      "Epoch [2/85] Batch 400/938 Loss D: 0.2396, Loss G: 2.8276\n",
      "Epoch [2/85] Batch 410/938 Loss D: 0.4347, Loss G: 2.6832\n",
      "Epoch [2/85] Batch 420/938 Loss D: 0.1922, Loss G: 3.2031\n",
      "Epoch [2/85] Batch 430/938 Loss D: 0.1987, Loss G: 2.4917\n",
      "Epoch [2/85] Batch 440/938 Loss D: 0.1388, Loss G: 2.3494\n",
      "Epoch [2/85] Batch 450/938 Loss D: 0.2629, Loss G: 2.4511\n",
      "Epoch [2/85] Batch 460/938 Loss D: 0.2205, Loss G: 2.6674\n",
      "Epoch [2/85] Batch 470/938 Loss D: 0.2077, Loss G: 2.1647\n",
      "Epoch [2/85] Batch 480/938 Loss D: 0.1386, Loss G: 2.4977\n",
      "Epoch [2/85] Batch 490/938 Loss D: 0.2420, Loss G: 2.2337\n",
      "Epoch [2/85] Batch 500/938 Loss D: 0.2907, Loss G: 1.7134\n",
      "Epoch [2/85] Batch 510/938 Loss D: 0.3296, Loss G: 1.7362\n",
      "Epoch [2/85] Batch 520/938 Loss D: 0.1449, Loss G: 2.4800\n",
      "Epoch [2/85] Batch 530/938 Loss D: 0.1230, Loss G: 3.1746\n",
      "Epoch [2/85] Batch 540/938 Loss D: 0.2268, Loss G: 2.4742\n",
      "Epoch [2/85] Batch 550/938 Loss D: 0.2966, Loss G: 2.0470\n",
      "Epoch [2/85] Batch 560/938 Loss D: 0.2947, Loss G: 2.7111\n",
      "Epoch [2/85] Batch 570/938 Loss D: 0.4414, Loss G: 1.9678\n",
      "Epoch [2/85] Batch 580/938 Loss D: 0.1722, Loss G: 2.6375\n",
      "Epoch [2/85] Batch 590/938 Loss D: 0.1979, Loss G: 2.8500\n",
      "Epoch [2/85] Batch 600/938 Loss D: 0.1898, Loss G: 2.5037\n",
      "Epoch [2/85] Batch 610/938 Loss D: 0.2330, Loss G: 2.1692\n",
      "Epoch [2/85] Batch 620/938 Loss D: 0.2623, Loss G: 1.7041\n",
      "Epoch [2/85] Batch 630/938 Loss D: 0.1691, Loss G: 2.1291\n",
      "Epoch [2/85] Batch 640/938 Loss D: 0.3186, Loss G: 2.1349\n",
      "Epoch [2/85] Batch 650/938 Loss D: 0.3184, Loss G: 1.8654\n",
      "Epoch [2/85] Batch 660/938 Loss D: 0.1120, Loss G: 3.3577\n",
      "Epoch [2/85] Batch 670/938 Loss D: 0.0605, Loss G: 3.7427\n",
      "Epoch [2/85] Batch 680/938 Loss D: 0.1266, Loss G: 3.0805\n",
      "Epoch [2/85] Batch 690/938 Loss D: 0.2317, Loss G: 2.6947\n",
      "Epoch [2/85] Batch 700/938 Loss D: 0.1828, Loss G: 2.7796\n",
      "Epoch [2/85] Batch 710/938 Loss D: 0.1699, Loss G: 2.4172\n",
      "Epoch [2/85] Batch 720/938 Loss D: 0.1642, Loss G: 2.2171\n",
      "Epoch [2/85] Batch 730/938 Loss D: 0.1889, Loss G: 2.0371\n",
      "Epoch [2/85] Batch 740/938 Loss D: 0.2248, Loss G: 2.0109\n",
      "Epoch [2/85] Batch 750/938 Loss D: 0.1560, Loss G: 2.7738\n",
      "Epoch [2/85] Batch 760/938 Loss D: 0.1984, Loss G: 2.1908\n",
      "Epoch [2/85] Batch 770/938 Loss D: 0.2042, Loss G: 2.2053\n",
      "Epoch [2/85] Batch 780/938 Loss D: 0.1873, Loss G: 2.2983\n",
      "Epoch [2/85] Batch 790/938 Loss D: 0.2690, Loss G: 2.1543\n",
      "Epoch [2/85] Batch 800/938 Loss D: 0.2044, Loss G: 2.9667\n",
      "Epoch [2/85] Batch 810/938 Loss D: 0.2011, Loss G: 2.4760\n",
      "Epoch [2/85] Batch 820/938 Loss D: 0.3222, Loss G: 1.7497\n",
      "Epoch [2/85] Batch 830/938 Loss D: 0.2937, Loss G: 1.7098\n",
      "Epoch [2/85] Batch 840/938 Loss D: 0.2879, Loss G: 1.4361\n",
      "Epoch [2/85] Batch 850/938 Loss D: 0.1747, Loss G: 2.4184\n",
      "Epoch [2/85] Batch 860/938 Loss D: 0.2197, Loss G: 2.8154\n",
      "Epoch [2/85] Batch 870/938 Loss D: 0.2046, Loss G: 2.3662\n",
      "Epoch [2/85] Batch 880/938 Loss D: 0.2376, Loss G: 2.1174\n",
      "Epoch [2/85] Batch 890/938 Loss D: 0.2507, Loss G: 2.0953\n",
      "Epoch [2/85] Batch 900/938 Loss D: 0.2088, Loss G: 2.1896\n",
      "Epoch [2/85] Batch 910/938 Loss D: 0.1908, Loss G: 2.0673\n",
      "Epoch [2/85] Batch 920/938 Loss D: 0.1952, Loss G: 2.3111\n",
      "Epoch [2/85] Batch 930/938 Loss D: 0.2090, Loss G: 1.8794\n",
      "Epoch [3/85] Batch 0/938 Loss D: 0.2000, Loss G: 2.2205\n",
      "Epoch [3/85] Batch 10/938 Loss D: 0.2454, Loss G: 2.3496\n",
      "Epoch [3/85] Batch 20/938 Loss D: 0.2123, Loss G: 2.3953\n",
      "Epoch [3/85] Batch 30/938 Loss D: 0.1623, Loss G: 2.7077\n",
      "Epoch [3/85] Batch 40/938 Loss D: 0.2095, Loss G: 2.5273\n",
      "Epoch [3/85] Batch 50/938 Loss D: 0.1923, Loss G: 2.1723\n",
      "Epoch [3/85] Batch 60/938 Loss D: 0.2018, Loss G: 2.3601\n",
      "Epoch [3/85] Batch 70/938 Loss D: 0.1281, Loss G: 2.8780\n",
      "Epoch [3/85] Batch 80/938 Loss D: 0.2141, Loss G: 2.1435\n",
      "Epoch [3/85] Batch 90/938 Loss D: 0.2480, Loss G: 2.1069\n",
      "Epoch [3/85] Batch 100/938 Loss D: 0.1732, Loss G: 2.3137\n",
      "Epoch [3/85] Batch 110/938 Loss D: 0.2079, Loss G: 2.7720\n",
      "Epoch [3/85] Batch 120/938 Loss D: 0.2502, Loss G: 2.3906\n",
      "Epoch [3/85] Batch 130/938 Loss D: 0.2511, Loss G: 2.6326\n",
      "Epoch [3/85] Batch 140/938 Loss D: 0.1583, Loss G: 2.7937\n",
      "Epoch [3/85] Batch 150/938 Loss D: 0.1225, Loss G: 2.7948\n",
      "Epoch [3/85] Batch 160/938 Loss D: 0.1381, Loss G: 2.8437\n",
      "Epoch [3/85] Batch 170/938 Loss D: 0.2093, Loss G: 2.5851\n",
      "Epoch [3/85] Batch 180/938 Loss D: 0.1270, Loss G: 3.0540\n",
      "Epoch [3/85] Batch 190/938 Loss D: 0.1637, Loss G: 2.8921\n",
      "Epoch [3/85] Batch 200/938 Loss D: 0.1947, Loss G: 2.5501\n",
      "Epoch [3/85] Batch 210/938 Loss D: 0.2378, Loss G: 2.1694\n",
      "Epoch [3/85] Batch 220/938 Loss D: 0.2594, Loss G: 1.9268\n",
      "Epoch [3/85] Batch 230/938 Loss D: 0.1123, Loss G: 3.1478\n",
      "Epoch [3/85] Batch 240/938 Loss D: 0.1765, Loss G: 2.6021\n",
      "Epoch [3/85] Batch 250/938 Loss D: 0.1932, Loss G: 2.4319\n",
      "Epoch [3/85] Batch 260/938 Loss D: 0.1833, Loss G: 2.6851\n",
      "Epoch [3/85] Batch 270/938 Loss D: 0.2556, Loss G: 1.9906\n",
      "Epoch [3/85] Batch 280/938 Loss D: 0.2070, Loss G: 2.3602\n",
      "Epoch [3/85] Batch 290/938 Loss D: 0.3050, Loss G: 2.0570\n",
      "Epoch [3/85] Batch 300/938 Loss D: 0.2654, Loss G: 2.3800\n",
      "Epoch [3/85] Batch 310/938 Loss D: 0.2103, Loss G: 2.2354\n",
      "Epoch [3/85] Batch 320/938 Loss D: 0.2687, Loss G: 1.9445\n",
      "Epoch [3/85] Batch 330/938 Loss D: 0.1964, Loss G: 2.8090\n",
      "Epoch [3/85] Batch 340/938 Loss D: 0.1125, Loss G: 3.3771\n",
      "Epoch [3/85] Batch 350/938 Loss D: 0.2031, Loss G: 2.8623\n",
      "Epoch [3/85] Batch 360/938 Loss D: 0.3204, Loss G: 1.8541\n",
      "Epoch [3/85] Batch 370/938 Loss D: 0.2209, Loss G: 2.5989\n",
      "Epoch [3/85] Batch 380/938 Loss D: 0.1347, Loss G: 2.4545\n",
      "Epoch [3/85] Batch 390/938 Loss D: 0.2008, Loss G: 2.7537\n",
      "Epoch [3/85] Batch 400/938 Loss D: 0.3444, Loss G: 1.6103\n",
      "Epoch [3/85] Batch 410/938 Loss D: 0.3148, Loss G: 1.7119\n",
      "Epoch [3/85] Batch 420/938 Loss D: 0.1666, Loss G: 2.5279\n",
      "Epoch [3/85] Batch 430/938 Loss D: 0.1928, Loss G: 2.3792\n",
      "Epoch [3/85] Batch 440/938 Loss D: 0.1564, Loss G: 2.3012\n",
      "Epoch [3/85] Batch 450/938 Loss D: 0.1384, Loss G: 2.1220\n",
      "Epoch [3/85] Batch 460/938 Loss D: 0.2009, Loss G: 2.0246\n",
      "Epoch [3/85] Batch 470/938 Loss D: 0.3990, Loss G: 1.7072\n",
      "Epoch [3/85] Batch 480/938 Loss D: 0.2053, Loss G: 2.1004\n",
      "Epoch [3/85] Batch 490/938 Loss D: 0.1420, Loss G: 2.8881\n",
      "Epoch [3/85] Batch 500/938 Loss D: 0.1828, Loss G: 2.5138\n",
      "Epoch [3/85] Batch 510/938 Loss D: 0.2287, Loss G: 2.0180\n",
      "Epoch [3/85] Batch 520/938 Loss D: 0.1412, Loss G: 2.7249\n",
      "Epoch [3/85] Batch 530/938 Loss D: 0.1370, Loss G: 2.7534\n",
      "Epoch [3/85] Batch 540/938 Loss D: 0.2473, Loss G: 2.4632\n",
      "Epoch [3/85] Batch 550/938 Loss D: 0.3042, Loss G: 2.1654\n",
      "Epoch [3/85] Batch 560/938 Loss D: 0.2460, Loss G: 1.9846\n",
      "Epoch [3/85] Batch 570/938 Loss D: 0.1841, Loss G: 2.4135\n",
      "Epoch [3/85] Batch 580/938 Loss D: 0.1043, Loss G: 2.8225\n",
      "Epoch [3/85] Batch 590/938 Loss D: 0.1739, Loss G: 2.9006\n",
      "Epoch [3/85] Batch 600/938 Loss D: 0.2557, Loss G: 2.7846\n",
      "Epoch [3/85] Batch 610/938 Loss D: 0.2295, Loss G: 2.5814\n",
      "Epoch [3/85] Batch 620/938 Loss D: 0.2514, Loss G: 2.3775\n",
      "Epoch [3/85] Batch 630/938 Loss D: 0.1978, Loss G: 2.6952\n",
      "Epoch [3/85] Batch 640/938 Loss D: 0.2119, Loss G: 2.5841\n",
      "Epoch [3/85] Batch 650/938 Loss D: 0.1989, Loss G: 2.3953\n",
      "Epoch [3/85] Batch 660/938 Loss D: 0.2710, Loss G: 2.3514\n",
      "Epoch [3/85] Batch 670/938 Loss D: 0.3255, Loss G: 1.9464\n",
      "Epoch [3/85] Batch 680/938 Loss D: 0.2823, Loss G: 1.9801\n",
      "Epoch [3/85] Batch 690/938 Loss D: 0.2585, Loss G: 2.0164\n",
      "Epoch [3/85] Batch 700/938 Loss D: 0.3510, Loss G: 1.6098\n",
      "Epoch [3/85] Batch 710/938 Loss D: 0.2252, Loss G: 2.1773\n",
      "Epoch [3/85] Batch 720/938 Loss D: 0.2231, Loss G: 2.3965\n",
      "Epoch [3/85] Batch 730/938 Loss D: 0.3618, Loss G: 2.5215\n",
      "Epoch [3/85] Batch 740/938 Loss D: 0.2319, Loss G: 2.7189\n",
      "Epoch [3/85] Batch 750/938 Loss D: 0.3029, Loss G: 2.4299\n",
      "Epoch [3/85] Batch 760/938 Loss D: 0.3389, Loss G: 2.5348\n",
      "Epoch [3/85] Batch 770/938 Loss D: 0.1676, Loss G: 3.0181\n",
      "Epoch [3/85] Batch 780/938 Loss D: 0.2481, Loss G: 2.1944\n",
      "Epoch [3/85] Batch 790/938 Loss D: 0.2466, Loss G: 2.3102\n",
      "Epoch [3/85] Batch 800/938 Loss D: 0.2936, Loss G: 1.8477\n",
      "Epoch [3/85] Batch 810/938 Loss D: 0.2681, Loss G: 1.8393\n",
      "Epoch [3/85] Batch 820/938 Loss D: 0.3247, Loss G: 2.0513\n",
      "Epoch [3/85] Batch 830/938 Loss D: 0.2059, Loss G: 2.3644\n",
      "Epoch [3/85] Batch 840/938 Loss D: 0.2815, Loss G: 2.5959\n",
      "Epoch [3/85] Batch 850/938 Loss D: 0.1822, Loss G: 2.5581\n",
      "Epoch [3/85] Batch 860/938 Loss D: 0.2615, Loss G: 2.0976\n",
      "Epoch [3/85] Batch 870/938 Loss D: 0.2276, Loss G: 2.3048\n",
      "Epoch [3/85] Batch 880/938 Loss D: 0.2122, Loss G: 2.3369\n",
      "Epoch [3/85] Batch 890/938 Loss D: 0.1984, Loss G: 2.0392\n",
      "Epoch [3/85] Batch 900/938 Loss D: 0.2264, Loss G: 2.2095\n",
      "Epoch [3/85] Batch 910/938 Loss D: 0.1694, Loss G: 2.7622\n",
      "Epoch [3/85] Batch 920/938 Loss D: 0.2142, Loss G: 2.2763\n",
      "Epoch [3/85] Batch 930/938 Loss D: 0.2503, Loss G: 2.0157\n",
      "Epoch [4/85] Batch 0/938 Loss D: 0.1785, Loss G: 2.2564\n",
      "Epoch [4/85] Batch 10/938 Loss D: 0.2441, Loss G: 1.8484\n",
      "Epoch [4/85] Batch 20/938 Loss D: 0.3438, Loss G: 1.9809\n",
      "Epoch [4/85] Batch 30/938 Loss D: 0.2006, Loss G: 2.4896\n",
      "Epoch [4/85] Batch 40/938 Loss D: 0.2281, Loss G: 2.0760\n",
      "Epoch [4/85] Batch 50/938 Loss D: 0.2523, Loss G: 2.0541\n",
      "Epoch [4/85] Batch 60/938 Loss D: 0.2736, Loss G: 1.7287\n",
      "Epoch [4/85] Batch 70/938 Loss D: 0.2309, Loss G: 2.0840\n",
      "Epoch [4/85] Batch 80/938 Loss D: 0.2816, Loss G: 2.0812\n",
      "Epoch [4/85] Batch 90/938 Loss D: 0.2859, Loss G: 1.8037\n",
      "Epoch [4/85] Batch 100/938 Loss D: 0.2921, Loss G: 1.7512\n",
      "Epoch [4/85] Batch 110/938 Loss D: 0.1867, Loss G: 2.3142\n",
      "Epoch [4/85] Batch 120/938 Loss D: 0.2099, Loss G: 2.3756\n",
      "Epoch [4/85] Batch 130/938 Loss D: 0.2843, Loss G: 2.2451\n",
      "Epoch [4/85] Batch 140/938 Loss D: 0.2708, Loss G: 1.9834\n",
      "Epoch [4/85] Batch 150/938 Loss D: 0.2996, Loss G: 2.1010\n",
      "Epoch [4/85] Batch 160/938 Loss D: 0.2290, Loss G: 2.6604\n",
      "Epoch [4/85] Batch 170/938 Loss D: 0.1859, Loss G: 2.5349\n",
      "Epoch [4/85] Batch 180/938 Loss D: 0.2710, Loss G: 2.5488\n",
      "Epoch [4/85] Batch 190/938 Loss D: 0.3371, Loss G: 1.8435\n",
      "Epoch [4/85] Batch 200/938 Loss D: 0.1302, Loss G: 3.1104\n",
      "Epoch [4/85] Batch 210/938 Loss D: 0.2340, Loss G: 2.6271\n",
      "Epoch [4/85] Batch 220/938 Loss D: 0.3621, Loss G: 1.7875\n",
      "Epoch [4/85] Batch 230/938 Loss D: 0.2963, Loss G: 2.0919\n",
      "Epoch [4/85] Batch 240/938 Loss D: 0.1756, Loss G: 2.4211\n",
      "Epoch [4/85] Batch 250/938 Loss D: 0.2811, Loss G: 2.0170\n",
      "Epoch [4/85] Batch 260/938 Loss D: 0.2932, Loss G: 1.7606\n",
      "Epoch [4/85] Batch 270/938 Loss D: 0.4645, Loss G: 1.8371\n",
      "Epoch [4/85] Batch 280/938 Loss D: 0.2564, Loss G: 2.4824\n",
      "Epoch [4/85] Batch 290/938 Loss D: 0.1801, Loss G: 3.1386\n",
      "Epoch [4/85] Batch 300/938 Loss D: 0.4505, Loss G: 1.6336\n",
      "Epoch [4/85] Batch 310/938 Loss D: 0.4851, Loss G: 2.1652\n",
      "Epoch [4/85] Batch 320/938 Loss D: 0.1812, Loss G: 2.9403\n",
      "Epoch [4/85] Batch 330/938 Loss D: 0.2761, Loss G: 2.7960\n",
      "Epoch [4/85] Batch 340/938 Loss D: 0.5341, Loss G: 2.0256\n",
      "Epoch [4/85] Batch 350/938 Loss D: 0.3078, Loss G: 2.6341\n",
      "Epoch [4/85] Batch 360/938 Loss D: 0.2537, Loss G: 2.3981\n",
      "Epoch [4/85] Batch 370/938 Loss D: 0.2410, Loss G: 2.8888\n",
      "Epoch [4/85] Batch 380/938 Loss D: 0.3610, Loss G: 2.1447\n",
      "Epoch [4/85] Batch 390/938 Loss D: 0.3165, Loss G: 2.8484\n",
      "Epoch [4/85] Batch 400/938 Loss D: 0.2215, Loss G: 3.0307\n",
      "Epoch [4/85] Batch 410/938 Loss D: 0.2155, Loss G: 2.9856\n",
      "Epoch [4/85] Batch 420/938 Loss D: 0.2540, Loss G: 2.4995\n",
      "Epoch [4/85] Batch 430/938 Loss D: 0.1220, Loss G: 2.8374\n",
      "Epoch [4/85] Batch 440/938 Loss D: 0.2154, Loss G: 2.3966\n",
      "Epoch [4/85] Batch 450/938 Loss D: 0.3894, Loss G: 1.6561\n",
      "Epoch [4/85] Batch 460/938 Loss D: 0.2710, Loss G: 2.0913\n",
      "Epoch [4/85] Batch 470/938 Loss D: 0.2446, Loss G: 2.0705\n",
      "Epoch [4/85] Batch 480/938 Loss D: 0.4256, Loss G: 2.1496\n",
      "Epoch [4/85] Batch 490/938 Loss D: 0.3099, Loss G: 2.2657\n",
      "Epoch [4/85] Batch 500/938 Loss D: 0.2017, Loss G: 2.6750\n",
      "Epoch [4/85] Batch 510/938 Loss D: 0.4170, Loss G: 1.6947\n",
      "Epoch [4/85] Batch 520/938 Loss D: 0.3745, Loss G: 1.9532\n",
      "Epoch [4/85] Batch 530/938 Loss D: 0.3706, Loss G: 2.5694\n",
      "Epoch [4/85] Batch 540/938 Loss D: 0.3080, Loss G: 2.3544\n",
      "Epoch [4/85] Batch 550/938 Loss D: 0.4018, Loss G: 2.3410\n",
      "Epoch [4/85] Batch 560/938 Loss D: 0.5113, Loss G: 1.8762\n",
      "Epoch [4/85] Batch 570/938 Loss D: 0.4124, Loss G: 1.9340\n",
      "Epoch [4/85] Batch 580/938 Loss D: 0.2955, Loss G: 2.5851\n",
      "Epoch [4/85] Batch 590/938 Loss D: 0.3000, Loss G: 2.8274\n",
      "Epoch [4/85] Batch 600/938 Loss D: 0.2520, Loss G: 2.1895\n",
      "Epoch [4/85] Batch 610/938 Loss D: 0.3577, Loss G: 2.0475\n",
      "Epoch [4/85] Batch 620/938 Loss D: 0.3139, Loss G: 2.1945\n",
      "Epoch [4/85] Batch 630/938 Loss D: 0.3448, Loss G: 2.3381\n",
      "Epoch [4/85] Batch 640/938 Loss D: 0.3132, Loss G: 2.2433\n",
      "Epoch [4/85] Batch 650/938 Loss D: 0.2778, Loss G: 2.2844\n",
      "Epoch [4/85] Batch 660/938 Loss D: 0.2351, Loss G: 2.3536\n",
      "Epoch [4/85] Batch 670/938 Loss D: 0.3597, Loss G: 2.1601\n",
      "Epoch [4/85] Batch 680/938 Loss D: 0.3473, Loss G: 2.2961\n",
      "Epoch [4/85] Batch 690/938 Loss D: 0.1691, Loss G: 2.4340\n",
      "Epoch [4/85] Batch 700/938 Loss D: 0.2248, Loss G: 2.6121\n",
      "Epoch [4/85] Batch 710/938 Loss D: 0.2495, Loss G: 1.9893\n",
      "Epoch [4/85] Batch 720/938 Loss D: 0.3643, Loss G: 2.2001\n",
      "Epoch [4/85] Batch 730/938 Loss D: 0.2635, Loss G: 2.1537\n",
      "Epoch [4/85] Batch 740/938 Loss D: 0.2847, Loss G: 2.2900\n",
      "Epoch [4/85] Batch 750/938 Loss D: 0.2323, Loss G: 2.3301\n",
      "Epoch [4/85] Batch 760/938 Loss D: 0.3051, Loss G: 2.0037\n",
      "Epoch [4/85] Batch 770/938 Loss D: 0.2628, Loss G: 2.4765\n",
      "Epoch [4/85] Batch 780/938 Loss D: 0.2867, Loss G: 1.9051\n",
      "Epoch [4/85] Batch 790/938 Loss D: 0.2558, Loss G: 2.4153\n",
      "Epoch [4/85] Batch 800/938 Loss D: 0.2595, Loss G: 2.2401\n",
      "Epoch [4/85] Batch 810/938 Loss D: 0.4294, Loss G: 2.0599\n",
      "Epoch [4/85] Batch 820/938 Loss D: 0.4206, Loss G: 2.2081\n",
      "Epoch [4/85] Batch 830/938 Loss D: 0.3388, Loss G: 2.0751\n",
      "Epoch [4/85] Batch 840/938 Loss D: 0.3107, Loss G: 2.0337\n",
      "Epoch [4/85] Batch 850/938 Loss D: 0.4803, Loss G: 1.7645\n",
      "Epoch [4/85] Batch 860/938 Loss D: 0.3674, Loss G: 2.3786\n",
      "Epoch [4/85] Batch 870/938 Loss D: 0.2135, Loss G: 2.4951\n",
      "Epoch [4/85] Batch 880/938 Loss D: 0.3673, Loss G: 1.7840\n",
      "Epoch [4/85] Batch 890/938 Loss D: 0.2987, Loss G: 2.1292\n",
      "Epoch [4/85] Batch 900/938 Loss D: 0.3528, Loss G: 1.8188\n",
      "Epoch [4/85] Batch 910/938 Loss D: 0.3590, Loss G: 1.7712\n",
      "Epoch [4/85] Batch 920/938 Loss D: 0.2608, Loss G: 1.9136\n",
      "Epoch [4/85] Batch 930/938 Loss D: 0.2833, Loss G: 1.7916\n",
      "Epoch [5/85] Batch 0/938 Loss D: 0.5047, Loss G: 2.0526\n",
      "Epoch [5/85] Batch 10/938 Loss D: 0.4065, Loss G: 1.5720\n",
      "Epoch [5/85] Batch 20/938 Loss D: 0.5262, Loss G: 1.6676\n",
      "Epoch [5/85] Batch 30/938 Loss D: 0.4151, Loss G: 2.0307\n",
      "Epoch [5/85] Batch 40/938 Loss D: 0.4577, Loss G: 1.6597\n",
      "Epoch [5/85] Batch 50/938 Loss D: 0.2588, Loss G: 2.3670\n",
      "Epoch [5/85] Batch 60/938 Loss D: 0.4137, Loss G: 1.8088\n",
      "Epoch [5/85] Batch 70/938 Loss D: 0.2881, Loss G: 2.0541\n",
      "Epoch [5/85] Batch 80/938 Loss D: 0.4806, Loss G: 1.2659\n",
      "Epoch [5/85] Batch 90/938 Loss D: 0.4042, Loss G: 1.3707\n",
      "Epoch [5/85] Batch 100/938 Loss D: 0.5079, Loss G: 1.7557\n",
      "Epoch [5/85] Batch 110/938 Loss D: 0.3610, Loss G: 2.4860\n",
      "Epoch [5/85] Batch 120/938 Loss D: 0.2588, Loss G: 2.8660\n",
      "Epoch [5/85] Batch 130/938 Loss D: 0.3042, Loss G: 2.6330\n",
      "Epoch [5/85] Batch 140/938 Loss D: 0.4246, Loss G: 2.1245\n",
      "Epoch [5/85] Batch 150/938 Loss D: 0.3011, Loss G: 2.5439\n",
      "Epoch [5/85] Batch 160/938 Loss D: 0.3379, Loss G: 1.7873\n",
      "Epoch [5/85] Batch 170/938 Loss D: 0.5642, Loss G: 1.4379\n",
      "Epoch [5/85] Batch 180/938 Loss D: 0.3730, Loss G: 2.0190\n",
      "Epoch [5/85] Batch 190/938 Loss D: 0.3242, Loss G: 2.2219\n",
      "Epoch [5/85] Batch 200/938 Loss D: 0.4431, Loss G: 2.0277\n",
      "Epoch [5/85] Batch 210/938 Loss D: 0.3180, Loss G: 2.2010\n",
      "Epoch [5/85] Batch 220/938 Loss D: 0.2560, Loss G: 2.4727\n",
      "Epoch [5/85] Batch 230/938 Loss D: 0.2332, Loss G: 2.1261\n",
      "Epoch [5/85] Batch 240/938 Loss D: 0.3769, Loss G: 1.6792\n",
      "Epoch [5/85] Batch 250/938 Loss D: 0.6040, Loss G: 1.2626\n",
      "Epoch [5/85] Batch 260/938 Loss D: 0.2826, Loss G: 2.4668\n",
      "Epoch [5/85] Batch 270/938 Loss D: 0.2881, Loss G: 2.2744\n",
      "Epoch [5/85] Batch 280/938 Loss D: 0.3044, Loss G: 1.8111\n",
      "Epoch [5/85] Batch 290/938 Loss D: 0.3769, Loss G: 1.9669\n",
      "Epoch [5/85] Batch 300/938 Loss D: 0.5473, Loss G: 1.7087\n",
      "Epoch [5/85] Batch 310/938 Loss D: 0.2271, Loss G: 2.3761\n",
      "Epoch [5/85] Batch 320/938 Loss D: 0.2078, Loss G: 2.3579\n",
      "Epoch [5/85] Batch 330/938 Loss D: 0.2857, Loss G: 2.2923\n",
      "Epoch [5/85] Batch 340/938 Loss D: 0.4435, Loss G: 1.9291\n",
      "Epoch [5/85] Batch 350/938 Loss D: 0.3790, Loss G: 1.8491\n",
      "Epoch [5/85] Batch 360/938 Loss D: 0.3298, Loss G: 1.7152\n",
      "Epoch [5/85] Batch 370/938 Loss D: 0.3299, Loss G: 2.2368\n",
      "Epoch [5/85] Batch 380/938 Loss D: 0.3234, Loss G: 2.2104\n",
      "Epoch [5/85] Batch 390/938 Loss D: 0.3145, Loss G: 2.0944\n",
      "Epoch [5/85] Batch 400/938 Loss D: 0.3173, Loss G: 1.9460\n",
      "Epoch [5/85] Batch 410/938 Loss D: 0.3035, Loss G: 1.7849\n",
      "Epoch [5/85] Batch 420/938 Loss D: 0.3697, Loss G: 1.9383\n",
      "Epoch [5/85] Batch 430/938 Loss D: 0.5340, Loss G: 1.7918\n",
      "Epoch [5/85] Batch 440/938 Loss D: 0.4191, Loss G: 1.6784\n",
      "Epoch [5/85] Batch 450/938 Loss D: 0.3189, Loss G: 2.3460\n",
      "Epoch [5/85] Batch 460/938 Loss D: 0.3513, Loss G: 1.9002\n",
      "Epoch [5/85] Batch 470/938 Loss D: 0.3592, Loss G: 1.6650\n",
      "Epoch [5/85] Batch 480/938 Loss D: 0.5835, Loss G: 1.6573\n",
      "Epoch [5/85] Batch 490/938 Loss D: 0.3930, Loss G: 1.8016\n",
      "Epoch [5/85] Batch 500/938 Loss D: 0.4163, Loss G: 1.8917\n",
      "Epoch [5/85] Batch 510/938 Loss D: 0.4286, Loss G: 1.8013\n",
      "Epoch [5/85] Batch 520/938 Loss D: 0.2144, Loss G: 2.2798\n",
      "Epoch [5/85] Batch 530/938 Loss D: 0.4865, Loss G: 1.4350\n",
      "Epoch [5/85] Batch 540/938 Loss D: 0.4787, Loss G: 1.6343\n",
      "Epoch [5/85] Batch 550/938 Loss D: 0.4607, Loss G: 1.5554\n",
      "Epoch [5/85] Batch 560/938 Loss D: 0.4892, Loss G: 1.7949\n",
      "Epoch [5/85] Batch 570/938 Loss D: 0.3414, Loss G: 1.9510\n",
      "Epoch [5/85] Batch 580/938 Loss D: 0.3418, Loss G: 1.7879\n",
      "Epoch [5/85] Batch 590/938 Loss D: 0.2888, Loss G: 1.9256\n",
      "Epoch [5/85] Batch 600/938 Loss D: 0.3187, Loss G: 1.7197\n",
      "Epoch [5/85] Batch 610/938 Loss D: 0.3814, Loss G: 2.1048\n",
      "Epoch [5/85] Batch 620/938 Loss D: 0.3463, Loss G: 2.1857\n",
      "Epoch [5/85] Batch 630/938 Loss D: 0.2943, Loss G: 2.1168\n",
      "Epoch [5/85] Batch 640/938 Loss D: 0.4133, Loss G: 2.0340\n",
      "Epoch [5/85] Batch 650/938 Loss D: 0.4773, Loss G: 1.7895\n",
      "Epoch [5/85] Batch 660/938 Loss D: 0.2774, Loss G: 2.2423\n",
      "Epoch [5/85] Batch 670/938 Loss D: 0.3616, Loss G: 1.6933\n",
      "Epoch [5/85] Batch 680/938 Loss D: 0.3685, Loss G: 1.6128\n",
      "Epoch [5/85] Batch 690/938 Loss D: 0.4711, Loss G: 1.5957\n",
      "Epoch [5/85] Batch 700/938 Loss D: 0.4747, Loss G: 1.4185\n",
      "Epoch [5/85] Batch 710/938 Loss D: 0.4085, Loss G: 1.7455\n",
      "Epoch [5/85] Batch 720/938 Loss D: 0.3284, Loss G: 2.2660\n",
      "Epoch [5/85] Batch 730/938 Loss D: 0.1943, Loss G: 2.2498\n",
      "Epoch [5/85] Batch 740/938 Loss D: 0.4097, Loss G: 1.7909\n",
      "Epoch [5/85] Batch 750/938 Loss D: 0.3521, Loss G: 1.9787\n",
      "Epoch [5/85] Batch 760/938 Loss D: 0.3514, Loss G: 1.6456\n",
      "Epoch [5/85] Batch 770/938 Loss D: 0.4340, Loss G: 1.6439\n",
      "Epoch [5/85] Batch 780/938 Loss D: 0.4170, Loss G: 1.9566\n",
      "Epoch [5/85] Batch 790/938 Loss D: 0.3070, Loss G: 2.0874\n",
      "Epoch [5/85] Batch 800/938 Loss D: 0.3391, Loss G: 2.0918\n",
      "Epoch [5/85] Batch 810/938 Loss D: 0.2623, Loss G: 2.2609\n",
      "Epoch [5/85] Batch 820/938 Loss D: 0.3255, Loss G: 2.0613\n",
      "Epoch [5/85] Batch 830/938 Loss D: 0.5068, Loss G: 1.5683\n",
      "Epoch [5/85] Batch 840/938 Loss D: 0.3725, Loss G: 1.5211\n",
      "Epoch [5/85] Batch 850/938 Loss D: 0.3465, Loss G: 1.8836\n",
      "Epoch [5/85] Batch 860/938 Loss D: 0.4160, Loss G: 2.5698\n",
      "Epoch [5/85] Batch 870/938 Loss D: 0.3959, Loss G: 2.2669\n",
      "Epoch [5/85] Batch 880/938 Loss D: 0.3679, Loss G: 1.8632\n",
      "Epoch [5/85] Batch 890/938 Loss D: 0.3552, Loss G: 2.2908\n",
      "Epoch [5/85] Batch 900/938 Loss D: 0.2929, Loss G: 2.1215\n",
      "Epoch [5/85] Batch 910/938 Loss D: 0.3744, Loss G: 1.4946\n",
      "Epoch [5/85] Batch 920/938 Loss D: 0.2862, Loss G: 1.8906\n",
      "Epoch [5/85] Batch 930/938 Loss D: 0.3059, Loss G: 2.0419\n",
      "Epoch [6/85] Batch 0/938 Loss D: 0.3456, Loss G: 1.8768\n",
      "Epoch [6/85] Batch 10/938 Loss D: 0.4376, Loss G: 1.4235\n",
      "Epoch [6/85] Batch 20/938 Loss D: 0.4063, Loss G: 1.4636\n",
      "Epoch [6/85] Batch 30/938 Loss D: 0.3341, Loss G: 1.9545\n",
      "Epoch [6/85] Batch 40/938 Loss D: 0.3088, Loss G: 2.1044\n",
      "Epoch [6/85] Batch 50/938 Loss D: 0.4391, Loss G: 1.8046\n",
      "Epoch [6/85] Batch 60/938 Loss D: 0.3747, Loss G: 1.7409\n",
      "Epoch [6/85] Batch 70/938 Loss D: 0.3880, Loss G: 2.0022\n",
      "Epoch [6/85] Batch 80/938 Loss D: 0.3466, Loss G: 1.9198\n",
      "Epoch [6/85] Batch 90/938 Loss D: 0.4585, Loss G: 1.6151\n",
      "Epoch [6/85] Batch 100/938 Loss D: 0.2897, Loss G: 2.0393\n",
      "Epoch [6/85] Batch 110/938 Loss D: 0.3802, Loss G: 1.6864\n",
      "Epoch [6/85] Batch 120/938 Loss D: 0.3334, Loss G: 1.6747\n",
      "Epoch [6/85] Batch 130/938 Loss D: 0.3586, Loss G: 1.8203\n",
      "Epoch [6/85] Batch 140/938 Loss D: 0.3571, Loss G: 1.9526\n",
      "Epoch [6/85] Batch 150/938 Loss D: 0.3439, Loss G: 1.8640\n",
      "Epoch [6/85] Batch 160/938 Loss D: 0.3443, Loss G: 1.7797\n",
      "Epoch [6/85] Batch 170/938 Loss D: 0.3463, Loss G: 1.5248\n",
      "Epoch [6/85] Batch 180/938 Loss D: 0.2345, Loss G: 1.8786\n",
      "Epoch [6/85] Batch 190/938 Loss D: 0.4577, Loss G: 1.6575\n",
      "Epoch [6/85] Batch 200/938 Loss D: 0.2319, Loss G: 2.3650\n",
      "Epoch [6/85] Batch 210/938 Loss D: 0.3546, Loss G: 1.7495\n",
      "Epoch [6/85] Batch 220/938 Loss D: 0.4667, Loss G: 1.5981\n",
      "Epoch [6/85] Batch 230/938 Loss D: 0.3952, Loss G: 2.4009\n",
      "Epoch [6/85] Batch 240/938 Loss D: 0.4283, Loss G: 1.7625\n",
      "Epoch [6/85] Batch 250/938 Loss D: 0.4485, Loss G: 1.5404\n",
      "Epoch [6/85] Batch 260/938 Loss D: 0.2693, Loss G: 1.7457\n",
      "Epoch [6/85] Batch 270/938 Loss D: 0.3706, Loss G: 1.7686\n",
      "Epoch [6/85] Batch 280/938 Loss D: 0.3354, Loss G: 1.9841\n",
      "Epoch [6/85] Batch 290/938 Loss D: 0.2413, Loss G: 2.1067\n",
      "Epoch [6/85] Batch 300/938 Loss D: 0.3012, Loss G: 2.0877\n",
      "Epoch [6/85] Batch 310/938 Loss D: 0.2832, Loss G: 1.7233\n",
      "Epoch [6/85] Batch 320/938 Loss D: 0.3420, Loss G: 1.8161\n",
      "Epoch [6/85] Batch 330/938 Loss D: 0.3248, Loss G: 1.7502\n",
      "Epoch [6/85] Batch 340/938 Loss D: 0.3231, Loss G: 1.8657\n",
      "Epoch [6/85] Batch 350/938 Loss D: 0.4481, Loss G: 1.5781\n",
      "Epoch [6/85] Batch 360/938 Loss D: 0.4164, Loss G: 1.8884\n",
      "Epoch [6/85] Batch 370/938 Loss D: 0.3095, Loss G: 1.9325\n",
      "Epoch [6/85] Batch 380/938 Loss D: 0.3885, Loss G: 1.6061\n",
      "Epoch [6/85] Batch 390/938 Loss D: 0.2287, Loss G: 2.5491\n",
      "Epoch [6/85] Batch 400/938 Loss D: 0.3274, Loss G: 1.6733\n",
      "Epoch [6/85] Batch 410/938 Loss D: 0.3284, Loss G: 1.8954\n",
      "Epoch [6/85] Batch 420/938 Loss D: 0.2308, Loss G: 2.0132\n",
      "Epoch [6/85] Batch 430/938 Loss D: 0.3379, Loss G: 1.4775\n",
      "Epoch [6/85] Batch 440/938 Loss D: 0.2445, Loss G: 1.9618\n",
      "Epoch [6/85] Batch 450/938 Loss D: 0.3007, Loss G: 2.2480\n",
      "Epoch [6/85] Batch 460/938 Loss D: 0.3780, Loss G: 2.0675\n",
      "Epoch [6/85] Batch 470/938 Loss D: 0.3488, Loss G: 1.7652\n",
      "Epoch [6/85] Batch 480/938 Loss D: 0.2921, Loss G: 1.8629\n",
      "Epoch [6/85] Batch 490/938 Loss D: 0.4272, Loss G: 1.5520\n",
      "Epoch [6/85] Batch 500/938 Loss D: 0.3266, Loss G: 1.9435\n",
      "Epoch [6/85] Batch 510/938 Loss D: 0.3618, Loss G: 2.0618\n",
      "Epoch [6/85] Batch 520/938 Loss D: 0.2933, Loss G: 2.0196\n",
      "Epoch [6/85] Batch 530/938 Loss D: 0.2799, Loss G: 1.8772\n",
      "Epoch [6/85] Batch 540/938 Loss D: 0.3578, Loss G: 1.9632\n",
      "Epoch [6/85] Batch 550/938 Loss D: 0.3276, Loss G: 1.5647\n",
      "Epoch [6/85] Batch 560/938 Loss D: 0.3629, Loss G: 1.4916\n",
      "Epoch [6/85] Batch 570/938 Loss D: 0.3271, Loss G: 1.8658\n",
      "Epoch [6/85] Batch 580/938 Loss D: 0.3180, Loss G: 1.5867\n",
      "Epoch [6/85] Batch 590/938 Loss D: 0.4954, Loss G: 1.2163\n",
      "Epoch [6/85] Batch 600/938 Loss D: 0.3679, Loss G: 1.4144\n",
      "Epoch [6/85] Batch 610/938 Loss D: 0.3620, Loss G: 1.4776\n",
      "Epoch [6/85] Batch 620/938 Loss D: 0.3248, Loss G: 1.6584\n",
      "Epoch [6/85] Batch 630/938 Loss D: 0.2980, Loss G: 1.8777\n",
      "Epoch [6/85] Batch 640/938 Loss D: 0.3018, Loss G: 2.0658\n",
      "Epoch [6/85] Batch 650/938 Loss D: 0.3214, Loss G: 1.9981\n",
      "Epoch [6/85] Batch 660/938 Loss D: 0.3033, Loss G: 1.7249\n",
      "Epoch [6/85] Batch 670/938 Loss D: 0.4008, Loss G: 1.4667\n",
      "Epoch [6/85] Batch 680/938 Loss D: 0.3069, Loss G: 1.8055\n",
      "Epoch [6/85] Batch 690/938 Loss D: 0.2966, Loss G: 1.7888\n",
      "Epoch [6/85] Batch 700/938 Loss D: 0.3197, Loss G: 1.6662\n",
      "Epoch [6/85] Batch 710/938 Loss D: 0.2624, Loss G: 2.0090\n",
      "Epoch [6/85] Batch 720/938 Loss D: 0.3080, Loss G: 1.9069\n",
      "Epoch [6/85] Batch 730/938 Loss D: 0.4352, Loss G: 1.5484\n",
      "Epoch [6/85] Batch 740/938 Loss D: 0.3413, Loss G: 1.6257\n",
      "Epoch [6/85] Batch 750/938 Loss D: 0.4094, Loss G: 1.5151\n",
      "Epoch [6/85] Batch 760/938 Loss D: 0.3475, Loss G: 1.9843\n",
      "Epoch [6/85] Batch 770/938 Loss D: 0.3603, Loss G: 1.8006\n",
      "Epoch [6/85] Batch 780/938 Loss D: 0.3620, Loss G: 1.8213\n",
      "Epoch [6/85] Batch 790/938 Loss D: 0.3281, Loss G: 1.6282\n",
      "Epoch [6/85] Batch 800/938 Loss D: 0.2721, Loss G: 1.6125\n",
      "Epoch [6/85] Batch 810/938 Loss D: 0.2886, Loss G: 1.9933\n",
      "Epoch [6/85] Batch 820/938 Loss D: 0.3630, Loss G: 1.9947\n",
      "Epoch [6/85] Batch 830/938 Loss D: 0.3348, Loss G: 1.7369\n",
      "Epoch [6/85] Batch 840/938 Loss D: 0.4283, Loss G: 1.5245\n",
      "Epoch [6/85] Batch 850/938 Loss D: 0.3163, Loss G: 1.9609\n",
      "Epoch [6/85] Batch 860/938 Loss D: 0.3380, Loss G: 1.5572\n",
      "Epoch [6/85] Batch 870/938 Loss D: 0.3838, Loss G: 1.5688\n",
      "Epoch [6/85] Batch 880/938 Loss D: 0.3680, Loss G: 1.8315\n",
      "Epoch [6/85] Batch 890/938 Loss D: 0.3711, Loss G: 1.7128\n",
      "Epoch [6/85] Batch 900/938 Loss D: 0.3348, Loss G: 1.6920\n",
      "Epoch [6/85] Batch 910/938 Loss D: 0.3315, Loss G: 1.6892\n",
      "Epoch [6/85] Batch 920/938 Loss D: 0.2680, Loss G: 1.9581\n",
      "Epoch [6/85] Batch 930/938 Loss D: 0.2693, Loss G: 2.0112\n",
      "Epoch [7/85] Batch 0/938 Loss D: 0.2694, Loss G: 2.0295\n",
      "Epoch [7/85] Batch 10/938 Loss D: 0.3116, Loss G: 1.7473\n",
      "Epoch [7/85] Batch 20/938 Loss D: 0.3665, Loss G: 1.7249\n",
      "Epoch [7/85] Batch 30/938 Loss D: 0.3216, Loss G: 2.0384\n",
      "Epoch [7/85] Batch 40/938 Loss D: 0.3703, Loss G: 1.9699\n",
      "Epoch [7/85] Batch 50/938 Loss D: 0.3210, Loss G: 1.7999\n",
      "Epoch [7/85] Batch 60/938 Loss D: 0.2531, Loss G: 2.1324\n",
      "Epoch [7/85] Batch 70/938 Loss D: 0.4010, Loss G: 1.6113\n",
      "Epoch [7/85] Batch 80/938 Loss D: 0.3124, Loss G: 1.7657\n",
      "Epoch [7/85] Batch 90/938 Loss D: 0.3862, Loss G: 1.8574\n",
      "Epoch [7/85] Batch 100/938 Loss D: 0.3229, Loss G: 1.8648\n",
      "Epoch [7/85] Batch 110/938 Loss D: 0.3467, Loss G: 1.7203\n",
      "Epoch [7/85] Batch 120/938 Loss D: 0.2951, Loss G: 2.0777\n",
      "Epoch [7/85] Batch 130/938 Loss D: 0.2876, Loss G: 1.8893\n",
      "Epoch [7/85] Batch 140/938 Loss D: 0.3760, Loss G: 1.6421\n",
      "Epoch [7/85] Batch 150/938 Loss D: 0.4080, Loss G: 1.7273\n",
      "Epoch [7/85] Batch 160/938 Loss D: 0.3374, Loss G: 1.9802\n",
      "Epoch [7/85] Batch 170/938 Loss D: 0.3054, Loss G: 1.8289\n",
      "Epoch [7/85] Batch 180/938 Loss D: 0.3114, Loss G: 1.8728\n",
      "Epoch [7/85] Batch 190/938 Loss D: 0.4057, Loss G: 1.4707\n",
      "Epoch [7/85] Batch 200/938 Loss D: 0.2666, Loss G: 1.7962\n",
      "Epoch [7/85] Batch 210/938 Loss D: 0.3399, Loss G: 1.8504\n",
      "Epoch [7/85] Batch 220/938 Loss D: 0.2842, Loss G: 2.0674\n",
      "Epoch [7/85] Batch 230/938 Loss D: 0.3634, Loss G: 2.0805\n",
      "Epoch [7/85] Batch 240/938 Loss D: 0.3708, Loss G: 2.1340\n",
      "Epoch [7/85] Batch 250/938 Loss D: 0.3076, Loss G: 1.8244\n",
      "Epoch [7/85] Batch 260/938 Loss D: 0.3139, Loss G: 1.7521\n",
      "Epoch [7/85] Batch 270/938 Loss D: 0.3178, Loss G: 1.9096\n",
      "Epoch [7/85] Batch 280/938 Loss D: 0.3639, Loss G: 1.7275\n",
      "Epoch [7/85] Batch 290/938 Loss D: 0.3707, Loss G: 1.5368\n",
      "Epoch [7/85] Batch 300/938 Loss D: 0.3137, Loss G: 1.8785\n",
      "Epoch [7/85] Batch 310/938 Loss D: 0.2852, Loss G: 2.0415\n",
      "Epoch [7/85] Batch 320/938 Loss D: 0.3078, Loss G: 1.7915\n",
      "Epoch [7/85] Batch 330/938 Loss D: 0.2381, Loss G: 2.0362\n",
      "Epoch [7/85] Batch 340/938 Loss D: 0.3106, Loss G: 2.1087\n",
      "Epoch [7/85] Batch 350/938 Loss D: 0.4271, Loss G: 1.4446\n",
      "Epoch [7/85] Batch 360/938 Loss D: 0.2723, Loss G: 2.0329\n",
      "Epoch [7/85] Batch 370/938 Loss D: 0.3783, Loss G: 1.7944\n",
      "Epoch [7/85] Batch 380/938 Loss D: 0.4179, Loss G: 1.6649\n",
      "Epoch [7/85] Batch 390/938 Loss D: 0.3270, Loss G: 1.9595\n",
      "Epoch [7/85] Batch 400/938 Loss D: 0.3158, Loss G: 2.2274\n",
      "Epoch [7/85] Batch 410/938 Loss D: 0.4006, Loss G: 1.5483\n",
      "Epoch [7/85] Batch 420/938 Loss D: 0.2886, Loss G: 1.9240\n",
      "Epoch [7/85] Batch 430/938 Loss D: 0.2727, Loss G: 1.8944\n",
      "Epoch [7/85] Batch 440/938 Loss D: 0.3490, Loss G: 1.4649\n",
      "Epoch [7/85] Batch 450/938 Loss D: 0.4381, Loss G: 1.3385\n",
      "Epoch [7/85] Batch 460/938 Loss D: 0.2582, Loss G: 1.6516\n",
      "Epoch [7/85] Batch 470/938 Loss D: 0.2225, Loss G: 1.8024\n",
      "Epoch [7/85] Batch 480/938 Loss D: 0.3666, Loss G: 1.5514\n",
      "Epoch [7/85] Batch 490/938 Loss D: 0.2732, Loss G: 2.0397\n",
      "Epoch [7/85] Batch 500/938 Loss D: 0.2765, Loss G: 1.8350\n",
      "Epoch [7/85] Batch 510/938 Loss D: 0.3665, Loss G: 1.7736\n",
      "Epoch [7/85] Batch 520/938 Loss D: 0.2511, Loss G: 2.1815\n",
      "Epoch [7/85] Batch 530/938 Loss D: 0.2997, Loss G: 1.7360\n",
      "Epoch [7/85] Batch 540/938 Loss D: 0.4170, Loss G: 1.5811\n",
      "Epoch [7/85] Batch 550/938 Loss D: 0.3195, Loss G: 2.0112\n",
      "Epoch [7/85] Batch 560/938 Loss D: 0.2275, Loss G: 2.0267\n",
      "Epoch [7/85] Batch 570/938 Loss D: 0.2989, Loss G: 1.8946\n",
      "Epoch [7/85] Batch 580/938 Loss D: 0.3022, Loss G: 1.9512\n",
      "Epoch [7/85] Batch 590/938 Loss D: 0.2342, Loss G: 2.2622\n",
      "Epoch [7/85] Batch 600/938 Loss D: 0.2993, Loss G: 2.0617\n",
      "Epoch [7/85] Batch 610/938 Loss D: 0.3241, Loss G: 1.7192\n",
      "Epoch [7/85] Batch 620/938 Loss D: 0.2608, Loss G: 2.2935\n",
      "Epoch [7/85] Batch 630/938 Loss D: 0.2825, Loss G: 2.1062\n",
      "Epoch [7/85] Batch 640/938 Loss D: 0.3585, Loss G: 1.6813\n",
      "Epoch [7/85] Batch 650/938 Loss D: 0.2376, Loss G: 2.1030\n",
      "Epoch [7/85] Batch 660/938 Loss D: 0.2484, Loss G: 1.9878\n",
      "Epoch [7/85] Batch 670/938 Loss D: 0.3545, Loss G: 1.4799\n",
      "Epoch [7/85] Batch 680/938 Loss D: 0.3597, Loss G: 1.5837\n",
      "Epoch [7/85] Batch 690/938 Loss D: 0.3955, Loss G: 1.3201\n",
      "Epoch [7/85] Batch 700/938 Loss D: 0.3352, Loss G: 1.6018\n",
      "Epoch [7/85] Batch 710/938 Loss D: 0.2693, Loss G: 1.9096\n",
      "Epoch [7/85] Batch 720/938 Loss D: 0.4031, Loss G: 1.8429\n",
      "Epoch [7/85] Batch 730/938 Loss D: 0.3577, Loss G: 1.5212\n",
      "Epoch [7/85] Batch 740/938 Loss D: 0.2709, Loss G: 1.7950\n",
      "Epoch [7/85] Batch 750/938 Loss D: 0.2842, Loss G: 1.9360\n",
      "Epoch [7/85] Batch 760/938 Loss D: 0.3096, Loss G: 1.6625\n",
      "Epoch [7/85] Batch 770/938 Loss D: 0.3022, Loss G: 1.9608\n",
      "Epoch [7/85] Batch 780/938 Loss D: 0.2315, Loss G: 2.0496\n",
      "Epoch [7/85] Batch 790/938 Loss D: 0.2960, Loss G: 1.8759\n",
      "Epoch [7/85] Batch 800/938 Loss D: 0.3048, Loss G: 1.5827\n",
      "Epoch [7/85] Batch 810/938 Loss D: 0.2432, Loss G: 1.9449\n",
      "Epoch [7/85] Batch 820/938 Loss D: 0.3794, Loss G: 1.8816\n",
      "Epoch [7/85] Batch 830/938 Loss D: 0.3359, Loss G: 1.9591\n",
      "Epoch [7/85] Batch 840/938 Loss D: 0.2144, Loss G: 2.4420\n",
      "Epoch [7/85] Batch 850/938 Loss D: 0.2785, Loss G: 2.0326\n",
      "Epoch [7/85] Batch 860/938 Loss D: 0.2969, Loss G: 1.7476\n",
      "Epoch [7/85] Batch 870/938 Loss D: 0.2905, Loss G: 1.9041\n",
      "Epoch [7/85] Batch 880/938 Loss D: 0.3763, Loss G: 1.7207\n",
      "Epoch [7/85] Batch 890/938 Loss D: 0.3247, Loss G: 1.7891\n",
      "Epoch [7/85] Batch 900/938 Loss D: 0.2885, Loss G: 1.9107\n",
      "Epoch [7/85] Batch 910/938 Loss D: 0.2919, Loss G: 2.3160\n",
      "Epoch [7/85] Batch 920/938 Loss D: 0.4027, Loss G: 1.6884\n",
      "Epoch [7/85] Batch 930/938 Loss D: 0.2496, Loss G: 1.9683\n",
      "Epoch [8/85] Batch 0/938 Loss D: 0.2570, Loss G: 1.9089\n",
      "Epoch [8/85] Batch 10/938 Loss D: 0.3336, Loss G: 1.4664\n",
      "Epoch [8/85] Batch 20/938 Loss D: 0.3606, Loss G: 1.9949\n",
      "Epoch [8/85] Batch 30/938 Loss D: 0.1937, Loss G: 2.4284\n",
      "Epoch [8/85] Batch 40/938 Loss D: 0.2991, Loss G: 1.8789\n",
      "Epoch [8/85] Batch 50/938 Loss D: 0.4099, Loss G: 1.6728\n",
      "Epoch [8/85] Batch 60/938 Loss D: 0.2946, Loss G: 2.1944\n",
      "Epoch [8/85] Batch 70/938 Loss D: 0.3514, Loss G: 1.9550\n",
      "Epoch [8/85] Batch 80/938 Loss D: 0.3899, Loss G: 1.7848\n",
      "Epoch [8/85] Batch 90/938 Loss D: 0.2461, Loss G: 2.4673\n",
      "Epoch [8/85] Batch 100/938 Loss D: 0.2702, Loss G: 2.1738\n",
      "Epoch [8/85] Batch 110/938 Loss D: 0.3001, Loss G: 1.9194\n",
      "Epoch [8/85] Batch 120/938 Loss D: 0.3201, Loss G: 1.8641\n",
      "Epoch [8/85] Batch 130/938 Loss D: 0.3101, Loss G: 2.0917\n",
      "Epoch [8/85] Batch 140/938 Loss D: 0.3395, Loss G: 1.6906\n",
      "Epoch [8/85] Batch 150/938 Loss D: 0.2654, Loss G: 2.2474\n",
      "Epoch [8/85] Batch 160/938 Loss D: 0.2586, Loss G: 2.2082\n",
      "Epoch [8/85] Batch 170/938 Loss D: 0.3646, Loss G: 2.0005\n",
      "Epoch [8/85] Batch 180/938 Loss D: 0.2704, Loss G: 1.9967\n",
      "Epoch [8/85] Batch 190/938 Loss D: 0.3182, Loss G: 1.5614\n",
      "Epoch [8/85] Batch 200/938 Loss D: 0.2844, Loss G: 1.9751\n",
      "Epoch [8/85] Batch 210/938 Loss D: 0.3235, Loss G: 2.0224\n",
      "Epoch [8/85] Batch 220/938 Loss D: 0.2467, Loss G: 2.2795\n",
      "Epoch [8/85] Batch 230/938 Loss D: 0.2782, Loss G: 2.3319\n",
      "Epoch [8/85] Batch 240/938 Loss D: 0.2749, Loss G: 1.9024\n",
      "Epoch [8/85] Batch 250/938 Loss D: 0.2764, Loss G: 1.8639\n",
      "Epoch [8/85] Batch 260/938 Loss D: 0.2017, Loss G: 2.1243\n",
      "Epoch [8/85] Batch 270/938 Loss D: 0.3606, Loss G: 1.4327\n",
      "Epoch [8/85] Batch 280/938 Loss D: 0.2750, Loss G: 2.0818\n",
      "Epoch [8/85] Batch 290/938 Loss D: 0.2626, Loss G: 2.0213\n",
      "Epoch [8/85] Batch 300/938 Loss D: 0.3124, Loss G: 1.7218\n",
      "Epoch [8/85] Batch 310/938 Loss D: 0.2682, Loss G: 1.7570\n",
      "Epoch [8/85] Batch 320/938 Loss D: 0.2873, Loss G: 1.8024\n",
      "Epoch [8/85] Batch 330/938 Loss D: 0.3149, Loss G: 1.6390\n",
      "Epoch [8/85] Batch 340/938 Loss D: 0.2457, Loss G: 1.9773\n",
      "Epoch [8/85] Batch 350/938 Loss D: 0.2654, Loss G: 2.0868\n",
      "Epoch [8/85] Batch 360/938 Loss D: 0.4393, Loss G: 1.7268\n",
      "Epoch [8/85] Batch 370/938 Loss D: 0.2891, Loss G: 1.8241\n",
      "Epoch [8/85] Batch 380/938 Loss D: 0.2592, Loss G: 2.4582\n",
      "Epoch [8/85] Batch 390/938 Loss D: 0.3712, Loss G: 1.8665\n",
      "Epoch [8/85] Batch 400/938 Loss D: 0.2727, Loss G: 2.2358\n",
      "Epoch [8/85] Batch 410/938 Loss D: 0.2733, Loss G: 2.0022\n",
      "Epoch [8/85] Batch 420/938 Loss D: 0.4053, Loss G: 1.6057\n",
      "Epoch [8/85] Batch 430/938 Loss D: 0.3448, Loss G: 1.8107\n",
      "Epoch [8/85] Batch 440/938 Loss D: 0.1464, Loss G: 2.4786\n",
      "Epoch [8/85] Batch 450/938 Loss D: 0.3181, Loss G: 1.5680\n",
      "Epoch [8/85] Batch 460/938 Loss D: 0.2788, Loss G: 1.8164\n",
      "Epoch [8/85] Batch 470/938 Loss D: 0.3365, Loss G: 1.7400\n",
      "Epoch [8/85] Batch 480/938 Loss D: 0.3650, Loss G: 1.7148\n",
      "Epoch [8/85] Batch 490/938 Loss D: 0.2248, Loss G: 1.8415\n",
      "Epoch [8/85] Batch 500/938 Loss D: 0.2246, Loss G: 1.8821\n",
      "Epoch [8/85] Batch 510/938 Loss D: 0.4006, Loss G: 1.6024\n",
      "Epoch [8/85] Batch 520/938 Loss D: 0.2451, Loss G: 2.3796\n",
      "Epoch [8/85] Batch 530/938 Loss D: 0.1998, Loss G: 2.1767\n",
      "Epoch [8/85] Batch 540/938 Loss D: 0.4062, Loss G: 1.6822\n",
      "Epoch [8/85] Batch 550/938 Loss D: 0.3111, Loss G: 1.9721\n",
      "Epoch [8/85] Batch 560/938 Loss D: 0.2950, Loss G: 1.9082\n",
      "Epoch [8/85] Batch 570/938 Loss D: 0.3059, Loss G: 1.8620\n",
      "Epoch [8/85] Batch 580/938 Loss D: 0.2769, Loss G: 1.8673\n",
      "Epoch [8/85] Batch 590/938 Loss D: 0.2186, Loss G: 2.2051\n",
      "Epoch [8/85] Batch 600/938 Loss D: 0.2974, Loss G: 1.7514\n",
      "Epoch [8/85] Batch 610/938 Loss D: 0.3755, Loss G: 1.4210\n",
      "Epoch [8/85] Batch 620/938 Loss D: 0.3712, Loss G: 1.9698\n",
      "Epoch [8/85] Batch 630/938 Loss D: 0.3200, Loss G: 2.1595\n",
      "Epoch [8/85] Batch 640/938 Loss D: 0.2906, Loss G: 2.0992\n",
      "Epoch [8/85] Batch 650/938 Loss D: 0.2127, Loss G: 2.2443\n",
      "Epoch [8/85] Batch 660/938 Loss D: 0.2736, Loss G: 1.8687\n",
      "Epoch [8/85] Batch 670/938 Loss D: 0.3462, Loss G: 1.5627\n",
      "Epoch [8/85] Batch 680/938 Loss D: 0.3695, Loss G: 2.0269\n",
      "Epoch [8/85] Batch 690/938 Loss D: 0.3140, Loss G: 1.8539\n",
      "Epoch [8/85] Batch 700/938 Loss D: 0.2923, Loss G: 1.8184\n",
      "Epoch [8/85] Batch 710/938 Loss D: 0.2009, Loss G: 2.0778\n",
      "Epoch [8/85] Batch 720/938 Loss D: 0.1726, Loss G: 2.2290\n",
      "Epoch [8/85] Batch 730/938 Loss D: 0.3439, Loss G: 1.7532\n",
      "Epoch [8/85] Batch 740/938 Loss D: 0.3813, Loss G: 1.8255\n",
      "Epoch [8/85] Batch 750/938 Loss D: 0.1808, Loss G: 2.5416\n",
      "Epoch [8/85] Batch 760/938 Loss D: 0.3602, Loss G: 2.0663\n",
      "Epoch [8/85] Batch 770/938 Loss D: 0.3550, Loss G: 2.0009\n",
      "Epoch [8/85] Batch 780/938 Loss D: 0.1770, Loss G: 2.9058\n",
      "Epoch [8/85] Batch 790/938 Loss D: 0.3116, Loss G: 1.7189\n",
      "Epoch [8/85] Batch 800/938 Loss D: 0.3908, Loss G: 1.5295\n",
      "Epoch [8/85] Batch 810/938 Loss D: 0.2431, Loss G: 1.8787\n",
      "Epoch [8/85] Batch 820/938 Loss D: 0.2680, Loss G: 1.6683\n",
      "Epoch [8/85] Batch 830/938 Loss D: 0.3776, Loss G: 1.7341\n",
      "Epoch [8/85] Batch 840/938 Loss D: 0.2665, Loss G: 1.9321\n",
      "Epoch [8/85] Batch 850/938 Loss D: 0.3352, Loss G: 1.4944\n",
      "Epoch [8/85] Batch 860/938 Loss D: 0.3099, Loss G: 1.8350\n",
      "Epoch [8/85] Batch 870/938 Loss D: 0.2153, Loss G: 2.3921\n",
      "Epoch [8/85] Batch 880/938 Loss D: 0.3378, Loss G: 1.7993\n",
      "Epoch [8/85] Batch 890/938 Loss D: 0.2587, Loss G: 2.2102\n",
      "Epoch [8/85] Batch 900/938 Loss D: 0.2410, Loss G: 2.2987\n",
      "Epoch [8/85] Batch 910/938 Loss D: 0.3163, Loss G: 2.2508\n",
      "Epoch [8/85] Batch 920/938 Loss D: 0.3464, Loss G: 1.9137\n",
      "Epoch [8/85] Batch 930/938 Loss D: 0.1832, Loss G: 2.5428\n",
      "Epoch [9/85] Batch 0/938 Loss D: 0.2075, Loss G: 1.9996\n",
      "Epoch [9/85] Batch 10/938 Loss D: 0.3328, Loss G: 1.5479\n",
      "Epoch [9/85] Batch 20/938 Loss D: 0.3273, Loss G: 1.6514\n",
      "Epoch [9/85] Batch 30/938 Loss D: 0.2503, Loss G: 2.2967\n",
      "Epoch [9/85] Batch 40/938 Loss D: 0.2623, Loss G: 2.0775\n",
      "Epoch [9/85] Batch 50/938 Loss D: 0.3130, Loss G: 2.0197\n",
      "Epoch [9/85] Batch 60/938 Loss D: 0.2558, Loss G: 2.3120\n",
      "Epoch [9/85] Batch 70/938 Loss D: 0.2092, Loss G: 1.8345\n",
      "Epoch [9/85] Batch 80/938 Loss D: 0.2419, Loss G: 1.7851\n",
      "Epoch [9/85] Batch 90/938 Loss D: 0.2623, Loss G: 1.5073\n",
      "Epoch [9/85] Batch 100/938 Loss D: 0.3114, Loss G: 1.5869\n",
      "Epoch [9/85] Batch 110/938 Loss D: 0.2256, Loss G: 2.4251\n",
      "Epoch [9/85] Batch 120/938 Loss D: 0.3111, Loss G: 1.9932\n",
      "Epoch [9/85] Batch 130/938 Loss D: 0.3164, Loss G: 1.7240\n",
      "Epoch [9/85] Batch 140/938 Loss D: 0.2137, Loss G: 2.1198\n",
      "Epoch [9/85] Batch 150/938 Loss D: 0.2682, Loss G: 2.2299\n",
      "Epoch [9/85] Batch 160/938 Loss D: 0.3064, Loss G: 1.5939\n",
      "Epoch [9/85] Batch 170/938 Loss D: 0.2801, Loss G: 1.8828\n",
      "Epoch [9/85] Batch 180/938 Loss D: 0.2226, Loss G: 2.1094\n",
      "Epoch [9/85] Batch 190/938 Loss D: 0.2253, Loss G: 2.0816\n",
      "Epoch [9/85] Batch 200/938 Loss D: 0.3383, Loss G: 1.4771\n",
      "Epoch [9/85] Batch 210/938 Loss D: 0.2892, Loss G: 1.7655\n",
      "Epoch [9/85] Batch 220/938 Loss D: 0.3435, Loss G: 1.4680\n",
      "Epoch [9/85] Batch 230/938 Loss D: 0.3748, Loss G: 1.2122\n",
      "Epoch [9/85] Batch 240/938 Loss D: 0.2256, Loss G: 1.6173\n",
      "Epoch [9/85] Batch 250/938 Loss D: 0.1948, Loss G: 2.1845\n",
      "Epoch [9/85] Batch 260/938 Loss D: 0.3038, Loss G: 2.0268\n",
      "Epoch [9/85] Batch 270/938 Loss D: 0.2702, Loss G: 2.1325\n",
      "Epoch [9/85] Batch 280/938 Loss D: 0.3025, Loss G: 1.7171\n",
      "Epoch [9/85] Batch 290/938 Loss D: 0.3526, Loss G: 1.6985\n",
      "Epoch [9/85] Batch 300/938 Loss D: 0.2769, Loss G: 1.8384\n",
      "Epoch [9/85] Batch 310/938 Loss D: 0.2998, Loss G: 1.6950\n",
      "Epoch [9/85] Batch 320/938 Loss D: 0.3341, Loss G: 1.7423\n",
      "Epoch [9/85] Batch 330/938 Loss D: 0.2875, Loss G: 2.1697\n",
      "Epoch [9/85] Batch 340/938 Loss D: 0.2211, Loss G: 2.0358\n",
      "Epoch [9/85] Batch 350/938 Loss D: 0.2399, Loss G: 2.0701\n",
      "Epoch [9/85] Batch 360/938 Loss D: 0.2768, Loss G: 1.8689\n",
      "Epoch [9/85] Batch 370/938 Loss D: 0.4061, Loss G: 1.6154\n",
      "Epoch [9/85] Batch 380/938 Loss D: 0.2334, Loss G: 2.1471\n",
      "Epoch [9/85] Batch 390/938 Loss D: 0.2910, Loss G: 1.9396\n",
      "Epoch [9/85] Batch 400/938 Loss D: 0.2929, Loss G: 1.7737\n",
      "Epoch [9/85] Batch 410/938 Loss D: 0.3427, Loss G: 1.8800\n",
      "Epoch [9/85] Batch 420/938 Loss D: 0.2581, Loss G: 2.1390\n",
      "Epoch [9/85] Batch 430/938 Loss D: 0.2804, Loss G: 1.9733\n",
      "Epoch [9/85] Batch 440/938 Loss D: 0.3656, Loss G: 1.5293\n",
      "Epoch [9/85] Batch 450/938 Loss D: 0.2890, Loss G: 1.8145\n",
      "Epoch [9/85] Batch 460/938 Loss D: 0.1999, Loss G: 2.2061\n",
      "Epoch [9/85] Batch 470/938 Loss D: 0.2361, Loss G: 1.8266\n",
      "Epoch [9/85] Batch 480/938 Loss D: 0.2528, Loss G: 2.2258\n",
      "Epoch [9/85] Batch 490/938 Loss D: 0.3184, Loss G: 2.0271\n",
      "Epoch [9/85] Batch 500/938 Loss D: 0.3650, Loss G: 1.6979\n",
      "Epoch [9/85] Batch 510/938 Loss D: 0.2835, Loss G: 1.8060\n",
      "Epoch [9/85] Batch 520/938 Loss D: 0.3215, Loss G: 1.6332\n",
      "Epoch [9/85] Batch 530/938 Loss D: 0.2833, Loss G: 1.7833\n",
      "Epoch [9/85] Batch 540/938 Loss D: 0.2642, Loss G: 1.9487\n",
      "Epoch [9/85] Batch 550/938 Loss D: 0.2525, Loss G: 2.2482\n",
      "Epoch [9/85] Batch 560/938 Loss D: 0.2975, Loss G: 1.9337\n",
      "Epoch [9/85] Batch 570/938 Loss D: 0.3584, Loss G: 2.2483\n",
      "Epoch [9/85] Batch 580/938 Loss D: 0.3815, Loss G: 2.4874\n",
      "Epoch [9/85] Batch 590/938 Loss D: 0.2412, Loss G: 2.1973\n",
      "Epoch [9/85] Batch 600/938 Loss D: 0.2833, Loss G: 2.3852\n",
      "Epoch [9/85] Batch 610/938 Loss D: 0.2709, Loss G: 2.3378\n",
      "Epoch [9/85] Batch 620/938 Loss D: 0.2390, Loss G: 2.3188\n",
      "Epoch [9/85] Batch 630/938 Loss D: 0.2888, Loss G: 1.7288\n",
      "Epoch [9/85] Batch 640/938 Loss D: 0.3114, Loss G: 1.7512\n",
      "Epoch [9/85] Batch 650/938 Loss D: 0.2147, Loss G: 2.1560\n",
      "Epoch [9/85] Batch 660/938 Loss D: 0.3078, Loss G: 2.0032\n",
      "Epoch [9/85] Batch 670/938 Loss D: 0.3132, Loss G: 1.9155\n",
      "Epoch [9/85] Batch 680/938 Loss D: 0.3053, Loss G: 2.0877\n",
      "Epoch [9/85] Batch 690/938 Loss D: 0.1905, Loss G: 2.4573\n",
      "Epoch [9/85] Batch 700/938 Loss D: 0.3681, Loss G: 1.7172\n",
      "Epoch [9/85] Batch 710/938 Loss D: 0.2423, Loss G: 1.7639\n",
      "Epoch [9/85] Batch 720/938 Loss D: 0.3138, Loss G: 2.0303\n",
      "Epoch [9/85] Batch 730/938 Loss D: 0.2571, Loss G: 1.6737\n",
      "Epoch [9/85] Batch 740/938 Loss D: 0.2119, Loss G: 2.2747\n",
      "Epoch [9/85] Batch 750/938 Loss D: 0.2585, Loss G: 2.2501\n",
      "Epoch [9/85] Batch 760/938 Loss D: 0.2300, Loss G: 2.0674\n",
      "Epoch [9/85] Batch 770/938 Loss D: 0.3394, Loss G: 2.5346\n",
      "Epoch [9/85] Batch 780/938 Loss D: 0.2642, Loss G: 2.0775\n",
      "Epoch [9/85] Batch 790/938 Loss D: 0.3008, Loss G: 2.1323\n",
      "Epoch [9/85] Batch 800/938 Loss D: 0.3919, Loss G: 1.6079\n",
      "Epoch [9/85] Batch 810/938 Loss D: 0.1859, Loss G: 2.1825\n",
      "Epoch [9/85] Batch 820/938 Loss D: 0.2166, Loss G: 2.1224\n",
      "Epoch [9/85] Batch 830/938 Loss D: 0.3309, Loss G: 1.4122\n",
      "Epoch [9/85] Batch 840/938 Loss D: 0.2757, Loss G: 2.0046\n",
      "Epoch [9/85] Batch 850/938 Loss D: 0.2595, Loss G: 2.4063\n",
      "Epoch [9/85] Batch 860/938 Loss D: 0.2927, Loss G: 1.9363\n",
      "Epoch [9/85] Batch 870/938 Loss D: 0.3424, Loss G: 1.7617\n",
      "Epoch [9/85] Batch 880/938 Loss D: 0.2021, Loss G: 2.1918\n",
      "Epoch [9/85] Batch 890/938 Loss D: 0.2125, Loss G: 2.0899\n",
      "Epoch [9/85] Batch 900/938 Loss D: 0.2744, Loss G: 1.8552\n",
      "Epoch [9/85] Batch 910/938 Loss D: 0.3177, Loss G: 1.9606\n",
      "Epoch [9/85] Batch 920/938 Loss D: 0.2624, Loss G: 2.0167\n",
      "Epoch [9/85] Batch 930/938 Loss D: 0.2489, Loss G: 2.1262\n",
      "Epoch [10/85] Batch 0/938 Loss D: 0.3050, Loss G: 1.7972\n",
      "Epoch [10/85] Batch 10/938 Loss D: 0.2815, Loss G: 1.6921\n",
      "Epoch [10/85] Batch 20/938 Loss D: 0.2146, Loss G: 2.0998\n",
      "Epoch [10/85] Batch 30/938 Loss D: 0.3762, Loss G: 1.5967\n",
      "Epoch [10/85] Batch 40/938 Loss D: 0.2754, Loss G: 1.9754\n",
      "Epoch [10/85] Batch 50/938 Loss D: 0.2292, Loss G: 2.1237\n",
      "Epoch [10/85] Batch 60/938 Loss D: 0.2105, Loss G: 2.2072\n",
      "Epoch [10/85] Batch 70/938 Loss D: 0.2781, Loss G: 1.8866\n",
      "Epoch [10/85] Batch 80/938 Loss D: 0.2721, Loss G: 1.8755\n",
      "Epoch [10/85] Batch 90/938 Loss D: 0.2244, Loss G: 2.3305\n",
      "Epoch [10/85] Batch 100/938 Loss D: 0.2590, Loss G: 2.2563\n",
      "Epoch [10/85] Batch 110/938 Loss D: 0.2948, Loss G: 2.0933\n",
      "Epoch [10/85] Batch 120/938 Loss D: 0.2581, Loss G: 1.9171\n",
      "Epoch [10/85] Batch 130/938 Loss D: 0.2462, Loss G: 2.0661\n",
      "Epoch [10/85] Batch 140/938 Loss D: 0.2384, Loss G: 2.1562\n",
      "Epoch [10/85] Batch 150/938 Loss D: 0.2789, Loss G: 2.0604\n",
      "Epoch [10/85] Batch 160/938 Loss D: 0.2981, Loss G: 2.0647\n",
      "Epoch [10/85] Batch 170/938 Loss D: 0.2707, Loss G: 1.7463\n",
      "Epoch [10/85] Batch 180/938 Loss D: 0.2302, Loss G: 2.1219\n",
      "Epoch [10/85] Batch 190/938 Loss D: 0.2193, Loss G: 2.4801\n",
      "Epoch [10/85] Batch 200/938 Loss D: 0.3703, Loss G: 1.6615\n",
      "Epoch [10/85] Batch 210/938 Loss D: 0.2780, Loss G: 1.9281\n",
      "Epoch [10/85] Batch 220/938 Loss D: 0.2580, Loss G: 2.4735\n",
      "Epoch [10/85] Batch 230/938 Loss D: 0.3312, Loss G: 2.7032\n",
      "Epoch [10/85] Batch 240/938 Loss D: 0.1916, Loss G: 2.4392\n",
      "Epoch [10/85] Batch 250/938 Loss D: 0.2492, Loss G: 2.1926\n",
      "Epoch [10/85] Batch 260/938 Loss D: 0.2135, Loss G: 1.9453\n",
      "Epoch [10/85] Batch 270/938 Loss D: 0.3080, Loss G: 1.8195\n",
      "Epoch [10/85] Batch 280/938 Loss D: 0.3004, Loss G: 1.7017\n",
      "Epoch [10/85] Batch 290/938 Loss D: 0.2110, Loss G: 1.9963\n",
      "Epoch [10/85] Batch 300/938 Loss D: 0.2852, Loss G: 1.5817\n",
      "Epoch [10/85] Batch 310/938 Loss D: 0.2186, Loss G: 2.3413\n",
      "Epoch [10/85] Batch 320/938 Loss D: 0.2361, Loss G: 2.2607\n",
      "Epoch [10/85] Batch 330/938 Loss D: 0.2903, Loss G: 2.0532\n",
      "Epoch [10/85] Batch 340/938 Loss D: 0.2756, Loss G: 2.2647\n",
      "Epoch [10/85] Batch 350/938 Loss D: 0.2362, Loss G: 2.5571\n",
      "Epoch [10/85] Batch 360/938 Loss D: 0.2620, Loss G: 2.6255\n",
      "Epoch [10/85] Batch 370/938 Loss D: 0.3292, Loss G: 2.3365\n",
      "Epoch [10/85] Batch 380/938 Loss D: 0.4489, Loss G: 1.7436\n",
      "Epoch [10/85] Batch 390/938 Loss D: 0.2049, Loss G: 2.1750\n",
      "Epoch [10/85] Batch 400/938 Loss D: 0.3124, Loss G: 1.9174\n",
      "Epoch [10/85] Batch 410/938 Loss D: 0.3089, Loss G: 2.3669\n",
      "Epoch [10/85] Batch 420/938 Loss D: 0.1906, Loss G: 2.7677\n",
      "Epoch [10/85] Batch 430/938 Loss D: 0.2160, Loss G: 2.2922\n",
      "Epoch [10/85] Batch 440/938 Loss D: 0.3051, Loss G: 2.2545\n",
      "Epoch [10/85] Batch 450/938 Loss D: 0.2680, Loss G: 2.0189\n",
      "Epoch [10/85] Batch 460/938 Loss D: 0.2561, Loss G: 1.9846\n",
      "Epoch [10/85] Batch 470/938 Loss D: 0.2176, Loss G: 2.1354\n",
      "Epoch [10/85] Batch 480/938 Loss D: 0.2893, Loss G: 2.0178\n",
      "Epoch [10/85] Batch 490/938 Loss D: 0.1758, Loss G: 2.1658\n",
      "Epoch [10/85] Batch 500/938 Loss D: 0.3032, Loss G: 2.2816\n",
      "Epoch [10/85] Batch 510/938 Loss D: 0.3174, Loss G: 2.3092\n",
      "Epoch [10/85] Batch 520/938 Loss D: 0.2069, Loss G: 2.3413\n",
      "Epoch [10/85] Batch 530/938 Loss D: 0.2699, Loss G: 1.9238\n",
      "Epoch [10/85] Batch 540/938 Loss D: 0.2683, Loss G: 2.1170\n",
      "Epoch [10/85] Batch 550/938 Loss D: 0.2065, Loss G: 2.3137\n",
      "Epoch [10/85] Batch 560/938 Loss D: 0.2626, Loss G: 2.1876\n",
      "Epoch [10/85] Batch 570/938 Loss D: 0.2794, Loss G: 1.9104\n",
      "Epoch [10/85] Batch 580/938 Loss D: 0.2159, Loss G: 1.9902\n",
      "Epoch [10/85] Batch 590/938 Loss D: 0.2123, Loss G: 2.5383\n",
      "Epoch [10/85] Batch 600/938 Loss D: 0.2823, Loss G: 1.9385\n",
      "Epoch [10/85] Batch 610/938 Loss D: 0.3331, Loss G: 1.5248\n",
      "Epoch [10/85] Batch 620/938 Loss D: 0.2153, Loss G: 2.0870\n",
      "Epoch [10/85] Batch 630/938 Loss D: 0.2463, Loss G: 1.8002\n",
      "Epoch [10/85] Batch 640/938 Loss D: 0.1600, Loss G: 2.5005\n",
      "Epoch [10/85] Batch 650/938 Loss D: 0.2504, Loss G: 2.8056\n",
      "Epoch [10/85] Batch 660/938 Loss D: 0.2596, Loss G: 2.1547\n",
      "Epoch [10/85] Batch 670/938 Loss D: 0.2447, Loss G: 2.2789\n",
      "Epoch [10/85] Batch 680/938 Loss D: 0.1795, Loss G: 2.0968\n",
      "Epoch [10/85] Batch 690/938 Loss D: 0.2354, Loss G: 2.0307\n",
      "Epoch [10/85] Batch 700/938 Loss D: 0.2605, Loss G: 1.6723\n",
      "Epoch [10/85] Batch 710/938 Loss D: 0.2185, Loss G: 2.2910\n",
      "Epoch [10/85] Batch 720/938 Loss D: 0.2745, Loss G: 1.8714\n",
      "Epoch [10/85] Batch 730/938 Loss D: 0.2677, Loss G: 1.5690\n",
      "Epoch [10/85] Batch 740/938 Loss D: 0.2876, Loss G: 1.9693\n",
      "Epoch [10/85] Batch 750/938 Loss D: 0.1885, Loss G: 2.2393\n",
      "Epoch [10/85] Batch 760/938 Loss D: 0.3163, Loss G: 2.0339\n",
      "Epoch [10/85] Batch 770/938 Loss D: 0.2659, Loss G: 1.8465\n",
      "Epoch [10/85] Batch 780/938 Loss D: 0.1871, Loss G: 2.6755\n",
      "Epoch [10/85] Batch 790/938 Loss D: 0.2446, Loss G: 2.4274\n",
      "Epoch [10/85] Batch 800/938 Loss D: 0.2431, Loss G: 2.3006\n",
      "Epoch [10/85] Batch 810/938 Loss D: 0.1717, Loss G: 2.5871\n",
      "Epoch [10/85] Batch 820/938 Loss D: 0.2181, Loss G: 2.0853\n",
      "Epoch [10/85] Batch 830/938 Loss D: 0.3661, Loss G: 1.8944\n",
      "Epoch [10/85] Batch 840/938 Loss D: 0.2344, Loss G: 2.1968\n",
      "Epoch [10/85] Batch 850/938 Loss D: 0.1638, Loss G: 2.4210\n",
      "Epoch [10/85] Batch 860/938 Loss D: 0.2661, Loss G: 2.0888\n",
      "Epoch [10/85] Batch 870/938 Loss D: 0.2354, Loss G: 2.0874\n",
      "Epoch [10/85] Batch 880/938 Loss D: 0.1466, Loss G: 2.5546\n",
      "Epoch [10/85] Batch 890/938 Loss D: 0.2138, Loss G: 2.2500\n",
      "Epoch [10/85] Batch 900/938 Loss D: 0.3118, Loss G: 1.9319\n",
      "Epoch [10/85] Batch 910/938 Loss D: 0.2719, Loss G: 2.2555\n",
      "Epoch [10/85] Batch 920/938 Loss D: 0.2463, Loss G: 2.1850\n",
      "Epoch [10/85] Batch 930/938 Loss D: 0.3491, Loss G: 2.0918\n",
      "Epoch [11/85] Batch 0/938 Loss D: 0.2434, Loss G: 2.5668\n",
      "Epoch [11/85] Batch 10/938 Loss D: 0.2364, Loss G: 2.2340\n",
      "Epoch [11/85] Batch 20/938 Loss D: 0.2999, Loss G: 2.0874\n",
      "Epoch [11/85] Batch 30/938 Loss D: 0.3156, Loss G: 1.9414\n",
      "Epoch [11/85] Batch 40/938 Loss D: 0.2035, Loss G: 2.1811\n",
      "Epoch [11/85] Batch 50/938 Loss D: 0.2283, Loss G: 2.0713\n",
      "Epoch [11/85] Batch 60/938 Loss D: 0.2464, Loss G: 2.1217\n",
      "Epoch [11/85] Batch 70/938 Loss D: 0.1686, Loss G: 2.7086\n",
      "Epoch [11/85] Batch 80/938 Loss D: 0.2338, Loss G: 2.4435\n",
      "Epoch [11/85] Batch 90/938 Loss D: 0.3862, Loss G: 2.2564\n",
      "Epoch [11/85] Batch 100/938 Loss D: 0.2423, Loss G: 2.5517\n",
      "Epoch [11/85] Batch 110/938 Loss D: 0.1888, Loss G: 2.9222\n",
      "Epoch [11/85] Batch 120/938 Loss D: 0.2691, Loss G: 2.2999\n",
      "Epoch [11/85] Batch 130/938 Loss D: 0.2693, Loss G: 2.0525\n",
      "Epoch [11/85] Batch 140/938 Loss D: 0.2595, Loss G: 1.9688\n",
      "Epoch [11/85] Batch 150/938 Loss D: 0.1423, Loss G: 2.7957\n",
      "Epoch [11/85] Batch 160/938 Loss D: 0.2211, Loss G: 2.3190\n",
      "Epoch [11/85] Batch 170/938 Loss D: 0.2890, Loss G: 1.8903\n",
      "Epoch [11/85] Batch 180/938 Loss D: 0.1474, Loss G: 2.6979\n",
      "Epoch [11/85] Batch 190/938 Loss D: 0.2251, Loss G: 2.4469\n",
      "Epoch [11/85] Batch 200/938 Loss D: 0.2713, Loss G: 1.7964\n",
      "Epoch [11/85] Batch 210/938 Loss D: 0.2668, Loss G: 1.7010\n",
      "Epoch [11/85] Batch 220/938 Loss D: 0.1520, Loss G: 2.4914\n",
      "Epoch [11/85] Batch 230/938 Loss D: 0.1894, Loss G: 3.0469\n",
      "Epoch [11/85] Batch 240/938 Loss D: 0.2922, Loss G: 2.4741\n",
      "Epoch [11/85] Batch 250/938 Loss D: 0.2504, Loss G: 2.3635\n",
      "Epoch [11/85] Batch 260/938 Loss D: 0.2316, Loss G: 2.2524\n",
      "Epoch [11/85] Batch 270/938 Loss D: 0.2400, Loss G: 2.1089\n",
      "Epoch [11/85] Batch 280/938 Loss D: 0.2775, Loss G: 1.8599\n",
      "Epoch [11/85] Batch 290/938 Loss D: 0.1863, Loss G: 2.4569\n",
      "Epoch [11/85] Batch 300/938 Loss D: 0.2065, Loss G: 2.7399\n",
      "Epoch [11/85] Batch 310/938 Loss D: 0.2361, Loss G: 2.1194\n",
      "Epoch [11/85] Batch 320/938 Loss D: 0.2649, Loss G: 1.5780\n",
      "Epoch [11/85] Batch 330/938 Loss D: 0.2182, Loss G: 2.0807\n",
      "Epoch [11/85] Batch 340/938 Loss D: 0.2904, Loss G: 2.3851\n",
      "Epoch [11/85] Batch 350/938 Loss D: 0.4293, Loss G: 1.5690\n",
      "Epoch [11/85] Batch 360/938 Loss D: 0.1935, Loss G: 2.0757\n",
      "Epoch [11/85] Batch 370/938 Loss D: 0.1904, Loss G: 2.3724\n",
      "Epoch [11/85] Batch 380/938 Loss D: 0.3789, Loss G: 1.9322\n",
      "Epoch [11/85] Batch 390/938 Loss D: 0.2283, Loss G: 2.1925\n",
      "Epoch [11/85] Batch 400/938 Loss D: 0.1478, Loss G: 3.0953\n",
      "Epoch [11/85] Batch 410/938 Loss D: 0.2371, Loss G: 3.0019\n",
      "Epoch [11/85] Batch 420/938 Loss D: 0.2756, Loss G: 2.2772\n",
      "Epoch [11/85] Batch 430/938 Loss D: 0.1744, Loss G: 2.2263\n",
      "Epoch [11/85] Batch 440/938 Loss D: 0.2821, Loss G: 2.0846\n",
      "Epoch [11/85] Batch 450/938 Loss D: 0.2938, Loss G: 2.2760\n",
      "Epoch [11/85] Batch 460/938 Loss D: 0.2642, Loss G: 2.3626\n",
      "Epoch [11/85] Batch 470/938 Loss D: 0.1713, Loss G: 2.6403\n",
      "Epoch [11/85] Batch 480/938 Loss D: 0.3176, Loss G: 1.7212\n",
      "Epoch [11/85] Batch 490/938 Loss D: 0.2985, Loss G: 1.7538\n",
      "Epoch [11/85] Batch 500/938 Loss D: 0.2657, Loss G: 2.3193\n",
      "Epoch [11/85] Batch 510/938 Loss D: 0.1815, Loss G: 2.3172\n",
      "Epoch [11/85] Batch 520/938 Loss D: 0.3356, Loss G: 1.7702\n",
      "Epoch [11/85] Batch 530/938 Loss D: 0.2515, Loss G: 2.1887\n",
      "Epoch [11/85] Batch 540/938 Loss D: 0.2114, Loss G: 2.3602\n",
      "Epoch [11/85] Batch 550/938 Loss D: 0.2986, Loss G: 2.6031\n",
      "Epoch [11/85] Batch 560/938 Loss D: 0.2437, Loss G: 2.2633\n",
      "Epoch [11/85] Batch 570/938 Loss D: 0.3238, Loss G: 2.2653\n",
      "Epoch [11/85] Batch 580/938 Loss D: 0.2142, Loss G: 2.3349\n",
      "Epoch [11/85] Batch 590/938 Loss D: 0.1883, Loss G: 2.5820\n",
      "Epoch [11/85] Batch 600/938 Loss D: 0.2592, Loss G: 1.8910\n",
      "Epoch [11/85] Batch 610/938 Loss D: 0.1600, Loss G: 2.6653\n",
      "Epoch [11/85] Batch 620/938 Loss D: 0.2578, Loss G: 1.8809\n",
      "Epoch [11/85] Batch 630/938 Loss D: 0.3042, Loss G: 1.8305\n",
      "Epoch [11/85] Batch 640/938 Loss D: 0.2805, Loss G: 2.1615\n",
      "Epoch [11/85] Batch 650/938 Loss D: 0.3375, Loss G: 2.8115\n",
      "Epoch [11/85] Batch 660/938 Loss D: 0.2759, Loss G: 2.4804\n",
      "Epoch [11/85] Batch 670/938 Loss D: 0.3450, Loss G: 1.9059\n",
      "Epoch [11/85] Batch 680/938 Loss D: 0.3816, Loss G: 2.2747\n",
      "Epoch [11/85] Batch 690/938 Loss D: 0.2182, Loss G: 2.3468\n",
      "Epoch [11/85] Batch 700/938 Loss D: 0.3431, Loss G: 2.0945\n",
      "Epoch [11/85] Batch 710/938 Loss D: 0.1812, Loss G: 2.5730\n",
      "Epoch [11/85] Batch 720/938 Loss D: 0.1997, Loss G: 2.4267\n",
      "Epoch [11/85] Batch 730/938 Loss D: 0.2331, Loss G: 2.3117\n",
      "Epoch [11/85] Batch 740/938 Loss D: 0.3162, Loss G: 2.0314\n",
      "Epoch [11/85] Batch 750/938 Loss D: 0.1970, Loss G: 2.3013\n",
      "Epoch [11/85] Batch 760/938 Loss D: 0.2927, Loss G: 2.0703\n",
      "Epoch [11/85] Batch 770/938 Loss D: 0.2524, Loss G: 2.1571\n",
      "Epoch [11/85] Batch 780/938 Loss D: 0.2911, Loss G: 2.1580\n",
      "Epoch [11/85] Batch 790/938 Loss D: 0.2329, Loss G: 2.0719\n",
      "Epoch [11/85] Batch 800/938 Loss D: 0.2654, Loss G: 1.9976\n",
      "Epoch [11/85] Batch 810/938 Loss D: 0.2773, Loss G: 1.9033\n",
      "Epoch [11/85] Batch 820/938 Loss D: 0.2572, Loss G: 2.2003\n",
      "Epoch [11/85] Batch 830/938 Loss D: 0.1947, Loss G: 2.1118\n",
      "Epoch [11/85] Batch 840/938 Loss D: 0.2806, Loss G: 1.8759\n",
      "Epoch [11/85] Batch 850/938 Loss D: 0.3089, Loss G: 1.6440\n",
      "Epoch [11/85] Batch 860/938 Loss D: 0.2539, Loss G: 1.9954\n",
      "Epoch [11/85] Batch 870/938 Loss D: 0.1544, Loss G: 2.3270\n",
      "Epoch [11/85] Batch 880/938 Loss D: 0.2982, Loss G: 1.8874\n",
      "Epoch [11/85] Batch 890/938 Loss D: 0.2793, Loss G: 1.8521\n",
      "Epoch [11/85] Batch 900/938 Loss D: 0.2458, Loss G: 2.2178\n",
      "Epoch [11/85] Batch 910/938 Loss D: 0.1847, Loss G: 2.6746\n",
      "Epoch [11/85] Batch 920/938 Loss D: 0.2945, Loss G: 1.7249\n",
      "Epoch [11/85] Batch 930/938 Loss D: 0.2333, Loss G: 2.3322\n",
      "Epoch [12/85] Batch 0/938 Loss D: 0.2629, Loss G: 2.1612\n",
      "Epoch [12/85] Batch 10/938 Loss D: 0.2204, Loss G: 2.0020\n",
      "Epoch [12/85] Batch 20/938 Loss D: 0.3580, Loss G: 1.7028\n",
      "Epoch [12/85] Batch 30/938 Loss D: 0.1821, Loss G: 1.9894\n",
      "Epoch [12/85] Batch 40/938 Loss D: 0.1835, Loss G: 2.0317\n",
      "Epoch [12/85] Batch 50/938 Loss D: 0.3176, Loss G: 2.2649\n",
      "Epoch [12/85] Batch 60/938 Loss D: 0.1975, Loss G: 2.5881\n",
      "Epoch [12/85] Batch 70/938 Loss D: 0.1956, Loss G: 2.8450\n",
      "Epoch [12/85] Batch 80/938 Loss D: 0.2911, Loss G: 2.0171\n",
      "Epoch [12/85] Batch 90/938 Loss D: 0.3354, Loss G: 2.4549\n",
      "Epoch [12/85] Batch 100/938 Loss D: 0.1725, Loss G: 2.6536\n",
      "Epoch [12/85] Batch 110/938 Loss D: 0.2315, Loss G: 2.3537\n",
      "Epoch [12/85] Batch 120/938 Loss D: 0.3646, Loss G: 1.9124\n",
      "Epoch [12/85] Batch 130/938 Loss D: 0.1632, Loss G: 2.3214\n",
      "Epoch [12/85] Batch 140/938 Loss D: 0.2846, Loss G: 2.0317\n",
      "Epoch [12/85] Batch 150/938 Loss D: 0.2123, Loss G: 2.1246\n",
      "Epoch [12/85] Batch 160/938 Loss D: 0.2386, Loss G: 1.9182\n",
      "Epoch [12/85] Batch 170/938 Loss D: 0.2272, Loss G: 1.8912\n",
      "Epoch [12/85] Batch 180/938 Loss D: 0.1923, Loss G: 2.6818\n",
      "Epoch [12/85] Batch 190/938 Loss D: 0.2468, Loss G: 2.2361\n",
      "Epoch [12/85] Batch 200/938 Loss D: 0.2179, Loss G: 2.1883\n",
      "Epoch [12/85] Batch 210/938 Loss D: 0.2461, Loss G: 2.1781\n",
      "Epoch [12/85] Batch 220/938 Loss D: 0.2226, Loss G: 2.0298\n",
      "Epoch [12/85] Batch 230/938 Loss D: 0.2002, Loss G: 2.1481\n",
      "Epoch [12/85] Batch 240/938 Loss D: 0.2403, Loss G: 2.1755\n",
      "Epoch [12/85] Batch 250/938 Loss D: 0.2645, Loss G: 2.0185\n",
      "Epoch [12/85] Batch 260/938 Loss D: 0.1641, Loss G: 2.3436\n",
      "Epoch [12/85] Batch 270/938 Loss D: 0.2951, Loss G: 2.0113\n",
      "Epoch [12/85] Batch 280/938 Loss D: 0.2094, Loss G: 2.3894\n",
      "Epoch [12/85] Batch 290/938 Loss D: 0.1920, Loss G: 2.4220\n",
      "Epoch [12/85] Batch 300/938 Loss D: 0.2040, Loss G: 2.3855\n",
      "Epoch [12/85] Batch 310/938 Loss D: 0.3526, Loss G: 2.1101\n",
      "Epoch [12/85] Batch 320/938 Loss D: 0.3084, Loss G: 1.9267\n",
      "Epoch [12/85] Batch 330/938 Loss D: 0.2256, Loss G: 2.5265\n",
      "Epoch [12/85] Batch 340/938 Loss D: 0.2923, Loss G: 2.0033\n",
      "Epoch [12/85] Batch 350/938 Loss D: 0.2384, Loss G: 1.8643\n",
      "Epoch [12/85] Batch 360/938 Loss D: 0.1815, Loss G: 2.3098\n",
      "Epoch [12/85] Batch 370/938 Loss D: 0.2792, Loss G: 2.0460\n",
      "Epoch [12/85] Batch 380/938 Loss D: 0.2509, Loss G: 2.1378\n",
      "Epoch [12/85] Batch 390/938 Loss D: 0.2679, Loss G: 2.3012\n",
      "Epoch [12/85] Batch 400/938 Loss D: 0.2020, Loss G: 2.0131\n",
      "Epoch [12/85] Batch 410/938 Loss D: 0.2011, Loss G: 2.2798\n",
      "Epoch [12/85] Batch 420/938 Loss D: 0.2216, Loss G: 2.3472\n",
      "Epoch [12/85] Batch 430/938 Loss D: 0.1841, Loss G: 2.5403\n",
      "Epoch [12/85] Batch 440/938 Loss D: 0.1940, Loss G: 1.8973\n",
      "Epoch [12/85] Batch 450/938 Loss D: 0.2318, Loss G: 1.9744\n",
      "Epoch [12/85] Batch 460/938 Loss D: 0.2451, Loss G: 1.8397\n",
      "Epoch [12/85] Batch 470/938 Loss D: 0.1794, Loss G: 2.2133\n",
      "Epoch [12/85] Batch 480/938 Loss D: 0.1909, Loss G: 1.9512\n",
      "Epoch [12/85] Batch 490/938 Loss D: 0.3257, Loss G: 1.5661\n",
      "Epoch [12/85] Batch 500/938 Loss D: 0.2750, Loss G: 2.1483\n",
      "Epoch [12/85] Batch 510/938 Loss D: 0.2333, Loss G: 2.3540\n",
      "Epoch [12/85] Batch 520/938 Loss D: 0.2234, Loss G: 2.3462\n",
      "Epoch [12/85] Batch 530/938 Loss D: 0.3212, Loss G: 1.7676\n",
      "Epoch [12/85] Batch 540/938 Loss D: 0.1979, Loss G: 2.5076\n",
      "Epoch [12/85] Batch 550/938 Loss D: 0.1584, Loss G: 2.5540\n",
      "Epoch [12/85] Batch 560/938 Loss D: 0.2958, Loss G: 2.3410\n",
      "Epoch [12/85] Batch 570/938 Loss D: 0.2605, Loss G: 1.9853\n",
      "Epoch [12/85] Batch 580/938 Loss D: 0.2064, Loss G: 1.9890\n",
      "Epoch [12/85] Batch 590/938 Loss D: 0.1668, Loss G: 2.3934\n",
      "Epoch [12/85] Batch 600/938 Loss D: 0.2182, Loss G: 2.1717\n",
      "Epoch [12/85] Batch 610/938 Loss D: 0.3187, Loss G: 2.1729\n",
      "Epoch [12/85] Batch 620/938 Loss D: 0.1753, Loss G: 2.4883\n",
      "Epoch [12/85] Batch 630/938 Loss D: 0.4118, Loss G: 1.4174\n",
      "Epoch [12/85] Batch 640/938 Loss D: 0.2699, Loss G: 1.8759\n",
      "Epoch [12/85] Batch 650/938 Loss D: 0.2803, Loss G: 2.1076\n",
      "Epoch [12/85] Batch 660/938 Loss D: 0.2979, Loss G: 1.9711\n",
      "Epoch [12/85] Batch 670/938 Loss D: 0.1870, Loss G: 2.3417\n",
      "Epoch [12/85] Batch 680/938 Loss D: 0.2541, Loss G: 2.3936\n",
      "Epoch [12/85] Batch 690/938 Loss D: 0.3078, Loss G: 2.2300\n",
      "Epoch [12/85] Batch 700/938 Loss D: 0.3320, Loss G: 2.1672\n",
      "Epoch [12/85] Batch 710/938 Loss D: 0.2348, Loss G: 2.2696\n",
      "Epoch [12/85] Batch 720/938 Loss D: 0.2384, Loss G: 2.1498\n",
      "Epoch [12/85] Batch 730/938 Loss D: 0.2774, Loss G: 2.1534\n",
      "Epoch [12/85] Batch 740/938 Loss D: 0.2846, Loss G: 2.0506\n",
      "Epoch [12/85] Batch 750/938 Loss D: 0.2369, Loss G: 2.6423\n",
      "Epoch [12/85] Batch 760/938 Loss D: 0.2461, Loss G: 2.2394\n",
      "Epoch [12/85] Batch 770/938 Loss D: 0.3253, Loss G: 2.0057\n",
      "Epoch [12/85] Batch 780/938 Loss D: 0.1993, Loss G: 2.6276\n",
      "Epoch [12/85] Batch 790/938 Loss D: 0.1724, Loss G: 2.6375\n",
      "Epoch [12/85] Batch 800/938 Loss D: 0.3592, Loss G: 2.0022\n",
      "Epoch [12/85] Batch 810/938 Loss D: 0.2212, Loss G: 2.4962\n",
      "Epoch [12/85] Batch 820/938 Loss D: 0.1526, Loss G: 2.5649\n",
      "Epoch [12/85] Batch 830/938 Loss D: 0.2112, Loss G: 2.5210\n",
      "Epoch [12/85] Batch 840/938 Loss D: 0.2828, Loss G: 2.2402\n",
      "Epoch [12/85] Batch 850/938 Loss D: 0.1383, Loss G: 2.6870\n",
      "Epoch [12/85] Batch 860/938 Loss D: 0.3100, Loss G: 1.9234\n",
      "Epoch [12/85] Batch 870/938 Loss D: 0.3621, Loss G: 1.9473\n",
      "Epoch [12/85] Batch 880/938 Loss D: 0.2075, Loss G: 2.3398\n",
      "Epoch [12/85] Batch 890/938 Loss D: 0.1504, Loss G: 2.8119\n",
      "Epoch [12/85] Batch 900/938 Loss D: 0.3084, Loss G: 1.6895\n",
      "Epoch [12/85] Batch 910/938 Loss D: 0.2053, Loss G: 2.4046\n",
      "Epoch [12/85] Batch 920/938 Loss D: 0.1448, Loss G: 2.7339\n",
      "Epoch [12/85] Batch 930/938 Loss D: 0.3638, Loss G: 1.5871\n",
      "Epoch [13/85] Batch 0/938 Loss D: 0.3515, Loss G: 1.5364\n",
      "Epoch [13/85] Batch 10/938 Loss D: 0.1921, Loss G: 2.0286\n",
      "Epoch [13/85] Batch 20/938 Loss D: 0.1833, Loss G: 2.1274\n",
      "Epoch [13/85] Batch 30/938 Loss D: 0.3212, Loss G: 1.9958\n",
      "Epoch [13/85] Batch 40/938 Loss D: 0.2941, Loss G: 1.7617\n",
      "Epoch [13/85] Batch 50/938 Loss D: 0.1378, Loss G: 2.3149\n",
      "Epoch [13/85] Batch 60/938 Loss D: 0.2244, Loss G: 2.0014\n",
      "Epoch [13/85] Batch 70/938 Loss D: 0.2432, Loss G: 1.9024\n",
      "Epoch [13/85] Batch 80/938 Loss D: 0.3121, Loss G: 1.8199\n",
      "Epoch [13/85] Batch 90/938 Loss D: 0.3564, Loss G: 2.0389\n",
      "Epoch [13/85] Batch 100/938 Loss D: 0.1817, Loss G: 2.3924\n",
      "Epoch [13/85] Batch 110/938 Loss D: 0.2362, Loss G: 2.0209\n",
      "Epoch [13/85] Batch 120/938 Loss D: 0.2176, Loss G: 2.2624\n",
      "Epoch [13/85] Batch 130/938 Loss D: 0.2173, Loss G: 2.4039\n",
      "Epoch [13/85] Batch 140/938 Loss D: 0.2436, Loss G: 2.1513\n",
      "Epoch [13/85] Batch 150/938 Loss D: 0.2676, Loss G: 2.0319\n",
      "Epoch [13/85] Batch 160/938 Loss D: 0.1929, Loss G: 2.3399\n",
      "Epoch [13/85] Batch 170/938 Loss D: 0.2416, Loss G: 1.8668\n",
      "Epoch [13/85] Batch 180/938 Loss D: 0.2558, Loss G: 2.0939\n",
      "Epoch [13/85] Batch 190/938 Loss D: 0.3022, Loss G: 1.7803\n",
      "Epoch [13/85] Batch 200/938 Loss D: 0.1670, Loss G: 2.2804\n",
      "Epoch [13/85] Batch 210/938 Loss D: 0.2315, Loss G: 2.4439\n",
      "Epoch [13/85] Batch 220/938 Loss D: 0.2936, Loss G: 2.3781\n",
      "Epoch [13/85] Batch 230/938 Loss D: 0.2769, Loss G: 2.0946\n",
      "Epoch [13/85] Batch 240/938 Loss D: 0.1991, Loss G: 2.4521\n",
      "Epoch [13/85] Batch 250/938 Loss D: 0.2465, Loss G: 2.6039\n",
      "Epoch [13/85] Batch 260/938 Loss D: 0.2753, Loss G: 2.1801\n",
      "Epoch [13/85] Batch 270/938 Loss D: 0.1874, Loss G: 2.3933\n",
      "Epoch [13/85] Batch 280/938 Loss D: 0.2041, Loss G: 2.4870\n",
      "Epoch [13/85] Batch 290/938 Loss D: 0.1478, Loss G: 2.2181\n",
      "Epoch [13/85] Batch 300/938 Loss D: 0.2408, Loss G: 1.7702\n",
      "Epoch [13/85] Batch 310/938 Loss D: 0.2360, Loss G: 1.9880\n",
      "Epoch [13/85] Batch 320/938 Loss D: 0.2550, Loss G: 2.1350\n",
      "Epoch [13/85] Batch 330/938 Loss D: 0.2254, Loss G: 2.2378\n",
      "Epoch [13/85] Batch 340/938 Loss D: 0.2794, Loss G: 2.1515\n",
      "Epoch [13/85] Batch 350/938 Loss D: 0.2617, Loss G: 2.4138\n",
      "Epoch [13/85] Batch 360/938 Loss D: 0.2205, Loss G: 2.5157\n",
      "Epoch [13/85] Batch 370/938 Loss D: 0.3350, Loss G: 1.9393\n",
      "Epoch [13/85] Batch 380/938 Loss D: 0.2022, Loss G: 2.9096\n",
      "Epoch [13/85] Batch 390/938 Loss D: 0.2172, Loss G: 2.8510\n",
      "Epoch [13/85] Batch 400/938 Loss D: 0.2919, Loss G: 2.2581\n",
      "Epoch [13/85] Batch 410/938 Loss D: 0.1888, Loss G: 2.4805\n",
      "Epoch [13/85] Batch 420/938 Loss D: 0.2869, Loss G: 2.3483\n",
      "Epoch [13/85] Batch 430/938 Loss D: 0.1731, Loss G: 2.3043\n",
      "Epoch [13/85] Batch 440/938 Loss D: 0.3513, Loss G: 1.4115\n",
      "Epoch [13/85] Batch 450/938 Loss D: 0.3045, Loss G: 1.8739\n",
      "Epoch [13/85] Batch 460/938 Loss D: 0.1538, Loss G: 2.6881\n",
      "Epoch [13/85] Batch 470/938 Loss D: 0.1531, Loss G: 2.8371\n",
      "Epoch [13/85] Batch 480/938 Loss D: 0.1763, Loss G: 2.8287\n",
      "Epoch [13/85] Batch 490/938 Loss D: 0.2708, Loss G: 2.3342\n",
      "Epoch [13/85] Batch 500/938 Loss D: 0.1747, Loss G: 2.5718\n",
      "Epoch [13/85] Batch 510/938 Loss D: 0.2356, Loss G: 2.8999\n",
      "Epoch [13/85] Batch 520/938 Loss D: 0.2677, Loss G: 2.5682\n",
      "Epoch [13/85] Batch 530/938 Loss D: 0.2227, Loss G: 2.4083\n",
      "Epoch [13/85] Batch 540/938 Loss D: 0.1987, Loss G: 1.9965\n",
      "Epoch [13/85] Batch 550/938 Loss D: 0.2097, Loss G: 2.0416\n",
      "Epoch [13/85] Batch 560/938 Loss D: 0.2719, Loss G: 2.1633\n",
      "Epoch [13/85] Batch 570/938 Loss D: 0.2369, Loss G: 2.2009\n",
      "Epoch [13/85] Batch 580/938 Loss D: 0.3003, Loss G: 2.2150\n",
      "Epoch [13/85] Batch 590/938 Loss D: 0.2475, Loss G: 2.0173\n",
      "Epoch [13/85] Batch 600/938 Loss D: 0.2201, Loss G: 2.6751\n",
      "Epoch [13/85] Batch 610/938 Loss D: 0.2319, Loss G: 2.3212\n",
      "Epoch [13/85] Batch 620/938 Loss D: 0.2281, Loss G: 2.2926\n",
      "Epoch [13/85] Batch 630/938 Loss D: 0.3919, Loss G: 2.0366\n",
      "Epoch [13/85] Batch 640/938 Loss D: 0.2686, Loss G: 2.5887\n",
      "Epoch [13/85] Batch 650/938 Loss D: 0.1671, Loss G: 2.2464\n",
      "Epoch [13/85] Batch 660/938 Loss D: 0.2360, Loss G: 2.2963\n",
      "Epoch [13/85] Batch 670/938 Loss D: 0.2590, Loss G: 1.9804\n",
      "Epoch [13/85] Batch 680/938 Loss D: 0.3066, Loss G: 1.5674\n",
      "Epoch [13/85] Batch 690/938 Loss D: 0.2780, Loss G: 2.2142\n",
      "Epoch [13/85] Batch 700/938 Loss D: 0.2884, Loss G: 2.0105\n",
      "Epoch [13/85] Batch 710/938 Loss D: 0.1558, Loss G: 2.7676\n",
      "Epoch [13/85] Batch 720/938 Loss D: 0.2987, Loss G: 2.3036\n",
      "Epoch [13/85] Batch 730/938 Loss D: 0.1792, Loss G: 2.8445\n",
      "Epoch [13/85] Batch 740/938 Loss D: 0.2661, Loss G: 2.2035\n",
      "Epoch [13/85] Batch 750/938 Loss D: 0.3249, Loss G: 1.9014\n",
      "Epoch [13/85] Batch 760/938 Loss D: 0.1902, Loss G: 2.3207\n",
      "Epoch [13/85] Batch 770/938 Loss D: 0.3259, Loss G: 1.8418\n",
      "Epoch [13/85] Batch 780/938 Loss D: 0.2283, Loss G: 2.0302\n",
      "Epoch [13/85] Batch 790/938 Loss D: 0.3096, Loss G: 1.8278\n",
      "Epoch [13/85] Batch 800/938 Loss D: 0.2378, Loss G: 2.7214\n",
      "Epoch [13/85] Batch 810/938 Loss D: 0.2743, Loss G: 2.4090\n",
      "Epoch [13/85] Batch 820/938 Loss D: 0.1645, Loss G: 2.6554\n",
      "Epoch [13/85] Batch 830/938 Loss D: 0.2263, Loss G: 2.1261\n",
      "Epoch [13/85] Batch 840/938 Loss D: 0.3125, Loss G: 2.1088\n",
      "Epoch [13/85] Batch 850/938 Loss D: 0.2560, Loss G: 2.2643\n",
      "Epoch [13/85] Batch 860/938 Loss D: 0.1737, Loss G: 2.1816\n",
      "Epoch [13/85] Batch 870/938 Loss D: 0.2068, Loss G: 2.1786\n",
      "Epoch [13/85] Batch 880/938 Loss D: 0.2958, Loss G: 1.6496\n",
      "Epoch [13/85] Batch 890/938 Loss D: 0.2809, Loss G: 2.1134\n",
      "Epoch [13/85] Batch 900/938 Loss D: 0.1656, Loss G: 2.3355\n",
      "Epoch [13/85] Batch 910/938 Loss D: 0.2131, Loss G: 2.4861\n",
      "Epoch [13/85] Batch 920/938 Loss D: 0.3331, Loss G: 1.4369\n",
      "Epoch [13/85] Batch 930/938 Loss D: 0.3270, Loss G: 1.6406\n",
      "Epoch [14/85] Batch 0/938 Loss D: 0.2074, Loss G: 2.0689\n",
      "Epoch [14/85] Batch 10/938 Loss D: 0.2358, Loss G: 1.9871\n",
      "Epoch [14/85] Batch 20/938 Loss D: 0.2716, Loss G: 2.0334\n",
      "Epoch [14/85] Batch 30/938 Loss D: 0.2373, Loss G: 2.0458\n",
      "Epoch [14/85] Batch 40/938 Loss D: 0.2375, Loss G: 2.3961\n",
      "Epoch [14/85] Batch 50/938 Loss D: 0.2577, Loss G: 2.5847\n",
      "Epoch [14/85] Batch 60/938 Loss D: 0.2807, Loss G: 2.2650\n",
      "Epoch [14/85] Batch 70/938 Loss D: 0.1908, Loss G: 2.8429\n",
      "Epoch [14/85] Batch 80/938 Loss D: 0.2380, Loss G: 2.7743\n",
      "Epoch [14/85] Batch 90/938 Loss D: 0.3287, Loss G: 2.5600\n",
      "Epoch [14/85] Batch 100/938 Loss D: 0.3948, Loss G: 2.0498\n",
      "Epoch [14/85] Batch 110/938 Loss D: 0.2030, Loss G: 2.2556\n",
      "Epoch [14/85] Batch 120/938 Loss D: 0.1712, Loss G: 2.3891\n",
      "Epoch [14/85] Batch 130/938 Loss D: 0.2679, Loss G: 1.9208\n",
      "Epoch [14/85] Batch 140/938 Loss D: 0.3528, Loss G: 2.1218\n",
      "Epoch [14/85] Batch 150/938 Loss D: 0.1845, Loss G: 2.6581\n",
      "Epoch [14/85] Batch 160/938 Loss D: 0.2325, Loss G: 2.4949\n",
      "Epoch [14/85] Batch 170/938 Loss D: 0.3886, Loss G: 2.7114\n",
      "Epoch [14/85] Batch 180/938 Loss D: 0.2707, Loss G: 2.8773\n",
      "Epoch [14/85] Batch 190/938 Loss D: 0.2457, Loss G: 2.4917\n",
      "Epoch [14/85] Batch 200/938 Loss D: 0.2262, Loss G: 2.2104\n",
      "Epoch [14/85] Batch 210/938 Loss D: 0.1579, Loss G: 2.7385\n",
      "Epoch [14/85] Batch 220/938 Loss D: 0.2981, Loss G: 2.4797\n",
      "Epoch [14/85] Batch 230/938 Loss D: 0.2869, Loss G: 2.0603\n",
      "Epoch [14/85] Batch 240/938 Loss D: 0.2578, Loss G: 2.4247\n",
      "Epoch [14/85] Batch 250/938 Loss D: 0.1782, Loss G: 2.3900\n",
      "Epoch [14/85] Batch 260/938 Loss D: 0.2464, Loss G: 2.6473\n",
      "Epoch [14/85] Batch 270/938 Loss D: 0.2475, Loss G: 3.0946\n",
      "Epoch [14/85] Batch 280/938 Loss D: 0.2649, Loss G: 2.6351\n",
      "Epoch [14/85] Batch 290/938 Loss D: 0.2880, Loss G: 2.1273\n",
      "Epoch [14/85] Batch 300/938 Loss D: 0.2907, Loss G: 1.8733\n",
      "Epoch [14/85] Batch 310/938 Loss D: 0.1916, Loss G: 2.6403\n",
      "Epoch [14/85] Batch 320/938 Loss D: 0.1800, Loss G: 2.2288\n",
      "Epoch [14/85] Batch 330/938 Loss D: 0.2289, Loss G: 2.0598\n",
      "Epoch [14/85] Batch 340/938 Loss D: 0.1926, Loss G: 2.3955\n",
      "Epoch [14/85] Batch 350/938 Loss D: 0.2008, Loss G: 2.6812\n",
      "Epoch [14/85] Batch 360/938 Loss D: 0.2447, Loss G: 2.0154\n",
      "Epoch [14/85] Batch 370/938 Loss D: 0.1801, Loss G: 2.5876\n",
      "Epoch [14/85] Batch 380/938 Loss D: 0.2616, Loss G: 2.1589\n",
      "Epoch [14/85] Batch 390/938 Loss D: 0.2059, Loss G: 1.9567\n",
      "Epoch [14/85] Batch 400/938 Loss D: 0.1919, Loss G: 2.2382\n",
      "Epoch [14/85] Batch 410/938 Loss D: 0.2366, Loss G: 2.4255\n",
      "Epoch [14/85] Batch 420/938 Loss D: 0.2118, Loss G: 1.9544\n",
      "Epoch [14/85] Batch 430/938 Loss D: 0.2642, Loss G: 2.0412\n",
      "Epoch [14/85] Batch 440/938 Loss D: 0.2532, Loss G: 2.0246\n",
      "Epoch [14/85] Batch 450/938 Loss D: 0.2267, Loss G: 2.5133\n",
      "Epoch [14/85] Batch 460/938 Loss D: 0.2057, Loss G: 2.6380\n",
      "Epoch [14/85] Batch 470/938 Loss D: 0.2819, Loss G: 2.0692\n",
      "Epoch [14/85] Batch 480/938 Loss D: 0.2103, Loss G: 2.2061\n",
      "Epoch [14/85] Batch 490/938 Loss D: 0.2263, Loss G: 2.4578\n",
      "Epoch [14/85] Batch 500/938 Loss D: 0.2105, Loss G: 2.2968\n",
      "Epoch [14/85] Batch 510/938 Loss D: 0.1946, Loss G: 2.1382\n",
      "Epoch [14/85] Batch 520/938 Loss D: 0.2368, Loss G: 2.1191\n",
      "Epoch [14/85] Batch 530/938 Loss D: 0.2455, Loss G: 2.7018\n",
      "Epoch [14/85] Batch 540/938 Loss D: 0.2331, Loss G: 1.9234\n",
      "Epoch [14/85] Batch 550/938 Loss D: 0.2772, Loss G: 1.8543\n",
      "Epoch [14/85] Batch 560/938 Loss D: 0.2999, Loss G: 1.9553\n",
      "Epoch [14/85] Batch 570/938 Loss D: 0.2667, Loss G: 2.3041\n",
      "Epoch [14/85] Batch 580/938 Loss D: 0.3092, Loss G: 1.9298\n",
      "Epoch [14/85] Batch 590/938 Loss D: 0.4183, Loss G: 2.4670\n",
      "Epoch [14/85] Batch 600/938 Loss D: 0.2390, Loss G: 2.6609\n",
      "Epoch [14/85] Batch 610/938 Loss D: 0.2436, Loss G: 2.2090\n",
      "Epoch [14/85] Batch 620/938 Loss D: 0.2487, Loss G: 2.3667\n",
      "Epoch [14/85] Batch 630/938 Loss D: 0.2363, Loss G: 2.6627\n",
      "Epoch [14/85] Batch 640/938 Loss D: 0.2190, Loss G: 2.1011\n",
      "Epoch [14/85] Batch 650/938 Loss D: 0.2561, Loss G: 1.9428\n",
      "Epoch [14/85] Batch 660/938 Loss D: 0.1826, Loss G: 2.2096\n",
      "Epoch [14/85] Batch 670/938 Loss D: 0.2657, Loss G: 1.6768\n",
      "Epoch [14/85] Batch 680/938 Loss D: 0.2809, Loss G: 1.8561\n",
      "Epoch [14/85] Batch 690/938 Loss D: 0.2286, Loss G: 1.9960\n",
      "Epoch [14/85] Batch 700/938 Loss D: 0.3147, Loss G: 1.7405\n",
      "Epoch [14/85] Batch 710/938 Loss D: 0.2891, Loss G: 1.9124\n",
      "Epoch [14/85] Batch 720/938 Loss D: 0.2699, Loss G: 2.4150\n",
      "Epoch [14/85] Batch 730/938 Loss D: 0.2596, Loss G: 1.8409\n",
      "Epoch [14/85] Batch 740/938 Loss D: 0.2037, Loss G: 2.0656\n",
      "Epoch [14/85] Batch 750/938 Loss D: 0.2183, Loss G: 2.2836\n",
      "Epoch [14/85] Batch 760/938 Loss D: 0.2758, Loss G: 2.0295\n",
      "Epoch [14/85] Batch 770/938 Loss D: 0.2113, Loss G: 2.4334\n",
      "Epoch [14/85] Batch 780/938 Loss D: 0.1897, Loss G: 2.4442\n",
      "Epoch [14/85] Batch 790/938 Loss D: 0.2208, Loss G: 2.4729\n",
      "Epoch [14/85] Batch 800/938 Loss D: 0.2453, Loss G: 2.0219\n",
      "Epoch [14/85] Batch 810/938 Loss D: 0.1989, Loss G: 2.2820\n",
      "Epoch [14/85] Batch 820/938 Loss D: 0.2532, Loss G: 2.3684\n",
      "Epoch [14/85] Batch 830/938 Loss D: 0.3433, Loss G: 2.4561\n",
      "Epoch [14/85] Batch 840/938 Loss D: 0.2144, Loss G: 2.1518\n",
      "Epoch [14/85] Batch 850/938 Loss D: 0.2857, Loss G: 2.2706\n",
      "Epoch [14/85] Batch 860/938 Loss D: 0.2328, Loss G: 2.6041\n",
      "Epoch [14/85] Batch 870/938 Loss D: 0.1722, Loss G: 2.7446\n",
      "Epoch [14/85] Batch 880/938 Loss D: 0.2217, Loss G: 2.2103\n",
      "Epoch [14/85] Batch 890/938 Loss D: 0.2445, Loss G: 2.0027\n",
      "Epoch [14/85] Batch 900/938 Loss D: 0.1836, Loss G: 2.0030\n",
      "Epoch [14/85] Batch 910/938 Loss D: 0.2278, Loss G: 1.7376\n",
      "Epoch [14/85] Batch 920/938 Loss D: 0.2095, Loss G: 2.1627\n",
      "Epoch [14/85] Batch 930/938 Loss D: 0.2651, Loss G: 2.0001\n",
      "Epoch [15/85] Batch 0/938 Loss D: 0.2330, Loss G: 1.7657\n",
      "Epoch [15/85] Batch 10/938 Loss D: 0.1492, Loss G: 2.9266\n",
      "Epoch [15/85] Batch 20/938 Loss D: 0.2399, Loss G: 2.1243\n",
      "Epoch [15/85] Batch 30/938 Loss D: 0.2507, Loss G: 2.0643\n",
      "Epoch [15/85] Batch 40/938 Loss D: 0.2724, Loss G: 2.1777\n",
      "Epoch [15/85] Batch 50/938 Loss D: 0.2489, Loss G: 2.8573\n",
      "Epoch [15/85] Batch 60/938 Loss D: 0.2620, Loss G: 2.1896\n",
      "Epoch [15/85] Batch 70/938 Loss D: 0.2077, Loss G: 2.2089\n",
      "Epoch [15/85] Batch 80/938 Loss D: 0.1592, Loss G: 2.2776\n",
      "Epoch [15/85] Batch 90/938 Loss D: 0.2407, Loss G: 2.2593\n",
      "Epoch [15/85] Batch 100/938 Loss D: 0.2667, Loss G: 1.9552\n",
      "Epoch [15/85] Batch 110/938 Loss D: 0.2445, Loss G: 2.1469\n",
      "Epoch [15/85] Batch 120/938 Loss D: 0.1842, Loss G: 2.0651\n",
      "Epoch [15/85] Batch 130/938 Loss D: 0.2203, Loss G: 2.2901\n",
      "Epoch [15/85] Batch 140/938 Loss D: 0.2370, Loss G: 2.2379\n",
      "Epoch [15/85] Batch 150/938 Loss D: 0.4589, Loss G: 2.1452\n",
      "Epoch [15/85] Batch 160/938 Loss D: 0.3325, Loss G: 2.4096\n",
      "Epoch [15/85] Batch 170/938 Loss D: 0.3719, Loss G: 2.2983\n",
      "Epoch [15/85] Batch 180/938 Loss D: 0.2384, Loss G: 2.7415\n",
      "Epoch [15/85] Batch 190/938 Loss D: 0.2667, Loss G: 2.2880\n",
      "Epoch [15/85] Batch 200/938 Loss D: 0.2022, Loss G: 2.6054\n",
      "Epoch [15/85] Batch 210/938 Loss D: 0.2041, Loss G: 2.9107\n",
      "Epoch [15/85] Batch 220/938 Loss D: 0.2190, Loss G: 3.1065\n",
      "Epoch [15/85] Batch 230/938 Loss D: 0.2931, Loss G: 2.5030\n",
      "Epoch [15/85] Batch 240/938 Loss D: 0.2041, Loss G: 2.5061\n",
      "Epoch [15/85] Batch 250/938 Loss D: 0.2104, Loss G: 2.1845\n",
      "Epoch [15/85] Batch 260/938 Loss D: 0.2245, Loss G: 2.1769\n",
      "Epoch [15/85] Batch 270/938 Loss D: 0.1842, Loss G: 2.3604\n",
      "Epoch [15/85] Batch 280/938 Loss D: 0.2725, Loss G: 2.2305\n",
      "Epoch [15/85] Batch 290/938 Loss D: 0.2828, Loss G: 2.2864\n",
      "Epoch [15/85] Batch 300/938 Loss D: 0.2629, Loss G: 2.3488\n",
      "Epoch [15/85] Batch 310/938 Loss D: 0.2091, Loss G: 2.4170\n",
      "Epoch [15/85] Batch 320/938 Loss D: 0.2233, Loss G: 2.1477\n",
      "Epoch [15/85] Batch 330/938 Loss D: 0.3231, Loss G: 2.7569\n",
      "Epoch [15/85] Batch 340/938 Loss D: 0.1840, Loss G: 2.9030\n",
      "Epoch [15/85] Batch 350/938 Loss D: 0.3213, Loss G: 2.2024\n",
      "Epoch [15/85] Batch 360/938 Loss D: 0.3458, Loss G: 2.0013\n",
      "Epoch [15/85] Batch 370/938 Loss D: 0.2555, Loss G: 2.1558\n",
      "Epoch [15/85] Batch 380/938 Loss D: 0.2080, Loss G: 2.4245\n",
      "Epoch [15/85] Batch 390/938 Loss D: 0.2332, Loss G: 2.1334\n",
      "Epoch [15/85] Batch 400/938 Loss D: 0.3757, Loss G: 2.0009\n",
      "Epoch [15/85] Batch 410/938 Loss D: 0.2550, Loss G: 2.4928\n",
      "Epoch [15/85] Batch 420/938 Loss D: 0.2032, Loss G: 2.4790\n",
      "Epoch [15/85] Batch 430/938 Loss D: 0.2910, Loss G: 2.1950\n",
      "Epoch [15/85] Batch 440/938 Loss D: 0.2699, Loss G: 1.8917\n",
      "Epoch [15/85] Batch 450/938 Loss D: 0.1567, Loss G: 2.6216\n",
      "Epoch [15/85] Batch 460/938 Loss D: 0.1804, Loss G: 2.6667\n",
      "Epoch [15/85] Batch 470/938 Loss D: 0.2174, Loss G: 2.1111\n",
      "Epoch [15/85] Batch 480/938 Loss D: 0.1671, Loss G: 2.7247\n",
      "Epoch [15/85] Batch 490/938 Loss D: 0.1657, Loss G: 2.6452\n",
      "Epoch [15/85] Batch 500/938 Loss D: 0.2233, Loss G: 2.1760\n",
      "Epoch [15/85] Batch 510/938 Loss D: 0.1671, Loss G: 2.1743\n",
      "Epoch [15/85] Batch 520/938 Loss D: 0.3173, Loss G: 2.1050\n",
      "Epoch [15/85] Batch 530/938 Loss D: 0.2181, Loss G: 2.1736\n",
      "Epoch [15/85] Batch 540/938 Loss D: 0.2381, Loss G: 2.1291\n",
      "Epoch [15/85] Batch 550/938 Loss D: 0.3745, Loss G: 1.7661\n",
      "Epoch [15/85] Batch 560/938 Loss D: 0.2462, Loss G: 2.2056\n",
      "Epoch [15/85] Batch 570/938 Loss D: 0.1647, Loss G: 2.3747\n",
      "Epoch [15/85] Batch 580/938 Loss D: 0.3716, Loss G: 1.6720\n",
      "Epoch [15/85] Batch 590/938 Loss D: 0.2742, Loss G: 2.6512\n",
      "Epoch [15/85] Batch 600/938 Loss D: 0.2054, Loss G: 2.4403\n",
      "Epoch [15/85] Batch 610/938 Loss D: 0.1761, Loss G: 2.3048\n",
      "Epoch [15/85] Batch 620/938 Loss D: 0.3145, Loss G: 2.5924\n",
      "Epoch [15/85] Batch 630/938 Loss D: 0.2525, Loss G: 2.0999\n",
      "Epoch [15/85] Batch 640/938 Loss D: 0.1861, Loss G: 2.3275\n",
      "Epoch [15/85] Batch 650/938 Loss D: 0.2220, Loss G: 2.4234\n",
      "Epoch [15/85] Batch 660/938 Loss D: 0.2733, Loss G: 2.1598\n",
      "Epoch [15/85] Batch 670/938 Loss D: 0.2321, Loss G: 2.5266\n",
      "Epoch [15/85] Batch 680/938 Loss D: 0.2288, Loss G: 2.0209\n",
      "Epoch [15/85] Batch 690/938 Loss D: 0.2214, Loss G: 2.5433\n",
      "Epoch [15/85] Batch 700/938 Loss D: 0.3099, Loss G: 2.6162\n",
      "Epoch [15/85] Batch 710/938 Loss D: 0.1919, Loss G: 2.8111\n",
      "Epoch [15/85] Batch 720/938 Loss D: 0.2288, Loss G: 1.7817\n",
      "Epoch [15/85] Batch 730/938 Loss D: 0.4200, Loss G: 1.9360\n",
      "Epoch [15/85] Batch 740/938 Loss D: 0.2670, Loss G: 1.8818\n",
      "Epoch [15/85] Batch 750/938 Loss D: 0.1988, Loss G: 2.3553\n",
      "Epoch [15/85] Batch 760/938 Loss D: 0.2068, Loss G: 2.1757\n",
      "Epoch [15/85] Batch 770/938 Loss D: 0.2649, Loss G: 1.9299\n",
      "Epoch [15/85] Batch 780/938 Loss D: 0.2433, Loss G: 2.2359\n",
      "Epoch [15/85] Batch 790/938 Loss D: 0.3154, Loss G: 2.8444\n",
      "Epoch [15/85] Batch 800/938 Loss D: 0.3409, Loss G: 2.3330\n",
      "Epoch [15/85] Batch 810/938 Loss D: 0.2369, Loss G: 2.4649\n",
      "Epoch [15/85] Batch 820/938 Loss D: 0.1678, Loss G: 2.2530\n",
      "Epoch [15/85] Batch 830/938 Loss D: 0.1915, Loss G: 2.1534\n",
      "Epoch [15/85] Batch 840/938 Loss D: 0.2975, Loss G: 2.4729\n",
      "Epoch [15/85] Batch 850/938 Loss D: 0.2491, Loss G: 2.2660\n",
      "Epoch [15/85] Batch 860/938 Loss D: 0.3035, Loss G: 2.5034\n",
      "Epoch [15/85] Batch 870/938 Loss D: 0.2040, Loss G: 2.5334\n",
      "Epoch [15/85] Batch 880/938 Loss D: 0.3054, Loss G: 2.1579\n",
      "Epoch [15/85] Batch 890/938 Loss D: 0.2574, Loss G: 1.8711\n",
      "Epoch [15/85] Batch 900/938 Loss D: 0.2317, Loss G: 2.3726\n",
      "Epoch [15/85] Batch 910/938 Loss D: 0.2011, Loss G: 2.1524\n",
      "Epoch [15/85] Batch 920/938 Loss D: 0.2842, Loss G: 2.0897\n",
      "Epoch [15/85] Batch 930/938 Loss D: 0.2518, Loss G: 2.3308\n",
      "Epoch [16/85] Batch 0/938 Loss D: 0.2264, Loss G: 2.5007\n",
      "Epoch [16/85] Batch 10/938 Loss D: 0.2506, Loss G: 2.6898\n",
      "Epoch [16/85] Batch 20/938 Loss D: 0.1705, Loss G: 2.6831\n",
      "Epoch [16/85] Batch 30/938 Loss D: 0.2395, Loss G: 2.5800\n",
      "Epoch [16/85] Batch 40/938 Loss D: 0.2264, Loss G: 2.9016\n",
      "Epoch [16/85] Batch 50/938 Loss D: 0.1766, Loss G: 2.5149\n",
      "Epoch [16/85] Batch 60/938 Loss D: 0.2420, Loss G: 2.1982\n",
      "Epoch [16/85] Batch 70/938 Loss D: 0.3316, Loss G: 1.6730\n",
      "Epoch [16/85] Batch 80/938 Loss D: 0.2785, Loss G: 1.7539\n",
      "Epoch [16/85] Batch 90/938 Loss D: 0.2919, Loss G: 1.7438\n",
      "Epoch [16/85] Batch 100/938 Loss D: 0.2560, Loss G: 1.7445\n",
      "Epoch [16/85] Batch 110/938 Loss D: 0.2282, Loss G: 2.0493\n",
      "Epoch [16/85] Batch 120/938 Loss D: 0.3588, Loss G: 1.8900\n",
      "Epoch [16/85] Batch 130/938 Loss D: 0.2731, Loss G: 2.3352\n",
      "Epoch [16/85] Batch 140/938 Loss D: 0.3814, Loss G: 1.8931\n",
      "Epoch [16/85] Batch 150/938 Loss D: 0.2725, Loss G: 2.4184\n",
      "Epoch [16/85] Batch 160/938 Loss D: 0.1611, Loss G: 2.8810\n",
      "Epoch [16/85] Batch 170/938 Loss D: 0.2111, Loss G: 2.3774\n",
      "Epoch [16/85] Batch 180/938 Loss D: 0.3210, Loss G: 1.8769\n",
      "Epoch [16/85] Batch 190/938 Loss D: 0.2386, Loss G: 2.0488\n",
      "Epoch [16/85] Batch 200/938 Loss D: 0.2187, Loss G: 1.8388\n",
      "Epoch [16/85] Batch 210/938 Loss D: 0.2933, Loss G: 1.9057\n",
      "Epoch [16/85] Batch 220/938 Loss D: 0.2027, Loss G: 2.4479\n",
      "Epoch [16/85] Batch 230/938 Loss D: 0.3118, Loss G: 1.8394\n",
      "Epoch [16/85] Batch 240/938 Loss D: 0.2197, Loss G: 2.2417\n",
      "Epoch [16/85] Batch 250/938 Loss D: 0.2598, Loss G: 2.0678\n",
      "Epoch [16/85] Batch 260/938 Loss D: 0.2493, Loss G: 2.1371\n",
      "Epoch [16/85] Batch 270/938 Loss D: 0.3029, Loss G: 1.9365\n",
      "Epoch [16/85] Batch 280/938 Loss D: 0.1932, Loss G: 2.6227\n",
      "Epoch [16/85] Batch 290/938 Loss D: 0.2565, Loss G: 2.0926\n",
      "Epoch [16/85] Batch 300/938 Loss D: 0.2414, Loss G: 1.8640\n",
      "Epoch [16/85] Batch 310/938 Loss D: 0.1609, Loss G: 2.7124\n",
      "Epoch [16/85] Batch 320/938 Loss D: 0.3429, Loss G: 2.3864\n",
      "Epoch [16/85] Batch 330/938 Loss D: 0.2696, Loss G: 2.5190\n",
      "Epoch [16/85] Batch 340/938 Loss D: 0.2730, Loss G: 2.1208\n",
      "Epoch [16/85] Batch 350/938 Loss D: 0.2588, Loss G: 2.2176\n",
      "Epoch [16/85] Batch 360/938 Loss D: 0.2542, Loss G: 1.7752\n",
      "Epoch [16/85] Batch 370/938 Loss D: 0.2912, Loss G: 1.9341\n",
      "Epoch [16/85] Batch 380/938 Loss D: 0.2847, Loss G: 2.1725\n",
      "Epoch [16/85] Batch 390/938 Loss D: 0.3029, Loss G: 1.9134\n",
      "Epoch [16/85] Batch 400/938 Loss D: 0.2223, Loss G: 2.2225\n",
      "Epoch [16/85] Batch 410/938 Loss D: 0.2729, Loss G: 2.1875\n",
      "Epoch [16/85] Batch 420/938 Loss D: 0.3281, Loss G: 1.9759\n",
      "Epoch [16/85] Batch 430/938 Loss D: 0.2269, Loss G: 2.8013\n",
      "Epoch [16/85] Batch 440/938 Loss D: 0.1866, Loss G: 2.5204\n",
      "Epoch [16/85] Batch 450/938 Loss D: 0.1801, Loss G: 2.0642\n",
      "Epoch [16/85] Batch 460/938 Loss D: 0.2281, Loss G: 2.1792\n",
      "Epoch [16/85] Batch 470/938 Loss D: 0.2785, Loss G: 2.2754\n",
      "Epoch [16/85] Batch 480/938 Loss D: 0.2161, Loss G: 2.1154\n",
      "Epoch [16/85] Batch 490/938 Loss D: 0.2947, Loss G: 2.6655\n",
      "Epoch [16/85] Batch 500/938 Loss D: 0.3179, Loss G: 2.5016\n",
      "Epoch [16/85] Batch 510/938 Loss D: 0.2813, Loss G: 2.2476\n",
      "Epoch [16/85] Batch 520/938 Loss D: 0.3242, Loss G: 2.2450\n",
      "Epoch [16/85] Batch 530/938 Loss D: 0.3158, Loss G: 1.7211\n",
      "Epoch [16/85] Batch 540/938 Loss D: 0.1913, Loss G: 2.7179\n",
      "Epoch [16/85] Batch 550/938 Loss D: 0.2575, Loss G: 2.4271\n",
      "Epoch [16/85] Batch 560/938 Loss D: 0.2267, Loss G: 2.9529\n",
      "Epoch [16/85] Batch 570/938 Loss D: 0.3117, Loss G: 2.4891\n",
      "Epoch [16/85] Batch 580/938 Loss D: 0.3077, Loss G: 2.0844\n",
      "Epoch [16/85] Batch 590/938 Loss D: 0.2686, Loss G: 2.3415\n",
      "Epoch [16/85] Batch 600/938 Loss D: 0.2243, Loss G: 2.7078\n",
      "Epoch [16/85] Batch 610/938 Loss D: 0.1905, Loss G: 2.6953\n",
      "Epoch [16/85] Batch 620/938 Loss D: 0.2521, Loss G: 2.1566\n",
      "Epoch [16/85] Batch 630/938 Loss D: 0.2853, Loss G: 2.2282\n",
      "Epoch [16/85] Batch 640/938 Loss D: 0.2987, Loss G: 2.2484\n",
      "Epoch [16/85] Batch 650/938 Loss D: 0.2278, Loss G: 3.2678\n",
      "Epoch [16/85] Batch 660/938 Loss D: 0.2436, Loss G: 2.5361\n",
      "Epoch [16/85] Batch 670/938 Loss D: 0.3168, Loss G: 2.2085\n",
      "Epoch [16/85] Batch 680/938 Loss D: 0.2103, Loss G: 1.8483\n",
      "Epoch [16/85] Batch 690/938 Loss D: 0.2987, Loss G: 2.5456\n",
      "Epoch [16/85] Batch 700/938 Loss D: 0.2365, Loss G: 2.1058\n",
      "Epoch [16/85] Batch 710/938 Loss D: 0.1853, Loss G: 2.4853\n",
      "Epoch [16/85] Batch 720/938 Loss D: 0.2619, Loss G: 2.3438\n",
      "Epoch [16/85] Batch 730/938 Loss D: 0.2557, Loss G: 1.8808\n",
      "Epoch [16/85] Batch 740/938 Loss D: 0.2987, Loss G: 1.8538\n",
      "Epoch [16/85] Batch 750/938 Loss D: 0.1979, Loss G: 2.8321\n",
      "Epoch [16/85] Batch 760/938 Loss D: 0.3373, Loss G: 1.8473\n",
      "Epoch [16/85] Batch 770/938 Loss D: 0.2487, Loss G: 2.2680\n",
      "Epoch [16/85] Batch 780/938 Loss D: 0.2814, Loss G: 2.0539\n",
      "Epoch [16/85] Batch 790/938 Loss D: 0.1802, Loss G: 2.5109\n",
      "Epoch [16/85] Batch 800/938 Loss D: 0.3074, Loss G: 2.6756\n",
      "Epoch [16/85] Batch 810/938 Loss D: 0.2043, Loss G: 2.3995\n",
      "Epoch [16/85] Batch 820/938 Loss D: 0.3650, Loss G: 2.0264\n",
      "Epoch [16/85] Batch 830/938 Loss D: 0.2814, Loss G: 2.1467\n",
      "Epoch [16/85] Batch 840/938 Loss D: 0.2302, Loss G: 2.2455\n",
      "Epoch [16/85] Batch 850/938 Loss D: 0.2340, Loss G: 2.3989\n",
      "Epoch [16/85] Batch 860/938 Loss D: 0.3508, Loss G: 2.5571\n",
      "Epoch [16/85] Batch 870/938 Loss D: 0.2151, Loss G: 2.9279\n",
      "Epoch [16/85] Batch 880/938 Loss D: 0.2590, Loss G: 2.2234\n",
      "Epoch [16/85] Batch 890/938 Loss D: 0.1879, Loss G: 2.4905\n",
      "Epoch [16/85] Batch 900/938 Loss D: 0.2877, Loss G: 2.3653\n",
      "Epoch [16/85] Batch 910/938 Loss D: 0.2579, Loss G: 2.0904\n",
      "Epoch [16/85] Batch 920/938 Loss D: 0.2457, Loss G: 2.6607\n",
      "Epoch [16/85] Batch 930/938 Loss D: 0.3007, Loss G: 2.4218\n",
      "Epoch [17/85] Batch 0/938 Loss D: 0.2509, Loss G: 2.1691\n",
      "Epoch [17/85] Batch 10/938 Loss D: 0.2077, Loss G: 2.5948\n",
      "Epoch [17/85] Batch 20/938 Loss D: 0.2182, Loss G: 2.5351\n",
      "Epoch [17/85] Batch 30/938 Loss D: 0.2252, Loss G: 2.0728\n",
      "Epoch [17/85] Batch 40/938 Loss D: 0.2376, Loss G: 2.0318\n",
      "Epoch [17/85] Batch 50/938 Loss D: 0.2545, Loss G: 1.9759\n",
      "Epoch [17/85] Batch 60/938 Loss D: 0.3591, Loss G: 2.0361\n",
      "Epoch [17/85] Batch 70/938 Loss D: 0.2062, Loss G: 2.5754\n",
      "Epoch [17/85] Batch 80/938 Loss D: 0.2469, Loss G: 2.7068\n",
      "Epoch [17/85] Batch 90/938 Loss D: 0.2824, Loss G: 2.7801\n",
      "Epoch [17/85] Batch 100/938 Loss D: 0.2623, Loss G: 2.2578\n",
      "Epoch [17/85] Batch 110/938 Loss D: 0.2068, Loss G: 2.3882\n",
      "Epoch [17/85] Batch 120/938 Loss D: 0.1480, Loss G: 2.6919\n",
      "Epoch [17/85] Batch 130/938 Loss D: 0.2630, Loss G: 2.2987\n",
      "Epoch [17/85] Batch 140/938 Loss D: 0.1950, Loss G: 2.1345\n",
      "Epoch [17/85] Batch 150/938 Loss D: 0.3075, Loss G: 2.3446\n",
      "Epoch [17/85] Batch 160/938 Loss D: 0.2079, Loss G: 3.0752\n",
      "Epoch [17/85] Batch 170/938 Loss D: 0.2176, Loss G: 2.0951\n",
      "Epoch [17/85] Batch 180/938 Loss D: 0.3058, Loss G: 1.9848\n",
      "Epoch [17/85] Batch 190/938 Loss D: 0.1592, Loss G: 2.6907\n",
      "Epoch [17/85] Batch 200/938 Loss D: 0.2768, Loss G: 2.4562\n",
      "Epoch [17/85] Batch 210/938 Loss D: 0.3775, Loss G: 2.3136\n",
      "Epoch [17/85] Batch 220/938 Loss D: 0.2457, Loss G: 2.7271\n",
      "Epoch [17/85] Batch 230/938 Loss D: 0.2074, Loss G: 2.5608\n",
      "Epoch [17/85] Batch 240/938 Loss D: 0.2387, Loss G: 1.9805\n",
      "Epoch [17/85] Batch 250/938 Loss D: 0.2707, Loss G: 1.8505\n",
      "Epoch [17/85] Batch 260/938 Loss D: 0.2091, Loss G: 2.9004\n",
      "Epoch [17/85] Batch 270/938 Loss D: 0.2119, Loss G: 2.7819\n",
      "Epoch [17/85] Batch 280/938 Loss D: 0.3068, Loss G: 2.3927\n",
      "Epoch [17/85] Batch 290/938 Loss D: 0.2220, Loss G: 2.5687\n",
      "Epoch [17/85] Batch 300/938 Loss D: 0.2661, Loss G: 2.2733\n",
      "Epoch [17/85] Batch 310/938 Loss D: 0.3012, Loss G: 1.9131\n",
      "Epoch [17/85] Batch 320/938 Loss D: 0.1122, Loss G: 2.7169\n",
      "Epoch [17/85] Batch 330/938 Loss D: 0.2863, Loss G: 1.9740\n",
      "Epoch [17/85] Batch 340/938 Loss D: 0.2444, Loss G: 2.6454\n",
      "Epoch [17/85] Batch 350/938 Loss D: 0.2177, Loss G: 2.2701\n",
      "Epoch [17/85] Batch 360/938 Loss D: 0.1752, Loss G: 2.6258\n",
      "Epoch [17/85] Batch 370/938 Loss D: 0.2507, Loss G: 2.4813\n",
      "Epoch [17/85] Batch 380/938 Loss D: 0.2642, Loss G: 2.3598\n",
      "Epoch [17/85] Batch 390/938 Loss D: 0.1820, Loss G: 2.7667\n",
      "Epoch [17/85] Batch 400/938 Loss D: 0.2521, Loss G: 2.4827\n",
      "Epoch [17/85] Batch 410/938 Loss D: 0.2055, Loss G: 2.3175\n",
      "Epoch [17/85] Batch 420/938 Loss D: 0.3054, Loss G: 2.5019\n",
      "Epoch [17/85] Batch 430/938 Loss D: 0.2995, Loss G: 1.7447\n",
      "Epoch [17/85] Batch 440/938 Loss D: 0.2125, Loss G: 2.7217\n",
      "Epoch [17/85] Batch 450/938 Loss D: 0.2435, Loss G: 3.0772\n",
      "Epoch [17/85] Batch 460/938 Loss D: 0.2159, Loss G: 2.6070\n",
      "Epoch [17/85] Batch 470/938 Loss D: 0.2734, Loss G: 2.0794\n",
      "Epoch [17/85] Batch 480/938 Loss D: 0.1772, Loss G: 2.4394\n",
      "Epoch [17/85] Batch 490/938 Loss D: 0.2640, Loss G: 1.8213\n",
      "Epoch [17/85] Batch 500/938 Loss D: 0.2645, Loss G: 2.3037\n",
      "Epoch [17/85] Batch 510/938 Loss D: 0.2402, Loss G: 2.4024\n",
      "Epoch [17/85] Batch 520/938 Loss D: 0.3058, Loss G: 2.8380\n",
      "Epoch [17/85] Batch 530/938 Loss D: 0.1984, Loss G: 2.5235\n",
      "Epoch [17/85] Batch 540/938 Loss D: 0.3327, Loss G: 2.2266\n",
      "Epoch [17/85] Batch 550/938 Loss D: 0.2556, Loss G: 2.5347\n",
      "Epoch [17/85] Batch 560/938 Loss D: 0.2892, Loss G: 2.2506\n",
      "Epoch [17/85] Batch 570/938 Loss D: 0.2669, Loss G: 2.4294\n",
      "Epoch [17/85] Batch 580/938 Loss D: 0.2147, Loss G: 2.4400\n",
      "Epoch [17/85] Batch 590/938 Loss D: 0.2046, Loss G: 2.1485\n",
      "Epoch [17/85] Batch 600/938 Loss D: 0.2440, Loss G: 1.9769\n",
      "Epoch [17/85] Batch 610/938 Loss D: 0.1595, Loss G: 2.4804\n",
      "Epoch [17/85] Batch 620/938 Loss D: 0.2043, Loss G: 2.4672\n",
      "Epoch [17/85] Batch 630/938 Loss D: 0.2527, Loss G: 2.7201\n",
      "Epoch [17/85] Batch 640/938 Loss D: 0.3372, Loss G: 2.4301\n",
      "Epoch [17/85] Batch 650/938 Loss D: 0.2401, Loss G: 1.9778\n",
      "Epoch [17/85] Batch 660/938 Loss D: 0.2390, Loss G: 2.4245\n",
      "Epoch [17/85] Batch 670/938 Loss D: 0.2262, Loss G: 2.6339\n",
      "Epoch [17/85] Batch 680/938 Loss D: 0.2853, Loss G: 2.3785\n",
      "Epoch [17/85] Batch 690/938 Loss D: 0.2868, Loss G: 2.5279\n",
      "Epoch [17/85] Batch 700/938 Loss D: 0.1906, Loss G: 2.8573\n",
      "Epoch [17/85] Batch 710/938 Loss D: 0.2673, Loss G: 2.1206\n",
      "Epoch [17/85] Batch 720/938 Loss D: 0.3014, Loss G: 2.5679\n",
      "Epoch [17/85] Batch 730/938 Loss D: 0.3093, Loss G: 1.7665\n",
      "Epoch [17/85] Batch 740/938 Loss D: 0.2205, Loss G: 2.3911\n",
      "Epoch [17/85] Batch 750/938 Loss D: 0.3515, Loss G: 1.7321\n",
      "Epoch [17/85] Batch 760/938 Loss D: 0.2565, Loss G: 2.2174\n",
      "Epoch [17/85] Batch 770/938 Loss D: 0.1655, Loss G: 2.3797\n",
      "Epoch [17/85] Batch 780/938 Loss D: 0.2488, Loss G: 2.2608\n",
      "Epoch [17/85] Batch 790/938 Loss D: 0.2091, Loss G: 2.2415\n",
      "Epoch [17/85] Batch 800/938 Loss D: 0.2459, Loss G: 2.2434\n",
      "Epoch [17/85] Batch 810/938 Loss D: 0.2641, Loss G: 2.2226\n",
      "Epoch [17/85] Batch 820/938 Loss D: 0.3158, Loss G: 2.3119\n",
      "Epoch [17/85] Batch 830/938 Loss D: 0.2066, Loss G: 2.3367\n",
      "Epoch [17/85] Batch 840/938 Loss D: 0.1734, Loss G: 2.5418\n",
      "Epoch [17/85] Batch 850/938 Loss D: 0.3010, Loss G: 2.3537\n",
      "Epoch [17/85] Batch 860/938 Loss D: 0.2580, Loss G: 2.2574\n",
      "Epoch [17/85] Batch 870/938 Loss D: 0.2056, Loss G: 2.7295\n",
      "Epoch [17/85] Batch 880/938 Loss D: 0.2386, Loss G: 2.4671\n",
      "Epoch [17/85] Batch 890/938 Loss D: 0.2374, Loss G: 2.3564\n",
      "Epoch [17/85] Batch 900/938 Loss D: 0.2055, Loss G: 3.0955\n",
      "Epoch [17/85] Batch 910/938 Loss D: 0.1871, Loss G: 2.6195\n",
      "Epoch [17/85] Batch 920/938 Loss D: 0.1627, Loss G: 2.6496\n",
      "Epoch [17/85] Batch 930/938 Loss D: 0.2007, Loss G: 2.4766\n",
      "Epoch [18/85] Batch 0/938 Loss D: 0.2333, Loss G: 2.4021\n",
      "Epoch [18/85] Batch 10/938 Loss D: 0.2443, Loss G: 2.2528\n",
      "Epoch [18/85] Batch 20/938 Loss D: 0.2145, Loss G: 2.4501\n",
      "Epoch [18/85] Batch 30/938 Loss D: 0.2655, Loss G: 2.0487\n",
      "Epoch [18/85] Batch 40/938 Loss D: 0.2821, Loss G: 2.7900\n",
      "Epoch [18/85] Batch 50/938 Loss D: 0.2448, Loss G: 2.7050\n",
      "Epoch [18/85] Batch 60/938 Loss D: 0.2226, Loss G: 2.5369\n",
      "Epoch [18/85] Batch 70/938 Loss D: 0.2474, Loss G: 2.5501\n",
      "Epoch [18/85] Batch 80/938 Loss D: 0.2160, Loss G: 2.0181\n",
      "Epoch [18/85] Batch 90/938 Loss D: 0.2933, Loss G: 2.2588\n",
      "Epoch [18/85] Batch 100/938 Loss D: 0.2235, Loss G: 2.4159\n",
      "Epoch [18/85] Batch 110/938 Loss D: 0.2770, Loss G: 2.1973\n",
      "Epoch [18/85] Batch 120/938 Loss D: 0.2569, Loss G: 1.9824\n",
      "Epoch [18/85] Batch 130/938 Loss D: 0.1880, Loss G: 2.2559\n",
      "Epoch [18/85] Batch 140/938 Loss D: 0.2259, Loss G: 2.4103\n",
      "Epoch [18/85] Batch 150/938 Loss D: 0.2484, Loss G: 2.3374\n",
      "Epoch [18/85] Batch 160/938 Loss D: 0.2520, Loss G: 2.1886\n",
      "Epoch [18/85] Batch 170/938 Loss D: 0.2767, Loss G: 1.8715\n",
      "Epoch [18/85] Batch 180/938 Loss D: 0.2651, Loss G: 2.3454\n",
      "Epoch [18/85] Batch 190/938 Loss D: 0.3136, Loss G: 2.1450\n",
      "Epoch [18/85] Batch 200/938 Loss D: 0.2557, Loss G: 2.1125\n",
      "Epoch [18/85] Batch 210/938 Loss D: 0.2663, Loss G: 2.3909\n",
      "Epoch [18/85] Batch 220/938 Loss D: 0.2032, Loss G: 2.1109\n",
      "Epoch [18/85] Batch 230/938 Loss D: 0.1827, Loss G: 2.9156\n",
      "Epoch [18/85] Batch 240/938 Loss D: 0.1990, Loss G: 2.7369\n",
      "Epoch [18/85] Batch 250/938 Loss D: 0.3186, Loss G: 2.6894\n",
      "Epoch [18/85] Batch 260/938 Loss D: 0.3118, Loss G: 2.3861\n",
      "Epoch [18/85] Batch 270/938 Loss D: 0.2525, Loss G: 2.5802\n",
      "Epoch [18/85] Batch 280/938 Loss D: 0.2247, Loss G: 2.0094\n",
      "Epoch [18/85] Batch 290/938 Loss D: 0.2280, Loss G: 2.0781\n",
      "Epoch [18/85] Batch 300/938 Loss D: 0.2883, Loss G: 2.1688\n",
      "Epoch [18/85] Batch 310/938 Loss D: 0.3050, Loss G: 2.1286\n",
      "Epoch [18/85] Batch 320/938 Loss D: 0.3036, Loss G: 1.8294\n",
      "Epoch [18/85] Batch 330/938 Loss D: 0.1837, Loss G: 2.4926\n",
      "Epoch [18/85] Batch 340/938 Loss D: 0.2592, Loss G: 2.3806\n",
      "Epoch [18/85] Batch 350/938 Loss D: 0.2613, Loss G: 2.0526\n",
      "Epoch [18/85] Batch 360/938 Loss D: 0.3372, Loss G: 1.6515\n",
      "Epoch [18/85] Batch 370/938 Loss D: 0.3213, Loss G: 2.4016\n",
      "Epoch [18/85] Batch 380/938 Loss D: 0.2653, Loss G: 1.9606\n",
      "Epoch [18/85] Batch 390/938 Loss D: 0.2421, Loss G: 1.9965\n",
      "Epoch [18/85] Batch 400/938 Loss D: 0.2532, Loss G: 2.3466\n",
      "Epoch [18/85] Batch 410/938 Loss D: 0.2887, Loss G: 2.1893\n",
      "Epoch [18/85] Batch 420/938 Loss D: 0.2290, Loss G: 2.2947\n",
      "Epoch [18/85] Batch 430/938 Loss D: 0.2005, Loss G: 2.4159\n",
      "Epoch [18/85] Batch 440/938 Loss D: 0.3397, Loss G: 1.9453\n",
      "Epoch [18/85] Batch 450/938 Loss D: 0.2457, Loss G: 2.1550\n",
      "Epoch [18/85] Batch 460/938 Loss D: 0.2104, Loss G: 2.3867\n",
      "Epoch [18/85] Batch 470/938 Loss D: 0.2430, Loss G: 2.3059\n",
      "Epoch [18/85] Batch 480/938 Loss D: 0.3139, Loss G: 1.6369\n",
      "Epoch [18/85] Batch 490/938 Loss D: 0.3008, Loss G: 2.2259\n",
      "Epoch [18/85] Batch 500/938 Loss D: 0.2463, Loss G: 2.5952\n",
      "Epoch [18/85] Batch 510/938 Loss D: 0.2327, Loss G: 2.7656\n",
      "Epoch [18/85] Batch 520/938 Loss D: 0.3362, Loss G: 2.0146\n",
      "Epoch [18/85] Batch 530/938 Loss D: 0.2645, Loss G: 1.9572\n",
      "Epoch [18/85] Batch 540/938 Loss D: 0.4023, Loss G: 1.3215\n",
      "Epoch [18/85] Batch 550/938 Loss D: 0.3545, Loss G: 1.5619\n",
      "Epoch [18/85] Batch 560/938 Loss D: 0.3507, Loss G: 2.1619\n",
      "Epoch [18/85] Batch 570/938 Loss D: 0.1933, Loss G: 3.1486\n",
      "Epoch [18/85] Batch 580/938 Loss D: 0.2596, Loss G: 2.2824\n",
      "Epoch [18/85] Batch 590/938 Loss D: 0.2736, Loss G: 2.2121\n",
      "Epoch [18/85] Batch 600/938 Loss D: 0.3196, Loss G: 1.9195\n",
      "Epoch [18/85] Batch 610/938 Loss D: 0.3051, Loss G: 1.9080\n",
      "Epoch [18/85] Batch 620/938 Loss D: 0.2384, Loss G: 1.7974\n",
      "Epoch [18/85] Batch 630/938 Loss D: 0.1591, Loss G: 2.2654\n",
      "Epoch [18/85] Batch 640/938 Loss D: 0.3123, Loss G: 1.8240\n",
      "Epoch [18/85] Batch 650/938 Loss D: 0.3201, Loss G: 2.1925\n",
      "Epoch [18/85] Batch 660/938 Loss D: 0.2509, Loss G: 2.3607\n",
      "Epoch [18/85] Batch 670/938 Loss D: 0.2712, Loss G: 1.8500\n",
      "Epoch [18/85] Batch 680/938 Loss D: 0.1810, Loss G: 2.4813\n",
      "Epoch [18/85] Batch 690/938 Loss D: 0.2558, Loss G: 2.5628\n",
      "Epoch [18/85] Batch 700/938 Loss D: 0.2301, Loss G: 2.3239\n",
      "Epoch [18/85] Batch 710/938 Loss D: 0.2211, Loss G: 2.3159\n",
      "Epoch [18/85] Batch 720/938 Loss D: 0.1906, Loss G: 2.6718\n",
      "Epoch [18/85] Batch 730/938 Loss D: 0.1811, Loss G: 2.8698\n",
      "Epoch [18/85] Batch 740/938 Loss D: 0.3477, Loss G: 2.7671\n",
      "Epoch [18/85] Batch 750/938 Loss D: 0.2095, Loss G: 2.5303\n",
      "Epoch [18/85] Batch 760/938 Loss D: 0.3145, Loss G: 1.8498\n",
      "Epoch [18/85] Batch 770/938 Loss D: 0.1934, Loss G: 2.4707\n",
      "Epoch [18/85] Batch 780/938 Loss D: 0.2368, Loss G: 2.5870\n",
      "Epoch [18/85] Batch 790/938 Loss D: 0.2984, Loss G: 2.4665\n",
      "Epoch [18/85] Batch 800/938 Loss D: 0.2958, Loss G: 2.5157\n",
      "Epoch [18/85] Batch 810/938 Loss D: 0.2688, Loss G: 2.9755\n",
      "Epoch [18/85] Batch 820/938 Loss D: 0.2106, Loss G: 2.9103\n",
      "Epoch [18/85] Batch 830/938 Loss D: 0.3621, Loss G: 1.6875\n",
      "Epoch [18/85] Batch 840/938 Loss D: 0.2549, Loss G: 2.3063\n",
      "Epoch [18/85] Batch 850/938 Loss D: 0.2429, Loss G: 2.1461\n",
      "Epoch [18/85] Batch 860/938 Loss D: 0.2551, Loss G: 2.0752\n",
      "Epoch [18/85] Batch 870/938 Loss D: 0.2699, Loss G: 1.9884\n",
      "Epoch [18/85] Batch 880/938 Loss D: 0.2645, Loss G: 2.0027\n",
      "Epoch [18/85] Batch 890/938 Loss D: 0.2102, Loss G: 2.4194\n",
      "Epoch [18/85] Batch 900/938 Loss D: 0.2889, Loss G: 2.2044\n",
      "Epoch [18/85] Batch 910/938 Loss D: 0.2548, Loss G: 2.5628\n",
      "Epoch [18/85] Batch 920/938 Loss D: 0.2287, Loss G: 2.8608\n",
      "Epoch [18/85] Batch 930/938 Loss D: 0.1553, Loss G: 2.9323\n",
      "Epoch [19/85] Batch 0/938 Loss D: 0.3197, Loss G: 1.9572\n",
      "Epoch [19/85] Batch 10/938 Loss D: 0.1873, Loss G: 2.2769\n",
      "Epoch [19/85] Batch 20/938 Loss D: 0.1642, Loss G: 2.4743\n",
      "Epoch [19/85] Batch 30/938 Loss D: 0.2506, Loss G: 2.2445\n",
      "Epoch [19/85] Batch 40/938 Loss D: 0.2585, Loss G: 2.5268\n",
      "Epoch [19/85] Batch 50/938 Loss D: 0.2917, Loss G: 1.4536\n",
      "Epoch [19/85] Batch 60/938 Loss D: 0.2743, Loss G: 2.0144\n",
      "Epoch [19/85] Batch 70/938 Loss D: 0.2299, Loss G: 2.6469\n",
      "Epoch [19/85] Batch 80/938 Loss D: 0.3180, Loss G: 2.5428\n",
      "Epoch [19/85] Batch 90/938 Loss D: 0.2152, Loss G: 2.2527\n",
      "Epoch [19/85] Batch 100/938 Loss D: 0.1857, Loss G: 2.5425\n",
      "Epoch [19/85] Batch 110/938 Loss D: 0.2734, Loss G: 2.0249\n",
      "Epoch [19/85] Batch 120/938 Loss D: 0.2877, Loss G: 2.2819\n",
      "Epoch [19/85] Batch 130/938 Loss D: 0.1983, Loss G: 2.9258\n",
      "Epoch [19/85] Batch 140/938 Loss D: 0.2233, Loss G: 2.2696\n",
      "Epoch [19/85] Batch 150/938 Loss D: 0.2624, Loss G: 2.5185\n",
      "Epoch [19/85] Batch 160/938 Loss D: 0.1899, Loss G: 2.8837\n",
      "Epoch [19/85] Batch 170/938 Loss D: 0.1948, Loss G: 2.5952\n",
      "Epoch [19/85] Batch 180/938 Loss D: 0.1570, Loss G: 3.5686\n",
      "Epoch [19/85] Batch 190/938 Loss D: 0.2540, Loss G: 2.8360\n",
      "Epoch [19/85] Batch 200/938 Loss D: 0.3331, Loss G: 2.5361\n",
      "Epoch [19/85] Batch 210/938 Loss D: 0.1779, Loss G: 3.0615\n",
      "Epoch [19/85] Batch 220/938 Loss D: 0.2623, Loss G: 2.1265\n",
      "Epoch [19/85] Batch 230/938 Loss D: 0.2194, Loss G: 2.4943\n",
      "Epoch [19/85] Batch 240/938 Loss D: 0.2460, Loss G: 2.0797\n",
      "Epoch [19/85] Batch 250/938 Loss D: 0.2360, Loss G: 2.6719\n",
      "Epoch [19/85] Batch 260/938 Loss D: 0.2037, Loss G: 2.9122\n",
      "Epoch [19/85] Batch 270/938 Loss D: 0.2272, Loss G: 2.4485\n",
      "Epoch [19/85] Batch 280/938 Loss D: 0.2097, Loss G: 2.3902\n",
      "Epoch [19/85] Batch 290/938 Loss D: 0.2356, Loss G: 2.2554\n",
      "Epoch [19/85] Batch 300/938 Loss D: 0.3762, Loss G: 1.8563\n",
      "Epoch [19/85] Batch 310/938 Loss D: 0.2413, Loss G: 2.0765\n",
      "Epoch [19/85] Batch 320/938 Loss D: 0.2605, Loss G: 2.1246\n",
      "Epoch [19/85] Batch 330/938 Loss D: 0.2514, Loss G: 1.8683\n",
      "Epoch [19/85] Batch 340/938 Loss D: 0.1543, Loss G: 2.1912\n",
      "Epoch [19/85] Batch 350/938 Loss D: 0.2824, Loss G: 1.8461\n",
      "Epoch [19/85] Batch 360/938 Loss D: 0.2032, Loss G: 2.2853\n",
      "Epoch [19/85] Batch 370/938 Loss D: 0.2531, Loss G: 2.2549\n",
      "Epoch [19/85] Batch 380/938 Loss D: 0.2639, Loss G: 1.9572\n",
      "Epoch [19/85] Batch 390/938 Loss D: 0.1932, Loss G: 2.3279\n",
      "Epoch [19/85] Batch 400/938 Loss D: 0.1703, Loss G: 2.4824\n",
      "Epoch [19/85] Batch 410/938 Loss D: 0.1958, Loss G: 2.1632\n",
      "Epoch [19/85] Batch 420/938 Loss D: 0.1726, Loss G: 2.7226\n",
      "Epoch [19/85] Batch 430/938 Loss D: 0.2820, Loss G: 2.6980\n",
      "Epoch [19/85] Batch 440/938 Loss D: 0.1816, Loss G: 2.5876\n",
      "Epoch [19/85] Batch 450/938 Loss D: 0.1964, Loss G: 2.2397\n",
      "Epoch [19/85] Batch 460/938 Loss D: 0.2160, Loss G: 2.3416\n",
      "Epoch [19/85] Batch 470/938 Loss D: 0.2126, Loss G: 2.3732\n",
      "Epoch [19/85] Batch 480/938 Loss D: 0.3147, Loss G: 2.3750\n",
      "Epoch [19/85] Batch 490/938 Loss D: 0.2484, Loss G: 2.3382\n",
      "Epoch [19/85] Batch 500/938 Loss D: 0.2209, Loss G: 2.2777\n",
      "Epoch [19/85] Batch 510/938 Loss D: 0.1860, Loss G: 2.4642\n",
      "Epoch [19/85] Batch 520/938 Loss D: 0.2517, Loss G: 2.0751\n",
      "Epoch [19/85] Batch 530/938 Loss D: 0.2373, Loss G: 1.7975\n",
      "Epoch [19/85] Batch 540/938 Loss D: 0.2921, Loss G: 2.0664\n",
      "Epoch [19/85] Batch 550/938 Loss D: 0.2692, Loss G: 2.0432\n",
      "Epoch [19/85] Batch 560/938 Loss D: 0.2970, Loss G: 1.9033\n",
      "Epoch [19/85] Batch 570/938 Loss D: 0.3205, Loss G: 2.0978\n",
      "Epoch [19/85] Batch 580/938 Loss D: 0.2373, Loss G: 2.7268\n",
      "Epoch [19/85] Batch 590/938 Loss D: 0.3000, Loss G: 2.4381\n",
      "Epoch [19/85] Batch 600/938 Loss D: 0.2033, Loss G: 3.1682\n",
      "Epoch [19/85] Batch 610/938 Loss D: 0.2570, Loss G: 2.7178\n",
      "Epoch [19/85] Batch 620/938 Loss D: 0.2141, Loss G: 2.5106\n",
      "Epoch [19/85] Batch 630/938 Loss D: 0.2521, Loss G: 2.0006\n",
      "Epoch [19/85] Batch 640/938 Loss D: 0.2241, Loss G: 2.2105\n",
      "Epoch [19/85] Batch 650/938 Loss D: 0.2489, Loss G: 1.9024\n",
      "Epoch [19/85] Batch 660/938 Loss D: 0.2004, Loss G: 2.6474\n",
      "Epoch [19/85] Batch 670/938 Loss D: 0.1845, Loss G: 2.5103\n",
      "Epoch [19/85] Batch 680/938 Loss D: 0.3564, Loss G: 1.5589\n",
      "Epoch [19/85] Batch 690/938 Loss D: 0.2946, Loss G: 2.1148\n",
      "Epoch [19/85] Batch 700/938 Loss D: 0.3642, Loss G: 2.0122\n",
      "Epoch [19/85] Batch 710/938 Loss D: 0.1971, Loss G: 2.6968\n",
      "Epoch [19/85] Batch 720/938 Loss D: 0.2588, Loss G: 2.4039\n",
      "Epoch [19/85] Batch 730/938 Loss D: 0.1887, Loss G: 2.9037\n",
      "Epoch [19/85] Batch 740/938 Loss D: 0.2402, Loss G: 2.6609\n",
      "Epoch [19/85] Batch 750/938 Loss D: 0.2232, Loss G: 1.7754\n",
      "Epoch [19/85] Batch 760/938 Loss D: 0.1896, Loss G: 2.2183\n",
      "Epoch [19/85] Batch 770/938 Loss D: 0.3406, Loss G: 1.6560\n",
      "Epoch [19/85] Batch 780/938 Loss D: 0.2437, Loss G: 2.2235\n",
      "Epoch [19/85] Batch 790/938 Loss D: 0.3013, Loss G: 1.6983\n",
      "Epoch [19/85] Batch 800/938 Loss D: 0.2633, Loss G: 1.9968\n",
      "Epoch [19/85] Batch 810/938 Loss D: 0.2593, Loss G: 2.0729\n",
      "Epoch [19/85] Batch 820/938 Loss D: 0.2148, Loss G: 2.6349\n",
      "Epoch [19/85] Batch 830/938 Loss D: 0.2732, Loss G: 1.7427\n",
      "Epoch [19/85] Batch 840/938 Loss D: 0.2400, Loss G: 1.7361\n",
      "Epoch [19/85] Batch 850/938 Loss D: 0.2102, Loss G: 2.4391\n",
      "Epoch [19/85] Batch 860/938 Loss D: 0.2526, Loss G: 1.7685\n",
      "Epoch [19/85] Batch 870/938 Loss D: 0.2134, Loss G: 2.0878\n",
      "Epoch [19/85] Batch 880/938 Loss D: 0.1813, Loss G: 2.4033\n",
      "Epoch [19/85] Batch 890/938 Loss D: 0.1776, Loss G: 2.4763\n",
      "Epoch [19/85] Batch 900/938 Loss D: 0.2238, Loss G: 2.8099\n",
      "Epoch [19/85] Batch 910/938 Loss D: 0.2354, Loss G: 2.5125\n",
      "Epoch [19/85] Batch 920/938 Loss D: 0.2262, Loss G: 2.5882\n",
      "Epoch [19/85] Batch 930/938 Loss D: 0.2991, Loss G: 2.1652\n",
      "Epoch [20/85] Batch 0/938 Loss D: 0.2881, Loss G: 1.8426\n",
      "Epoch [20/85] Batch 10/938 Loss D: 0.2799, Loss G: 2.0176\n",
      "Epoch [20/85] Batch 20/938 Loss D: 0.2620, Loss G: 1.8951\n",
      "Epoch [20/85] Batch 30/938 Loss D: 0.3763, Loss G: 1.8104\n",
      "Epoch [20/85] Batch 40/938 Loss D: 0.2856, Loss G: 1.9631\n",
      "Epoch [20/85] Batch 50/938 Loss D: 0.3121, Loss G: 1.9346\n",
      "Epoch [20/85] Batch 60/938 Loss D: 0.2208, Loss G: 2.4593\n",
      "Epoch [20/85] Batch 70/938 Loss D: 0.2381, Loss G: 2.6474\n",
      "Epoch [20/85] Batch 80/938 Loss D: 0.2939, Loss G: 2.5624\n",
      "Epoch [20/85] Batch 90/938 Loss D: 0.2722, Loss G: 2.2347\n",
      "Epoch [20/85] Batch 100/938 Loss D: 0.2372, Loss G: 2.5326\n",
      "Epoch [20/85] Batch 110/938 Loss D: 0.2393, Loss G: 2.2285\n",
      "Epoch [20/85] Batch 120/938 Loss D: 0.1942, Loss G: 2.2424\n",
      "Epoch [20/85] Batch 130/938 Loss D: 0.1740, Loss G: 2.5394\n",
      "Epoch [20/85] Batch 140/938 Loss D: 0.2583, Loss G: 2.3233\n",
      "Epoch [20/85] Batch 150/938 Loss D: 0.3078, Loss G: 1.5803\n",
      "Epoch [20/85] Batch 160/938 Loss D: 0.2575, Loss G: 2.1411\n",
      "Epoch [20/85] Batch 170/938 Loss D: 0.3379, Loss G: 1.8353\n",
      "Epoch [20/85] Batch 180/938 Loss D: 0.1559, Loss G: 2.8820\n",
      "Epoch [20/85] Batch 190/938 Loss D: 0.2516, Loss G: 2.2327\n",
      "Epoch [20/85] Batch 200/938 Loss D: 0.2746, Loss G: 1.7363\n",
      "Epoch [20/85] Batch 210/938 Loss D: 0.3124, Loss G: 2.1072\n",
      "Epoch [20/85] Batch 220/938 Loss D: 0.3095, Loss G: 1.9398\n",
      "Epoch [20/85] Batch 230/938 Loss D: 0.2834, Loss G: 2.2167\n",
      "Epoch [20/85] Batch 240/938 Loss D: 0.1654, Loss G: 2.5566\n",
      "Epoch [20/85] Batch 250/938 Loss D: 0.2885, Loss G: 2.2969\n",
      "Epoch [20/85] Batch 260/938 Loss D: 0.1706, Loss G: 2.8703\n",
      "Epoch [20/85] Batch 270/938 Loss D: 0.2718, Loss G: 2.0326\n",
      "Epoch [20/85] Batch 280/938 Loss D: 0.3033, Loss G: 2.2681\n",
      "Epoch [20/85] Batch 290/938 Loss D: 0.2831, Loss G: 2.2754\n",
      "Epoch [20/85] Batch 300/938 Loss D: 0.2550, Loss G: 2.2747\n",
      "Epoch [20/85] Batch 310/938 Loss D: 0.1902, Loss G: 3.1808\n",
      "Epoch [20/85] Batch 320/938 Loss D: 0.3295, Loss G: 2.1818\n",
      "Epoch [20/85] Batch 330/938 Loss D: 0.2510, Loss G: 2.3538\n",
      "Epoch [20/85] Batch 340/938 Loss D: 0.3158, Loss G: 1.9752\n",
      "Epoch [20/85] Batch 350/938 Loss D: 0.3220, Loss G: 1.8011\n",
      "Epoch [20/85] Batch 360/938 Loss D: 0.2731, Loss G: 2.9777\n",
      "Epoch [20/85] Batch 370/938 Loss D: 0.3126, Loss G: 2.5028\n",
      "Epoch [20/85] Batch 380/938 Loss D: 0.2435, Loss G: 2.1806\n",
      "Epoch [20/85] Batch 390/938 Loss D: 0.2896, Loss G: 1.9731\n",
      "Epoch [20/85] Batch 400/938 Loss D: 0.2773, Loss G: 2.3129\n",
      "Epoch [20/85] Batch 410/938 Loss D: 0.2015, Loss G: 2.6930\n",
      "Epoch [20/85] Batch 420/938 Loss D: 0.2287, Loss G: 2.2068\n",
      "Epoch [20/85] Batch 430/938 Loss D: 0.1638, Loss G: 2.3571\n",
      "Epoch [20/85] Batch 440/938 Loss D: 0.2408, Loss G: 2.4362\n",
      "Epoch [20/85] Batch 450/938 Loss D: 0.2209, Loss G: 2.1202\n",
      "Epoch [20/85] Batch 460/938 Loss D: 0.2349, Loss G: 1.9401\n",
      "Epoch [20/85] Batch 470/938 Loss D: 0.3222, Loss G: 1.6575\n",
      "Epoch [20/85] Batch 480/938 Loss D: 0.2165, Loss G: 2.2681\n",
      "Epoch [20/85] Batch 490/938 Loss D: 0.1901, Loss G: 2.4111\n",
      "Epoch [20/85] Batch 500/938 Loss D: 0.2428, Loss G: 2.5569\n",
      "Epoch [20/85] Batch 510/938 Loss D: 0.1874, Loss G: 2.7780\n",
      "Epoch [20/85] Batch 520/938 Loss D: 0.1844, Loss G: 2.3473\n",
      "Epoch [20/85] Batch 530/938 Loss D: 0.2438, Loss G: 2.4071\n",
      "Epoch [20/85] Batch 540/938 Loss D: 0.2471, Loss G: 2.2258\n",
      "Epoch [20/85] Batch 550/938 Loss D: 0.3788, Loss G: 2.0790\n",
      "Epoch [20/85] Batch 560/938 Loss D: 0.2194, Loss G: 2.5203\n",
      "Epoch [20/85] Batch 570/938 Loss D: 0.2257, Loss G: 2.6617\n",
      "Epoch [20/85] Batch 580/938 Loss D: 0.3411, Loss G: 2.3103\n",
      "Epoch [20/85] Batch 590/938 Loss D: 0.2435, Loss G: 2.3122\n",
      "Epoch [20/85] Batch 600/938 Loss D: 0.3018, Loss G: 1.8613\n",
      "Epoch [20/85] Batch 610/938 Loss D: 0.2452, Loss G: 2.1987\n",
      "Epoch [20/85] Batch 620/938 Loss D: 0.2700, Loss G: 1.7486\n",
      "Epoch [20/85] Batch 630/938 Loss D: 0.2112, Loss G: 2.2680\n",
      "Epoch [20/85] Batch 640/938 Loss D: 0.2685, Loss G: 2.6960\n",
      "Epoch [20/85] Batch 650/938 Loss D: 0.3969, Loss G: 2.7607\n",
      "Epoch [20/85] Batch 660/938 Loss D: 0.1808, Loss G: 2.5388\n",
      "Epoch [20/85] Batch 670/938 Loss D: 0.1687, Loss G: 2.6688\n",
      "Epoch [20/85] Batch 680/938 Loss D: 0.3415, Loss G: 2.1901\n",
      "Epoch [20/85] Batch 690/938 Loss D: 0.2085, Loss G: 2.9717\n",
      "Epoch [20/85] Batch 700/938 Loss D: 0.3151, Loss G: 2.3451\n",
      "Epoch [20/85] Batch 710/938 Loss D: 0.2793, Loss G: 2.0118\n",
      "Epoch [20/85] Batch 720/938 Loss D: 0.2937, Loss G: 1.9063\n",
      "Epoch [20/85] Batch 730/938 Loss D: 0.1428, Loss G: 3.0110\n",
      "Epoch [20/85] Batch 740/938 Loss D: 0.2168, Loss G: 2.3939\n",
      "Epoch [20/85] Batch 750/938 Loss D: 0.2068, Loss G: 2.7658\n",
      "Epoch [20/85] Batch 760/938 Loss D: 0.2410, Loss G: 2.8996\n",
      "Epoch [20/85] Batch 770/938 Loss D: 0.1938, Loss G: 2.4526\n",
      "Epoch [20/85] Batch 780/938 Loss D: 0.1610, Loss G: 2.2091\n",
      "Epoch [20/85] Batch 790/938 Loss D: 0.2761, Loss G: 1.9740\n",
      "Epoch [20/85] Batch 800/938 Loss D: 0.2328, Loss G: 2.2275\n",
      "Epoch [20/85] Batch 810/938 Loss D: 0.3518, Loss G: 2.0335\n",
      "Epoch [20/85] Batch 820/938 Loss D: 0.2512, Loss G: 1.9749\n",
      "Epoch [20/85] Batch 830/938 Loss D: 0.2017, Loss G: 2.6787\n",
      "Epoch [20/85] Batch 840/938 Loss D: 0.2518, Loss G: 2.2956\n",
      "Epoch [20/85] Batch 850/938 Loss D: 0.2080, Loss G: 2.2034\n",
      "Epoch [20/85] Batch 860/938 Loss D: 0.2374, Loss G: 2.2365\n",
      "Epoch [20/85] Batch 870/938 Loss D: 0.2565, Loss G: 2.3824\n",
      "Epoch [20/85] Batch 880/938 Loss D: 0.2540, Loss G: 2.4099\n",
      "Epoch [20/85] Batch 890/938 Loss D: 0.2624, Loss G: 2.8626\n",
      "Epoch [20/85] Batch 900/938 Loss D: 0.2110, Loss G: 2.1388\n",
      "Epoch [20/85] Batch 910/938 Loss D: 0.1503, Loss G: 2.3935\n",
      "Epoch [20/85] Batch 920/938 Loss D: 0.2278, Loss G: 2.3837\n",
      "Epoch [20/85] Batch 930/938 Loss D: 0.3032, Loss G: 2.5866\n",
      "Epoch [21/85] Batch 0/938 Loss D: 0.3279, Loss G: 1.7019\n",
      "Epoch [21/85] Batch 10/938 Loss D: 0.2366, Loss G: 2.2538\n",
      "Epoch [21/85] Batch 20/938 Loss D: 0.2500, Loss G: 2.4589\n",
      "Epoch [21/85] Batch 30/938 Loss D: 0.2227, Loss G: 2.2683\n",
      "Epoch [21/85] Batch 40/938 Loss D: 0.2205, Loss G: 2.8040\n",
      "Epoch [21/85] Batch 50/938 Loss D: 0.2164, Loss G: 2.5422\n",
      "Epoch [21/85] Batch 60/938 Loss D: 0.1860, Loss G: 2.8398\n",
      "Epoch [21/85] Batch 70/938 Loss D: 0.2143, Loss G: 2.6131\n",
      "Epoch [21/85] Batch 80/938 Loss D: 0.3317, Loss G: 2.6322\n",
      "Epoch [21/85] Batch 90/938 Loss D: 0.1844, Loss G: 2.9190\n",
      "Epoch [21/85] Batch 100/938 Loss D: 0.3314, Loss G: 2.1991\n",
      "Epoch [21/85] Batch 110/938 Loss D: 0.3031, Loss G: 2.1061\n",
      "Epoch [21/85] Batch 120/938 Loss D: 0.2391, Loss G: 2.6842\n",
      "Epoch [21/85] Batch 130/938 Loss D: 0.3606, Loss G: 2.4296\n",
      "Epoch [21/85] Batch 140/938 Loss D: 0.2086, Loss G: 3.1586\n",
      "Epoch [21/85] Batch 150/938 Loss D: 0.2383, Loss G: 2.6606\n",
      "Epoch [21/85] Batch 160/938 Loss D: 0.1931, Loss G: 2.4440\n",
      "Epoch [21/85] Batch 170/938 Loss D: 0.3460, Loss G: 1.9271\n",
      "Epoch [21/85] Batch 180/938 Loss D: 0.2521, Loss G: 1.7673\n",
      "Epoch [21/85] Batch 190/938 Loss D: 0.2801, Loss G: 1.8777\n",
      "Epoch [21/85] Batch 200/938 Loss D: 0.2515, Loss G: 2.3418\n",
      "Epoch [21/85] Batch 210/938 Loss D: 0.2652, Loss G: 2.4466\n",
      "Epoch [21/85] Batch 220/938 Loss D: 0.1718, Loss G: 2.7684\n",
      "Epoch [21/85] Batch 230/938 Loss D: 0.1969, Loss G: 2.2738\n",
      "Epoch [21/85] Batch 240/938 Loss D: 0.2677, Loss G: 2.0550\n",
      "Epoch [21/85] Batch 250/938 Loss D: 0.1961, Loss G: 2.3992\n",
      "Epoch [21/85] Batch 260/938 Loss D: 0.3100, Loss G: 2.1421\n",
      "Epoch [21/85] Batch 270/938 Loss D: 0.2947, Loss G: 2.4127\n",
      "Epoch [21/85] Batch 280/938 Loss D: 0.2181, Loss G: 2.5142\n",
      "Epoch [21/85] Batch 290/938 Loss D: 0.4595, Loss G: 1.9780\n",
      "Epoch [21/85] Batch 300/938 Loss D: 0.3241, Loss G: 2.0242\n",
      "Epoch [21/85] Batch 310/938 Loss D: 0.2596, Loss G: 2.6631\n",
      "Epoch [21/85] Batch 320/938 Loss D: 0.2547, Loss G: 2.5381\n",
      "Epoch [21/85] Batch 330/938 Loss D: 0.2472, Loss G: 2.8403\n",
      "Epoch [21/85] Batch 340/938 Loss D: 0.2332, Loss G: 1.7123\n",
      "Epoch [21/85] Batch 350/938 Loss D: 0.3209, Loss G: 2.1059\n",
      "Epoch [21/85] Batch 360/938 Loss D: 0.2090, Loss G: 2.8104\n",
      "Epoch [21/85] Batch 370/938 Loss D: 0.2348, Loss G: 2.5366\n",
      "Epoch [21/85] Batch 380/938 Loss D: 0.1962, Loss G: 2.2148\n",
      "Epoch [21/85] Batch 390/938 Loss D: 0.2545, Loss G: 2.1695\n",
      "Epoch [21/85] Batch 400/938 Loss D: 0.3093, Loss G: 1.9749\n",
      "Epoch [21/85] Batch 410/938 Loss D: 0.2744, Loss G: 2.0666\n",
      "Epoch [21/85] Batch 420/938 Loss D: 0.2439, Loss G: 2.1924\n",
      "Epoch [21/85] Batch 430/938 Loss D: 0.3048, Loss G: 2.3663\n",
      "Epoch [21/85] Batch 440/938 Loss D: 0.3513, Loss G: 2.1621\n",
      "Epoch [21/85] Batch 450/938 Loss D: 0.2560, Loss G: 2.5581\n",
      "Epoch [21/85] Batch 460/938 Loss D: 0.1885, Loss G: 2.8409\n",
      "Epoch [21/85] Batch 470/938 Loss D: 0.2972, Loss G: 2.4637\n",
      "Epoch [21/85] Batch 480/938 Loss D: 0.2753, Loss G: 2.5138\n",
      "Epoch [21/85] Batch 490/938 Loss D: 0.2949, Loss G: 2.0593\n",
      "Epoch [21/85] Batch 500/938 Loss D: 0.2274, Loss G: 2.3020\n",
      "Epoch [21/85] Batch 510/938 Loss D: 0.2868, Loss G: 1.9924\n",
      "Epoch [21/85] Batch 520/938 Loss D: 0.2511, Loss G: 2.7413\n",
      "Epoch [21/85] Batch 530/938 Loss D: 0.2949, Loss G: 1.8092\n",
      "Epoch [21/85] Batch 540/938 Loss D: 0.2344, Loss G: 2.3112\n",
      "Epoch [21/85] Batch 550/938 Loss D: 0.2383, Loss G: 2.3224\n",
      "Epoch [21/85] Batch 560/938 Loss D: 0.3375, Loss G: 2.6496\n",
      "Epoch [21/85] Batch 570/938 Loss D: 0.2923, Loss G: 2.9847\n",
      "Epoch [21/85] Batch 580/938 Loss D: 0.2660, Loss G: 2.3769\n",
      "Epoch [21/85] Batch 590/938 Loss D: 0.2905, Loss G: 2.2947\n",
      "Epoch [21/85] Batch 600/938 Loss D: 0.3558, Loss G: 2.0231\n",
      "Epoch [21/85] Batch 610/938 Loss D: 0.2784, Loss G: 1.8884\n",
      "Epoch [21/85] Batch 620/938 Loss D: 0.2209, Loss G: 2.3934\n",
      "Epoch [21/85] Batch 630/938 Loss D: 0.1478, Loss G: 2.6661\n",
      "Epoch [21/85] Batch 640/938 Loss D: 0.2927, Loss G: 2.4015\n",
      "Epoch [21/85] Batch 650/938 Loss D: 0.2775, Loss G: 2.5080\n",
      "Epoch [21/85] Batch 660/938 Loss D: 0.2616, Loss G: 2.0911\n",
      "Epoch [21/85] Batch 670/938 Loss D: 0.2695, Loss G: 1.8527\n",
      "Epoch [21/85] Batch 680/938 Loss D: 0.3461, Loss G: 2.1218\n",
      "Epoch [21/85] Batch 690/938 Loss D: 0.2465, Loss G: 1.9639\n",
      "Epoch [21/85] Batch 700/938 Loss D: 0.2035, Loss G: 2.2264\n",
      "Epoch [21/85] Batch 710/938 Loss D: 0.3544, Loss G: 1.8690\n",
      "Epoch [21/85] Batch 720/938 Loss D: 0.2540, Loss G: 2.4934\n",
      "Epoch [21/85] Batch 730/938 Loss D: 0.1952, Loss G: 2.4921\n",
      "Epoch [21/85] Batch 740/938 Loss D: 0.2515, Loss G: 1.9356\n",
      "Epoch [21/85] Batch 750/938 Loss D: 0.2565, Loss G: 1.9422\n",
      "Epoch [21/85] Batch 760/938 Loss D: 0.3185, Loss G: 2.1540\n",
      "Epoch [21/85] Batch 770/938 Loss D: 0.1898, Loss G: 2.4352\n",
      "Epoch [21/85] Batch 780/938 Loss D: 0.2467, Loss G: 2.2245\n",
      "Epoch [21/85] Batch 790/938 Loss D: 0.2218, Loss G: 2.2076\n",
      "Epoch [21/85] Batch 800/938 Loss D: 0.2431, Loss G: 2.4384\n",
      "Epoch [21/85] Batch 810/938 Loss D: 0.2618, Loss G: 2.4225\n",
      "Epoch [21/85] Batch 820/938 Loss D: 0.3056, Loss G: 1.6561\n",
      "Epoch [21/85] Batch 830/938 Loss D: 0.1690, Loss G: 2.4781\n",
      "Epoch [21/85] Batch 840/938 Loss D: 0.2059, Loss G: 2.3805\n",
      "Epoch [21/85] Batch 850/938 Loss D: 0.3222, Loss G: 1.9439\n",
      "Epoch [21/85] Batch 860/938 Loss D: 0.3527, Loss G: 2.1859\n",
      "Epoch [21/85] Batch 870/938 Loss D: 0.2451, Loss G: 2.2457\n",
      "Epoch [21/85] Batch 880/938 Loss D: 0.2974, Loss G: 1.9746\n",
      "Epoch [21/85] Batch 890/938 Loss D: 0.2290, Loss G: 2.0892\n",
      "Epoch [21/85] Batch 900/938 Loss D: 0.1998, Loss G: 2.2447\n",
      "Epoch [21/85] Batch 910/938 Loss D: 0.2149, Loss G: 2.2097\n",
      "Epoch [21/85] Batch 920/938 Loss D: 0.3765, Loss G: 1.7040\n",
      "Epoch [21/85] Batch 930/938 Loss D: 0.2500, Loss G: 2.1115\n",
      "Epoch [22/85] Batch 0/938 Loss D: 0.2518, Loss G: 1.8176\n",
      "Epoch [22/85] Batch 10/938 Loss D: 0.2359, Loss G: 2.0122\n",
      "Epoch [22/85] Batch 20/938 Loss D: 0.3188, Loss G: 2.0730\n",
      "Epoch [22/85] Batch 30/938 Loss D: 0.2189, Loss G: 2.7833\n",
      "Epoch [22/85] Batch 40/938 Loss D: 0.2338, Loss G: 2.4700\n",
      "Epoch [22/85] Batch 50/938 Loss D: 0.2169, Loss G: 2.7633\n",
      "Epoch [22/85] Batch 60/938 Loss D: 0.2474, Loss G: 2.8359\n",
      "Epoch [22/85] Batch 70/938 Loss D: 0.2235, Loss G: 2.2552\n",
      "Epoch [22/85] Batch 80/938 Loss D: 0.2668, Loss G: 2.0177\n",
      "Epoch [22/85] Batch 90/938 Loss D: 0.2887, Loss G: 1.9847\n",
      "Epoch [22/85] Batch 100/938 Loss D: 0.4124, Loss G: 1.7009\n",
      "Epoch [22/85] Batch 110/938 Loss D: 0.3246, Loss G: 2.7534\n",
      "Epoch [22/85] Batch 120/938 Loss D: 0.3680, Loss G: 1.9732\n",
      "Epoch [22/85] Batch 130/938 Loss D: 0.2693, Loss G: 2.0474\n",
      "Epoch [22/85] Batch 140/938 Loss D: 0.2363, Loss G: 2.5967\n",
      "Epoch [22/85] Batch 150/938 Loss D: 0.2296, Loss G: 3.0435\n",
      "Epoch [22/85] Batch 160/938 Loss D: 0.2081, Loss G: 2.8243\n",
      "Epoch [22/85] Batch 170/938 Loss D: 0.2427, Loss G: 2.4062\n",
      "Epoch [22/85] Batch 180/938 Loss D: 0.2810, Loss G: 2.1701\n",
      "Epoch [22/85] Batch 190/938 Loss D: 0.3100, Loss G: 2.5039\n",
      "Epoch [22/85] Batch 200/938 Loss D: 0.2103, Loss G: 2.1178\n",
      "Epoch [22/85] Batch 210/938 Loss D: 0.3167, Loss G: 2.0809\n",
      "Epoch [22/85] Batch 220/938 Loss D: 0.2404, Loss G: 2.4109\n",
      "Epoch [22/85] Batch 230/938 Loss D: 0.2473, Loss G: 2.9058\n",
      "Epoch [22/85] Batch 240/938 Loss D: 0.3430, Loss G: 2.2025\n",
      "Epoch [22/85] Batch 250/938 Loss D: 0.3836, Loss G: 2.9266\n",
      "Epoch [22/85] Batch 260/938 Loss D: 0.2746, Loss G: 2.8839\n",
      "Epoch [22/85] Batch 270/938 Loss D: 0.1999, Loss G: 2.6129\n",
      "Epoch [22/85] Batch 280/938 Loss D: 0.3220, Loss G: 1.8889\n",
      "Epoch [22/85] Batch 290/938 Loss D: 0.1975, Loss G: 2.6782\n",
      "Epoch [22/85] Batch 300/938 Loss D: 0.2871, Loss G: 1.9602\n",
      "Epoch [22/85] Batch 310/938 Loss D: 0.2911, Loss G: 1.8749\n",
      "Epoch [22/85] Batch 320/938 Loss D: 0.2807, Loss G: 2.1239\n",
      "Epoch [22/85] Batch 330/938 Loss D: 0.2540, Loss G: 2.2616\n",
      "Epoch [22/85] Batch 340/938 Loss D: 0.3235, Loss G: 2.0926\n",
      "Epoch [22/85] Batch 350/938 Loss D: 0.3201, Loss G: 2.5342\n",
      "Epoch [22/85] Batch 360/938 Loss D: 0.2327, Loss G: 3.3982\n",
      "Epoch [22/85] Batch 370/938 Loss D: 0.2649, Loss G: 2.7570\n",
      "Epoch [22/85] Batch 380/938 Loss D: 0.2282, Loss G: 2.8585\n",
      "Epoch [22/85] Batch 390/938 Loss D: 0.2439, Loss G: 2.1651\n",
      "Epoch [22/85] Batch 400/938 Loss D: 0.2074, Loss G: 2.3998\n",
      "Epoch [22/85] Batch 410/938 Loss D: 0.2650, Loss G: 3.0177\n",
      "Epoch [22/85] Batch 420/938 Loss D: 0.3446, Loss G: 2.2102\n",
      "Epoch [22/85] Batch 430/938 Loss D: 0.2509, Loss G: 2.4723\n",
      "Epoch [22/85] Batch 440/938 Loss D: 0.2259, Loss G: 2.1551\n",
      "Epoch [22/85] Batch 450/938 Loss D: 0.2251, Loss G: 2.2011\n",
      "Epoch [22/85] Batch 460/938 Loss D: 0.2579, Loss G: 1.9142\n",
      "Epoch [22/85] Batch 470/938 Loss D: 0.2092, Loss G: 2.5838\n",
      "Epoch [22/85] Batch 480/938 Loss D: 0.3340, Loss G: 1.7626\n",
      "Epoch [22/85] Batch 490/938 Loss D: 0.2190, Loss G: 3.1802\n",
      "Epoch [22/85] Batch 500/938 Loss D: 0.2368, Loss G: 2.5666\n",
      "Epoch [22/85] Batch 510/938 Loss D: 0.2419, Loss G: 2.1164\n",
      "Epoch [22/85] Batch 520/938 Loss D: 0.3021, Loss G: 1.8383\n",
      "Epoch [22/85] Batch 530/938 Loss D: 0.3039, Loss G: 2.0670\n",
      "Epoch [22/85] Batch 540/938 Loss D: 0.2759, Loss G: 1.9899\n",
      "Epoch [22/85] Batch 550/938 Loss D: 0.2158, Loss G: 2.6607\n",
      "Epoch [22/85] Batch 560/938 Loss D: 0.1789, Loss G: 2.3678\n",
      "Epoch [22/85] Batch 570/938 Loss D: 0.2645, Loss G: 2.3595\n",
      "Epoch [22/85] Batch 580/938 Loss D: 0.3009, Loss G: 2.7213\n",
      "Epoch [22/85] Batch 590/938 Loss D: 0.3130, Loss G: 2.3634\n",
      "Epoch [22/85] Batch 600/938 Loss D: 0.1762, Loss G: 2.5814\n",
      "Epoch [22/85] Batch 610/938 Loss D: 0.2859, Loss G: 2.0275\n",
      "Epoch [22/85] Batch 620/938 Loss D: 0.2858, Loss G: 2.6366\n",
      "Epoch [22/85] Batch 630/938 Loss D: 0.3361, Loss G: 1.9665\n",
      "Epoch [22/85] Batch 640/938 Loss D: 0.2558, Loss G: 2.1524\n",
      "Epoch [22/85] Batch 650/938 Loss D: 0.3096, Loss G: 1.9818\n",
      "Epoch [22/85] Batch 660/938 Loss D: 0.2715, Loss G: 2.7209\n",
      "Epoch [22/85] Batch 670/938 Loss D: 0.2576, Loss G: 2.6750\n",
      "Epoch [22/85] Batch 680/938 Loss D: 0.2729, Loss G: 2.0858\n",
      "Epoch [22/85] Batch 690/938 Loss D: 0.2343, Loss G: 2.3389\n",
      "Epoch [22/85] Batch 700/938 Loss D: 0.3075, Loss G: 2.4138\n",
      "Epoch [22/85] Batch 710/938 Loss D: 0.2284, Loss G: 2.7681\n",
      "Epoch [22/85] Batch 720/938 Loss D: 0.1956, Loss G: 2.6150\n",
      "Epoch [22/85] Batch 730/938 Loss D: 0.3403, Loss G: 1.9996\n",
      "Epoch [22/85] Batch 740/938 Loss D: 0.2327, Loss G: 2.2576\n",
      "Epoch [22/85] Batch 750/938 Loss D: 0.3227, Loss G: 2.1363\n",
      "Epoch [22/85] Batch 760/938 Loss D: 0.4411, Loss G: 1.6170\n",
      "Epoch [22/85] Batch 770/938 Loss D: 0.2740, Loss G: 2.1379\n",
      "Epoch [22/85] Batch 780/938 Loss D: 0.2875, Loss G: 2.3475\n",
      "Epoch [22/85] Batch 790/938 Loss D: 0.1603, Loss G: 2.9339\n",
      "Epoch [22/85] Batch 800/938 Loss D: 0.2370, Loss G: 2.7364\n",
      "Epoch [22/85] Batch 810/938 Loss D: 0.1951, Loss G: 3.1376\n",
      "Epoch [22/85] Batch 820/938 Loss D: 0.2177, Loss G: 3.2688\n",
      "Epoch [22/85] Batch 830/938 Loss D: 0.1780, Loss G: 2.4237\n",
      "Epoch [22/85] Batch 840/938 Loss D: 0.3545, Loss G: 2.0639\n",
      "Epoch [22/85] Batch 850/938 Loss D: 0.4137, Loss G: 2.0290\n",
      "Epoch [22/85] Batch 860/938 Loss D: 0.2586, Loss G: 2.2873\n",
      "Epoch [22/85] Batch 870/938 Loss D: 0.2293, Loss G: 2.5036\n",
      "Epoch [22/85] Batch 880/938 Loss D: 0.2854, Loss G: 2.3566\n",
      "Epoch [22/85] Batch 890/938 Loss D: 0.2067, Loss G: 2.8476\n",
      "Epoch [22/85] Batch 900/938 Loss D: 0.2967, Loss G: 3.1141\n",
      "Epoch [22/85] Batch 910/938 Loss D: 0.1861, Loss G: 2.5485\n",
      "Epoch [22/85] Batch 920/938 Loss D: 0.2845, Loss G: 2.0365\n",
      "Epoch [22/85] Batch 930/938 Loss D: 0.3275, Loss G: 2.0113\n",
      "Epoch [23/85] Batch 0/938 Loss D: 0.2768, Loss G: 2.1176\n",
      "Epoch [23/85] Batch 10/938 Loss D: 0.1998, Loss G: 2.2116\n",
      "Epoch [23/85] Batch 20/938 Loss D: 0.3049, Loss G: 1.9834\n",
      "Epoch [23/85] Batch 30/938 Loss D: 0.2215, Loss G: 2.0937\n",
      "Epoch [23/85] Batch 40/938 Loss D: 0.2450, Loss G: 2.6882\n",
      "Epoch [23/85] Batch 50/938 Loss D: 0.2719, Loss G: 2.4624\n",
      "Epoch [23/85] Batch 60/938 Loss D: 0.2380, Loss G: 2.5405\n",
      "Epoch [23/85] Batch 70/938 Loss D: 0.2121, Loss G: 2.2138\n",
      "Epoch [23/85] Batch 80/938 Loss D: 0.3797, Loss G: 2.1478\n",
      "Epoch [23/85] Batch 90/938 Loss D: 0.2538, Loss G: 2.6845\n",
      "Epoch [23/85] Batch 100/938 Loss D: 0.3303, Loss G: 2.2002\n",
      "Epoch [23/85] Batch 110/938 Loss D: 0.2731, Loss G: 2.2956\n",
      "Epoch [23/85] Batch 120/938 Loss D: 0.4103, Loss G: 2.1813\n",
      "Epoch [23/85] Batch 130/938 Loss D: 0.2706, Loss G: 2.3432\n",
      "Epoch [23/85] Batch 140/938 Loss D: 0.2443, Loss G: 2.4606\n",
      "Epoch [23/85] Batch 150/938 Loss D: 0.2431, Loss G: 2.6823\n",
      "Epoch [23/85] Batch 160/938 Loss D: 0.3084, Loss G: 2.2010\n",
      "Epoch [23/85] Batch 170/938 Loss D: 0.2781, Loss G: 2.8398\n",
      "Epoch [23/85] Batch 180/938 Loss D: 0.3215, Loss G: 2.9001\n",
      "Epoch [23/85] Batch 190/938 Loss D: 0.2511, Loss G: 2.5821\n",
      "Epoch [23/85] Batch 200/938 Loss D: 0.2810, Loss G: 1.8814\n",
      "Epoch [23/85] Batch 210/938 Loss D: 0.2306, Loss G: 2.7402\n",
      "Epoch [23/85] Batch 220/938 Loss D: 0.2152, Loss G: 2.5871\n",
      "Epoch [23/85] Batch 230/938 Loss D: 0.2280, Loss G: 2.7876\n",
      "Epoch [23/85] Batch 240/938 Loss D: 0.3031, Loss G: 2.0288\n",
      "Epoch [23/85] Batch 250/938 Loss D: 0.2685, Loss G: 2.1485\n",
      "Epoch [23/85] Batch 260/938 Loss D: 0.3389, Loss G: 2.4867\n",
      "Epoch [23/85] Batch 270/938 Loss D: 0.1867, Loss G: 2.4183\n",
      "Epoch [23/85] Batch 280/938 Loss D: 0.3023, Loss G: 1.7616\n",
      "Epoch [23/85] Batch 290/938 Loss D: 0.2622, Loss G: 1.9686\n",
      "Epoch [23/85] Batch 300/938 Loss D: 0.2118, Loss G: 2.4590\n",
      "Epoch [23/85] Batch 310/938 Loss D: 0.2087, Loss G: 2.6376\n",
      "Epoch [23/85] Batch 320/938 Loss D: 0.3559, Loss G: 2.2164\n",
      "Epoch [23/85] Batch 330/938 Loss D: 0.1693, Loss G: 2.8520\n",
      "Epoch [23/85] Batch 340/938 Loss D: 0.3829, Loss G: 2.5373\n",
      "Epoch [23/85] Batch 350/938 Loss D: 0.2065, Loss G: 2.3167\n",
      "Epoch [23/85] Batch 360/938 Loss D: 0.2626, Loss G: 2.4283\n",
      "Epoch [23/85] Batch 370/938 Loss D: 0.2667, Loss G: 2.2813\n",
      "Epoch [23/85] Batch 380/938 Loss D: 0.2605, Loss G: 2.0468\n",
      "Epoch [23/85] Batch 390/938 Loss D: 0.2923, Loss G: 2.0243\n",
      "Epoch [23/85] Batch 400/938 Loss D: 0.2892, Loss G: 2.0986\n",
      "Epoch [23/85] Batch 410/938 Loss D: 0.2766, Loss G: 2.4574\n",
      "Epoch [23/85] Batch 420/938 Loss D: 0.2464, Loss G: 2.5206\n",
      "Epoch [23/85] Batch 430/938 Loss D: 0.2743, Loss G: 2.4356\n",
      "Epoch [23/85] Batch 440/938 Loss D: 0.3073, Loss G: 2.7249\n",
      "Epoch [23/85] Batch 450/938 Loss D: 0.2195, Loss G: 2.3632\n",
      "Epoch [23/85] Batch 460/938 Loss D: 0.4061, Loss G: 1.7525\n",
      "Epoch [23/85] Batch 470/938 Loss D: 0.3175, Loss G: 2.4881\n",
      "Epoch [23/85] Batch 480/938 Loss D: 0.4185, Loss G: 3.0161\n",
      "Epoch [23/85] Batch 490/938 Loss D: 0.2484, Loss G: 2.7390\n",
      "Epoch [23/85] Batch 500/938 Loss D: 0.3028, Loss G: 2.1456\n",
      "Epoch [23/85] Batch 510/938 Loss D: 0.2296, Loss G: 2.0398\n",
      "Epoch [23/85] Batch 520/938 Loss D: 0.3232, Loss G: 2.3671\n",
      "Epoch [23/85] Batch 530/938 Loss D: 0.3445, Loss G: 2.1082\n",
      "Epoch [23/85] Batch 540/938 Loss D: 0.2590, Loss G: 2.2285\n",
      "Epoch [23/85] Batch 550/938 Loss D: 0.3451, Loss G: 2.2694\n",
      "Epoch [23/85] Batch 560/938 Loss D: 0.2439, Loss G: 2.5590\n",
      "Epoch [23/85] Batch 570/938 Loss D: 0.2344, Loss G: 2.3607\n",
      "Epoch [23/85] Batch 580/938 Loss D: 0.3284, Loss G: 1.9421\n",
      "Epoch [23/85] Batch 590/938 Loss D: 0.3549, Loss G: 2.1390\n",
      "Epoch [23/85] Batch 600/938 Loss D: 0.2507, Loss G: 2.0140\n",
      "Epoch [23/85] Batch 610/938 Loss D: 0.2826, Loss G: 1.9133\n",
      "Epoch [23/85] Batch 620/938 Loss D: 0.2379, Loss G: 2.2215\n",
      "Epoch [23/85] Batch 630/938 Loss D: 0.2572, Loss G: 2.1443\n",
      "Epoch [23/85] Batch 640/938 Loss D: 0.2329, Loss G: 2.8471\n",
      "Epoch [23/85] Batch 650/938 Loss D: 0.2808, Loss G: 2.1816\n",
      "Epoch [23/85] Batch 660/938 Loss D: 0.2939, Loss G: 2.0174\n",
      "Epoch [23/85] Batch 670/938 Loss D: 0.2445, Loss G: 2.1463\n",
      "Epoch [23/85] Batch 680/938 Loss D: 0.3208, Loss G: 1.8849\n",
      "Epoch [23/85] Batch 690/938 Loss D: 0.2584, Loss G: 2.4964\n",
      "Epoch [23/85] Batch 700/938 Loss D: 0.2345, Loss G: 2.9263\n",
      "Epoch [23/85] Batch 710/938 Loss D: 0.3488, Loss G: 2.0682\n",
      "Epoch [23/85] Batch 720/938 Loss D: 0.2604, Loss G: 2.2290\n",
      "Epoch [23/85] Batch 730/938 Loss D: 0.2880, Loss G: 1.9059\n",
      "Epoch [23/85] Batch 740/938 Loss D: 0.2583, Loss G: 2.5174\n",
      "Epoch [23/85] Batch 750/938 Loss D: 0.3262, Loss G: 2.5337\n",
      "Epoch [23/85] Batch 760/938 Loss D: 0.2703, Loss G: 2.7574\n",
      "Epoch [23/85] Batch 770/938 Loss D: 0.3019, Loss G: 2.5373\n",
      "Epoch [23/85] Batch 780/938 Loss D: 0.3005, Loss G: 2.4303\n",
      "Epoch [23/85] Batch 790/938 Loss D: 0.2486, Loss G: 2.6107\n",
      "Epoch [23/85] Batch 800/938 Loss D: 0.2271, Loss G: 2.7825\n",
      "Epoch [23/85] Batch 810/938 Loss D: 0.3925, Loss G: 2.1141\n",
      "Epoch [23/85] Batch 820/938 Loss D: 0.2796, Loss G: 2.1338\n",
      "Epoch [23/85] Batch 830/938 Loss D: 0.2724, Loss G: 1.9850\n",
      "Epoch [23/85] Batch 840/938 Loss D: 0.3718, Loss G: 2.4373\n",
      "Epoch [23/85] Batch 850/938 Loss D: 0.2706, Loss G: 2.5555\n",
      "Epoch [23/85] Batch 860/938 Loss D: 0.3005, Loss G: 1.8890\n",
      "Epoch [23/85] Batch 870/938 Loss D: 0.4703, Loss G: 2.3293\n",
      "Epoch [23/85] Batch 880/938 Loss D: 0.2719, Loss G: 2.4819\n",
      "Epoch [23/85] Batch 890/938 Loss D: 0.3517, Loss G: 1.8091\n",
      "Epoch [23/85] Batch 900/938 Loss D: 0.3341, Loss G: 1.5423\n",
      "Epoch [23/85] Batch 910/938 Loss D: 0.3031, Loss G: 2.2348\n",
      "Epoch [23/85] Batch 920/938 Loss D: 0.2770, Loss G: 2.9858\n",
      "Epoch [23/85] Batch 930/938 Loss D: 0.3672, Loss G: 2.9837\n",
      "Epoch [24/85] Batch 0/938 Loss D: 0.2250, Loss G: 2.7725\n",
      "Epoch [24/85] Batch 10/938 Loss D: 0.2564, Loss G: 2.0782\n",
      "Epoch [24/85] Batch 20/938 Loss D: 0.3161, Loss G: 1.9244\n",
      "Epoch [24/85] Batch 30/938 Loss D: 0.2369, Loss G: 2.1074\n",
      "Epoch [24/85] Batch 40/938 Loss D: 0.2321, Loss G: 2.8424\n",
      "Epoch [24/85] Batch 50/938 Loss D: 0.2748, Loss G: 2.5864\n",
      "Epoch [24/85] Batch 60/938 Loss D: 0.2647, Loss G: 2.4478\n",
      "Epoch [24/85] Batch 70/938 Loss D: 0.2791, Loss G: 2.3703\n",
      "Epoch [24/85] Batch 80/938 Loss D: 0.1772, Loss G: 2.6615\n",
      "Epoch [24/85] Batch 90/938 Loss D: 0.3018, Loss G: 2.0003\n",
      "Epoch [24/85] Batch 100/938 Loss D: 0.1976, Loss G: 2.0352\n",
      "Epoch [24/85] Batch 110/938 Loss D: 0.2630, Loss G: 2.0239\n",
      "Epoch [24/85] Batch 120/938 Loss D: 0.2328, Loss G: 2.5344\n",
      "Epoch [24/85] Batch 130/938 Loss D: 0.2368, Loss G: 2.4520\n",
      "Epoch [24/85] Batch 140/938 Loss D: 0.3347, Loss G: 2.5684\n",
      "Epoch [24/85] Batch 150/938 Loss D: 0.3692, Loss G: 2.6705\n",
      "Epoch [24/85] Batch 160/938 Loss D: 0.3089, Loss G: 2.5114\n",
      "Epoch [24/85] Batch 170/938 Loss D: 0.2365, Loss G: 2.4035\n",
      "Epoch [24/85] Batch 180/938 Loss D: 0.2417, Loss G: 2.3528\n",
      "Epoch [24/85] Batch 190/938 Loss D: 0.2566, Loss G: 2.5385\n",
      "Epoch [24/85] Batch 200/938 Loss D: 0.2936, Loss G: 1.9649\n",
      "Epoch [24/85] Batch 210/938 Loss D: 0.2450, Loss G: 2.3334\n",
      "Epoch [24/85] Batch 220/938 Loss D: 0.3084, Loss G: 2.5312\n",
      "Epoch [24/85] Batch 230/938 Loss D: 0.2993, Loss G: 2.5154\n",
      "Epoch [24/85] Batch 240/938 Loss D: 0.2530, Loss G: 2.5478\n",
      "Epoch [24/85] Batch 250/938 Loss D: 0.1977, Loss G: 2.9817\n",
      "Epoch [24/85] Batch 260/938 Loss D: 0.2425, Loss G: 2.4325\n",
      "Epoch [24/85] Batch 270/938 Loss D: 0.2342, Loss G: 2.4906\n",
      "Epoch [24/85] Batch 280/938 Loss D: 0.2858, Loss G: 2.2737\n",
      "Epoch [24/85] Batch 290/938 Loss D: 0.2989, Loss G: 2.7711\n",
      "Epoch [24/85] Batch 300/938 Loss D: 0.2571, Loss G: 2.5942\n",
      "Epoch [24/85] Batch 310/938 Loss D: 0.2271, Loss G: 3.0698\n",
      "Epoch [24/85] Batch 320/938 Loss D: 0.1824, Loss G: 2.8822\n",
      "Epoch [24/85] Batch 330/938 Loss D: 0.2896, Loss G: 2.8148\n",
      "Epoch [24/85] Batch 340/938 Loss D: 0.2695, Loss G: 2.1567\n",
      "Epoch [24/85] Batch 350/938 Loss D: 0.2827, Loss G: 2.5668\n",
      "Epoch [24/85] Batch 360/938 Loss D: 0.4231, Loss G: 2.3600\n",
      "Epoch [24/85] Batch 370/938 Loss D: 0.2915, Loss G: 2.1316\n",
      "Epoch [24/85] Batch 380/938 Loss D: 0.2089, Loss G: 2.5208\n",
      "Epoch [24/85] Batch 390/938 Loss D: 0.2351, Loss G: 1.9556\n",
      "Epoch [24/85] Batch 400/938 Loss D: 0.2610, Loss G: 2.3946\n",
      "Epoch [24/85] Batch 410/938 Loss D: 0.2016, Loss G: 2.2087\n",
      "Epoch [24/85] Batch 420/938 Loss D: 0.2590, Loss G: 2.3344\n",
      "Epoch [24/85] Batch 430/938 Loss D: 0.3676, Loss G: 1.8040\n",
      "Epoch [24/85] Batch 440/938 Loss D: 0.2660, Loss G: 1.9362\n",
      "Epoch [24/85] Batch 450/938 Loss D: 0.2301, Loss G: 2.4254\n",
      "Epoch [24/85] Batch 460/938 Loss D: 0.2463, Loss G: 2.7273\n",
      "Epoch [24/85] Batch 470/938 Loss D: 0.2489, Loss G: 2.3829\n",
      "Epoch [24/85] Batch 480/938 Loss D: 0.3444, Loss G: 2.2189\n",
      "Epoch [24/85] Batch 490/938 Loss D: 0.3287, Loss G: 1.6626\n",
      "Epoch [24/85] Batch 500/938 Loss D: 0.2664, Loss G: 1.9581\n",
      "Epoch [24/85] Batch 510/938 Loss D: 0.2552, Loss G: 2.3316\n",
      "Epoch [24/85] Batch 520/938 Loss D: 0.2638, Loss G: 2.3959\n",
      "Epoch [24/85] Batch 530/938 Loss D: 0.2845, Loss G: 2.1535\n",
      "Epoch [24/85] Batch 540/938 Loss D: 0.2040, Loss G: 2.3067\n",
      "Epoch [24/85] Batch 550/938 Loss D: 0.3352, Loss G: 2.2323\n",
      "Epoch [24/85] Batch 560/938 Loss D: 0.2885, Loss G: 2.2684\n",
      "Epoch [24/85] Batch 570/938 Loss D: 0.3722, Loss G: 1.8317\n",
      "Epoch [24/85] Batch 580/938 Loss D: 0.2271, Loss G: 2.2420\n",
      "Epoch [24/85] Batch 590/938 Loss D: 0.2775, Loss G: 2.2128\n",
      "Epoch [24/85] Batch 600/938 Loss D: 0.2742, Loss G: 2.2609\n",
      "Epoch [24/85] Batch 610/938 Loss D: 0.2884, Loss G: 2.1952\n",
      "Epoch [24/85] Batch 620/938 Loss D: 0.2102, Loss G: 2.9446\n",
      "Epoch [24/85] Batch 630/938 Loss D: 0.3392, Loss G: 1.8811\n",
      "Epoch [24/85] Batch 640/938 Loss D: 0.2025, Loss G: 2.1727\n",
      "Epoch [24/85] Batch 650/938 Loss D: 0.2241, Loss G: 1.9700\n",
      "Epoch [24/85] Batch 660/938 Loss D: 0.3208, Loss G: 2.1177\n",
      "Epoch [24/85] Batch 670/938 Loss D: 0.2002, Loss G: 2.7013\n",
      "Epoch [24/85] Batch 680/938 Loss D: 0.3450, Loss G: 2.5820\n",
      "Epoch [24/85] Batch 690/938 Loss D: 0.2158, Loss G: 2.9348\n",
      "Epoch [24/85] Batch 700/938 Loss D: 0.3950, Loss G: 1.8716\n",
      "Epoch [24/85] Batch 710/938 Loss D: 0.2190, Loss G: 2.5717\n",
      "Epoch [24/85] Batch 720/938 Loss D: 0.2313, Loss G: 2.6888\n",
      "Epoch [24/85] Batch 730/938 Loss D: 0.2026, Loss G: 2.2714\n",
      "Epoch [24/85] Batch 740/938 Loss D: 0.2869, Loss G: 2.4161\n",
      "Epoch [24/85] Batch 750/938 Loss D: 0.2674, Loss G: 1.9221\n",
      "Epoch [24/85] Batch 760/938 Loss D: 0.3333, Loss G: 1.7336\n",
      "Epoch [24/85] Batch 770/938 Loss D: 0.2724, Loss G: 2.4624\n",
      "Epoch [24/85] Batch 780/938 Loss D: 0.1912, Loss G: 2.7812\n",
      "Epoch [24/85] Batch 790/938 Loss D: 0.3667, Loss G: 2.5029\n",
      "Epoch [24/85] Batch 800/938 Loss D: 0.2178, Loss G: 2.3193\n",
      "Epoch [24/85] Batch 810/938 Loss D: 0.3781, Loss G: 2.2706\n",
      "Epoch [24/85] Batch 820/938 Loss D: 0.2600, Loss G: 2.1139\n",
      "Epoch [24/85] Batch 830/938 Loss D: 0.3455, Loss G: 1.8578\n",
      "Epoch [24/85] Batch 840/938 Loss D: 0.2225, Loss G: 2.2487\n",
      "Epoch [24/85] Batch 850/938 Loss D: 0.2538, Loss G: 2.0575\n",
      "Epoch [24/85] Batch 860/938 Loss D: 0.2539, Loss G: 2.2852\n",
      "Epoch [24/85] Batch 870/938 Loss D: 0.3621, Loss G: 1.7456\n",
      "Epoch [24/85] Batch 880/938 Loss D: 0.2578, Loss G: 2.5413\n",
      "Epoch [24/85] Batch 890/938 Loss D: 0.4016, Loss G: 2.3707\n",
      "Epoch [24/85] Batch 900/938 Loss D: 0.3934, Loss G: 2.9726\n",
      "Epoch [24/85] Batch 910/938 Loss D: 0.2840, Loss G: 2.3417\n",
      "Epoch [24/85] Batch 920/938 Loss D: 0.2391, Loss G: 2.3269\n",
      "Epoch [24/85] Batch 930/938 Loss D: 0.3043, Loss G: 2.2536\n",
      "Epoch [25/85] Batch 0/938 Loss D: 0.1847, Loss G: 2.4822\n",
      "Epoch [25/85] Batch 10/938 Loss D: 0.3061, Loss G: 2.3278\n",
      "Epoch [25/85] Batch 20/938 Loss D: 0.2884, Loss G: 2.5914\n",
      "Epoch [25/85] Batch 30/938 Loss D: 0.3294, Loss G: 2.6572\n",
      "Epoch [25/85] Batch 40/938 Loss D: 0.3135, Loss G: 2.3963\n",
      "Epoch [25/85] Batch 50/938 Loss D: 0.3281, Loss G: 2.3691\n",
      "Epoch [25/85] Batch 60/938 Loss D: 0.2166, Loss G: 2.4950\n",
      "Epoch [25/85] Batch 70/938 Loss D: 0.1861, Loss G: 2.6526\n",
      "Epoch [25/85] Batch 80/938 Loss D: 0.2677, Loss G: 2.4004\n",
      "Epoch [25/85] Batch 90/938 Loss D: 0.3026, Loss G: 2.4569\n",
      "Epoch [25/85] Batch 100/938 Loss D: 0.2228, Loss G: 2.5913\n",
      "Epoch [25/85] Batch 110/938 Loss D: 0.2499, Loss G: 2.5172\n",
      "Epoch [25/85] Batch 120/938 Loss D: 0.2507, Loss G: 1.9758\n",
      "Epoch [25/85] Batch 130/938 Loss D: 0.2280, Loss G: 2.1079\n",
      "Epoch [25/85] Batch 140/938 Loss D: 0.2056, Loss G: 2.5520\n",
      "Epoch [25/85] Batch 150/938 Loss D: 0.2429, Loss G: 2.5492\n",
      "Epoch [25/85] Batch 160/938 Loss D: 0.2361, Loss G: 2.3672\n",
      "Epoch [25/85] Batch 170/938 Loss D: 0.1734, Loss G: 2.5848\n",
      "Epoch [25/85] Batch 180/938 Loss D: 0.3449, Loss G: 1.8427\n",
      "Epoch [25/85] Batch 190/938 Loss D: 0.2794, Loss G: 1.9402\n",
      "Epoch [25/85] Batch 200/938 Loss D: 0.2736, Loss G: 2.6249\n",
      "Epoch [25/85] Batch 210/938 Loss D: 0.2497, Loss G: 2.7836\n",
      "Epoch [25/85] Batch 220/938 Loss D: 0.2598, Loss G: 2.4668\n",
      "Epoch [25/85] Batch 230/938 Loss D: 0.1509, Loss G: 2.7814\n",
      "Epoch [25/85] Batch 240/938 Loss D: 0.2459, Loss G: 2.3417\n",
      "Epoch [25/85] Batch 250/938 Loss D: 0.2042, Loss G: 2.4286\n",
      "Epoch [25/85] Batch 260/938 Loss D: 0.2644, Loss G: 2.8565\n",
      "Epoch [25/85] Batch 270/938 Loss D: 0.2675, Loss G: 3.0639\n",
      "Epoch [25/85] Batch 280/938 Loss D: 0.1962, Loss G: 2.6952\n",
      "Epoch [25/85] Batch 290/938 Loss D: 0.2288, Loss G: 2.8236\n",
      "Epoch [25/85] Batch 300/938 Loss D: 0.3612, Loss G: 2.0716\n",
      "Epoch [25/85] Batch 310/938 Loss D: 0.2442, Loss G: 2.2731\n",
      "Epoch [25/85] Batch 320/938 Loss D: 0.2813, Loss G: 1.9947\n",
      "Epoch [25/85] Batch 330/938 Loss D: 0.3904, Loss G: 1.5743\n",
      "Epoch [25/85] Batch 340/938 Loss D: 0.2474, Loss G: 2.5429\n",
      "Epoch [25/85] Batch 350/938 Loss D: 0.2445, Loss G: 1.9591\n",
      "Epoch [25/85] Batch 360/938 Loss D: 0.3461, Loss G: 1.8895\n",
      "Epoch [25/85] Batch 370/938 Loss D: 0.2968, Loss G: 2.1437\n",
      "Epoch [25/85] Batch 380/938 Loss D: 0.3479, Loss G: 1.7321\n",
      "Epoch [25/85] Batch 390/938 Loss D: 0.3270, Loss G: 2.2576\n",
      "Epoch [25/85] Batch 400/938 Loss D: 0.2789, Loss G: 2.2791\n",
      "Epoch [25/85] Batch 410/938 Loss D: 0.3196, Loss G: 2.0404\n",
      "Epoch [25/85] Batch 420/938 Loss D: 0.2625, Loss G: 2.0521\n",
      "Epoch [25/85] Batch 430/938 Loss D: 0.2445, Loss G: 2.6482\n",
      "Epoch [25/85] Batch 440/938 Loss D: 0.2627, Loss G: 2.2112\n",
      "Epoch [25/85] Batch 450/938 Loss D: 0.2605, Loss G: 2.0755\n",
      "Epoch [25/85] Batch 460/938 Loss D: 0.2580, Loss G: 1.9252\n",
      "Epoch [25/85] Batch 470/938 Loss D: 0.2816, Loss G: 2.1561\n",
      "Epoch [25/85] Batch 480/938 Loss D: 0.3598, Loss G: 2.1544\n",
      "Epoch [25/85] Batch 490/938 Loss D: 0.2989, Loss G: 2.2422\n",
      "Epoch [25/85] Batch 500/938 Loss D: 0.2380, Loss G: 2.5783\n",
      "Epoch [25/85] Batch 510/938 Loss D: 0.3173, Loss G: 2.5896\n",
      "Epoch [25/85] Batch 520/938 Loss D: 0.2819, Loss G: 2.0112\n",
      "Epoch [25/85] Batch 530/938 Loss D: 0.2364, Loss G: 2.4461\n",
      "Epoch [25/85] Batch 540/938 Loss D: 0.3390, Loss G: 2.4081\n",
      "Epoch [25/85] Batch 550/938 Loss D: 0.2614, Loss G: 2.1953\n",
      "Epoch [25/85] Batch 560/938 Loss D: 0.2716, Loss G: 2.4680\n",
      "Epoch [25/85] Batch 570/938 Loss D: 0.3216, Loss G: 2.2206\n",
      "Epoch [25/85] Batch 580/938 Loss D: 0.3371, Loss G: 2.8614\n",
      "Epoch [25/85] Batch 590/938 Loss D: 0.3314, Loss G: 3.1561\n",
      "Epoch [25/85] Batch 600/938 Loss D: 0.3294, Loss G: 2.9790\n",
      "Epoch [25/85] Batch 610/938 Loss D: 0.1974, Loss G: 2.6760\n",
      "Epoch [25/85] Batch 620/938 Loss D: 0.1798, Loss G: 2.4684\n",
      "Epoch [25/85] Batch 630/938 Loss D: 0.3373, Loss G: 1.8540\n",
      "Epoch [25/85] Batch 640/938 Loss D: 0.2233, Loss G: 2.2741\n",
      "Epoch [25/85] Batch 650/938 Loss D: 0.2369, Loss G: 2.4019\n",
      "Epoch [25/85] Batch 660/938 Loss D: 0.2675, Loss G: 2.3672\n",
      "Epoch [25/85] Batch 670/938 Loss D: 0.2896, Loss G: 1.9811\n",
      "Epoch [25/85] Batch 680/938 Loss D: 0.4702, Loss G: 1.4975\n",
      "Epoch [25/85] Batch 690/938 Loss D: 0.3277, Loss G: 2.0623\n",
      "Epoch [25/85] Batch 700/938 Loss D: 0.2095, Loss G: 2.8911\n",
      "Epoch [25/85] Batch 710/938 Loss D: 0.2841, Loss G: 2.5931\n",
      "Epoch [25/85] Batch 720/938 Loss D: 0.2308, Loss G: 2.7345\n",
      "Epoch [25/85] Batch 730/938 Loss D: 0.2944, Loss G: 2.5550\n",
      "Epoch [25/85] Batch 740/938 Loss D: 0.2952, Loss G: 2.3155\n",
      "Epoch [25/85] Batch 750/938 Loss D: 0.2898, Loss G: 1.8809\n",
      "Epoch [25/85] Batch 760/938 Loss D: 0.2786, Loss G: 2.3768\n",
      "Epoch [25/85] Batch 770/938 Loss D: 0.2470, Loss G: 2.2825\n",
      "Epoch [25/85] Batch 780/938 Loss D: 0.2546, Loss G: 2.3850\n",
      "Epoch [25/85] Batch 790/938 Loss D: 0.3287, Loss G: 1.9473\n",
      "Epoch [25/85] Batch 800/938 Loss D: 0.1888, Loss G: 2.7276\n",
      "Epoch [25/85] Batch 810/938 Loss D: 0.3499, Loss G: 2.3682\n",
      "Epoch [25/85] Batch 820/938 Loss D: 0.3176, Loss G: 2.4013\n",
      "Epoch [25/85] Batch 830/938 Loss D: 0.3058, Loss G: 2.4658\n",
      "Epoch [25/85] Batch 840/938 Loss D: 0.2189, Loss G: 2.9669\n",
      "Epoch [25/85] Batch 850/938 Loss D: 0.3258, Loss G: 2.7246\n",
      "Epoch [25/85] Batch 860/938 Loss D: 0.3341, Loss G: 2.2093\n",
      "Epoch [25/85] Batch 870/938 Loss D: 0.2772, Loss G: 2.3244\n",
      "Epoch [25/85] Batch 880/938 Loss D: 0.2671, Loss G: 1.9719\n",
      "Epoch [25/85] Batch 890/938 Loss D: 0.2591, Loss G: 2.0529\n",
      "Epoch [25/85] Batch 900/938 Loss D: 0.1906, Loss G: 2.6103\n",
      "Epoch [25/85] Batch 910/938 Loss D: 0.2311, Loss G: 2.4095\n",
      "Epoch [25/85] Batch 920/938 Loss D: 0.3467, Loss G: 2.4130\n",
      "Epoch [25/85] Batch 930/938 Loss D: 0.3273, Loss G: 2.0972\n",
      "Epoch [26/85] Batch 0/938 Loss D: 0.3539, Loss G: 2.0570\n",
      "Epoch [26/85] Batch 10/938 Loss D: 0.2196, Loss G: 2.0205\n",
      "Epoch [26/85] Batch 20/938 Loss D: 0.2565, Loss G: 2.4164\n",
      "Epoch [26/85] Batch 30/938 Loss D: 0.3144, Loss G: 2.5001\n",
      "Epoch [26/85] Batch 40/938 Loss D: 0.2443, Loss G: 2.7481\n",
      "Epoch [26/85] Batch 50/938 Loss D: 0.2167, Loss G: 2.5662\n",
      "Epoch [26/85] Batch 60/938 Loss D: 0.3529, Loss G: 1.9659\n",
      "Epoch [26/85] Batch 70/938 Loss D: 0.2404, Loss G: 2.6420\n",
      "Epoch [26/85] Batch 80/938 Loss D: 0.2333, Loss G: 2.5755\n",
      "Epoch [26/85] Batch 90/938 Loss D: 0.2227, Loss G: 2.5765\n",
      "Epoch [26/85] Batch 100/938 Loss D: 0.2757, Loss G: 2.1118\n",
      "Epoch [26/85] Batch 110/938 Loss D: 0.3715, Loss G: 1.6595\n",
      "Epoch [26/85] Batch 120/938 Loss D: 0.2503, Loss G: 2.0205\n",
      "Epoch [26/85] Batch 130/938 Loss D: 0.3793, Loss G: 2.0275\n",
      "Epoch [26/85] Batch 140/938 Loss D: 0.3148, Loss G: 2.6274\n",
      "Epoch [26/85] Batch 150/938 Loss D: 0.3772, Loss G: 2.7016\n",
      "Epoch [26/85] Batch 160/938 Loss D: 0.2636, Loss G: 2.2619\n",
      "Epoch [26/85] Batch 170/938 Loss D: 0.3457, Loss G: 2.2930\n",
      "Epoch [26/85] Batch 180/938 Loss D: 0.2650, Loss G: 2.4011\n",
      "Epoch [26/85] Batch 190/938 Loss D: 0.3167, Loss G: 2.5749\n",
      "Epoch [26/85] Batch 200/938 Loss D: 0.2897, Loss G: 3.0981\n",
      "Epoch [26/85] Batch 210/938 Loss D: 0.2541, Loss G: 2.4735\n",
      "Epoch [26/85] Batch 220/938 Loss D: 0.3343, Loss G: 2.4790\n",
      "Epoch [26/85] Batch 230/938 Loss D: 0.2676, Loss G: 1.9790\n",
      "Epoch [26/85] Batch 240/938 Loss D: 0.1939, Loss G: 2.7603\n",
      "Epoch [26/85] Batch 250/938 Loss D: 0.3489, Loss G: 2.3261\n",
      "Epoch [26/85] Batch 260/938 Loss D: 0.3055, Loss G: 2.5436\n",
      "Epoch [26/85] Batch 270/938 Loss D: 0.2626, Loss G: 2.3133\n",
      "Epoch [26/85] Batch 280/938 Loss D: 0.2546, Loss G: 2.4222\n",
      "Epoch [26/85] Batch 290/938 Loss D: 0.2203, Loss G: 2.9547\n",
      "Epoch [26/85] Batch 300/938 Loss D: 0.2326, Loss G: 2.2338\n",
      "Epoch [26/85] Batch 310/938 Loss D: 0.2613, Loss G: 2.9686\n",
      "Epoch [26/85] Batch 320/938 Loss D: 0.2852, Loss G: 2.6488\n",
      "Epoch [26/85] Batch 330/938 Loss D: 0.2337, Loss G: 2.2787\n",
      "Epoch [26/85] Batch 340/938 Loss D: 0.1998, Loss G: 3.1356\n",
      "Epoch [26/85] Batch 350/938 Loss D: 0.3151, Loss G: 1.5763\n",
      "Epoch [26/85] Batch 360/938 Loss D: 0.2697, Loss G: 2.2191\n",
      "Epoch [26/85] Batch 370/938 Loss D: 0.3445, Loss G: 2.7057\n",
      "Epoch [26/85] Batch 380/938 Loss D: 0.3429, Loss G: 2.5547\n",
      "Epoch [26/85] Batch 390/938 Loss D: 0.2798, Loss G: 2.6156\n",
      "Epoch [26/85] Batch 400/938 Loss D: 0.3700, Loss G: 2.3838\n",
      "Epoch [26/85] Batch 410/938 Loss D: 0.2285, Loss G: 2.0595\n",
      "Epoch [26/85] Batch 420/938 Loss D: 0.2479, Loss G: 1.9129\n",
      "Epoch [26/85] Batch 430/938 Loss D: 0.2170, Loss G: 2.3121\n",
      "Epoch [26/85] Batch 440/938 Loss D: 0.3480, Loss G: 1.7261\n",
      "Epoch [26/85] Batch 450/938 Loss D: 0.2481, Loss G: 2.3533\n",
      "Epoch [26/85] Batch 460/938 Loss D: 0.2420, Loss G: 2.4980\n",
      "Epoch [26/85] Batch 470/938 Loss D: 0.3297, Loss G: 1.8058\n",
      "Epoch [26/85] Batch 480/938 Loss D: 0.3802, Loss G: 2.3249\n",
      "Epoch [26/85] Batch 490/938 Loss D: 0.1581, Loss G: 2.9296\n",
      "Epoch [26/85] Batch 500/938 Loss D: 0.2946, Loss G: 2.2267\n",
      "Epoch [26/85] Batch 510/938 Loss D: 0.2546, Loss G: 2.1139\n",
      "Epoch [26/85] Batch 520/938 Loss D: 0.2708, Loss G: 2.0464\n",
      "Epoch [26/85] Batch 530/938 Loss D: 0.2572, Loss G: 2.2685\n",
      "Epoch [26/85] Batch 540/938 Loss D: 0.2040, Loss G: 2.0736\n",
      "Epoch [26/85] Batch 550/938 Loss D: 0.3374, Loss G: 2.1447\n",
      "Epoch [26/85] Batch 560/938 Loss D: 0.2259, Loss G: 2.3639\n",
      "Epoch [26/85] Batch 570/938 Loss D: 0.2222, Loss G: 2.8430\n",
      "Epoch [26/85] Batch 580/938 Loss D: 0.3671, Loss G: 1.9099\n",
      "Epoch [26/85] Batch 590/938 Loss D: 0.2411, Loss G: 1.9949\n",
      "Epoch [26/85] Batch 600/938 Loss D: 0.1964, Loss G: 2.1778\n",
      "Epoch [26/85] Batch 610/938 Loss D: 0.2895, Loss G: 2.1921\n",
      "Epoch [26/85] Batch 620/938 Loss D: 0.2731, Loss G: 2.5028\n",
      "Epoch [26/85] Batch 630/938 Loss D: 0.2816, Loss G: 2.7040\n",
      "Epoch [26/85] Batch 640/938 Loss D: 0.2365, Loss G: 2.5785\n",
      "Epoch [26/85] Batch 650/938 Loss D: 0.2929, Loss G: 2.3618\n",
      "Epoch [26/85] Batch 660/938 Loss D: 0.2361, Loss G: 2.8117\n",
      "Epoch [26/85] Batch 670/938 Loss D: 0.2849, Loss G: 2.6124\n",
      "Epoch [26/85] Batch 680/938 Loss D: 0.3777, Loss G: 1.8498\n",
      "Epoch [26/85] Batch 690/938 Loss D: 0.2293, Loss G: 2.8731\n",
      "Epoch [26/85] Batch 700/938 Loss D: 0.2735, Loss G: 2.4155\n",
      "Epoch [26/85] Batch 710/938 Loss D: 0.2687, Loss G: 2.0354\n",
      "Epoch [26/85] Batch 720/938 Loss D: 0.2317, Loss G: 2.5418\n",
      "Epoch [26/85] Batch 730/938 Loss D: 0.2522, Loss G: 2.3952\n",
      "Epoch [26/85] Batch 740/938 Loss D: 0.2170, Loss G: 2.7946\n",
      "Epoch [26/85] Batch 750/938 Loss D: 0.2996, Loss G: 1.8015\n",
      "Epoch [26/85] Batch 760/938 Loss D: 0.2388, Loss G: 2.3683\n",
      "Epoch [26/85] Batch 770/938 Loss D: 0.2331, Loss G: 2.5764\n",
      "Epoch [26/85] Batch 780/938 Loss D: 0.3058, Loss G: 3.1289\n",
      "Epoch [26/85] Batch 790/938 Loss D: 0.2913, Loss G: 2.4005\n",
      "Epoch [26/85] Batch 800/938 Loss D: 0.2806, Loss G: 2.5912\n",
      "Epoch [26/85] Batch 810/938 Loss D: 0.1946, Loss G: 2.6353\n",
      "Epoch [26/85] Batch 820/938 Loss D: 0.3626, Loss G: 2.1680\n",
      "Epoch [26/85] Batch 830/938 Loss D: 0.2109, Loss G: 2.1138\n",
      "Epoch [26/85] Batch 840/938 Loss D: 0.3033, Loss G: 2.2555\n",
      "Epoch [26/85] Batch 850/938 Loss D: 0.2900, Loss G: 2.4138\n",
      "Epoch [26/85] Batch 860/938 Loss D: 0.2715, Loss G: 2.4976\n",
      "Epoch [26/85] Batch 870/938 Loss D: 0.3258, Loss G: 2.1306\n",
      "Epoch [26/85] Batch 880/938 Loss D: 0.2506, Loss G: 1.8493\n",
      "Epoch [26/85] Batch 890/938 Loss D: 0.3225, Loss G: 2.4288\n",
      "Epoch [26/85] Batch 900/938 Loss D: 0.1627, Loss G: 2.8210\n",
      "Epoch [26/85] Batch 910/938 Loss D: 0.3494, Loss G: 2.3399\n",
      "Epoch [26/85] Batch 920/938 Loss D: 0.4004, Loss G: 2.7130\n",
      "Epoch [26/85] Batch 930/938 Loss D: 0.2333, Loss G: 2.7674\n",
      "Epoch [27/85] Batch 0/938 Loss D: 0.3603, Loss G: 2.1119\n",
      "Epoch [27/85] Batch 10/938 Loss D: 0.2923, Loss G: 2.8930\n",
      "Epoch [27/85] Batch 20/938 Loss D: 0.2577, Loss G: 2.1787\n",
      "Epoch [27/85] Batch 30/938 Loss D: 0.4564, Loss G: 1.8974\n",
      "Epoch [27/85] Batch 40/938 Loss D: 0.2751, Loss G: 2.8049\n",
      "Epoch [27/85] Batch 50/938 Loss D: 0.3193, Loss G: 2.3767\n",
      "Epoch [27/85] Batch 60/938 Loss D: 0.2950, Loss G: 2.6399\n",
      "Epoch [27/85] Batch 70/938 Loss D: 0.3143, Loss G: 1.6865\n",
      "Epoch [27/85] Batch 80/938 Loss D: 0.4277, Loss G: 1.4615\n",
      "Epoch [27/85] Batch 90/938 Loss D: 0.2318, Loss G: 1.9419\n",
      "Epoch [27/85] Batch 100/938 Loss D: 0.2470, Loss G: 2.1435\n",
      "Epoch [27/85] Batch 110/938 Loss D: 0.2178, Loss G: 3.0897\n",
      "Epoch [27/85] Batch 120/938 Loss D: 0.1571, Loss G: 3.1983\n",
      "Epoch [27/85] Batch 130/938 Loss D: 0.2806, Loss G: 2.3987\n",
      "Epoch [27/85] Batch 140/938 Loss D: 0.2274, Loss G: 2.9601\n",
      "Epoch [27/85] Batch 150/938 Loss D: 0.2929, Loss G: 2.1434\n",
      "Epoch [27/85] Batch 160/938 Loss D: 0.3029, Loss G: 2.0260\n",
      "Epoch [27/85] Batch 170/938 Loss D: 0.3020, Loss G: 2.1379\n",
      "Epoch [27/85] Batch 180/938 Loss D: 0.1910, Loss G: 2.9282\n",
      "Epoch [27/85] Batch 190/938 Loss D: 0.2483, Loss G: 2.8840\n",
      "Epoch [27/85] Batch 200/938 Loss D: 0.3501, Loss G: 2.4131\n",
      "Epoch [27/85] Batch 210/938 Loss D: 0.2453, Loss G: 2.6194\n",
      "Epoch [27/85] Batch 220/938 Loss D: 0.3259, Loss G: 2.3916\n",
      "Epoch [27/85] Batch 230/938 Loss D: 0.2767, Loss G: 2.7618\n",
      "Epoch [27/85] Batch 240/938 Loss D: 0.3431, Loss G: 2.3906\n",
      "Epoch [27/85] Batch 250/938 Loss D: 0.5148, Loss G: 2.3988\n",
      "Epoch [27/85] Batch 260/938 Loss D: 0.3768, Loss G: 2.3656\n",
      "Epoch [27/85] Batch 270/938 Loss D: 0.3081, Loss G: 2.5904\n",
      "Epoch [27/85] Batch 280/938 Loss D: 0.2540, Loss G: 2.0821\n",
      "Epoch [27/85] Batch 290/938 Loss D: 0.1972, Loss G: 2.4733\n",
      "Epoch [27/85] Batch 300/938 Loss D: 0.2829, Loss G: 1.9137\n",
      "Epoch [27/85] Batch 310/938 Loss D: 0.3631, Loss G: 2.7343\n",
      "Epoch [27/85] Batch 320/938 Loss D: 0.3011, Loss G: 2.3206\n",
      "Epoch [27/85] Batch 330/938 Loss D: 0.2997, Loss G: 1.9929\n",
      "Epoch [27/85] Batch 340/938 Loss D: 0.3190, Loss G: 1.9018\n",
      "Epoch [27/85] Batch 350/938 Loss D: 0.3144, Loss G: 2.3192\n",
      "Epoch [27/85] Batch 360/938 Loss D: 0.3789, Loss G: 2.1401\n",
      "Epoch [27/85] Batch 370/938 Loss D: 0.2906, Loss G: 2.2294\n",
      "Epoch [27/85] Batch 380/938 Loss D: 0.2322, Loss G: 2.3808\n",
      "Epoch [27/85] Batch 390/938 Loss D: 0.2427, Loss G: 2.4438\n",
      "Epoch [27/85] Batch 400/938 Loss D: 0.3274, Loss G: 2.2668\n",
      "Epoch [27/85] Batch 410/938 Loss D: 0.2787, Loss G: 2.0642\n",
      "Epoch [27/85] Batch 420/938 Loss D: 0.2870, Loss G: 2.2864\n",
      "Epoch [27/85] Batch 430/938 Loss D: 0.3231, Loss G: 2.3370\n",
      "Epoch [27/85] Batch 440/938 Loss D: 0.3423, Loss G: 1.9347\n",
      "Epoch [27/85] Batch 450/938 Loss D: 0.3172, Loss G: 2.2657\n",
      "Epoch [27/85] Batch 460/938 Loss D: 0.3046, Loss G: 1.9647\n",
      "Epoch [27/85] Batch 470/938 Loss D: 0.2516, Loss G: 2.1670\n",
      "Epoch [27/85] Batch 480/938 Loss D: 0.2904, Loss G: 2.0578\n",
      "Epoch [27/85] Batch 490/938 Loss D: 0.2606, Loss G: 2.4996\n",
      "Epoch [27/85] Batch 500/938 Loss D: 0.2862, Loss G: 2.8880\n",
      "Epoch [27/85] Batch 510/938 Loss D: 0.3785, Loss G: 2.0506\n",
      "Epoch [27/85] Batch 520/938 Loss D: 0.3121, Loss G: 2.2062\n",
      "Epoch [27/85] Batch 530/938 Loss D: 0.2586, Loss G: 2.1987\n",
      "Epoch [27/85] Batch 540/938 Loss D: 0.2435, Loss G: 2.3091\n",
      "Epoch [27/85] Batch 550/938 Loss D: 0.2669, Loss G: 2.5039\n",
      "Epoch [27/85] Batch 560/938 Loss D: 0.2998, Loss G: 1.8244\n",
      "Epoch [27/85] Batch 570/938 Loss D: 0.2572, Loss G: 2.4135\n",
      "Epoch [27/85] Batch 580/938 Loss D: 0.2573, Loss G: 2.2467\n",
      "Epoch [27/85] Batch 590/938 Loss D: 0.3908, Loss G: 2.0435\n",
      "Epoch [27/85] Batch 600/938 Loss D: 0.3395, Loss G: 1.8099\n",
      "Epoch [27/85] Batch 610/938 Loss D: 0.2542, Loss G: 2.8723\n",
      "Epoch [27/85] Batch 620/938 Loss D: 0.2527, Loss G: 2.0230\n",
      "Epoch [27/85] Batch 630/938 Loss D: 0.2692, Loss G: 2.8767\n",
      "Epoch [27/85] Batch 640/938 Loss D: 0.3252, Loss G: 2.4974\n",
      "Epoch [27/85] Batch 650/938 Loss D: 0.1879, Loss G: 2.9359\n",
      "Epoch [27/85] Batch 660/938 Loss D: 0.2660, Loss G: 2.4935\n",
      "Epoch [27/85] Batch 670/938 Loss D: 0.3106, Loss G: 1.9584\n",
      "Epoch [27/85] Batch 680/938 Loss D: 0.2534, Loss G: 2.6053\n",
      "Epoch [27/85] Batch 690/938 Loss D: 0.2569, Loss G: 2.9862\n",
      "Epoch [27/85] Batch 700/938 Loss D: 0.2405, Loss G: 2.2387\n",
      "Epoch [27/85] Batch 710/938 Loss D: 0.3076, Loss G: 2.4936\n",
      "Epoch [27/85] Batch 720/938 Loss D: 0.2413, Loss G: 2.6900\n",
      "Epoch [27/85] Batch 730/938 Loss D: 0.3434, Loss G: 2.1840\n",
      "Epoch [27/85] Batch 740/938 Loss D: 0.2023, Loss G: 2.8533\n",
      "Epoch [27/85] Batch 750/938 Loss D: 0.1865, Loss G: 3.0334\n",
      "Epoch [27/85] Batch 760/938 Loss D: 0.2336, Loss G: 2.1606\n",
      "Epoch [27/85] Batch 770/938 Loss D: 0.2214, Loss G: 2.3383\n",
      "Epoch [27/85] Batch 780/938 Loss D: 0.3750, Loss G: 2.0229\n",
      "Epoch [27/85] Batch 790/938 Loss D: 0.3359, Loss G: 1.9856\n",
      "Epoch [27/85] Batch 800/938 Loss D: 0.2741, Loss G: 2.8669\n",
      "Epoch [27/85] Batch 810/938 Loss D: 0.3098, Loss G: 2.3638\n",
      "Epoch [27/85] Batch 820/938 Loss D: 0.2899, Loss G: 3.0596\n",
      "Epoch [27/85] Batch 830/938 Loss D: 0.3368, Loss G: 2.6909\n",
      "Epoch [27/85] Batch 840/938 Loss D: 0.2530, Loss G: 2.3623\n",
      "Epoch [27/85] Batch 850/938 Loss D: 0.3421, Loss G: 1.7090\n",
      "Epoch [27/85] Batch 860/938 Loss D: 0.2144, Loss G: 2.4837\n",
      "Epoch [27/85] Batch 870/938 Loss D: 0.1811, Loss G: 2.6726\n",
      "Epoch [27/85] Batch 880/938 Loss D: 0.2366, Loss G: 2.4100\n",
      "Epoch [27/85] Batch 890/938 Loss D: 0.3532, Loss G: 1.9524\n",
      "Epoch [27/85] Batch 900/938 Loss D: 0.3490, Loss G: 2.1308\n",
      "Epoch [27/85] Batch 910/938 Loss D: 0.2785, Loss G: 2.3528\n",
      "Epoch [27/85] Batch 920/938 Loss D: 0.3099, Loss G: 2.3738\n",
      "Epoch [27/85] Batch 930/938 Loss D: 0.1961, Loss G: 2.3152\n",
      "Epoch [28/85] Batch 0/938 Loss D: 0.1964, Loss G: 2.2600\n",
      "Epoch [28/85] Batch 10/938 Loss D: 0.2654, Loss G: 2.3912\n",
      "Epoch [28/85] Batch 20/938 Loss D: 0.3618, Loss G: 2.5338\n",
      "Epoch [28/85] Batch 30/938 Loss D: 0.3257, Loss G: 2.5073\n",
      "Epoch [28/85] Batch 40/938 Loss D: 0.2652, Loss G: 2.9200\n",
      "Epoch [28/85] Batch 50/938 Loss D: 0.2849, Loss G: 2.4084\n",
      "Epoch [28/85] Batch 60/938 Loss D: 0.2825, Loss G: 2.7456\n",
      "Epoch [28/85] Batch 70/938 Loss D: 0.3372, Loss G: 2.2848\n",
      "Epoch [28/85] Batch 80/938 Loss D: 0.2379, Loss G: 2.1509\n",
      "Epoch [28/85] Batch 90/938 Loss D: 0.2844, Loss G: 2.4084\n",
      "Epoch [28/85] Batch 100/938 Loss D: 0.2367, Loss G: 2.2405\n",
      "Epoch [28/85] Batch 110/938 Loss D: 0.3519, Loss G: 1.8527\n",
      "Epoch [28/85] Batch 120/938 Loss D: 0.3312, Loss G: 2.4187\n",
      "Epoch [28/85] Batch 130/938 Loss D: 0.2494, Loss G: 3.1509\n",
      "Epoch [28/85] Batch 140/938 Loss D: 0.3276, Loss G: 2.6882\n",
      "Epoch [28/85] Batch 150/938 Loss D: 0.2430, Loss G: 2.2967\n",
      "Epoch [28/85] Batch 160/938 Loss D: 0.4147, Loss G: 2.6138\n",
      "Epoch [28/85] Batch 170/938 Loss D: 0.3478, Loss G: 1.8753\n",
      "Epoch [28/85] Batch 180/938 Loss D: 0.3178, Loss G: 2.4020\n",
      "Epoch [28/85] Batch 190/938 Loss D: 0.2866, Loss G: 2.4728\n",
      "Epoch [28/85] Batch 200/938 Loss D: 0.2172, Loss G: 2.8068\n",
      "Epoch [28/85] Batch 210/938 Loss D: 0.2707, Loss G: 1.9997\n",
      "Epoch [28/85] Batch 220/938 Loss D: 0.2238, Loss G: 2.2213\n",
      "Epoch [28/85] Batch 230/938 Loss D: 0.2650, Loss G: 2.6451\n",
      "Epoch [28/85] Batch 240/938 Loss D: 0.3280, Loss G: 2.0481\n",
      "Epoch [28/85] Batch 250/938 Loss D: 0.2656, Loss G: 2.4582\n",
      "Epoch [28/85] Batch 260/938 Loss D: 0.2636, Loss G: 2.4755\n",
      "Epoch [28/85] Batch 270/938 Loss D: 0.2781, Loss G: 2.4151\n",
      "Epoch [28/85] Batch 280/938 Loss D: 0.3154, Loss G: 2.4797\n",
      "Epoch [28/85] Batch 290/938 Loss D: 0.2380, Loss G: 2.3816\n",
      "Epoch [28/85] Batch 300/938 Loss D: 0.1974, Loss G: 2.7438\n",
      "Epoch [28/85] Batch 310/938 Loss D: 0.3260, Loss G: 2.0723\n",
      "Epoch [28/85] Batch 320/938 Loss D: 0.2907, Loss G: 1.8486\n",
      "Epoch [28/85] Batch 330/938 Loss D: 0.2276, Loss G: 2.2972\n",
      "Epoch [28/85] Batch 340/938 Loss D: 0.1957, Loss G: 2.3972\n",
      "Epoch [28/85] Batch 350/938 Loss D: 0.2562, Loss G: 2.5618\n",
      "Epoch [28/85] Batch 360/938 Loss D: 0.2925, Loss G: 2.0708\n",
      "Epoch [28/85] Batch 370/938 Loss D: 0.2343, Loss G: 2.3068\n",
      "Epoch [28/85] Batch 380/938 Loss D: 0.2206, Loss G: 2.7228\n",
      "Epoch [28/85] Batch 390/938 Loss D: 0.3528, Loss G: 2.4605\n",
      "Epoch [28/85] Batch 400/938 Loss D: 0.2685, Loss G: 2.7527\n",
      "Epoch [28/85] Batch 410/938 Loss D: 0.2525, Loss G: 2.4784\n",
      "Epoch [28/85] Batch 420/938 Loss D: 0.2627, Loss G: 2.5348\n",
      "Epoch [28/85] Batch 430/938 Loss D: 0.3509, Loss G: 2.4957\n",
      "Epoch [28/85] Batch 440/938 Loss D: 0.3010, Loss G: 1.9066\n",
      "Epoch [28/85] Batch 450/938 Loss D: 0.2852, Loss G: 2.4625\n",
      "Epoch [28/85] Batch 460/938 Loss D: 0.2857, Loss G: 2.8263\n",
      "Epoch [28/85] Batch 470/938 Loss D: 0.1691, Loss G: 3.1202\n",
      "Epoch [28/85] Batch 480/938 Loss D: 0.2062, Loss G: 2.5790\n",
      "Epoch [28/85] Batch 490/938 Loss D: 0.2576, Loss G: 2.0731\n",
      "Epoch [28/85] Batch 500/938 Loss D: 0.2363, Loss G: 2.1401\n",
      "Epoch [28/85] Batch 510/938 Loss D: 0.2537, Loss G: 1.9350\n",
      "Epoch [28/85] Batch 520/938 Loss D: 0.2086, Loss G: 2.1760\n",
      "Epoch [28/85] Batch 530/938 Loss D: 0.2366, Loss G: 2.9462\n",
      "Epoch [28/85] Batch 540/938 Loss D: 0.2528, Loss G: 2.8198\n",
      "Epoch [28/85] Batch 550/938 Loss D: 0.3879, Loss G: 1.9182\n",
      "Epoch [28/85] Batch 560/938 Loss D: 0.2083, Loss G: 2.3639\n",
      "Epoch [28/85] Batch 570/938 Loss D: 0.2295, Loss G: 2.1537\n",
      "Epoch [28/85] Batch 580/938 Loss D: 0.3428, Loss G: 2.2793\n",
      "Epoch [28/85] Batch 590/938 Loss D: 0.3146, Loss G: 2.7361\n",
      "Epoch [28/85] Batch 600/938 Loss D: 0.2718, Loss G: 2.4273\n",
      "Epoch [28/85] Batch 610/938 Loss D: 0.3431, Loss G: 2.0989\n",
      "Epoch [28/85] Batch 620/938 Loss D: 0.2425, Loss G: 2.3723\n",
      "Epoch [28/85] Batch 630/938 Loss D: 0.4552, Loss G: 1.4479\n",
      "Epoch [28/85] Batch 640/938 Loss D: 0.1606, Loss G: 2.2008\n",
      "Epoch [28/85] Batch 650/938 Loss D: 0.3024, Loss G: 2.3171\n",
      "Epoch [28/85] Batch 660/938 Loss D: 0.3872, Loss G: 1.7324\n",
      "Epoch [28/85] Batch 670/938 Loss D: 0.2405, Loss G: 2.2585\n",
      "Epoch [28/85] Batch 680/938 Loss D: 0.3576, Loss G: 2.5511\n",
      "Epoch [28/85] Batch 690/938 Loss D: 0.2566, Loss G: 2.4159\n",
      "Epoch [28/85] Batch 700/938 Loss D: 0.2614, Loss G: 2.1610\n",
      "Epoch [28/85] Batch 710/938 Loss D: 0.2640, Loss G: 3.1170\n",
      "Epoch [28/85] Batch 720/938 Loss D: 0.3977, Loss G: 2.1455\n",
      "Epoch [28/85] Batch 730/938 Loss D: 0.3244, Loss G: 2.1182\n",
      "Epoch [28/85] Batch 740/938 Loss D: 0.2593, Loss G: 2.7442\n",
      "Epoch [28/85] Batch 750/938 Loss D: 0.2752, Loss G: 2.3303\n",
      "Epoch [28/85] Batch 760/938 Loss D: 0.2132, Loss G: 2.5549\n",
      "Epoch [28/85] Batch 770/938 Loss D: 0.2350, Loss G: 2.8787\n",
      "Epoch [28/85] Batch 780/938 Loss D: 0.3200, Loss G: 2.7475\n",
      "Epoch [28/85] Batch 790/938 Loss D: 0.4285, Loss G: 1.9726\n",
      "Epoch [28/85] Batch 800/938 Loss D: 0.3473, Loss G: 2.3997\n",
      "Epoch [28/85] Batch 810/938 Loss D: 0.3001, Loss G: 2.3661\n",
      "Epoch [28/85] Batch 820/938 Loss D: 0.1700, Loss G: 3.1952\n",
      "Epoch [28/85] Batch 830/938 Loss D: 0.2935, Loss G: 2.0633\n",
      "Epoch [28/85] Batch 840/938 Loss D: 0.3800, Loss G: 1.8629\n",
      "Epoch [28/85] Batch 850/938 Loss D: 0.2691, Loss G: 1.9794\n",
      "Epoch [28/85] Batch 860/938 Loss D: 0.2908, Loss G: 2.2653\n",
      "Epoch [28/85] Batch 870/938 Loss D: 0.3738, Loss G: 1.9502\n",
      "Epoch [28/85] Batch 880/938 Loss D: 0.2916, Loss G: 2.0521\n",
      "Epoch [28/85] Batch 890/938 Loss D: 0.2738, Loss G: 2.2878\n",
      "Epoch [28/85] Batch 900/938 Loss D: 0.2187, Loss G: 2.5968\n",
      "Epoch [28/85] Batch 910/938 Loss D: 0.2098, Loss G: 3.7341\n",
      "Epoch [28/85] Batch 920/938 Loss D: 0.3980, Loss G: 2.0476\n",
      "Epoch [28/85] Batch 930/938 Loss D: 0.2921, Loss G: 1.8279\n",
      "Epoch [29/85] Batch 0/938 Loss D: 0.2965, Loss G: 2.4895\n",
      "Epoch [29/85] Batch 10/938 Loss D: 0.3468, Loss G: 2.4703\n",
      "Epoch [29/85] Batch 20/938 Loss D: 0.2158, Loss G: 2.5079\n",
      "Epoch [29/85] Batch 30/938 Loss D: 0.2773, Loss G: 2.1772\n",
      "Epoch [29/85] Batch 40/938 Loss D: 0.2062, Loss G: 2.3728\n",
      "Epoch [29/85] Batch 50/938 Loss D: 0.2552, Loss G: 2.5169\n",
      "Epoch [29/85] Batch 60/938 Loss D: 0.2775, Loss G: 2.1359\n",
      "Epoch [29/85] Batch 70/938 Loss D: 0.2979, Loss G: 2.3335\n",
      "Epoch [29/85] Batch 80/938 Loss D: 0.2673, Loss G: 1.9648\n",
      "Epoch [29/85] Batch 90/938 Loss D: 0.2787, Loss G: 2.4741\n",
      "Epoch [29/85] Batch 100/938 Loss D: 0.3575, Loss G: 2.0381\n",
      "Epoch [29/85] Batch 110/938 Loss D: 0.2724, Loss G: 2.3878\n",
      "Epoch [29/85] Batch 120/938 Loss D: 0.3159, Loss G: 2.2985\n",
      "Epoch [29/85] Batch 130/938 Loss D: 0.2333, Loss G: 2.2516\n",
      "Epoch [29/85] Batch 140/938 Loss D: 0.3326, Loss G: 2.1670\n",
      "Epoch [29/85] Batch 150/938 Loss D: 0.2924, Loss G: 2.2088\n",
      "Epoch [29/85] Batch 160/938 Loss D: 0.2919, Loss G: 2.0408\n",
      "Epoch [29/85] Batch 170/938 Loss D: 0.3344, Loss G: 2.0570\n",
      "Epoch [29/85] Batch 180/938 Loss D: 0.2412, Loss G: 2.4386\n",
      "Epoch [29/85] Batch 190/938 Loss D: 0.2653, Loss G: 2.2025\n",
      "Epoch [29/85] Batch 200/938 Loss D: 0.3085, Loss G: 2.3325\n",
      "Epoch [29/85] Batch 210/938 Loss D: 0.0972, Loss G: 3.3457\n",
      "Epoch [29/85] Batch 220/938 Loss D: 0.2359, Loss G: 2.1550\n",
      "Epoch [29/85] Batch 230/938 Loss D: 0.1846, Loss G: 2.2130\n",
      "Epoch [29/85] Batch 240/938 Loss D: 0.2993, Loss G: 2.4005\n",
      "Epoch [29/85] Batch 250/938 Loss D: 0.2982, Loss G: 2.5590\n",
      "Epoch [29/85] Batch 260/938 Loss D: 0.2862, Loss G: 2.9046\n",
      "Epoch [29/85] Batch 270/938 Loss D: 0.4160, Loss G: 2.1521\n",
      "Epoch [29/85] Batch 280/938 Loss D: 0.2884, Loss G: 2.1160\n",
      "Epoch [29/85] Batch 290/938 Loss D: 0.3667, Loss G: 1.7718\n",
      "Epoch [29/85] Batch 300/938 Loss D: 0.3440, Loss G: 1.8896\n",
      "Epoch [29/85] Batch 310/938 Loss D: 0.3324, Loss G: 1.9290\n",
      "Epoch [29/85] Batch 320/938 Loss D: 0.3857, Loss G: 2.8561\n",
      "Epoch [29/85] Batch 330/938 Loss D: 0.2518, Loss G: 3.3938\n",
      "Epoch [29/85] Batch 340/938 Loss D: 0.3652, Loss G: 2.9604\n",
      "Epoch [29/85] Batch 350/938 Loss D: 0.2323, Loss G: 2.9702\n",
      "Epoch [29/85] Batch 360/938 Loss D: 0.2930, Loss G: 2.5688\n",
      "Epoch [29/85] Batch 370/938 Loss D: 0.2071, Loss G: 2.9265\n",
      "Epoch [29/85] Batch 380/938 Loss D: 0.1565, Loss G: 3.1120\n",
      "Epoch [29/85] Batch 390/938 Loss D: 0.1920, Loss G: 2.9104\n",
      "Epoch [29/85] Batch 400/938 Loss D: 0.2318, Loss G: 2.6386\n",
      "Epoch [29/85] Batch 410/938 Loss D: 0.2887, Loss G: 2.4947\n",
      "Epoch [29/85] Batch 420/938 Loss D: 0.1959, Loss G: 2.7492\n",
      "Epoch [29/85] Batch 430/938 Loss D: 0.2186, Loss G: 2.5911\n",
      "Epoch [29/85] Batch 440/938 Loss D: 0.3431, Loss G: 1.8780\n",
      "Epoch [29/85] Batch 450/938 Loss D: 0.2564, Loss G: 2.5418\n",
      "Epoch [29/85] Batch 460/938 Loss D: 0.2411, Loss G: 2.2104\n",
      "Epoch [29/85] Batch 470/938 Loss D: 0.2138, Loss G: 3.0110\n",
      "Epoch [29/85] Batch 480/938 Loss D: 0.2444, Loss G: 2.9835\n",
      "Epoch [29/85] Batch 490/938 Loss D: 0.2505, Loss G: 2.9270\n",
      "Epoch [29/85] Batch 500/938 Loss D: 0.3089, Loss G: 1.7790\n",
      "Epoch [29/85] Batch 510/938 Loss D: 0.2289, Loss G: 2.3682\n",
      "Epoch [29/85] Batch 520/938 Loss D: 0.2968, Loss G: 1.9967\n",
      "Epoch [29/85] Batch 530/938 Loss D: 0.2356, Loss G: 2.6403\n",
      "Epoch [29/85] Batch 540/938 Loss D: 0.1992, Loss G: 2.5796\n",
      "Epoch [29/85] Batch 550/938 Loss D: 0.1625, Loss G: 2.6390\n",
      "Epoch [29/85] Batch 560/938 Loss D: 0.2593, Loss G: 1.9012\n",
      "Epoch [29/85] Batch 570/938 Loss D: 0.3093, Loss G: 1.9359\n",
      "Epoch [29/85] Batch 580/938 Loss D: 0.2841, Loss G: 1.8534\n",
      "Epoch [29/85] Batch 590/938 Loss D: 0.3710, Loss G: 1.4936\n",
      "Epoch [29/85] Batch 600/938 Loss D: 0.1769, Loss G: 2.4873\n",
      "Epoch [29/85] Batch 610/938 Loss D: 0.3321, Loss G: 2.1301\n",
      "Epoch [29/85] Batch 620/938 Loss D: 0.3685, Loss G: 2.2019\n",
      "Epoch [29/85] Batch 630/938 Loss D: 0.2581, Loss G: 2.4779\n",
      "Epoch [29/85] Batch 640/938 Loss D: 0.2288, Loss G: 2.5527\n",
      "Epoch [29/85] Batch 650/938 Loss D: 0.2535, Loss G: 2.1951\n",
      "Epoch [29/85] Batch 660/938 Loss D: 0.3194, Loss G: 2.1376\n",
      "Epoch [29/85] Batch 670/938 Loss D: 0.3118, Loss G: 2.6154\n",
      "Epoch [29/85] Batch 680/938 Loss D: 0.2985, Loss G: 2.8867\n",
      "Epoch [29/85] Batch 690/938 Loss D: 0.2333, Loss G: 2.4962\n",
      "Epoch [29/85] Batch 700/938 Loss D: 0.2586, Loss G: 2.4837\n",
      "Epoch [29/85] Batch 710/938 Loss D: 0.1955, Loss G: 2.5238\n",
      "Epoch [29/85] Batch 720/938 Loss D: 0.2869, Loss G: 2.2376\n",
      "Epoch [29/85] Batch 730/938 Loss D: 0.2871, Loss G: 2.2338\n",
      "Epoch [29/85] Batch 740/938 Loss D: 0.2401, Loss G: 2.6958\n",
      "Epoch [29/85] Batch 750/938 Loss D: 0.1967, Loss G: 2.5029\n",
      "Epoch [29/85] Batch 760/938 Loss D: 0.1995, Loss G: 2.8050\n",
      "Epoch [29/85] Batch 770/938 Loss D: 0.2957, Loss G: 2.1580\n",
      "Epoch [29/85] Batch 780/938 Loss D: 0.2308, Loss G: 1.8992\n",
      "Epoch [29/85] Batch 790/938 Loss D: 0.2338, Loss G: 2.1133\n",
      "Epoch [29/85] Batch 800/938 Loss D: 0.4158, Loss G: 2.0389\n",
      "Epoch [29/85] Batch 810/938 Loss D: 0.2009, Loss G: 2.6047\n",
      "Epoch [29/85] Batch 820/938 Loss D: 0.2819, Loss G: 2.2314\n",
      "Epoch [29/85] Batch 830/938 Loss D: 0.1724, Loss G: 3.1375\n",
      "Epoch [29/85] Batch 840/938 Loss D: 0.3836, Loss G: 1.9183\n",
      "Epoch [29/85] Batch 850/938 Loss D: 0.2644, Loss G: 2.8943\n",
      "Epoch [29/85] Batch 860/938 Loss D: 0.3634, Loss G: 2.4689\n",
      "Epoch [29/85] Batch 870/938 Loss D: 0.2952, Loss G: 2.4175\n",
      "Epoch [29/85] Batch 880/938 Loss D: 0.2986, Loss G: 3.5468\n",
      "Epoch [29/85] Batch 890/938 Loss D: 0.3386, Loss G: 2.5676\n",
      "Epoch [29/85] Batch 900/938 Loss D: 0.2896, Loss G: 2.1198\n",
      "Epoch [29/85] Batch 910/938 Loss D: 0.3502, Loss G: 2.0807\n",
      "Epoch [29/85] Batch 920/938 Loss D: 0.2684, Loss G: 1.9091\n",
      "Epoch [29/85] Batch 930/938 Loss D: 0.3290, Loss G: 2.0632\n",
      "Epoch [30/85] Batch 0/938 Loss D: 0.2923, Loss G: 2.1805\n",
      "Epoch [30/85] Batch 10/938 Loss D: 0.2797, Loss G: 2.0132\n",
      "Epoch [30/85] Batch 20/938 Loss D: 0.3188, Loss G: 1.7187\n",
      "Epoch [30/85] Batch 30/938 Loss D: 0.1923, Loss G: 2.5433\n",
      "Epoch [30/85] Batch 40/938 Loss D: 0.2734, Loss G: 2.3161\n",
      "Epoch [30/85] Batch 50/938 Loss D: 0.3210, Loss G: 2.1219\n",
      "Epoch [30/85] Batch 60/938 Loss D: 0.3593, Loss G: 1.6180\n",
      "Epoch [30/85] Batch 70/938 Loss D: 0.2436, Loss G: 2.3299\n",
      "Epoch [30/85] Batch 80/938 Loss D: 0.2647, Loss G: 2.5323\n",
      "Epoch [30/85] Batch 90/938 Loss D: 0.3499, Loss G: 2.2107\n",
      "Epoch [30/85] Batch 100/938 Loss D: 0.2479, Loss G: 2.9300\n",
      "Epoch [30/85] Batch 110/938 Loss D: 0.2615, Loss G: 2.6322\n",
      "Epoch [30/85] Batch 120/938 Loss D: 0.2973, Loss G: 2.6917\n",
      "Epoch [30/85] Batch 130/938 Loss D: 0.2493, Loss G: 1.8221\n",
      "Epoch [30/85] Batch 140/938 Loss D: 0.2848, Loss G: 1.9747\n",
      "Epoch [30/85] Batch 150/938 Loss D: 0.2620, Loss G: 2.2462\n",
      "Epoch [30/85] Batch 160/938 Loss D: 0.3376, Loss G: 1.6387\n",
      "Epoch [30/85] Batch 170/938 Loss D: 0.1984, Loss G: 2.4653\n",
      "Epoch [30/85] Batch 180/938 Loss D: 0.3112, Loss G: 2.8830\n",
      "Epoch [30/85] Batch 190/938 Loss D: 0.3128, Loss G: 2.4902\n",
      "Epoch [30/85] Batch 200/938 Loss D: 0.2993, Loss G: 2.3030\n",
      "Epoch [30/85] Batch 210/938 Loss D: 0.3332, Loss G: 1.5889\n",
      "Epoch [30/85] Batch 220/938 Loss D: 0.3166, Loss G: 1.6625\n",
      "Epoch [30/85] Batch 230/938 Loss D: 0.1998, Loss G: 3.4308\n",
      "Epoch [30/85] Batch 240/938 Loss D: 0.4058, Loss G: 2.6486\n",
      "Epoch [30/85] Batch 250/938 Loss D: 0.3399, Loss G: 3.3979\n",
      "Epoch [30/85] Batch 260/938 Loss D: 0.2453, Loss G: 2.4506\n",
      "Epoch [30/85] Batch 270/938 Loss D: 0.3450, Loss G: 2.0741\n",
      "Epoch [30/85] Batch 280/938 Loss D: 0.2255, Loss G: 2.9267\n",
      "Epoch [30/85] Batch 290/938 Loss D: 0.2571, Loss G: 2.4488\n",
      "Epoch [30/85] Batch 300/938 Loss D: 0.3030, Loss G: 2.4741\n",
      "Epoch [30/85] Batch 310/938 Loss D: 0.3730, Loss G: 2.3355\n",
      "Epoch [30/85] Batch 320/938 Loss D: 0.2274, Loss G: 2.2576\n",
      "Epoch [30/85] Batch 330/938 Loss D: 0.2034, Loss G: 2.6742\n",
      "Epoch [30/85] Batch 340/938 Loss D: 0.3349, Loss G: 2.0575\n",
      "Epoch [30/85] Batch 350/938 Loss D: 0.2633, Loss G: 2.5405\n",
      "Epoch [30/85] Batch 360/938 Loss D: 0.2344, Loss G: 2.5177\n",
      "Epoch [30/85] Batch 370/938 Loss D: 0.3316, Loss G: 2.7829\n",
      "Epoch [30/85] Batch 380/938 Loss D: 0.2554, Loss G: 3.0552\n",
      "Epoch [30/85] Batch 390/938 Loss D: 0.2294, Loss G: 2.8446\n",
      "Epoch [30/85] Batch 400/938 Loss D: 0.1952, Loss G: 2.8286\n",
      "Epoch [30/85] Batch 410/938 Loss D: 0.2794, Loss G: 1.8362\n",
      "Epoch [30/85] Batch 420/938 Loss D: 0.4142, Loss G: 1.4396\n",
      "Epoch [30/85] Batch 430/938 Loss D: 0.3141, Loss G: 1.6134\n",
      "Epoch [30/85] Batch 440/938 Loss D: 0.3264, Loss G: 1.6537\n",
      "Epoch [30/85] Batch 450/938 Loss D: 0.1610, Loss G: 2.9198\n",
      "Epoch [30/85] Batch 460/938 Loss D: 0.2818, Loss G: 2.1053\n",
      "Epoch [30/85] Batch 470/938 Loss D: 0.2004, Loss G: 2.4102\n",
      "Epoch [30/85] Batch 480/938 Loss D: 0.2156, Loss G: 2.0810\n",
      "Epoch [30/85] Batch 490/938 Loss D: 0.4523, Loss G: 2.3170\n",
      "Epoch [30/85] Batch 500/938 Loss D: 0.1703, Loss G: 2.9433\n",
      "Epoch [30/85] Batch 510/938 Loss D: 0.2456, Loss G: 2.8495\n",
      "Epoch [30/85] Batch 520/938 Loss D: 0.2720, Loss G: 2.3921\n",
      "Epoch [30/85] Batch 530/938 Loss D: 0.3126, Loss G: 1.9481\n",
      "Epoch [30/85] Batch 540/938 Loss D: 0.3528, Loss G: 2.0350\n",
      "Epoch [30/85] Batch 550/938 Loss D: 0.2743, Loss G: 2.3829\n",
      "Epoch [30/85] Batch 560/938 Loss D: 0.2955, Loss G: 2.4086\n",
      "Epoch [30/85] Batch 570/938 Loss D: 0.1965, Loss G: 2.5874\n",
      "Epoch [30/85] Batch 580/938 Loss D: 0.1970, Loss G: 2.3361\n",
      "Epoch [30/85] Batch 590/938 Loss D: 0.2736, Loss G: 2.1318\n",
      "Epoch [30/85] Batch 600/938 Loss D: 0.2886, Loss G: 2.2339\n",
      "Epoch [30/85] Batch 610/938 Loss D: 0.2308, Loss G: 2.5810\n",
      "Epoch [30/85] Batch 620/938 Loss D: 0.3241, Loss G: 2.3751\n",
      "Epoch [30/85] Batch 630/938 Loss D: 0.3007, Loss G: 2.5606\n",
      "Epoch [30/85] Batch 640/938 Loss D: 0.1767, Loss G: 2.5268\n",
      "Epoch [30/85] Batch 650/938 Loss D: 0.2906, Loss G: 2.0322\n",
      "Epoch [30/85] Batch 660/938 Loss D: 0.1826, Loss G: 2.4656\n",
      "Epoch [30/85] Batch 670/938 Loss D: 0.2497, Loss G: 2.5993\n",
      "Epoch [30/85] Batch 680/938 Loss D: 0.2565, Loss G: 2.7713\n",
      "Epoch [30/85] Batch 690/938 Loss D: 0.2712, Loss G: 2.2843\n",
      "Epoch [30/85] Batch 700/938 Loss D: 0.3852, Loss G: 1.7760\n",
      "Epoch [30/85] Batch 710/938 Loss D: 0.3239, Loss G: 2.0045\n",
      "Epoch [30/85] Batch 720/938 Loss D: 0.2338, Loss G: 1.9949\n",
      "Epoch [30/85] Batch 730/938 Loss D: 0.2447, Loss G: 1.8002\n",
      "Epoch [30/85] Batch 740/938 Loss D: 0.2042, Loss G: 2.6106\n",
      "Epoch [30/85] Batch 750/938 Loss D: 0.2884, Loss G: 2.4321\n",
      "Epoch [30/85] Batch 760/938 Loss D: 0.2111, Loss G: 2.5923\n",
      "Epoch [30/85] Batch 770/938 Loss D: 0.2242, Loss G: 2.6803\n",
      "Epoch [30/85] Batch 780/938 Loss D: 0.2649, Loss G: 2.7597\n",
      "Epoch [30/85] Batch 790/938 Loss D: 0.3059, Loss G: 2.2224\n",
      "Epoch [30/85] Batch 800/938 Loss D: 0.2582, Loss G: 2.1554\n",
      "Epoch [30/85] Batch 810/938 Loss D: 0.2622, Loss G: 2.6738\n",
      "Epoch [30/85] Batch 820/938 Loss D: 0.2493, Loss G: 2.5984\n",
      "Epoch [30/85] Batch 830/938 Loss D: 0.2514, Loss G: 2.5291\n",
      "Epoch [30/85] Batch 840/938 Loss D: 0.4239, Loss G: 2.4302\n",
      "Epoch [30/85] Batch 850/938 Loss D: 0.2409, Loss G: 2.7285\n",
      "Epoch [30/85] Batch 860/938 Loss D: 0.2248, Loss G: 2.6828\n",
      "Epoch [30/85] Batch 870/938 Loss D: 0.2768, Loss G: 2.3286\n",
      "Epoch [30/85] Batch 880/938 Loss D: 0.2436, Loss G: 2.4807\n",
      "Epoch [30/85] Batch 890/938 Loss D: 0.2420, Loss G: 2.4046\n",
      "Epoch [30/85] Batch 900/938 Loss D: 0.2760, Loss G: 2.1002\n",
      "Epoch [30/85] Batch 910/938 Loss D: 0.2931, Loss G: 2.0489\n",
      "Epoch [30/85] Batch 920/938 Loss D: 0.2281, Loss G: 2.3415\n",
      "Epoch [30/85] Batch 930/938 Loss D: 0.3251, Loss G: 2.0770\n",
      "Epoch [31/85] Batch 0/938 Loss D: 0.2314, Loss G: 2.1701\n",
      "Epoch [31/85] Batch 10/938 Loss D: 0.2383, Loss G: 1.8860\n",
      "Epoch [31/85] Batch 20/938 Loss D: 0.2927, Loss G: 2.2814\n",
      "Epoch [31/85] Batch 30/938 Loss D: 0.3777, Loss G: 2.5633\n",
      "Epoch [31/85] Batch 40/938 Loss D: 0.2845, Loss G: 2.2068\n",
      "Epoch [31/85] Batch 50/938 Loss D: 0.4751, Loss G: 2.2397\n",
      "Epoch [31/85] Batch 60/938 Loss D: 0.3016, Loss G: 2.7650\n",
      "Epoch [31/85] Batch 70/938 Loss D: 0.2146, Loss G: 2.6885\n",
      "Epoch [31/85] Batch 80/938 Loss D: 0.2929, Loss G: 2.3096\n",
      "Epoch [31/85] Batch 90/938 Loss D: 0.3884, Loss G: 1.8608\n",
      "Epoch [31/85] Batch 100/938 Loss D: 0.2569, Loss G: 2.3467\n",
      "Epoch [31/85] Batch 110/938 Loss D: 0.2842, Loss G: 2.1965\n",
      "Epoch [31/85] Batch 120/938 Loss D: 0.3580, Loss G: 2.4032\n",
      "Epoch [31/85] Batch 130/938 Loss D: 0.2730, Loss G: 2.8405\n",
      "Epoch [31/85] Batch 140/938 Loss D: 0.3978, Loss G: 2.4075\n",
      "Epoch [31/85] Batch 150/938 Loss D: 0.2571, Loss G: 2.4831\n",
      "Epoch [31/85] Batch 160/938 Loss D: 0.2678, Loss G: 2.4499\n",
      "Epoch [31/85] Batch 170/938 Loss D: 0.2223, Loss G: 2.3560\n",
      "Epoch [31/85] Batch 180/938 Loss D: 0.2297, Loss G: 3.1065\n",
      "Epoch [31/85] Batch 190/938 Loss D: 0.2419, Loss G: 2.0886\n",
      "Epoch [31/85] Batch 200/938 Loss D: 0.2730, Loss G: 2.2465\n",
      "Epoch [31/85] Batch 210/938 Loss D: 0.3820, Loss G: 2.4047\n",
      "Epoch [31/85] Batch 220/938 Loss D: 0.1676, Loss G: 3.0432\n",
      "Epoch [31/85] Batch 230/938 Loss D: 0.3166, Loss G: 2.0987\n",
      "Epoch [31/85] Batch 240/938 Loss D: 0.3548, Loss G: 1.7775\n",
      "Epoch [31/85] Batch 250/938 Loss D: 0.2506, Loss G: 2.3646\n",
      "Epoch [31/85] Batch 260/938 Loss D: 0.2662, Loss G: 2.2717\n",
      "Epoch [31/85] Batch 270/938 Loss D: 0.2944, Loss G: 2.5391\n",
      "Epoch [31/85] Batch 280/938 Loss D: 0.3683, Loss G: 1.7812\n",
      "Epoch [31/85] Batch 290/938 Loss D: 0.2572, Loss G: 2.3578\n",
      "Epoch [31/85] Batch 300/938 Loss D: 0.2633, Loss G: 1.9415\n",
      "Epoch [31/85] Batch 310/938 Loss D: 0.3679, Loss G: 2.3108\n",
      "Epoch [31/85] Batch 320/938 Loss D: 0.3094, Loss G: 2.1932\n",
      "Epoch [31/85] Batch 330/938 Loss D: 0.3266, Loss G: 2.3753\n",
      "Epoch [31/85] Batch 340/938 Loss D: 0.3348, Loss G: 2.1930\n",
      "Epoch [31/85] Batch 350/938 Loss D: 0.3319, Loss G: 1.7857\n",
      "Epoch [31/85] Batch 360/938 Loss D: 0.2603, Loss G: 1.7973\n",
      "Epoch [31/85] Batch 370/938 Loss D: 0.2850, Loss G: 2.1557\n",
      "Epoch [31/85] Batch 380/938 Loss D: 0.2324, Loss G: 2.9390\n",
      "Epoch [31/85] Batch 390/938 Loss D: 0.3040, Loss G: 2.5710\n",
      "Epoch [31/85] Batch 400/938 Loss D: 0.3057, Loss G: 2.1098\n",
      "Epoch [31/85] Batch 410/938 Loss D: 0.2032, Loss G: 2.8448\n",
      "Epoch [31/85] Batch 420/938 Loss D: 0.3627, Loss G: 2.2657\n",
      "Epoch [31/85] Batch 430/938 Loss D: 0.3637, Loss G: 2.0980\n",
      "Epoch [31/85] Batch 440/938 Loss D: 0.2946, Loss G: 2.0572\n",
      "Epoch [31/85] Batch 450/938 Loss D: 0.2999, Loss G: 2.1157\n",
      "Epoch [31/85] Batch 460/938 Loss D: 0.2896, Loss G: 2.1425\n",
      "Epoch [31/85] Batch 470/938 Loss D: 0.3326, Loss G: 2.4318\n",
      "Epoch [31/85] Batch 480/938 Loss D: 0.2803, Loss G: 2.0828\n",
      "Epoch [31/85] Batch 490/938 Loss D: 0.2496, Loss G: 2.4558\n",
      "Epoch [31/85] Batch 500/938 Loss D: 0.2586, Loss G: 2.4736\n",
      "Epoch [31/85] Batch 510/938 Loss D: 0.3357, Loss G: 2.8145\n",
      "Epoch [31/85] Batch 520/938 Loss D: 0.3086, Loss G: 2.4699\n",
      "Epoch [31/85] Batch 530/938 Loss D: 0.2498, Loss G: 2.0401\n",
      "Epoch [31/85] Batch 540/938 Loss D: 0.2333, Loss G: 2.2815\n",
      "Epoch [31/85] Batch 550/938 Loss D: 0.3105, Loss G: 2.7421\n",
      "Epoch [31/85] Batch 560/938 Loss D: 0.3918, Loss G: 2.2908\n",
      "Epoch [31/85] Batch 570/938 Loss D: 0.3545, Loss G: 2.1380\n",
      "Epoch [31/85] Batch 580/938 Loss D: 0.2696, Loss G: 2.4183\n",
      "Epoch [31/85] Batch 590/938 Loss D: 0.3023, Loss G: 3.1832\n",
      "Epoch [31/85] Batch 600/938 Loss D: 0.2795, Loss G: 2.4241\n",
      "Epoch [31/85] Batch 610/938 Loss D: 0.2071, Loss G: 2.7543\n",
      "Epoch [31/85] Batch 620/938 Loss D: 0.2680, Loss G: 2.0735\n",
      "Epoch [31/85] Batch 630/938 Loss D: 0.3346, Loss G: 2.0629\n",
      "Epoch [31/85] Batch 640/938 Loss D: 0.4098, Loss G: 1.5325\n",
      "Epoch [31/85] Batch 650/938 Loss D: 0.2459, Loss G: 2.2336\n",
      "Epoch [31/85] Batch 660/938 Loss D: 0.2681, Loss G: 2.0855\n",
      "Epoch [31/85] Batch 670/938 Loss D: 0.3041, Loss G: 1.8494\n",
      "Epoch [31/85] Batch 680/938 Loss D: 0.3310, Loss G: 2.2917\n",
      "Epoch [31/85] Batch 690/938 Loss D: 0.1808, Loss G: 2.9344\n",
      "Epoch [31/85] Batch 700/938 Loss D: 0.2262, Loss G: 3.2097\n",
      "Epoch [31/85] Batch 710/938 Loss D: 0.2467, Loss G: 2.5787\n",
      "Epoch [31/85] Batch 720/938 Loss D: 0.2219, Loss G: 2.5797\n",
      "Epoch [31/85] Batch 730/938 Loss D: 0.3136, Loss G: 2.0521\n",
      "Epoch [31/85] Batch 740/938 Loss D: 0.2859, Loss G: 2.0802\n",
      "Epoch [31/85] Batch 750/938 Loss D: 0.2361, Loss G: 2.1499\n",
      "Epoch [31/85] Batch 760/938 Loss D: 0.2378, Loss G: 2.2790\n",
      "Epoch [31/85] Batch 770/938 Loss D: 0.2929, Loss G: 2.2532\n",
      "Epoch [31/85] Batch 780/938 Loss D: 0.2328, Loss G: 2.6688\n",
      "Epoch [31/85] Batch 790/938 Loss D: 0.3384, Loss G: 2.3785\n",
      "Epoch [31/85] Batch 800/938 Loss D: 0.2735, Loss G: 2.4497\n",
      "Epoch [31/85] Batch 810/938 Loss D: 0.2203, Loss G: 2.4029\n",
      "Epoch [31/85] Batch 820/938 Loss D: 0.4220, Loss G: 2.1538\n",
      "Epoch [31/85] Batch 830/938 Loss D: 0.2120, Loss G: 2.1873\n",
      "Epoch [31/85] Batch 840/938 Loss D: 0.2380, Loss G: 2.8648\n",
      "Epoch [31/85] Batch 850/938 Loss D: 0.2368, Loss G: 2.2627\n",
      "Epoch [31/85] Batch 860/938 Loss D: 0.3241, Loss G: 2.2537\n",
      "Epoch [31/85] Batch 870/938 Loss D: 0.3125, Loss G: 2.4654\n",
      "Epoch [31/85] Batch 880/938 Loss D: 0.3519, Loss G: 2.5694\n",
      "Epoch [31/85] Batch 890/938 Loss D: 0.2510, Loss G: 2.1972\n",
      "Epoch [31/85] Batch 900/938 Loss D: 0.3156, Loss G: 1.7683\n",
      "Epoch [31/85] Batch 910/938 Loss D: 0.2383, Loss G: 2.1368\n",
      "Epoch [31/85] Batch 920/938 Loss D: 0.4344, Loss G: 1.7015\n",
      "Epoch [31/85] Batch 930/938 Loss D: 0.3228, Loss G: 1.9290\n",
      "Epoch [32/85] Batch 0/938 Loss D: 0.2801, Loss G: 1.9709\n",
      "Epoch [32/85] Batch 10/938 Loss D: 0.2950, Loss G: 2.3258\n",
      "Epoch [32/85] Batch 20/938 Loss D: 0.3573, Loss G: 2.2316\n",
      "Epoch [32/85] Batch 30/938 Loss D: 0.2602, Loss G: 2.6797\n",
      "Epoch [32/85] Batch 40/938 Loss D: 0.2186, Loss G: 2.6608\n",
      "Epoch [32/85] Batch 50/938 Loss D: 0.2674, Loss G: 2.6591\n",
      "Epoch [32/85] Batch 60/938 Loss D: 0.3127, Loss G: 2.0915\n",
      "Epoch [32/85] Batch 70/938 Loss D: 0.3416, Loss G: 1.8080\n",
      "Epoch [32/85] Batch 80/938 Loss D: 0.2563, Loss G: 2.9160\n",
      "Epoch [32/85] Batch 90/938 Loss D: 0.3082, Loss G: 2.4360\n",
      "Epoch [32/85] Batch 100/938 Loss D: 0.2585, Loss G: 2.4304\n",
      "Epoch [32/85] Batch 110/938 Loss D: 0.1579, Loss G: 2.6875\n",
      "Epoch [32/85] Batch 120/938 Loss D: 0.2262, Loss G: 2.1654\n",
      "Epoch [32/85] Batch 130/938 Loss D: 0.3735, Loss G: 1.9273\n",
      "Epoch [32/85] Batch 140/938 Loss D: 0.3272, Loss G: 1.8758\n",
      "Epoch [32/85] Batch 150/938 Loss D: 0.2643, Loss G: 2.4239\n",
      "Epoch [32/85] Batch 160/938 Loss D: 0.3172, Loss G: 2.4846\n",
      "Epoch [32/85] Batch 170/938 Loss D: 0.2493, Loss G: 2.2656\n",
      "Epoch [32/85] Batch 180/938 Loss D: 0.2876, Loss G: 2.1947\n",
      "Epoch [32/85] Batch 190/938 Loss D: 0.2526, Loss G: 2.5923\n",
      "Epoch [32/85] Batch 200/938 Loss D: 0.2894, Loss G: 2.1646\n",
      "Epoch [32/85] Batch 210/938 Loss D: 0.2181, Loss G: 2.3993\n",
      "Epoch [32/85] Batch 220/938 Loss D: 0.2465, Loss G: 2.6581\n",
      "Epoch [32/85] Batch 230/938 Loss D: 0.2913, Loss G: 2.3645\n",
      "Epoch [32/85] Batch 240/938 Loss D: 0.2693, Loss G: 2.3029\n",
      "Epoch [32/85] Batch 250/938 Loss D: 0.2811, Loss G: 2.7789\n",
      "Epoch [32/85] Batch 260/938 Loss D: 0.2535, Loss G: 2.7966\n",
      "Epoch [32/85] Batch 270/938 Loss D: 0.3551, Loss G: 2.0152\n",
      "Epoch [32/85] Batch 280/938 Loss D: 0.1936, Loss G: 2.5661\n",
      "Epoch [32/85] Batch 290/938 Loss D: 0.3323, Loss G: 1.7770\n",
      "Epoch [32/85] Batch 300/938 Loss D: 0.3342, Loss G: 1.9041\n",
      "Epoch [32/85] Batch 310/938 Loss D: 0.2863, Loss G: 2.1411\n",
      "Epoch [32/85] Batch 320/938 Loss D: 0.2547, Loss G: 2.6766\n",
      "Epoch [32/85] Batch 330/938 Loss D: 0.3586, Loss G: 1.9271\n",
      "Epoch [32/85] Batch 340/938 Loss D: 0.2051, Loss G: 2.6707\n",
      "Epoch [32/85] Batch 350/938 Loss D: 0.3292, Loss G: 2.0613\n",
      "Epoch [32/85] Batch 360/938 Loss D: 0.3047, Loss G: 2.1370\n",
      "Epoch [32/85] Batch 370/938 Loss D: 0.2970, Loss G: 2.5566\n",
      "Epoch [32/85] Batch 380/938 Loss D: 0.3112, Loss G: 2.1657\n",
      "Epoch [32/85] Batch 390/938 Loss D: 0.2115, Loss G: 2.5699\n",
      "Epoch [32/85] Batch 400/938 Loss D: 0.2874, Loss G: 2.5629\n",
      "Epoch [32/85] Batch 410/938 Loss D: 0.3825, Loss G: 1.9840\n",
      "Epoch [32/85] Batch 420/938 Loss D: 0.4225, Loss G: 1.8013\n",
      "Epoch [32/85] Batch 430/938 Loss D: 0.2840, Loss G: 2.4151\n",
      "Epoch [32/85] Batch 440/938 Loss D: 0.2894, Loss G: 1.9496\n",
      "Epoch [32/85] Batch 450/938 Loss D: 0.3219, Loss G: 2.1165\n",
      "Epoch [32/85] Batch 460/938 Loss D: 0.2653, Loss G: 2.1846\n",
      "Epoch [32/85] Batch 470/938 Loss D: 0.4350, Loss G: 1.7038\n",
      "Epoch [32/85] Batch 480/938 Loss D: 0.3269, Loss G: 2.7623\n",
      "Epoch [32/85] Batch 490/938 Loss D: 0.2969, Loss G: 2.3182\n",
      "Epoch [32/85] Batch 500/938 Loss D: 0.3876, Loss G: 1.9578\n",
      "Epoch [32/85] Batch 510/938 Loss D: 0.3057, Loss G: 2.1483\n",
      "Epoch [32/85] Batch 520/938 Loss D: 0.2893, Loss G: 1.7074\n",
      "Epoch [32/85] Batch 530/938 Loss D: 0.2942, Loss G: 2.2230\n",
      "Epoch [32/85] Batch 540/938 Loss D: 0.1689, Loss G: 3.8001\n",
      "Epoch [32/85] Batch 550/938 Loss D: 0.3096, Loss G: 3.0344\n",
      "Epoch [32/85] Batch 560/938 Loss D: 0.3242, Loss G: 2.7259\n",
      "Epoch [32/85] Batch 570/938 Loss D: 0.3847, Loss G: 1.8789\n",
      "Epoch [32/85] Batch 580/938 Loss D: 0.3524, Loss G: 2.0020\n",
      "Epoch [32/85] Batch 590/938 Loss D: 0.2812, Loss G: 2.0621\n",
      "Epoch [32/85] Batch 600/938 Loss D: 0.2822, Loss G: 2.1051\n",
      "Epoch [32/85] Batch 610/938 Loss D: 0.2767, Loss G: 2.2528\n",
      "Epoch [32/85] Batch 620/938 Loss D: 0.4044, Loss G: 2.3571\n",
      "Epoch [32/85] Batch 630/938 Loss D: 0.3467, Loss G: 2.2085\n",
      "Epoch [32/85] Batch 640/938 Loss D: 0.3397, Loss G: 2.9088\n",
      "Epoch [32/85] Batch 650/938 Loss D: 0.2874, Loss G: 2.8585\n",
      "Epoch [32/85] Batch 660/938 Loss D: 0.3576, Loss G: 1.8011\n",
      "Epoch [32/85] Batch 670/938 Loss D: 0.2423, Loss G: 2.3324\n",
      "Epoch [32/85] Batch 680/938 Loss D: 0.3064, Loss G: 2.2707\n",
      "Epoch [32/85] Batch 690/938 Loss D: 0.2439, Loss G: 2.6505\n",
      "Epoch [32/85] Batch 700/938 Loss D: 0.2592, Loss G: 2.6767\n",
      "Epoch [32/85] Batch 710/938 Loss D: 0.2335, Loss G: 2.5712\n",
      "Epoch [32/85] Batch 720/938 Loss D: 0.2830, Loss G: 2.5752\n",
      "Epoch [32/85] Batch 730/938 Loss D: 0.3630, Loss G: 1.7803\n",
      "Epoch [32/85] Batch 740/938 Loss D: 0.2982, Loss G: 2.7376\n",
      "Epoch [32/85] Batch 750/938 Loss D: 0.2268, Loss G: 2.5302\n",
      "Epoch [32/85] Batch 760/938 Loss D: 0.3706, Loss G: 2.1744\n",
      "Epoch [32/85] Batch 770/938 Loss D: 0.4101, Loss G: 2.4421\n",
      "Epoch [32/85] Batch 780/938 Loss D: 0.5733, Loss G: 2.1630\n",
      "Epoch [32/85] Batch 790/938 Loss D: 0.2535, Loss G: 2.6270\n",
      "Epoch [32/85] Batch 800/938 Loss D: 0.2914, Loss G: 2.2930\n",
      "Epoch [32/85] Batch 810/938 Loss D: 0.2335, Loss G: 2.7263\n",
      "Epoch [32/85] Batch 820/938 Loss D: 0.3626, Loss G: 2.2940\n",
      "Epoch [32/85] Batch 830/938 Loss D: 0.2580, Loss G: 1.8703\n",
      "Epoch [32/85] Batch 840/938 Loss D: 0.2821, Loss G: 2.0325\n",
      "Epoch [32/85] Batch 850/938 Loss D: 0.2564, Loss G: 2.4738\n",
      "Epoch [32/85] Batch 860/938 Loss D: 0.3669, Loss G: 2.0428\n",
      "Epoch [32/85] Batch 870/938 Loss D: 0.3285, Loss G: 1.9692\n",
      "Epoch [32/85] Batch 880/938 Loss D: 0.1970, Loss G: 2.8630\n",
      "Epoch [32/85] Batch 890/938 Loss D: 0.2822, Loss G: 2.4199\n",
      "Epoch [32/85] Batch 900/938 Loss D: 0.3216, Loss G: 1.9144\n",
      "Epoch [32/85] Batch 910/938 Loss D: 0.3554, Loss G: 1.8406\n",
      "Epoch [32/85] Batch 920/938 Loss D: 0.2582, Loss G: 2.2063\n",
      "Epoch [32/85] Batch 930/938 Loss D: 0.2927, Loss G: 1.9669\n",
      "Epoch [33/85] Batch 0/938 Loss D: 0.3774, Loss G: 2.5009\n",
      "Epoch [33/85] Batch 10/938 Loss D: 0.2735, Loss G: 2.7405\n",
      "Epoch [33/85] Batch 20/938 Loss D: 0.4335, Loss G: 2.6217\n",
      "Epoch [33/85] Batch 30/938 Loss D: 0.3063, Loss G: 2.7691\n",
      "Epoch [33/85] Batch 40/938 Loss D: 0.2652, Loss G: 2.4533\n",
      "Epoch [33/85] Batch 50/938 Loss D: 0.3910, Loss G: 2.0105\n",
      "Epoch [33/85] Batch 60/938 Loss D: 0.2545, Loss G: 2.1765\n",
      "Epoch [33/85] Batch 70/938 Loss D: 0.3664, Loss G: 2.5270\n",
      "Epoch [33/85] Batch 80/938 Loss D: 0.2677, Loss G: 2.8944\n",
      "Epoch [33/85] Batch 90/938 Loss D: 0.3020, Loss G: 2.2673\n",
      "Epoch [33/85] Batch 100/938 Loss D: 0.3266, Loss G: 2.3278\n",
      "Epoch [33/85] Batch 110/938 Loss D: 0.2978, Loss G: 2.6651\n",
      "Epoch [33/85] Batch 120/938 Loss D: 0.2722, Loss G: 2.5127\n",
      "Epoch [33/85] Batch 130/938 Loss D: 0.3042, Loss G: 2.0685\n",
      "Epoch [33/85] Batch 140/938 Loss D: 0.3151, Loss G: 2.2071\n",
      "Epoch [33/85] Batch 150/938 Loss D: 0.3646, Loss G: 2.0568\n",
      "Epoch [33/85] Batch 160/938 Loss D: 0.3584, Loss G: 2.1510\n",
      "Epoch [33/85] Batch 170/938 Loss D: 0.2964, Loss G: 2.5714\n",
      "Epoch [33/85] Batch 180/938 Loss D: 0.2664, Loss G: 2.0983\n",
      "Epoch [33/85] Batch 190/938 Loss D: 0.2761, Loss G: 2.5428\n",
      "Epoch [33/85] Batch 200/938 Loss D: 0.2302, Loss G: 2.8668\n",
      "Epoch [33/85] Batch 210/938 Loss D: 0.3367, Loss G: 2.3116\n",
      "Epoch [33/85] Batch 220/938 Loss D: 0.2981, Loss G: 2.1367\n",
      "Epoch [33/85] Batch 230/938 Loss D: 0.3259, Loss G: 1.7794\n",
      "Epoch [33/85] Batch 240/938 Loss D: 0.3280, Loss G: 2.2227\n",
      "Epoch [33/85] Batch 250/938 Loss D: 0.2624, Loss G: 2.7881\n",
      "Epoch [33/85] Batch 260/938 Loss D: 0.3583, Loss G: 2.3919\n",
      "Epoch [33/85] Batch 270/938 Loss D: 0.2844, Loss G: 2.4563\n",
      "Epoch [33/85] Batch 280/938 Loss D: 0.3844, Loss G: 1.6779\n",
      "Epoch [33/85] Batch 290/938 Loss D: 0.2742, Loss G: 1.7601\n",
      "Epoch [33/85] Batch 300/938 Loss D: 0.2504, Loss G: 1.8645\n",
      "Epoch [33/85] Batch 310/938 Loss D: 0.2892, Loss G: 1.9338\n",
      "Epoch [33/85] Batch 320/938 Loss D: 0.3681, Loss G: 2.0078\n",
      "Epoch [33/85] Batch 330/938 Loss D: 0.2406, Loss G: 3.3023\n",
      "Epoch [33/85] Batch 340/938 Loss D: 0.2794, Loss G: 2.8892\n",
      "Epoch [33/85] Batch 350/938 Loss D: 0.2667, Loss G: 2.0873\n",
      "Epoch [33/85] Batch 360/938 Loss D: 0.2986, Loss G: 1.6398\n",
      "Epoch [33/85] Batch 370/938 Loss D: 0.2297, Loss G: 2.5268\n",
      "Epoch [33/85] Batch 380/938 Loss D: 0.2430, Loss G: 2.6062\n",
      "Epoch [33/85] Batch 390/938 Loss D: 0.2525, Loss G: 2.0935\n",
      "Epoch [33/85] Batch 400/938 Loss D: 0.3255, Loss G: 2.0164\n",
      "Epoch [33/85] Batch 410/938 Loss D: 0.3444, Loss G: 1.8804\n",
      "Epoch [33/85] Batch 420/938 Loss D: 0.2474, Loss G: 3.0878\n",
      "Epoch [33/85] Batch 430/938 Loss D: 0.3073, Loss G: 2.9161\n",
      "Epoch [33/85] Batch 440/938 Loss D: 0.2197, Loss G: 2.4516\n",
      "Epoch [33/85] Batch 450/938 Loss D: 0.2201, Loss G: 2.6351\n",
      "Epoch [33/85] Batch 460/938 Loss D: 0.3588, Loss G: 1.7706\n",
      "Epoch [33/85] Batch 470/938 Loss D: 0.3376, Loss G: 1.8592\n",
      "Epoch [33/85] Batch 480/938 Loss D: 0.3284, Loss G: 1.8273\n",
      "Epoch [33/85] Batch 490/938 Loss D: 0.4162, Loss G: 1.9556\n",
      "Epoch [33/85] Batch 500/938 Loss D: 0.2372, Loss G: 2.4666\n",
      "Epoch [33/85] Batch 510/938 Loss D: 0.2693, Loss G: 2.0772\n",
      "Epoch [33/85] Batch 520/938 Loss D: 0.3031, Loss G: 2.6840\n",
      "Epoch [33/85] Batch 530/938 Loss D: 0.3668, Loss G: 2.4057\n",
      "Epoch [33/85] Batch 540/938 Loss D: 0.3109, Loss G: 2.7779\n",
      "Epoch [33/85] Batch 550/938 Loss D: 0.2290, Loss G: 3.2035\n",
      "Epoch [33/85] Batch 560/938 Loss D: 0.2592, Loss G: 2.7875\n",
      "Epoch [33/85] Batch 570/938 Loss D: 0.3626, Loss G: 1.8574\n",
      "Epoch [33/85] Batch 580/938 Loss D: 0.1702, Loss G: 2.8302\n",
      "Epoch [33/85] Batch 590/938 Loss D: 0.2738, Loss G: 3.0259\n",
      "Epoch [33/85] Batch 600/938 Loss D: 0.2453, Loss G: 3.1259\n",
      "Epoch [33/85] Batch 610/938 Loss D: 0.2494, Loss G: 3.1731\n",
      "Epoch [33/85] Batch 620/938 Loss D: 0.2802, Loss G: 2.3015\n",
      "Epoch [33/85] Batch 630/938 Loss D: 0.2597, Loss G: 2.1820\n",
      "Epoch [33/85] Batch 640/938 Loss D: 0.3840, Loss G: 1.6168\n",
      "Epoch [33/85] Batch 650/938 Loss D: 0.2458, Loss G: 1.9807\n",
      "Epoch [33/85] Batch 660/938 Loss D: 0.3359, Loss G: 1.9137\n",
      "Epoch [33/85] Batch 670/938 Loss D: 0.3995, Loss G: 2.0806\n",
      "Epoch [33/85] Batch 680/938 Loss D: 0.2440, Loss G: 2.9192\n",
      "Epoch [33/85] Batch 690/938 Loss D: 0.2257, Loss G: 2.5553\n",
      "Epoch [33/85] Batch 700/938 Loss D: 0.2389, Loss G: 2.8552\n",
      "Epoch [33/85] Batch 710/938 Loss D: 0.3130, Loss G: 2.3110\n",
      "Epoch [33/85] Batch 720/938 Loss D: 0.2039, Loss G: 2.2415\n",
      "Epoch [33/85] Batch 730/938 Loss D: 0.3293, Loss G: 2.2837\n",
      "Epoch [33/85] Batch 740/938 Loss D: 0.2823, Loss G: 2.1461\n",
      "Epoch [33/85] Batch 750/938 Loss D: 0.3571, Loss G: 1.8716\n",
      "Epoch [33/85] Batch 760/938 Loss D: 0.2321, Loss G: 2.6669\n",
      "Epoch [33/85] Batch 770/938 Loss D: 0.2771, Loss G: 2.3165\n",
      "Epoch [33/85] Batch 780/938 Loss D: 0.2799, Loss G: 2.6939\n",
      "Epoch [33/85] Batch 790/938 Loss D: 0.2862, Loss G: 2.3529\n",
      "Epoch [33/85] Batch 800/938 Loss D: 0.3938, Loss G: 1.8659\n",
      "Epoch [33/85] Batch 810/938 Loss D: 0.2882, Loss G: 1.9104\n",
      "Epoch [33/85] Batch 820/938 Loss D: 0.2765, Loss G: 2.3160\n",
      "Epoch [33/85] Batch 830/938 Loss D: 0.3133, Loss G: 2.5600\n",
      "Epoch [33/85] Batch 840/938 Loss D: 0.2504, Loss G: 2.4084\n",
      "Epoch [33/85] Batch 850/938 Loss D: 0.3218, Loss G: 1.9787\n",
      "Epoch [33/85] Batch 860/938 Loss D: 0.3217, Loss G: 2.5452\n",
      "Epoch [33/85] Batch 870/938 Loss D: 0.3037, Loss G: 1.9939\n",
      "Epoch [33/85] Batch 880/938 Loss D: 0.3359, Loss G: 1.8671\n",
      "Epoch [33/85] Batch 890/938 Loss D: 0.2615, Loss G: 2.5701\n",
      "Epoch [33/85] Batch 900/938 Loss D: 0.3471, Loss G: 1.6855\n",
      "Epoch [33/85] Batch 910/938 Loss D: 0.2624, Loss G: 2.0407\n",
      "Epoch [33/85] Batch 920/938 Loss D: 0.2272, Loss G: 2.4466\n",
      "Epoch [33/85] Batch 930/938 Loss D: 0.2575, Loss G: 2.5494\n",
      "Epoch [34/85] Batch 0/938 Loss D: 0.3519, Loss G: 1.7132\n",
      "Epoch [34/85] Batch 10/938 Loss D: 0.3270, Loss G: 2.5367\n",
      "Epoch [34/85] Batch 20/938 Loss D: 0.3018, Loss G: 2.4407\n",
      "Epoch [34/85] Batch 30/938 Loss D: 0.2724, Loss G: 2.7908\n",
      "Epoch [34/85] Batch 40/938 Loss D: 0.3219, Loss G: 1.9990\n",
      "Epoch [34/85] Batch 50/938 Loss D: 0.2952, Loss G: 1.8600\n",
      "Epoch [34/85] Batch 60/938 Loss D: 0.3299, Loss G: 2.2235\n",
      "Epoch [34/85] Batch 70/938 Loss D: 0.1954, Loss G: 2.6621\n",
      "Epoch [34/85] Batch 80/938 Loss D: 0.3901, Loss G: 1.6598\n",
      "Epoch [34/85] Batch 90/938 Loss D: 0.2904, Loss G: 1.8028\n",
      "Epoch [34/85] Batch 100/938 Loss D: 0.2571, Loss G: 2.6772\n",
      "Epoch [34/85] Batch 110/938 Loss D: 0.3410, Loss G: 2.7175\n",
      "Epoch [34/85] Batch 120/938 Loss D: 0.3067, Loss G: 2.2501\n",
      "Epoch [34/85] Batch 130/938 Loss D: 0.2589, Loss G: 2.2502\n",
      "Epoch [34/85] Batch 140/938 Loss D: 0.3229, Loss G: 2.2478\n",
      "Epoch [34/85] Batch 150/938 Loss D: 0.3243, Loss G: 2.1185\n",
      "Epoch [34/85] Batch 160/938 Loss D: 0.3148, Loss G: 2.2271\n",
      "Epoch [34/85] Batch 170/938 Loss D: 0.2335, Loss G: 2.3512\n",
      "Epoch [34/85] Batch 180/938 Loss D: 0.3021, Loss G: 1.9975\n",
      "Epoch [34/85] Batch 190/938 Loss D: 0.2649, Loss G: 2.3391\n",
      "Epoch [34/85] Batch 200/938 Loss D: 0.3253, Loss G: 2.0585\n",
      "Epoch [34/85] Batch 210/938 Loss D: 0.2865, Loss G: 2.1032\n",
      "Epoch [34/85] Batch 220/938 Loss D: 0.3304, Loss G: 1.9190\n",
      "Epoch [34/85] Batch 230/938 Loss D: 0.3344, Loss G: 2.0226\n",
      "Epoch [34/85] Batch 240/938 Loss D: 0.2705, Loss G: 2.1053\n",
      "Epoch [34/85] Batch 250/938 Loss D: 0.3287, Loss G: 2.2539\n",
      "Epoch [34/85] Batch 260/938 Loss D: 0.3033, Loss G: 2.4077\n",
      "Epoch [34/85] Batch 270/938 Loss D: 0.1552, Loss G: 2.7038\n",
      "Epoch [34/85] Batch 280/938 Loss D: 0.3085, Loss G: 2.5916\n",
      "Epoch [34/85] Batch 290/938 Loss D: 0.3045, Loss G: 2.5177\n",
      "Epoch [34/85] Batch 300/938 Loss D: 0.2191, Loss G: 2.3268\n",
      "Epoch [34/85] Batch 310/938 Loss D: 0.2660, Loss G: 2.2887\n",
      "Epoch [34/85] Batch 320/938 Loss D: 0.1995, Loss G: 2.4382\n",
      "Epoch [34/85] Batch 330/938 Loss D: 0.2833, Loss G: 2.0429\n",
      "Epoch [34/85] Batch 340/938 Loss D: 0.2577, Loss G: 2.5687\n",
      "Epoch [34/85] Batch 350/938 Loss D: 0.3364, Loss G: 2.7459\n",
      "Epoch [34/85] Batch 360/938 Loss D: 0.3716, Loss G: 1.9793\n",
      "Epoch [34/85] Batch 370/938 Loss D: 0.2726, Loss G: 2.5098\n",
      "Epoch [34/85] Batch 380/938 Loss D: 0.2818, Loss G: 2.4326\n",
      "Epoch [34/85] Batch 390/938 Loss D: 0.2243, Loss G: 2.3625\n",
      "Epoch [34/85] Batch 400/938 Loss D: 0.2668, Loss G: 2.1835\n",
      "Epoch [34/85] Batch 410/938 Loss D: 0.2641, Loss G: 2.4701\n",
      "Epoch [34/85] Batch 420/938 Loss D: 0.2623, Loss G: 2.3630\n",
      "Epoch [34/85] Batch 430/938 Loss D: 0.2765, Loss G: 1.8020\n",
      "Epoch [34/85] Batch 440/938 Loss D: 0.3429, Loss G: 1.8634\n",
      "Epoch [34/85] Batch 450/938 Loss D: 0.2111, Loss G: 2.6719\n",
      "Epoch [34/85] Batch 460/938 Loss D: 0.3516, Loss G: 1.9782\n",
      "Epoch [34/85] Batch 470/938 Loss D: 0.2657, Loss G: 2.8428\n",
      "Epoch [34/85] Batch 480/938 Loss D: 0.3547, Loss G: 2.3698\n",
      "Epoch [34/85] Batch 490/938 Loss D: 0.4379, Loss G: 2.1291\n",
      "Epoch [34/85] Batch 500/938 Loss D: 0.3698, Loss G: 2.3435\n",
      "Epoch [34/85] Batch 510/938 Loss D: 0.3244, Loss G: 2.7521\n",
      "Epoch [34/85] Batch 520/938 Loss D: 0.2600, Loss G: 1.8877\n",
      "Epoch [34/85] Batch 530/938 Loss D: 0.3900, Loss G: 1.9270\n",
      "Epoch [34/85] Batch 540/938 Loss D: 0.3241, Loss G: 1.8138\n",
      "Epoch [34/85] Batch 550/938 Loss D: 0.2802, Loss G: 2.7683\n",
      "Epoch [34/85] Batch 560/938 Loss D: 0.3091, Loss G: 2.3829\n",
      "Epoch [34/85] Batch 570/938 Loss D: 0.4311, Loss G: 2.2520\n",
      "Epoch [34/85] Batch 580/938 Loss D: 0.3068, Loss G: 2.0475\n",
      "Epoch [34/85] Batch 590/938 Loss D: 0.3154, Loss G: 2.4115\n",
      "Epoch [34/85] Batch 600/938 Loss D: 0.2489, Loss G: 2.0756\n",
      "Epoch [34/85] Batch 610/938 Loss D: 0.3038, Loss G: 1.8422\n",
      "Epoch [34/85] Batch 620/938 Loss D: 0.2990, Loss G: 2.6059\n",
      "Epoch [34/85] Batch 630/938 Loss D: 0.3226, Loss G: 2.5081\n",
      "Epoch [34/85] Batch 640/938 Loss D: 0.3062, Loss G: 2.2660\n",
      "Epoch [34/85] Batch 650/938 Loss D: 0.2311, Loss G: 2.8362\n",
      "Epoch [34/85] Batch 660/938 Loss D: 0.3044, Loss G: 2.4516\n",
      "Epoch [34/85] Batch 670/938 Loss D: 0.2739, Loss G: 2.0700\n",
      "Epoch [34/85] Batch 680/938 Loss D: 0.5078, Loss G: 2.1331\n",
      "Epoch [34/85] Batch 690/938 Loss D: 0.3062, Loss G: 2.4209\n",
      "Epoch [34/85] Batch 700/938 Loss D: 0.2984, Loss G: 2.2892\n",
      "Epoch [34/85] Batch 710/938 Loss D: 0.2916, Loss G: 2.8845\n",
      "Epoch [34/85] Batch 720/938 Loss D: 0.5098, Loss G: 2.6909\n",
      "Epoch [34/85] Batch 730/938 Loss D: 0.3591, Loss G: 2.2101\n",
      "Epoch [34/85] Batch 740/938 Loss D: 0.2695, Loss G: 2.2434\n",
      "Epoch [34/85] Batch 750/938 Loss D: 0.2762, Loss G: 2.7298\n",
      "Epoch [34/85] Batch 760/938 Loss D: 0.3184, Loss G: 2.3060\n",
      "Epoch [34/85] Batch 770/938 Loss D: 0.2578, Loss G: 2.2590\n",
      "Epoch [34/85] Batch 780/938 Loss D: 0.3482, Loss G: 1.9679\n",
      "Epoch [34/85] Batch 790/938 Loss D: 0.2575, Loss G: 3.1036\n",
      "Epoch [34/85] Batch 800/938 Loss D: 0.3092, Loss G: 2.7634\n",
      "Epoch [34/85] Batch 810/938 Loss D: 0.3058, Loss G: 3.1665\n",
      "Epoch [34/85] Batch 820/938 Loss D: 0.4247, Loss G: 2.7573\n",
      "Epoch [34/85] Batch 830/938 Loss D: 0.3295, Loss G: 2.0398\n",
      "Epoch [34/85] Batch 840/938 Loss D: 0.2698, Loss G: 2.2641\n",
      "Epoch [34/85] Batch 850/938 Loss D: 0.3414, Loss G: 1.9925\n",
      "Epoch [34/85] Batch 860/938 Loss D: 0.3099, Loss G: 2.1218\n",
      "Epoch [34/85] Batch 870/938 Loss D: 0.2532, Loss G: 2.2810\n",
      "Epoch [34/85] Batch 880/938 Loss D: 0.3180, Loss G: 2.2496\n",
      "Epoch [34/85] Batch 890/938 Loss D: 0.2461, Loss G: 2.5486\n",
      "Epoch [34/85] Batch 900/938 Loss D: 0.3370, Loss G: 3.5201\n",
      "Epoch [34/85] Batch 910/938 Loss D: 0.3532, Loss G: 2.5398\n",
      "Epoch [34/85] Batch 920/938 Loss D: 0.3199, Loss G: 2.2492\n",
      "Epoch [34/85] Batch 930/938 Loss D: 0.2533, Loss G: 2.5961\n",
      "Epoch [35/85] Batch 0/938 Loss D: 0.2949, Loss G: 1.8808\n",
      "Epoch [35/85] Batch 10/938 Loss D: 0.2072, Loss G: 2.1467\n",
      "Epoch [35/85] Batch 20/938 Loss D: 0.2809, Loss G: 2.5023\n",
      "Epoch [35/85] Batch 30/938 Loss D: 0.3559, Loss G: 2.1585\n",
      "Epoch [35/85] Batch 40/938 Loss D: 0.3366, Loss G: 2.0150\n",
      "Epoch [35/85] Batch 50/938 Loss D: 0.2448, Loss G: 3.4867\n",
      "Epoch [35/85] Batch 60/938 Loss D: 0.3567, Loss G: 2.0795\n",
      "Epoch [35/85] Batch 70/938 Loss D: 0.3260, Loss G: 2.3102\n",
      "Epoch [35/85] Batch 80/938 Loss D: 0.2241, Loss G: 2.8342\n",
      "Epoch [35/85] Batch 90/938 Loss D: 0.2835, Loss G: 2.3558\n",
      "Epoch [35/85] Batch 100/938 Loss D: 0.3040, Loss G: 2.3019\n",
      "Epoch [35/85] Batch 110/938 Loss D: 0.2945, Loss G: 2.1367\n",
      "Epoch [35/85] Batch 120/938 Loss D: 0.2255, Loss G: 2.6957\n",
      "Epoch [35/85] Batch 130/938 Loss D: 0.3369, Loss G: 2.1314\n",
      "Epoch [35/85] Batch 140/938 Loss D: 0.3504, Loss G: 2.5640\n",
      "Epoch [35/85] Batch 150/938 Loss D: 0.2713, Loss G: 2.3450\n",
      "Epoch [35/85] Batch 160/938 Loss D: 0.2986, Loss G: 1.8991\n",
      "Epoch [35/85] Batch 170/938 Loss D: 0.2306, Loss G: 2.3393\n",
      "Epoch [35/85] Batch 180/938 Loss D: 0.2965, Loss G: 2.1388\n",
      "Epoch [35/85] Batch 190/938 Loss D: 0.2841, Loss G: 1.8988\n",
      "Epoch [35/85] Batch 200/938 Loss D: 0.2871, Loss G: 1.7693\n",
      "Epoch [35/85] Batch 210/938 Loss D: 0.2599, Loss G: 2.4107\n",
      "Epoch [35/85] Batch 220/938 Loss D: 0.2398, Loss G: 2.1634\n",
      "Epoch [35/85] Batch 230/938 Loss D: 0.4000, Loss G: 2.4032\n",
      "Epoch [35/85] Batch 240/938 Loss D: 0.3741, Loss G: 2.0181\n",
      "Epoch [35/85] Batch 250/938 Loss D: 0.2644, Loss G: 2.0739\n",
      "Epoch [35/85] Batch 260/938 Loss D: 0.5383, Loss G: 1.6097\n",
      "Epoch [35/85] Batch 270/938 Loss D: 0.4338, Loss G: 2.0674\n",
      "Epoch [35/85] Batch 280/938 Loss D: 0.3719, Loss G: 2.0279\n",
      "Epoch [35/85] Batch 290/938 Loss D: 0.3710, Loss G: 2.2014\n",
      "Epoch [35/85] Batch 300/938 Loss D: 0.1453, Loss G: 2.8251\n",
      "Epoch [35/85] Batch 310/938 Loss D: 0.3268, Loss G: 2.0382\n",
      "Epoch [35/85] Batch 320/938 Loss D: 0.3095, Loss G: 1.9861\n",
      "Epoch [35/85] Batch 330/938 Loss D: 0.2783, Loss G: 2.4026\n",
      "Epoch [35/85] Batch 340/938 Loss D: 0.2843, Loss G: 2.1875\n",
      "Epoch [35/85] Batch 350/938 Loss D: 0.2535, Loss G: 2.4780\n",
      "Epoch [35/85] Batch 360/938 Loss D: 0.2468, Loss G: 2.4043\n",
      "Epoch [35/85] Batch 370/938 Loss D: 0.2814, Loss G: 2.9967\n",
      "Epoch [35/85] Batch 380/938 Loss D: 0.3073, Loss G: 1.8330\n",
      "Epoch [35/85] Batch 390/938 Loss D: 0.3224, Loss G: 1.7360\n",
      "Epoch [35/85] Batch 400/938 Loss D: 0.2855, Loss G: 2.5903\n",
      "Epoch [35/85] Batch 410/938 Loss D: 0.1973, Loss G: 2.4728\n",
      "Epoch [35/85] Batch 420/938 Loss D: 0.3002, Loss G: 1.9303\n",
      "Epoch [35/85] Batch 430/938 Loss D: 0.3594, Loss G: 1.8128\n",
      "Epoch [35/85] Batch 440/938 Loss D: 0.3238, Loss G: 1.7473\n",
      "Epoch [35/85] Batch 450/938 Loss D: 0.3378, Loss G: 2.1926\n",
      "Epoch [35/85] Batch 460/938 Loss D: 0.4549, Loss G: 2.3839\n",
      "Epoch [35/85] Batch 470/938 Loss D: 0.2636, Loss G: 2.3000\n",
      "Epoch [35/85] Batch 480/938 Loss D: 0.2605, Loss G: 2.7505\n",
      "Epoch [35/85] Batch 490/938 Loss D: 0.3349, Loss G: 2.2322\n",
      "Epoch [35/85] Batch 500/938 Loss D: 0.3359, Loss G: 1.8840\n",
      "Epoch [35/85] Batch 510/938 Loss D: 0.2718, Loss G: 2.3696\n",
      "Epoch [35/85] Batch 520/938 Loss D: 0.2045, Loss G: 2.4376\n",
      "Epoch [35/85] Batch 530/938 Loss D: 0.2853, Loss G: 1.9393\n",
      "Epoch [35/85] Batch 540/938 Loss D: 0.3398, Loss G: 1.8091\n",
      "Epoch [35/85] Batch 550/938 Loss D: 0.4386, Loss G: 1.7101\n",
      "Epoch [35/85] Batch 560/938 Loss D: 0.4323, Loss G: 1.9335\n",
      "Epoch [35/85] Batch 570/938 Loss D: 0.3299, Loss G: 2.5956\n",
      "Epoch [35/85] Batch 580/938 Loss D: 0.2950, Loss G: 2.4583\n",
      "Epoch [35/85] Batch 590/938 Loss D: 0.2570, Loss G: 3.3055\n",
      "Epoch [35/85] Batch 600/938 Loss D: 0.3723, Loss G: 2.5327\n",
      "Epoch [35/85] Batch 610/938 Loss D: 0.4429, Loss G: 2.5426\n",
      "Epoch [35/85] Batch 620/938 Loss D: 0.2387, Loss G: 3.0842\n",
      "Epoch [35/85] Batch 630/938 Loss D: 0.2111, Loss G: 2.3537\n",
      "Epoch [35/85] Batch 640/938 Loss D: 0.3292, Loss G: 1.9029\n",
      "Epoch [35/85] Batch 650/938 Loss D: 0.2518, Loss G: 2.1119\n",
      "Epoch [35/85] Batch 660/938 Loss D: 0.3474, Loss G: 2.2655\n",
      "Epoch [35/85] Batch 670/938 Loss D: 0.4222, Loss G: 2.3011\n",
      "Epoch [35/85] Batch 680/938 Loss D: 0.3033, Loss G: 2.1665\n",
      "Epoch [35/85] Batch 690/938 Loss D: 0.2060, Loss G: 2.2686\n",
      "Epoch [35/85] Batch 700/938 Loss D: 0.2216, Loss G: 2.4720\n",
      "Epoch [35/85] Batch 710/938 Loss D: 0.3178, Loss G: 2.5221\n",
      "Epoch [35/85] Batch 720/938 Loss D: 0.2380, Loss G: 2.6780\n",
      "Epoch [35/85] Batch 730/938 Loss D: 0.2409, Loss G: 2.7671\n",
      "Epoch [35/85] Batch 740/938 Loss D: 0.3586, Loss G: 2.2494\n",
      "Epoch [35/85] Batch 750/938 Loss D: 0.4400, Loss G: 1.5316\n",
      "Epoch [35/85] Batch 760/938 Loss D: 0.3970, Loss G: 1.5222\n",
      "Epoch [35/85] Batch 770/938 Loss D: 0.4192, Loss G: 1.7637\n",
      "Epoch [35/85] Batch 780/938 Loss D: 0.3954, Loss G: 2.1177\n",
      "Epoch [35/85] Batch 790/938 Loss D: 0.2931, Loss G: 2.7306\n",
      "Epoch [35/85] Batch 800/938 Loss D: 0.3132, Loss G: 2.6107\n",
      "Epoch [35/85] Batch 810/938 Loss D: 0.2236, Loss G: 2.0269\n",
      "Epoch [35/85] Batch 820/938 Loss D: 0.2662, Loss G: 2.2271\n",
      "Epoch [35/85] Batch 830/938 Loss D: 0.3914, Loss G: 2.3360\n",
      "Epoch [35/85] Batch 840/938 Loss D: 0.2475, Loss G: 2.3929\n",
      "Epoch [35/85] Batch 850/938 Loss D: 0.2653, Loss G: 2.3036\n",
      "Epoch [35/85] Batch 860/938 Loss D: 0.2608, Loss G: 2.2373\n",
      "Epoch [35/85] Batch 870/938 Loss D: 0.2309, Loss G: 2.1242\n",
      "Epoch [35/85] Batch 880/938 Loss D: 0.3059, Loss G: 2.3757\n",
      "Epoch [35/85] Batch 890/938 Loss D: 0.2566, Loss G: 2.6110\n",
      "Epoch [35/85] Batch 900/938 Loss D: 0.2691, Loss G: 2.7738\n",
      "Epoch [35/85] Batch 910/938 Loss D: 0.3377, Loss G: 2.2875\n",
      "Epoch [35/85] Batch 920/938 Loss D: 0.2908, Loss G: 2.2500\n",
      "Epoch [35/85] Batch 930/938 Loss D: 0.2803, Loss G: 2.7141\n",
      "Epoch [36/85] Batch 0/938 Loss D: 0.2408, Loss G: 2.2511\n",
      "Epoch [36/85] Batch 10/938 Loss D: 0.2593, Loss G: 2.4672\n",
      "Epoch [36/85] Batch 20/938 Loss D: 0.3216, Loss G: 1.7435\n",
      "Epoch [36/85] Batch 30/938 Loss D: 0.2564, Loss G: 2.3925\n",
      "Epoch [36/85] Batch 40/938 Loss D: 0.3165, Loss G: 2.3618\n",
      "Epoch [36/85] Batch 50/938 Loss D: 0.4612, Loss G: 1.6031\n",
      "Epoch [36/85] Batch 60/938 Loss D: 0.1803, Loss G: 2.3672\n",
      "Epoch [36/85] Batch 70/938 Loss D: 0.2355, Loss G: 2.5076\n",
      "Epoch [36/85] Batch 80/938 Loss D: 0.3381, Loss G: 1.9039\n",
      "Epoch [36/85] Batch 90/938 Loss D: 0.2320, Loss G: 2.4578\n",
      "Epoch [36/85] Batch 100/938 Loss D: 0.3841, Loss G: 2.1571\n",
      "Epoch [36/85] Batch 110/938 Loss D: 0.4496, Loss G: 1.7606\n",
      "Epoch [36/85] Batch 120/938 Loss D: 0.3315, Loss G: 2.1197\n",
      "Epoch [36/85] Batch 130/938 Loss D: 0.2825, Loss G: 3.0032\n",
      "Epoch [36/85] Batch 140/938 Loss D: 0.3187, Loss G: 1.9198\n",
      "Epoch [36/85] Batch 150/938 Loss D: 0.3194, Loss G: 2.4745\n",
      "Epoch [36/85] Batch 160/938 Loss D: 0.4037, Loss G: 1.9284\n",
      "Epoch [36/85] Batch 170/938 Loss D: 0.3782, Loss G: 1.8460\n",
      "Epoch [36/85] Batch 180/938 Loss D: 0.3102, Loss G: 2.2176\n",
      "Epoch [36/85] Batch 190/938 Loss D: 0.2239, Loss G: 2.5445\n",
      "Epoch [36/85] Batch 200/938 Loss D: 0.3012, Loss G: 2.2792\n",
      "Epoch [36/85] Batch 210/938 Loss D: 0.2786, Loss G: 2.2187\n",
      "Epoch [36/85] Batch 220/938 Loss D: 0.2764, Loss G: 2.3095\n",
      "Epoch [36/85] Batch 230/938 Loss D: 0.2740, Loss G: 2.2094\n",
      "Epoch [36/85] Batch 240/938 Loss D: 0.3369, Loss G: 1.9404\n",
      "Epoch [36/85] Batch 250/938 Loss D: 0.2311, Loss G: 2.7414\n",
      "Epoch [36/85] Batch 260/938 Loss D: 0.2419, Loss G: 2.4332\n",
      "Epoch [36/85] Batch 270/938 Loss D: 0.2222, Loss G: 2.4529\n",
      "Epoch [36/85] Batch 280/938 Loss D: 0.3095, Loss G: 1.9667\n",
      "Epoch [36/85] Batch 290/938 Loss D: 0.2938, Loss G: 2.1780\n",
      "Epoch [36/85] Batch 300/938 Loss D: 0.3569, Loss G: 1.8950\n",
      "Epoch [36/85] Batch 310/938 Loss D: 0.1965, Loss G: 2.5961\n",
      "Epoch [36/85] Batch 320/938 Loss D: 0.4039, Loss G: 2.0768\n",
      "Epoch [36/85] Batch 330/938 Loss D: 0.2829, Loss G: 2.4070\n",
      "Epoch [36/85] Batch 340/938 Loss D: 0.3021, Loss G: 2.1784\n",
      "Epoch [36/85] Batch 350/938 Loss D: 0.3175, Loss G: 2.6269\n",
      "Epoch [36/85] Batch 360/938 Loss D: 0.2819, Loss G: 2.4812\n",
      "Epoch [36/85] Batch 370/938 Loss D: 0.2930, Loss G: 2.2787\n",
      "Epoch [36/85] Batch 380/938 Loss D: 0.3827, Loss G: 2.3084\n",
      "Epoch [36/85] Batch 390/938 Loss D: 0.3584, Loss G: 2.5091\n",
      "Epoch [36/85] Batch 400/938 Loss D: 0.2841, Loss G: 2.1792\n",
      "Epoch [36/85] Batch 410/938 Loss D: 0.2787, Loss G: 2.1757\n",
      "Epoch [36/85] Batch 420/938 Loss D: 0.3127, Loss G: 2.6388\n",
      "Epoch [36/85] Batch 430/938 Loss D: 0.2296, Loss G: 2.5724\n",
      "Epoch [36/85] Batch 440/938 Loss D: 0.3288, Loss G: 2.8303\n",
      "Epoch [36/85] Batch 450/938 Loss D: 0.3378, Loss G: 2.7971\n",
      "Epoch [36/85] Batch 460/938 Loss D: 0.2861, Loss G: 3.0292\n",
      "Epoch [36/85] Batch 470/938 Loss D: 0.2944, Loss G: 3.1378\n",
      "Epoch [36/85] Batch 480/938 Loss D: 0.2856, Loss G: 2.9552\n",
      "Epoch [36/85] Batch 490/938 Loss D: 0.3808, Loss G: 2.2917\n",
      "Epoch [36/85] Batch 500/938 Loss D: 0.2223, Loss G: 2.9014\n",
      "Epoch [36/85] Batch 510/938 Loss D: 0.2985, Loss G: 2.0357\n",
      "Epoch [36/85] Batch 520/938 Loss D: 0.3125, Loss G: 2.0698\n",
      "Epoch [36/85] Batch 530/938 Loss D: 0.2337, Loss G: 2.5742\n",
      "Epoch [36/85] Batch 540/938 Loss D: 0.4045, Loss G: 2.9462\n",
      "Epoch [36/85] Batch 550/938 Loss D: 0.3050, Loss G: 2.7167\n",
      "Epoch [36/85] Batch 560/938 Loss D: 0.3680, Loss G: 1.9577\n",
      "Epoch [36/85] Batch 570/938 Loss D: 0.3303, Loss G: 1.9438\n",
      "Epoch [36/85] Batch 580/938 Loss D: 0.2554, Loss G: 1.7599\n",
      "Epoch [36/85] Batch 590/938 Loss D: 0.2289, Loss G: 2.5574\n",
      "Epoch [36/85] Batch 600/938 Loss D: 0.1888, Loss G: 3.3502\n",
      "Epoch [36/85] Batch 610/938 Loss D: 0.4272, Loss G: 2.5230\n",
      "Epoch [36/85] Batch 620/938 Loss D: 0.3599, Loss G: 2.7190\n",
      "Epoch [36/85] Batch 630/938 Loss D: 0.2473, Loss G: 2.8123\n",
      "Epoch [36/85] Batch 640/938 Loss D: 0.2863, Loss G: 2.8164\n",
      "Epoch [36/85] Batch 650/938 Loss D: 0.3260, Loss G: 2.3444\n",
      "Epoch [36/85] Batch 660/938 Loss D: 0.4289, Loss G: 1.8088\n",
      "Epoch [36/85] Batch 670/938 Loss D: 0.2959, Loss G: 2.5341\n",
      "Epoch [36/85] Batch 680/938 Loss D: 0.4174, Loss G: 2.1273\n",
      "Epoch [36/85] Batch 690/938 Loss D: 0.2905, Loss G: 2.7046\n",
      "Epoch [36/85] Batch 700/938 Loss D: 0.3442, Loss G: 2.7697\n",
      "Epoch [36/85] Batch 710/938 Loss D: 0.2440, Loss G: 2.5619\n",
      "Epoch [36/85] Batch 720/938 Loss D: 0.2392, Loss G: 2.2925\n",
      "Epoch [36/85] Batch 730/938 Loss D: 0.2714, Loss G: 2.0528\n",
      "Epoch [36/85] Batch 740/938 Loss D: 0.2808, Loss G: 2.3283\n",
      "Epoch [36/85] Batch 750/938 Loss D: 0.3300, Loss G: 2.3110\n",
      "Epoch [36/85] Batch 760/938 Loss D: 0.2980, Loss G: 2.3462\n",
      "Epoch [36/85] Batch 770/938 Loss D: 0.3240, Loss G: 2.2438\n",
      "Epoch [36/85] Batch 780/938 Loss D: 0.2609, Loss G: 2.3781\n",
      "Epoch [36/85] Batch 790/938 Loss D: 0.2455, Loss G: 2.4974\n",
      "Epoch [36/85] Batch 800/938 Loss D: 0.1790, Loss G: 2.5657\n",
      "Epoch [36/85] Batch 810/938 Loss D: 0.2051, Loss G: 2.7832\n",
      "Epoch [36/85] Batch 820/938 Loss D: 0.2722, Loss G: 2.7586\n",
      "Epoch [36/85] Batch 830/938 Loss D: 0.3534, Loss G: 1.8093\n",
      "Epoch [36/85] Batch 840/938 Loss D: 0.3438, Loss G: 1.9317\n",
      "Epoch [36/85] Batch 850/938 Loss D: 0.1969, Loss G: 2.3464\n",
      "Epoch [36/85] Batch 860/938 Loss D: 0.3366, Loss G: 1.8791\n",
      "Epoch [36/85] Batch 870/938 Loss D: 0.2787, Loss G: 2.2885\n",
      "Epoch [36/85] Batch 880/938 Loss D: 0.3234, Loss G: 2.2413\n",
      "Epoch [36/85] Batch 890/938 Loss D: 0.2177, Loss G: 3.0150\n",
      "Epoch [36/85] Batch 900/938 Loss D: 0.3131, Loss G: 2.3560\n",
      "Epoch [36/85] Batch 910/938 Loss D: 0.3888, Loss G: 1.8413\n",
      "Epoch [36/85] Batch 920/938 Loss D: 0.3299, Loss G: 2.2534\n",
      "Epoch [36/85] Batch 930/938 Loss D: 0.2462, Loss G: 2.4860\n",
      "Epoch [37/85] Batch 0/938 Loss D: 0.2321, Loss G: 2.4036\n",
      "Epoch [37/85] Batch 10/938 Loss D: 0.2417, Loss G: 2.5212\n",
      "Epoch [37/85] Batch 20/938 Loss D: 0.3520, Loss G: 1.9951\n",
      "Epoch [37/85] Batch 30/938 Loss D: 0.2301, Loss G: 2.3356\n",
      "Epoch [37/85] Batch 40/938 Loss D: 0.3295, Loss G: 1.9247\n",
      "Epoch [37/85] Batch 50/938 Loss D: 0.2507, Loss G: 2.2626\n",
      "Epoch [37/85] Batch 60/938 Loss D: 0.3191, Loss G: 1.8705\n",
      "Epoch [37/85] Batch 70/938 Loss D: 0.3046, Loss G: 2.0332\n",
      "Epoch [37/85] Batch 80/938 Loss D: 0.2338, Loss G: 2.4926\n",
      "Epoch [37/85] Batch 90/938 Loss D: 0.2534, Loss G: 2.8920\n",
      "Epoch [37/85] Batch 100/938 Loss D: 0.3155, Loss G: 2.5082\n",
      "Epoch [37/85] Batch 110/938 Loss D: 0.2877, Loss G: 2.1876\n",
      "Epoch [37/85] Batch 120/938 Loss D: 0.3385, Loss G: 2.4357\n",
      "Epoch [37/85] Batch 130/938 Loss D: 0.2437, Loss G: 2.8016\n",
      "Epoch [37/85] Batch 140/938 Loss D: 0.1473, Loss G: 3.4714\n",
      "Epoch [37/85] Batch 150/938 Loss D: 0.3553, Loss G: 2.1923\n",
      "Epoch [37/85] Batch 160/938 Loss D: 0.1999, Loss G: 2.4905\n",
      "Epoch [37/85] Batch 170/938 Loss D: 0.2754, Loss G: 2.5332\n",
      "Epoch [37/85] Batch 180/938 Loss D: 0.2711, Loss G: 2.6989\n",
      "Epoch [37/85] Batch 190/938 Loss D: 0.3171, Loss G: 2.3945\n",
      "Epoch [37/85] Batch 200/938 Loss D: 0.2267, Loss G: 3.1526\n",
      "Epoch [37/85] Batch 210/938 Loss D: 0.3433, Loss G: 1.9337\n",
      "Epoch [37/85] Batch 220/938 Loss D: 0.2186, Loss G: 2.5539\n",
      "Epoch [37/85] Batch 230/938 Loss D: 0.2324, Loss G: 2.5583\n",
      "Epoch [37/85] Batch 240/938 Loss D: 0.3587, Loss G: 2.1010\n",
      "Epoch [37/85] Batch 250/938 Loss D: 0.3126, Loss G: 2.6013\n",
      "Epoch [37/85] Batch 260/938 Loss D: 0.4065, Loss G: 1.8308\n",
      "Epoch [37/85] Batch 270/938 Loss D: 0.2745, Loss G: 1.9829\n",
      "Epoch [37/85] Batch 280/938 Loss D: 0.3126, Loss G: 1.9384\n",
      "Epoch [37/85] Batch 290/938 Loss D: 0.2190, Loss G: 2.4431\n",
      "Epoch [37/85] Batch 300/938 Loss D: 0.2188, Loss G: 2.3421\n",
      "Epoch [37/85] Batch 310/938 Loss D: 0.3446, Loss G: 2.0392\n",
      "Epoch [37/85] Batch 320/938 Loss D: 0.3588, Loss G: 2.0159\n",
      "Epoch [37/85] Batch 330/938 Loss D: 0.3150, Loss G: 2.3668\n",
      "Epoch [37/85] Batch 340/938 Loss D: 0.4124, Loss G: 2.1982\n",
      "Epoch [37/85] Batch 350/938 Loss D: 0.3087, Loss G: 2.9620\n",
      "Epoch [37/85] Batch 360/938 Loss D: 0.1518, Loss G: 3.4247\n",
      "Epoch [37/85] Batch 370/938 Loss D: 0.2235, Loss G: 2.4152\n",
      "Epoch [37/85] Batch 380/938 Loss D: 0.1606, Loss G: 2.4298\n",
      "Epoch [37/85] Batch 390/938 Loss D: 0.2481, Loss G: 1.7811\n",
      "Epoch [37/85] Batch 400/938 Loss D: 0.3784, Loss G: 1.9017\n",
      "Epoch [37/85] Batch 410/938 Loss D: 0.2952, Loss G: 2.1761\n",
      "Epoch [37/85] Batch 420/938 Loss D: 0.2445, Loss G: 2.5180\n",
      "Epoch [37/85] Batch 430/938 Loss D: 0.3148, Loss G: 2.7024\n",
      "Epoch [37/85] Batch 440/938 Loss D: 0.2034, Loss G: 2.8071\n",
      "Epoch [37/85] Batch 450/938 Loss D: 0.3659, Loss G: 1.8325\n",
      "Epoch [37/85] Batch 460/938 Loss D: 0.3041, Loss G: 2.0691\n",
      "Epoch [37/85] Batch 470/938 Loss D: 0.2380, Loss G: 2.6333\n",
      "Epoch [37/85] Batch 480/938 Loss D: 0.4103, Loss G: 2.1269\n",
      "Epoch [37/85] Batch 490/938 Loss D: 0.2011, Loss G: 2.7359\n",
      "Epoch [37/85] Batch 500/938 Loss D: 0.2540, Loss G: 2.4676\n",
      "Epoch [37/85] Batch 510/938 Loss D: 0.4501, Loss G: 1.9130\n",
      "Epoch [37/85] Batch 520/938 Loss D: 0.2821, Loss G: 2.3045\n",
      "Epoch [37/85] Batch 530/938 Loss D: 0.2900, Loss G: 2.0626\n",
      "Epoch [37/85] Batch 540/938 Loss D: 0.4392, Loss G: 2.1908\n",
      "Epoch [37/85] Batch 550/938 Loss D: 0.2915, Loss G: 2.5304\n",
      "Epoch [37/85] Batch 560/938 Loss D: 0.3354, Loss G: 2.7442\n",
      "Epoch [37/85] Batch 570/938 Loss D: 0.2878, Loss G: 3.1009\n",
      "Epoch [37/85] Batch 580/938 Loss D: 0.3690, Loss G: 3.0392\n",
      "Epoch [37/85] Batch 590/938 Loss D: 0.2045, Loss G: 2.7268\n",
      "Epoch [37/85] Batch 600/938 Loss D: 0.3536, Loss G: 1.7665\n",
      "Epoch [37/85] Batch 610/938 Loss D: 0.2209, Loss G: 2.7983\n",
      "Epoch [37/85] Batch 620/938 Loss D: 0.2308, Loss G: 2.2383\n",
      "Epoch [37/85] Batch 630/938 Loss D: 0.2049, Loss G: 2.8234\n",
      "Epoch [37/85] Batch 640/938 Loss D: 0.3586, Loss G: 2.1527\n",
      "Epoch [37/85] Batch 650/938 Loss D: 0.3383, Loss G: 2.4775\n",
      "Epoch [37/85] Batch 660/938 Loss D: 0.2852, Loss G: 2.3372\n",
      "Epoch [37/85] Batch 670/938 Loss D: 0.2598, Loss G: 2.8105\n",
      "Epoch [37/85] Batch 680/938 Loss D: 0.2864, Loss G: 2.2661\n",
      "Epoch [37/85] Batch 690/938 Loss D: 0.2890, Loss G: 2.7493\n",
      "Epoch [37/85] Batch 700/938 Loss D: 0.2709, Loss G: 2.9326\n",
      "Epoch [37/85] Batch 710/938 Loss D: 0.3214, Loss G: 2.5874\n",
      "Epoch [37/85] Batch 720/938 Loss D: 0.2949, Loss G: 2.3503\n",
      "Epoch [37/85] Batch 730/938 Loss D: 0.4779, Loss G: 1.2757\n",
      "Epoch [37/85] Batch 740/938 Loss D: 0.2421, Loss G: 2.1483\n",
      "Epoch [37/85] Batch 750/938 Loss D: 0.2703, Loss G: 2.4709\n",
      "Epoch [37/85] Batch 760/938 Loss D: 0.2012, Loss G: 2.4080\n",
      "Epoch [37/85] Batch 770/938 Loss D: 0.3608, Loss G: 1.5035\n",
      "Epoch [37/85] Batch 780/938 Loss D: 0.3294, Loss G: 2.6840\n",
      "Epoch [37/85] Batch 790/938 Loss D: 0.2737, Loss G: 2.3150\n",
      "Epoch [37/85] Batch 800/938 Loss D: 0.5362, Loss G: 2.5602\n",
      "Epoch [37/85] Batch 810/938 Loss D: 0.2828, Loss G: 2.3827\n",
      "Epoch [37/85] Batch 820/938 Loss D: 0.2144, Loss G: 2.6745\n",
      "Epoch [37/85] Batch 830/938 Loss D: 0.1820, Loss G: 2.4540\n",
      "Epoch [37/85] Batch 840/938 Loss D: 0.2886, Loss G: 1.9926\n",
      "Epoch [37/85] Batch 850/938 Loss D: 0.3424, Loss G: 2.0885\n",
      "Epoch [37/85] Batch 860/938 Loss D: 0.2978, Loss G: 2.2692\n",
      "Epoch [37/85] Batch 870/938 Loss D: 0.4663, Loss G: 1.7702\n",
      "Epoch [37/85] Batch 880/938 Loss D: 0.3053, Loss G: 2.3572\n",
      "Epoch [37/85] Batch 890/938 Loss D: 0.2437, Loss G: 2.4006\n",
      "Epoch [37/85] Batch 900/938 Loss D: 0.4626, Loss G: 1.9146\n",
      "Epoch [37/85] Batch 910/938 Loss D: 0.2731, Loss G: 2.9110\n",
      "Epoch [37/85] Batch 920/938 Loss D: 0.3363, Loss G: 1.9570\n",
      "Epoch [37/85] Batch 930/938 Loss D: 0.2474, Loss G: 2.2113\n",
      "Epoch [38/85] Batch 0/938 Loss D: 0.3357, Loss G: 1.8137\n",
      "Epoch [38/85] Batch 10/938 Loss D: 0.2848, Loss G: 2.4192\n",
      "Epoch [38/85] Batch 20/938 Loss D: 0.2123, Loss G: 3.1911\n",
      "Epoch [38/85] Batch 30/938 Loss D: 0.2639, Loss G: 2.6501\n",
      "Epoch [38/85] Batch 40/938 Loss D: 0.3362, Loss G: 2.5958\n",
      "Epoch [38/85] Batch 50/938 Loss D: 0.2272, Loss G: 2.7140\n",
      "Epoch [38/85] Batch 60/938 Loss D: 0.2796, Loss G: 2.0873\n",
      "Epoch [38/85] Batch 70/938 Loss D: 0.2513, Loss G: 3.1907\n",
      "Epoch [38/85] Batch 80/938 Loss D: 0.2282, Loss G: 2.8361\n",
      "Epoch [38/85] Batch 90/938 Loss D: 0.3955, Loss G: 2.6872\n",
      "Epoch [38/85] Batch 100/938 Loss D: 0.2874, Loss G: 2.1629\n",
      "Epoch [38/85] Batch 110/938 Loss D: 0.2646, Loss G: 2.5805\n",
      "Epoch [38/85] Batch 120/938 Loss D: 0.2936, Loss G: 2.0165\n",
      "Epoch [38/85] Batch 130/938 Loss D: 0.3133, Loss G: 2.3475\n",
      "Epoch [38/85] Batch 140/938 Loss D: 0.2432, Loss G: 2.7824\n",
      "Epoch [38/85] Batch 150/938 Loss D: 0.4125, Loss G: 2.0565\n",
      "Epoch [38/85] Batch 160/938 Loss D: 0.3748, Loss G: 2.1723\n",
      "Epoch [38/85] Batch 170/938 Loss D: 0.3406, Loss G: 1.9040\n",
      "Epoch [38/85] Batch 180/938 Loss D: 0.2508, Loss G: 2.2631\n",
      "Epoch [38/85] Batch 190/938 Loss D: 0.3274, Loss G: 2.8881\n",
      "Epoch [38/85] Batch 200/938 Loss D: 0.2682, Loss G: 1.9752\n",
      "Epoch [38/85] Batch 210/938 Loss D: 0.3403, Loss G: 2.6091\n",
      "Epoch [38/85] Batch 220/938 Loss D: 0.3050, Loss G: 2.0025\n",
      "Epoch [38/85] Batch 230/938 Loss D: 0.2423, Loss G: 2.4287\n",
      "Epoch [38/85] Batch 240/938 Loss D: 0.3333, Loss G: 2.1865\n",
      "Epoch [38/85] Batch 250/938 Loss D: 0.3037, Loss G: 2.7209\n",
      "Epoch [38/85] Batch 260/938 Loss D: 0.2729, Loss G: 2.9228\n",
      "Epoch [38/85] Batch 270/938 Loss D: 0.3272, Loss G: 2.9840\n",
      "Epoch [38/85] Batch 280/938 Loss D: 0.3043, Loss G: 2.6168\n",
      "Epoch [38/85] Batch 290/938 Loss D: 0.2268, Loss G: 2.8618\n",
      "Epoch [38/85] Batch 300/938 Loss D: 0.3186, Loss G: 2.3106\n",
      "Epoch [38/85] Batch 310/938 Loss D: 0.4455, Loss G: 2.6323\n",
      "Epoch [38/85] Batch 320/938 Loss D: 0.2794, Loss G: 3.3140\n",
      "Epoch [38/85] Batch 330/938 Loss D: 0.3026, Loss G: 2.3902\n",
      "Epoch [38/85] Batch 340/938 Loss D: 0.2517, Loss G: 2.2550\n",
      "Epoch [38/85] Batch 350/938 Loss D: 0.3249, Loss G: 1.8933\n",
      "Epoch [38/85] Batch 360/938 Loss D: 0.2430, Loss G: 2.2200\n",
      "Epoch [38/85] Batch 370/938 Loss D: 0.4230, Loss G: 1.8022\n",
      "Epoch [38/85] Batch 380/938 Loss D: 0.3388, Loss G: 2.1651\n",
      "Epoch [38/85] Batch 390/938 Loss D: 0.2732, Loss G: 2.2047\n",
      "Epoch [38/85] Batch 400/938 Loss D: 0.3358, Loss G: 1.8735\n",
      "Epoch [38/85] Batch 410/938 Loss D: 0.3137, Loss G: 2.2497\n",
      "Epoch [38/85] Batch 420/938 Loss D: 0.2443, Loss G: 2.4155\n",
      "Epoch [38/85] Batch 430/938 Loss D: 0.3044, Loss G: 2.0877\n",
      "Epoch [38/85] Batch 440/938 Loss D: 0.2990, Loss G: 2.1210\n",
      "Epoch [38/85] Batch 450/938 Loss D: 0.2458, Loss G: 2.1945\n",
      "Epoch [38/85] Batch 460/938 Loss D: 0.2199, Loss G: 2.8693\n",
      "Epoch [38/85] Batch 470/938 Loss D: 0.3703, Loss G: 1.9493\n",
      "Epoch [38/85] Batch 480/938 Loss D: 0.3218, Loss G: 2.6237\n",
      "Epoch [38/85] Batch 490/938 Loss D: 0.2453, Loss G: 3.0089\n",
      "Epoch [38/85] Batch 500/938 Loss D: 0.4287, Loss G: 1.9385\n",
      "Epoch [38/85] Batch 510/938 Loss D: 0.2959, Loss G: 2.5895\n",
      "Epoch [38/85] Batch 520/938 Loss D: 0.2729, Loss G: 2.4009\n",
      "Epoch [38/85] Batch 530/938 Loss D: 0.2163, Loss G: 2.2746\n",
      "Epoch [38/85] Batch 540/938 Loss D: 0.3800, Loss G: 1.5217\n",
      "Epoch [38/85] Batch 550/938 Loss D: 0.2337, Loss G: 2.2150\n",
      "Epoch [38/85] Batch 560/938 Loss D: 0.2877, Loss G: 2.2054\n",
      "Epoch [38/85] Batch 570/938 Loss D: 0.3999, Loss G: 1.5769\n",
      "Epoch [38/85] Batch 580/938 Loss D: 0.3814, Loss G: 1.7723\n",
      "Epoch [38/85] Batch 590/938 Loss D: 0.3596, Loss G: 2.1990\n",
      "Epoch [38/85] Batch 600/938 Loss D: 0.2869, Loss G: 3.1508\n",
      "Epoch [38/85] Batch 610/938 Loss D: 0.2205, Loss G: 2.6374\n",
      "Epoch [38/85] Batch 620/938 Loss D: 0.3118, Loss G: 2.7699\n",
      "Epoch [38/85] Batch 630/938 Loss D: 0.3186, Loss G: 1.9682\n",
      "Epoch [38/85] Batch 640/938 Loss D: 0.3052, Loss G: 2.3268\n",
      "Epoch [38/85] Batch 650/938 Loss D: 0.4313, Loss G: 2.5668\n",
      "Epoch [38/85] Batch 660/938 Loss D: 0.3588, Loss G: 2.1871\n",
      "Epoch [38/85] Batch 670/938 Loss D: 0.3306, Loss G: 2.1522\n",
      "Epoch [38/85] Batch 680/938 Loss D: 0.3076, Loss G: 2.3053\n",
      "Epoch [38/85] Batch 690/938 Loss D: 0.3030, Loss G: 2.1126\n",
      "Epoch [38/85] Batch 700/938 Loss D: 0.3474, Loss G: 1.6131\n",
      "Epoch [38/85] Batch 710/938 Loss D: 0.3477, Loss G: 2.2530\n",
      "Epoch [38/85] Batch 720/938 Loss D: 0.3471, Loss G: 2.6568\n",
      "Epoch [38/85] Batch 730/938 Loss D: 0.3629, Loss G: 3.0032\n",
      "Epoch [38/85] Batch 740/938 Loss D: 0.2911, Loss G: 2.3675\n",
      "Epoch [38/85] Batch 750/938 Loss D: 0.2929, Loss G: 2.1631\n",
      "Epoch [38/85] Batch 760/938 Loss D: 0.3765, Loss G: 1.8968\n",
      "Epoch [38/85] Batch 770/938 Loss D: 0.2378, Loss G: 2.4158\n",
      "Epoch [38/85] Batch 780/938 Loss D: 0.3573, Loss G: 1.8516\n",
      "Epoch [38/85] Batch 790/938 Loss D: 0.2872, Loss G: 2.5171\n",
      "Epoch [38/85] Batch 800/938 Loss D: 0.2751, Loss G: 2.3729\n",
      "Epoch [38/85] Batch 810/938 Loss D: 0.2547, Loss G: 2.2329\n",
      "Epoch [38/85] Batch 820/938 Loss D: 0.4339, Loss G: 2.0238\n",
      "Epoch [38/85] Batch 830/938 Loss D: 0.3038, Loss G: 1.9328\n",
      "Epoch [38/85] Batch 840/938 Loss D: 0.2701, Loss G: 1.6796\n",
      "Epoch [38/85] Batch 850/938 Loss D: 0.3423, Loss G: 1.8415\n",
      "Epoch [38/85] Batch 860/938 Loss D: 0.3511, Loss G: 1.5692\n",
      "Epoch [38/85] Batch 870/938 Loss D: 0.3528, Loss G: 2.6828\n",
      "Epoch [38/85] Batch 880/938 Loss D: 0.2641, Loss G: 2.7954\n",
      "Epoch [38/85] Batch 890/938 Loss D: 0.4195, Loss G: 1.7783\n",
      "Epoch [38/85] Batch 900/938 Loss D: 0.3548, Loss G: 1.8556\n",
      "Epoch [38/85] Batch 910/938 Loss D: 0.3533, Loss G: 1.7087\n",
      "Epoch [38/85] Batch 920/938 Loss D: 0.3164, Loss G: 2.0624\n",
      "Epoch [38/85] Batch 930/938 Loss D: 0.2391, Loss G: 2.0551\n",
      "Epoch [39/85] Batch 0/938 Loss D: 0.2541, Loss G: 2.5126\n",
      "Epoch [39/85] Batch 10/938 Loss D: 0.2623, Loss G: 2.6025\n",
      "Epoch [39/85] Batch 20/938 Loss D: 0.3484, Loss G: 2.8801\n",
      "Epoch [39/85] Batch 30/938 Loss D: 0.3502, Loss G: 2.6544\n",
      "Epoch [39/85] Batch 40/938 Loss D: 0.3082, Loss G: 2.6880\n",
      "Epoch [39/85] Batch 50/938 Loss D: 0.3244, Loss G: 2.4926\n",
      "Epoch [39/85] Batch 60/938 Loss D: 0.3538, Loss G: 2.0538\n",
      "Epoch [39/85] Batch 70/938 Loss D: 0.3446, Loss G: 1.4474\n",
      "Epoch [39/85] Batch 80/938 Loss D: 0.2705, Loss G: 2.9360\n",
      "Epoch [39/85] Batch 90/938 Loss D: 0.3014, Loss G: 2.4507\n",
      "Epoch [39/85] Batch 100/938 Loss D: 0.1713, Loss G: 2.4687\n",
      "Epoch [39/85] Batch 110/938 Loss D: 0.2179, Loss G: 2.4493\n",
      "Epoch [39/85] Batch 120/938 Loss D: 0.3085, Loss G: 2.4406\n",
      "Epoch [39/85] Batch 130/938 Loss D: 0.2418, Loss G: 2.2278\n",
      "Epoch [39/85] Batch 140/938 Loss D: 0.3712, Loss G: 3.0241\n",
      "Epoch [39/85] Batch 150/938 Loss D: 0.3033, Loss G: 2.7309\n",
      "Epoch [39/85] Batch 160/938 Loss D: 0.4321, Loss G: 2.0181\n",
      "Epoch [39/85] Batch 170/938 Loss D: 0.4570, Loss G: 1.9381\n",
      "Epoch [39/85] Batch 180/938 Loss D: 0.3069, Loss G: 2.1380\n",
      "Epoch [39/85] Batch 190/938 Loss D: 0.3253, Loss G: 2.2786\n",
      "Epoch [39/85] Batch 200/938 Loss D: 0.1777, Loss G: 3.0570\n",
      "Epoch [39/85] Batch 210/938 Loss D: 0.2402, Loss G: 2.5697\n",
      "Epoch [39/85] Batch 220/938 Loss D: 0.4258, Loss G: 2.2722\n",
      "Epoch [39/85] Batch 230/938 Loss D: 0.2744, Loss G: 2.6885\n",
      "Epoch [39/85] Batch 240/938 Loss D: 0.3231, Loss G: 2.9609\n",
      "Epoch [39/85] Batch 250/938 Loss D: 0.2792, Loss G: 2.4664\n",
      "Epoch [39/85] Batch 260/938 Loss D: 0.3149, Loss G: 2.3003\n",
      "Epoch [39/85] Batch 270/938 Loss D: 0.2345, Loss G: 2.4633\n",
      "Epoch [39/85] Batch 280/938 Loss D: 0.3146, Loss G: 2.4230\n",
      "Epoch [39/85] Batch 290/938 Loss D: 0.2667, Loss G: 2.3224\n",
      "Epoch [39/85] Batch 300/938 Loss D: 0.3363, Loss G: 1.9127\n",
      "Epoch [39/85] Batch 310/938 Loss D: 0.2538, Loss G: 2.5201\n",
      "Epoch [39/85] Batch 320/938 Loss D: 0.3373, Loss G: 2.0046\n",
      "Epoch [39/85] Batch 330/938 Loss D: 0.1811, Loss G: 3.0782\n",
      "Epoch [39/85] Batch 340/938 Loss D: 0.2348, Loss G: 2.5018\n",
      "Epoch [39/85] Batch 350/938 Loss D: 0.2836, Loss G: 2.2079\n",
      "Epoch [39/85] Batch 360/938 Loss D: 0.2780, Loss G: 1.5970\n",
      "Epoch [39/85] Batch 370/938 Loss D: 0.4275, Loss G: 2.9501\n",
      "Epoch [39/85] Batch 380/938 Loss D: 0.1904, Loss G: 2.9778\n",
      "Epoch [39/85] Batch 390/938 Loss D: 0.2499, Loss G: 2.7456\n",
      "Epoch [39/85] Batch 400/938 Loss D: 0.3329, Loss G: 2.3189\n",
      "Epoch [39/85] Batch 410/938 Loss D: 0.2834, Loss G: 2.2486\n",
      "Epoch [39/85] Batch 420/938 Loss D: 0.2635, Loss G: 2.6217\n",
      "Epoch [39/85] Batch 430/938 Loss D: 0.3529, Loss G: 2.0069\n",
      "Epoch [39/85] Batch 440/938 Loss D: 0.3310, Loss G: 2.3423\n",
      "Epoch [39/85] Batch 450/938 Loss D: 0.4085, Loss G: 1.6468\n",
      "Epoch [39/85] Batch 460/938 Loss D: 0.3238, Loss G: 1.7735\n",
      "Epoch [39/85] Batch 470/938 Loss D: 0.3706, Loss G: 2.4983\n",
      "Epoch [39/85] Batch 480/938 Loss D: 0.2844, Loss G: 2.0278\n",
      "Epoch [39/85] Batch 490/938 Loss D: 0.2489, Loss G: 2.5266\n",
      "Epoch [39/85] Batch 500/938 Loss D: 0.3041, Loss G: 2.5241\n",
      "Epoch [39/85] Batch 510/938 Loss D: 0.2484, Loss G: 2.5240\n",
      "Epoch [39/85] Batch 520/938 Loss D: 0.1930, Loss G: 2.4632\n",
      "Epoch [39/85] Batch 530/938 Loss D: 0.2206, Loss G: 2.8758\n",
      "Epoch [39/85] Batch 540/938 Loss D: 0.2303, Loss G: 2.7042\n",
      "Epoch [39/85] Batch 550/938 Loss D: 0.4237, Loss G: 2.2652\n",
      "Epoch [39/85] Batch 560/938 Loss D: 0.2568, Loss G: 2.5320\n",
      "Epoch [39/85] Batch 570/938 Loss D: 0.3082, Loss G: 3.0365\n",
      "Epoch [39/85] Batch 580/938 Loss D: 0.3009, Loss G: 2.6909\n",
      "Epoch [39/85] Batch 590/938 Loss D: 0.2257, Loss G: 2.6998\n",
      "Epoch [39/85] Batch 600/938 Loss D: 0.3505, Loss G: 2.1028\n",
      "Epoch [39/85] Batch 610/938 Loss D: 0.5001, Loss G: 1.8228\n",
      "Epoch [39/85] Batch 620/938 Loss D: 0.2128, Loss G: 2.7079\n",
      "Epoch [39/85] Batch 630/938 Loss D: 0.2332, Loss G: 2.6028\n",
      "Epoch [39/85] Batch 640/938 Loss D: 0.2782, Loss G: 2.2702\n",
      "Epoch [39/85] Batch 650/938 Loss D: 0.4296, Loss G: 2.4459\n",
      "Epoch [39/85] Batch 660/938 Loss D: 0.2585, Loss G: 3.2643\n",
      "Epoch [39/85] Batch 670/938 Loss D: 0.2206, Loss G: 3.0275\n",
      "Epoch [39/85] Batch 680/938 Loss D: 0.4769, Loss G: 2.3905\n",
      "Epoch [39/85] Batch 690/938 Loss D: 0.3417, Loss G: 2.2998\n",
      "Epoch [39/85] Batch 700/938 Loss D: 0.2582, Loss G: 2.2212\n",
      "Epoch [39/85] Batch 710/938 Loss D: 0.2777, Loss G: 2.1324\n",
      "Epoch [39/85] Batch 720/938 Loss D: 0.3839, Loss G: 2.4301\n",
      "Epoch [39/85] Batch 730/938 Loss D: 0.3349, Loss G: 2.3462\n",
      "Epoch [39/85] Batch 740/938 Loss D: 0.2882, Loss G: 2.9559\n",
      "Epoch [39/85] Batch 750/938 Loss D: 0.3502, Loss G: 2.4794\n",
      "Epoch [39/85] Batch 760/938 Loss D: 0.3528, Loss G: 2.1579\n",
      "Epoch [39/85] Batch 770/938 Loss D: 0.3263, Loss G: 2.0849\n",
      "Epoch [39/85] Batch 780/938 Loss D: 0.3913, Loss G: 2.1829\n",
      "Epoch [39/85] Batch 790/938 Loss D: 0.2475, Loss G: 2.4849\n",
      "Epoch [39/85] Batch 800/938 Loss D: 0.3135, Loss G: 1.7172\n",
      "Epoch [39/85] Batch 810/938 Loss D: 0.2582, Loss G: 2.4116\n",
      "Epoch [39/85] Batch 820/938 Loss D: 0.1770, Loss G: 2.7993\n",
      "Epoch [39/85] Batch 830/938 Loss D: 0.2573, Loss G: 2.9318\n",
      "Epoch [39/85] Batch 840/938 Loss D: 0.3353, Loss G: 3.0763\n",
      "Epoch [39/85] Batch 850/938 Loss D: 0.3225, Loss G: 2.2110\n",
      "Epoch [39/85] Batch 860/938 Loss D: 0.2689, Loss G: 2.1578\n",
      "Epoch [39/85] Batch 870/938 Loss D: 0.1933, Loss G: 2.9714\n",
      "Epoch [39/85] Batch 880/938 Loss D: 0.2050, Loss G: 2.6617\n",
      "Epoch [39/85] Batch 890/938 Loss D: 0.3109, Loss G: 2.6486\n",
      "Epoch [39/85] Batch 900/938 Loss D: 0.3543, Loss G: 2.2960\n",
      "Epoch [39/85] Batch 910/938 Loss D: 0.2745, Loss G: 2.4840\n",
      "Epoch [39/85] Batch 920/938 Loss D: 0.3028, Loss G: 2.2946\n",
      "Epoch [39/85] Batch 930/938 Loss D: 0.2492, Loss G: 2.2830\n",
      "Epoch [40/85] Batch 0/938 Loss D: 0.3541, Loss G: 2.1862\n",
      "Epoch [40/85] Batch 10/938 Loss D: 0.2494, Loss G: 2.3815\n",
      "Epoch [40/85] Batch 20/938 Loss D: 0.2715, Loss G: 2.0793\n",
      "Epoch [40/85] Batch 30/938 Loss D: 0.2137, Loss G: 2.7376\n",
      "Epoch [40/85] Batch 40/938 Loss D: 0.3219, Loss G: 2.1655\n",
      "Epoch [40/85] Batch 50/938 Loss D: 0.2583, Loss G: 2.4863\n",
      "Epoch [40/85] Batch 60/938 Loss D: 0.3392, Loss G: 1.7651\n",
      "Epoch [40/85] Batch 70/938 Loss D: 0.3691, Loss G: 2.2954\n",
      "Epoch [40/85] Batch 80/938 Loss D: 0.3072, Loss G: 2.3709\n",
      "Epoch [40/85] Batch 90/938 Loss D: 0.2572, Loss G: 2.3933\n",
      "Epoch [40/85] Batch 100/938 Loss D: 0.3541, Loss G: 2.1437\n",
      "Epoch [40/85] Batch 110/938 Loss D: 0.2957, Loss G: 2.1256\n",
      "Epoch [40/85] Batch 120/938 Loss D: 0.1869, Loss G: 2.4978\n",
      "Epoch [40/85] Batch 130/938 Loss D: 0.3338, Loss G: 2.2118\n",
      "Epoch [40/85] Batch 140/938 Loss D: 0.2173, Loss G: 2.5045\n",
      "Epoch [40/85] Batch 150/938 Loss D: 0.2702, Loss G: 2.3571\n",
      "Epoch [40/85] Batch 160/938 Loss D: 0.3944, Loss G: 1.9774\n",
      "Epoch [40/85] Batch 170/938 Loss D: 0.3316, Loss G: 2.6628\n",
      "Epoch [40/85] Batch 180/938 Loss D: 0.2310, Loss G: 2.9057\n",
      "Epoch [40/85] Batch 190/938 Loss D: 0.2626, Loss G: 2.9799\n",
      "Epoch [40/85] Batch 200/938 Loss D: 0.2426, Loss G: 2.6656\n",
      "Epoch [40/85] Batch 210/938 Loss D: 0.3527, Loss G: 1.8001\n",
      "Epoch [40/85] Batch 220/938 Loss D: 0.3239, Loss G: 1.8693\n",
      "Epoch [40/85] Batch 230/938 Loss D: 0.2570, Loss G: 1.9010\n",
      "Epoch [40/85] Batch 240/938 Loss D: 0.2541, Loss G: 2.2374\n",
      "Epoch [40/85] Batch 250/938 Loss D: 0.2935, Loss G: 2.3764\n",
      "Epoch [40/85] Batch 260/938 Loss D: 0.3185, Loss G: 2.4769\n",
      "Epoch [40/85] Batch 270/938 Loss D: 0.2358, Loss G: 2.9107\n",
      "Epoch [40/85] Batch 280/938 Loss D: 0.2565, Loss G: 2.2337\n",
      "Epoch [40/85] Batch 290/938 Loss D: 0.3570, Loss G: 2.1505\n",
      "Epoch [40/85] Batch 300/938 Loss D: 0.2733, Loss G: 2.3766\n",
      "Epoch [40/85] Batch 310/938 Loss D: 0.2217, Loss G: 2.0582\n",
      "Epoch [40/85] Batch 320/938 Loss D: 0.3467, Loss G: 2.7573\n",
      "Epoch [40/85] Batch 330/938 Loss D: 0.4061, Loss G: 1.9738\n",
      "Epoch [40/85] Batch 340/938 Loss D: 0.3429, Loss G: 2.3321\n",
      "Epoch [40/85] Batch 350/938 Loss D: 0.2909, Loss G: 2.2767\n",
      "Epoch [40/85] Batch 360/938 Loss D: 0.2794, Loss G: 2.6053\n",
      "Epoch [40/85] Batch 370/938 Loss D: 0.2928, Loss G: 2.5856\n",
      "Epoch [40/85] Batch 380/938 Loss D: 0.2737, Loss G: 2.2439\n",
      "Epoch [40/85] Batch 390/938 Loss D: 0.2884, Loss G: 2.1298\n",
      "Epoch [40/85] Batch 400/938 Loss D: 0.3060, Loss G: 2.2780\n",
      "Epoch [40/85] Batch 410/938 Loss D: 0.2613, Loss G: 2.2357\n",
      "Epoch [40/85] Batch 420/938 Loss D: 0.3310, Loss G: 1.8424\n",
      "Epoch [40/85] Batch 430/938 Loss D: 0.3584, Loss G: 2.3554\n",
      "Epoch [40/85] Batch 440/938 Loss D: 0.3066, Loss G: 2.6404\n",
      "Epoch [40/85] Batch 450/938 Loss D: 0.3587, Loss G: 2.7273\n",
      "Epoch [40/85] Batch 460/938 Loss D: 0.3005, Loss G: 2.5333\n",
      "Epoch [40/85] Batch 470/938 Loss D: 0.2400, Loss G: 2.6345\n",
      "Epoch [40/85] Batch 480/938 Loss D: 0.3220, Loss G: 2.5861\n",
      "Epoch [40/85] Batch 490/938 Loss D: 0.3145, Loss G: 1.9688\n",
      "Epoch [40/85] Batch 500/938 Loss D: 0.2854, Loss G: 1.9176\n",
      "Epoch [40/85] Batch 510/938 Loss D: 0.2866, Loss G: 3.1533\n",
      "Epoch [40/85] Batch 520/938 Loss D: 0.5033, Loss G: 2.4271\n",
      "Epoch [40/85] Batch 530/938 Loss D: 0.3026, Loss G: 2.8574\n",
      "Epoch [40/85] Batch 540/938 Loss D: 0.3034, Loss G: 2.8672\n",
      "Epoch [40/85] Batch 550/938 Loss D: 0.2555, Loss G: 3.0596\n",
      "Epoch [40/85] Batch 560/938 Loss D: 0.3736, Loss G: 1.7687\n",
      "Epoch [40/85] Batch 570/938 Loss D: 0.3514, Loss G: 1.6998\n",
      "Epoch [40/85] Batch 580/938 Loss D: 0.3151, Loss G: 2.3115\n",
      "Epoch [40/85] Batch 590/938 Loss D: 0.4352, Loss G: 2.5746\n",
      "Epoch [40/85] Batch 600/938 Loss D: 0.3261, Loss G: 2.1655\n",
      "Epoch [40/85] Batch 610/938 Loss D: 0.2577, Loss G: 2.1867\n",
      "Epoch [40/85] Batch 620/938 Loss D: 0.3201, Loss G: 2.0427\n",
      "Epoch [40/85] Batch 630/938 Loss D: 0.2568, Loss G: 1.9951\n",
      "Epoch [40/85] Batch 640/938 Loss D: 0.3340, Loss G: 2.4325\n",
      "Epoch [40/85] Batch 650/938 Loss D: 0.2817, Loss G: 1.9462\n",
      "Epoch [40/85] Batch 660/938 Loss D: 0.2032, Loss G: 2.2955\n",
      "Epoch [40/85] Batch 670/938 Loss D: 0.2523, Loss G: 2.0121\n",
      "Epoch [40/85] Batch 680/938 Loss D: 0.2735, Loss G: 2.5172\n",
      "Epoch [40/85] Batch 690/938 Loss D: 0.3456, Loss G: 2.2374\n",
      "Epoch [40/85] Batch 700/938 Loss D: 0.3692, Loss G: 2.1157\n",
      "Epoch [40/85] Batch 710/938 Loss D: 0.3466, Loss G: 2.2203\n",
      "Epoch [40/85] Batch 720/938 Loss D: 0.2176, Loss G: 2.4511\n",
      "Epoch [40/85] Batch 730/938 Loss D: 0.4275, Loss G: 2.6150\n",
      "Epoch [40/85] Batch 740/938 Loss D: 0.2953, Loss G: 2.1592\n",
      "Epoch [40/85] Batch 750/938 Loss D: 0.3976, Loss G: 2.0537\n",
      "Epoch [40/85] Batch 760/938 Loss D: 0.2380, Loss G: 2.4953\n",
      "Epoch [40/85] Batch 770/938 Loss D: 0.2949, Loss G: 2.3760\n",
      "Epoch [40/85] Batch 780/938 Loss D: 0.3446, Loss G: 1.9770\n",
      "Epoch [40/85] Batch 790/938 Loss D: 0.4324, Loss G: 2.1419\n",
      "Epoch [40/85] Batch 800/938 Loss D: 0.2155, Loss G: 3.4848\n",
      "Epoch [40/85] Batch 810/938 Loss D: 0.4060, Loss G: 2.3576\n",
      "Epoch [40/85] Batch 820/938 Loss D: 0.3661, Loss G: 2.8042\n",
      "Epoch [40/85] Batch 830/938 Loss D: 0.4443, Loss G: 2.5124\n",
      "Epoch [40/85] Batch 840/938 Loss D: 0.2432, Loss G: 2.8508\n",
      "Epoch [40/85] Batch 850/938 Loss D: 0.2954, Loss G: 2.2945\n",
      "Epoch [40/85] Batch 860/938 Loss D: 0.3006, Loss G: 2.5181\n",
      "Epoch [40/85] Batch 870/938 Loss D: 0.1772, Loss G: 2.6850\n",
      "Epoch [40/85] Batch 880/938 Loss D: 0.2746, Loss G: 1.7543\n",
      "Epoch [40/85] Batch 890/938 Loss D: 0.3552, Loss G: 2.3577\n",
      "Epoch [40/85] Batch 900/938 Loss D: 0.3194, Loss G: 1.9611\n",
      "Epoch [40/85] Batch 910/938 Loss D: 0.2952, Loss G: 2.4327\n",
      "Epoch [40/85] Batch 920/938 Loss D: 0.3318, Loss G: 2.2642\n",
      "Epoch [40/85] Batch 930/938 Loss D: 0.2453, Loss G: 2.4908\n",
      "Epoch [41/85] Batch 0/938 Loss D: 0.2667, Loss G: 1.8446\n",
      "Epoch [41/85] Batch 10/938 Loss D: 0.3621, Loss G: 1.8963\n",
      "Epoch [41/85] Batch 20/938 Loss D: 0.3373, Loss G: 2.6301\n",
      "Epoch [41/85] Batch 30/938 Loss D: 0.2367, Loss G: 2.3561\n",
      "Epoch [41/85] Batch 40/938 Loss D: 0.3376, Loss G: 2.4962\n",
      "Epoch [41/85] Batch 50/938 Loss D: 0.3495, Loss G: 2.3838\n",
      "Epoch [41/85] Batch 60/938 Loss D: 0.2851, Loss G: 2.6079\n",
      "Epoch [41/85] Batch 70/938 Loss D: 0.3624, Loss G: 2.3265\n",
      "Epoch [41/85] Batch 80/938 Loss D: 0.3359, Loss G: 2.1535\n",
      "Epoch [41/85] Batch 90/938 Loss D: 0.2595, Loss G: 2.5898\n",
      "Epoch [41/85] Batch 100/938 Loss D: 0.2848, Loss G: 2.6704\n",
      "Epoch [41/85] Batch 110/938 Loss D: 0.3007, Loss G: 2.3673\n",
      "Epoch [41/85] Batch 120/938 Loss D: 0.4307, Loss G: 2.5362\n",
      "Epoch [41/85] Batch 130/938 Loss D: 0.3106, Loss G: 2.6092\n",
      "Epoch [41/85] Batch 140/938 Loss D: 0.3073, Loss G: 2.4349\n",
      "Epoch [41/85] Batch 150/938 Loss D: 0.2850, Loss G: 3.1247\n",
      "Epoch [41/85] Batch 160/938 Loss D: 0.3073, Loss G: 2.2863\n",
      "Epoch [41/85] Batch 170/938 Loss D: 0.2701, Loss G: 2.6090\n",
      "Epoch [41/85] Batch 180/938 Loss D: 0.4913, Loss G: 2.4820\n",
      "Epoch [41/85] Batch 190/938 Loss D: 0.3491, Loss G: 2.7279\n",
      "Epoch [41/85] Batch 200/938 Loss D: 0.2616, Loss G: 2.8033\n",
      "Epoch [41/85] Batch 210/938 Loss D: 0.2821, Loss G: 2.7862\n",
      "Epoch [41/85] Batch 220/938 Loss D: 0.2996, Loss G: 2.3462\n",
      "Epoch [41/85] Batch 230/938 Loss D: 0.3001, Loss G: 2.6042\n",
      "Epoch [41/85] Batch 240/938 Loss D: 0.2528, Loss G: 2.5852\n",
      "Epoch [41/85] Batch 250/938 Loss D: 0.3375, Loss G: 2.5441\n",
      "Epoch [41/85] Batch 260/938 Loss D: 0.2754, Loss G: 2.2180\n",
      "Epoch [41/85] Batch 270/938 Loss D: 0.2412, Loss G: 2.2695\n",
      "Epoch [41/85] Batch 280/938 Loss D: 0.1773, Loss G: 2.6104\n",
      "Epoch [41/85] Batch 290/938 Loss D: 0.3291, Loss G: 2.2989\n",
      "Epoch [41/85] Batch 300/938 Loss D: 0.3327, Loss G: 1.9540\n",
      "Epoch [41/85] Batch 310/938 Loss D: 0.3319, Loss G: 2.1396\n",
      "Epoch [41/85] Batch 320/938 Loss D: 0.3296, Loss G: 2.2476\n",
      "Epoch [41/85] Batch 330/938 Loss D: 0.3577, Loss G: 3.3829\n",
      "Epoch [41/85] Batch 340/938 Loss D: 0.3039, Loss G: 2.7273\n",
      "Epoch [41/85] Batch 350/938 Loss D: 0.2864, Loss G: 2.4113\n",
      "Epoch [41/85] Batch 360/938 Loss D: 0.2719, Loss G: 2.2731\n",
      "Epoch [41/85] Batch 370/938 Loss D: 0.3383, Loss G: 2.1913\n",
      "Epoch [41/85] Batch 380/938 Loss D: 0.3466, Loss G: 2.0499\n",
      "Epoch [41/85] Batch 390/938 Loss D: 0.2603, Loss G: 1.7124\n",
      "Epoch [41/85] Batch 400/938 Loss D: 0.3268, Loss G: 1.8200\n",
      "Epoch [41/85] Batch 410/938 Loss D: 0.1874, Loss G: 2.8136\n",
      "Epoch [41/85] Batch 420/938 Loss D: 0.4320, Loss G: 2.3927\n",
      "Epoch [41/85] Batch 430/938 Loss D: 0.2309, Loss G: 2.9907\n",
      "Epoch [41/85] Batch 440/938 Loss D: 0.3906, Loss G: 2.8972\n",
      "Epoch [41/85] Batch 450/938 Loss D: 0.4105, Loss G: 2.0782\n",
      "Epoch [41/85] Batch 460/938 Loss D: 0.4475, Loss G: 2.2703\n",
      "Epoch [41/85] Batch 470/938 Loss D: 0.3680, Loss G: 3.5753\n",
      "Epoch [41/85] Batch 480/938 Loss D: 0.3293, Loss G: 2.8291\n",
      "Epoch [41/85] Batch 490/938 Loss D: 0.2699, Loss G: 2.6896\n",
      "Epoch [41/85] Batch 500/938 Loss D: 0.2397, Loss G: 2.2664\n",
      "Epoch [41/85] Batch 510/938 Loss D: 0.2723, Loss G: 2.4405\n",
      "Epoch [41/85] Batch 520/938 Loss D: 0.2946, Loss G: 3.3175\n",
      "Epoch [41/85] Batch 530/938 Loss D: 0.3188, Loss G: 2.5876\n",
      "Epoch [41/85] Batch 540/938 Loss D: 0.2336, Loss G: 2.4812\n",
      "Epoch [41/85] Batch 550/938 Loss D: 0.2720, Loss G: 2.3817\n",
      "Epoch [41/85] Batch 560/938 Loss D: 0.2529, Loss G: 2.8861\n",
      "Epoch [41/85] Batch 570/938 Loss D: 0.3116, Loss G: 2.3114\n",
      "Epoch [41/85] Batch 580/938 Loss D: 0.3193, Loss G: 2.3968\n",
      "Epoch [41/85] Batch 590/938 Loss D: 0.2160, Loss G: 2.5706\n",
      "Epoch [41/85] Batch 600/938 Loss D: 0.3152, Loss G: 2.0067\n",
      "Epoch [41/85] Batch 610/938 Loss D: 0.3365, Loss G: 1.6637\n",
      "Epoch [41/85] Batch 620/938 Loss D: 0.2712, Loss G: 2.6271\n",
      "Epoch [41/85] Batch 630/938 Loss D: 0.2488, Loss G: 2.9427\n",
      "Epoch [41/85] Batch 640/938 Loss D: 0.3236, Loss G: 2.5261\n",
      "Epoch [41/85] Batch 650/938 Loss D: 0.2752, Loss G: 2.3979\n",
      "Epoch [41/85] Batch 660/938 Loss D: 0.2130, Loss G: 2.0675\n",
      "Epoch [41/85] Batch 670/938 Loss D: 0.3407, Loss G: 2.4696\n",
      "Epoch [41/85] Batch 680/938 Loss D: 0.2788, Loss G: 2.2683\n",
      "Epoch [41/85] Batch 690/938 Loss D: 0.4618, Loss G: 2.4901\n",
      "Epoch [41/85] Batch 700/938 Loss D: 0.2883, Loss G: 2.7873\n",
      "Epoch [41/85] Batch 710/938 Loss D: 0.3968, Loss G: 2.4114\n",
      "Epoch [41/85] Batch 720/938 Loss D: 0.3372, Loss G: 2.7237\n",
      "Epoch [41/85] Batch 730/938 Loss D: 0.3496, Loss G: 2.8644\n",
      "Epoch [41/85] Batch 740/938 Loss D: 0.3471, Loss G: 2.1144\n",
      "Epoch [41/85] Batch 750/938 Loss D: 0.2985, Loss G: 2.8137\n",
      "Epoch [41/85] Batch 760/938 Loss D: 0.3885, Loss G: 1.7271\n",
      "Epoch [41/85] Batch 770/938 Loss D: 0.3253, Loss G: 1.8142\n",
      "Epoch [41/85] Batch 780/938 Loss D: 0.3574, Loss G: 2.0970\n",
      "Epoch [41/85] Batch 790/938 Loss D: 0.3124, Loss G: 2.7821\n",
      "Epoch [41/85] Batch 800/938 Loss D: 0.2729, Loss G: 2.6545\n",
      "Epoch [41/85] Batch 810/938 Loss D: 0.2938, Loss G: 2.1938\n",
      "Epoch [41/85] Batch 820/938 Loss D: 0.1636, Loss G: 3.1008\n",
      "Epoch [41/85] Batch 830/938 Loss D: 0.3104, Loss G: 1.7745\n",
      "Epoch [41/85] Batch 840/938 Loss D: 0.3573, Loss G: 1.6726\n",
      "Epoch [41/85] Batch 850/938 Loss D: 0.4032, Loss G: 1.8055\n",
      "Epoch [41/85] Batch 860/938 Loss D: 0.3430, Loss G: 2.5912\n",
      "Epoch [41/85] Batch 870/938 Loss D: 0.3179, Loss G: 2.3274\n",
      "Epoch [41/85] Batch 880/938 Loss D: 0.3397, Loss G: 2.3807\n",
      "Epoch [41/85] Batch 890/938 Loss D: 0.3610, Loss G: 2.5606\n",
      "Epoch [41/85] Batch 900/938 Loss D: 0.2499, Loss G: 2.6548\n",
      "Epoch [41/85] Batch 910/938 Loss D: 0.2741, Loss G: 2.5435\n",
      "Epoch [41/85] Batch 920/938 Loss D: 0.3563, Loss G: 2.0988\n",
      "Epoch [41/85] Batch 930/938 Loss D: 0.3779, Loss G: 2.0843\n",
      "Epoch [42/85] Batch 0/938 Loss D: 0.2257, Loss G: 2.7130\n",
      "Epoch [42/85] Batch 10/938 Loss D: 0.2913, Loss G: 2.5825\n",
      "Epoch [42/85] Batch 20/938 Loss D: 0.3923, Loss G: 2.9924\n",
      "Epoch [42/85] Batch 30/938 Loss D: 0.3710, Loss G: 2.5840\n",
      "Epoch [42/85] Batch 40/938 Loss D: 0.2613, Loss G: 2.2583\n",
      "Epoch [42/85] Batch 50/938 Loss D: 0.2106, Loss G: 2.7177\n",
      "Epoch [42/85] Batch 60/938 Loss D: 0.3219, Loss G: 2.3411\n",
      "Epoch [42/85] Batch 70/938 Loss D: 0.3909, Loss G: 2.1167\n",
      "Epoch [42/85] Batch 80/938 Loss D: 0.2698, Loss G: 1.9645\n",
      "Epoch [42/85] Batch 90/938 Loss D: 0.3097, Loss G: 1.9998\n",
      "Epoch [42/85] Batch 100/938 Loss D: 0.3715, Loss G: 2.2631\n",
      "Epoch [42/85] Batch 110/938 Loss D: 0.3975, Loss G: 1.9361\n",
      "Epoch [42/85] Batch 120/938 Loss D: 0.3299, Loss G: 1.7199\n",
      "Epoch [42/85] Batch 130/938 Loss D: 0.2673, Loss G: 2.1974\n",
      "Epoch [42/85] Batch 140/938 Loss D: 0.2616, Loss G: 2.2295\n",
      "Epoch [42/85] Batch 150/938 Loss D: 0.3074, Loss G: 2.1828\n",
      "Epoch [42/85] Batch 160/938 Loss D: 0.3335, Loss G: 2.7863\n",
      "Epoch [42/85] Batch 170/938 Loss D: 0.4070, Loss G: 2.5075\n",
      "Epoch [42/85] Batch 180/938 Loss D: 0.3486, Loss G: 2.1034\n",
      "Epoch [42/85] Batch 190/938 Loss D: 0.3748, Loss G: 2.1530\n",
      "Epoch [42/85] Batch 200/938 Loss D: 0.2563, Loss G: 2.3315\n",
      "Epoch [42/85] Batch 210/938 Loss D: 0.3011, Loss G: 1.9331\n",
      "Epoch [42/85] Batch 220/938 Loss D: 0.3388, Loss G: 2.3353\n",
      "Epoch [42/85] Batch 230/938 Loss D: 0.3450, Loss G: 2.2958\n",
      "Epoch [42/85] Batch 240/938 Loss D: 0.3036, Loss G: 2.3576\n",
      "Epoch [42/85] Batch 250/938 Loss D: 0.2138, Loss G: 2.5182\n",
      "Epoch [42/85] Batch 260/938 Loss D: 0.3549, Loss G: 1.9332\n",
      "Epoch [42/85] Batch 270/938 Loss D: 0.5164, Loss G: 2.2939\n",
      "Epoch [42/85] Batch 280/938 Loss D: 0.1947, Loss G: 3.0685\n",
      "Epoch [42/85] Batch 290/938 Loss D: 0.2530, Loss G: 2.7379\n",
      "Epoch [42/85] Batch 300/938 Loss D: 0.2681, Loss G: 2.4785\n",
      "Epoch [42/85] Batch 310/938 Loss D: 0.2989, Loss G: 2.1489\n",
      "Epoch [42/85] Batch 320/938 Loss D: 0.2986, Loss G: 1.8631\n",
      "Epoch [42/85] Batch 330/938 Loss D: 0.2757, Loss G: 2.1017\n",
      "Epoch [42/85] Batch 340/938 Loss D: 0.2682, Loss G: 2.5009\n",
      "Epoch [42/85] Batch 350/938 Loss D: 0.3656, Loss G: 2.2006\n",
      "Epoch [42/85] Batch 360/938 Loss D: 0.3275, Loss G: 2.1261\n",
      "Epoch [42/85] Batch 370/938 Loss D: 0.2167, Loss G: 2.4113\n",
      "Epoch [42/85] Batch 380/938 Loss D: 0.2928, Loss G: 1.9514\n",
      "Epoch [42/85] Batch 390/938 Loss D: 0.2320, Loss G: 2.5289\n",
      "Epoch [42/85] Batch 400/938 Loss D: 0.3650, Loss G: 2.1334\n",
      "Epoch [42/85] Batch 410/938 Loss D: 0.2285, Loss G: 3.0532\n",
      "Epoch [42/85] Batch 420/938 Loss D: 0.3101, Loss G: 2.6344\n",
      "Epoch [42/85] Batch 430/938 Loss D: 0.3057, Loss G: 2.2906\n",
      "Epoch [42/85] Batch 440/938 Loss D: 0.2293, Loss G: 2.6059\n",
      "Epoch [42/85] Batch 450/938 Loss D: 0.2736, Loss G: 2.2108\n",
      "Epoch [42/85] Batch 460/938 Loss D: 0.4290, Loss G: 1.6320\n",
      "Epoch [42/85] Batch 470/938 Loss D: 0.3828, Loss G: 1.9993\n",
      "Epoch [42/85] Batch 480/938 Loss D: 0.2463, Loss G: 2.2630\n",
      "Epoch [42/85] Batch 490/938 Loss D: 0.3844, Loss G: 2.2718\n",
      "Epoch [42/85] Batch 500/938 Loss D: 0.2880, Loss G: 1.9273\n",
      "Epoch [42/85] Batch 510/938 Loss D: 0.2508, Loss G: 2.5331\n",
      "Epoch [42/85] Batch 520/938 Loss D: 0.2835, Loss G: 2.3385\n",
      "Epoch [42/85] Batch 530/938 Loss D: 0.3407, Loss G: 2.4467\n",
      "Epoch [42/85] Batch 540/938 Loss D: 0.3048, Loss G: 2.2452\n",
      "Epoch [42/85] Batch 550/938 Loss D: 0.3401, Loss G: 2.2431\n",
      "Epoch [42/85] Batch 560/938 Loss D: 0.2321, Loss G: 2.4993\n",
      "Epoch [42/85] Batch 570/938 Loss D: 0.2039, Loss G: 3.6462\n",
      "Epoch [42/85] Batch 580/938 Loss D: 0.3917, Loss G: 2.2704\n",
      "Epoch [42/85] Batch 590/938 Loss D: 0.2732, Loss G: 2.4080\n",
      "Epoch [42/85] Batch 600/938 Loss D: 0.3014, Loss G: 2.5203\n",
      "Epoch [42/85] Batch 610/938 Loss D: 0.3257, Loss G: 1.8986\n",
      "Epoch [42/85] Batch 620/938 Loss D: 0.3560, Loss G: 2.0659\n",
      "Epoch [42/85] Batch 630/938 Loss D: 0.3088, Loss G: 1.8678\n",
      "Epoch [42/85] Batch 640/938 Loss D: 0.3272, Loss G: 1.8125\n",
      "Epoch [42/85] Batch 650/938 Loss D: 0.2516, Loss G: 2.6945\n",
      "Epoch [42/85] Batch 660/938 Loss D: 0.2754, Loss G: 2.0073\n",
      "Epoch [42/85] Batch 670/938 Loss D: 0.3425, Loss G: 2.1261\n",
      "Epoch [42/85] Batch 680/938 Loss D: 0.3175, Loss G: 2.2534\n",
      "Epoch [42/85] Batch 690/938 Loss D: 0.2724, Loss G: 2.1868\n",
      "Epoch [42/85] Batch 700/938 Loss D: 0.3017, Loss G: 2.2461\n",
      "Epoch [42/85] Batch 710/938 Loss D: 0.3429, Loss G: 2.2064\n",
      "Epoch [42/85] Batch 720/938 Loss D: 0.3997, Loss G: 2.3269\n",
      "Epoch [42/85] Batch 730/938 Loss D: 0.3691, Loss G: 2.0792\n",
      "Epoch [42/85] Batch 740/938 Loss D: 0.2102, Loss G: 2.4586\n",
      "Epoch [42/85] Batch 750/938 Loss D: 0.2809, Loss G: 2.2847\n",
      "Epoch [42/85] Batch 760/938 Loss D: 0.3388, Loss G: 2.2593\n",
      "Epoch [42/85] Batch 770/938 Loss D: 0.2217, Loss G: 2.4354\n",
      "Epoch [42/85] Batch 780/938 Loss D: 0.2326, Loss G: 2.9243\n",
      "Epoch [42/85] Batch 790/938 Loss D: 0.3041, Loss G: 1.9584\n",
      "Epoch [42/85] Batch 800/938 Loss D: 0.3833, Loss G: 1.8066\n",
      "Epoch [42/85] Batch 810/938 Loss D: 0.3554, Loss G: 1.5720\n",
      "Epoch [42/85] Batch 820/938 Loss D: 0.3450, Loss G: 1.8032\n",
      "Epoch [42/85] Batch 830/938 Loss D: 0.4045, Loss G: 2.1374\n",
      "Epoch [42/85] Batch 840/938 Loss D: 0.3749, Loss G: 1.9338\n",
      "Epoch [42/85] Batch 850/938 Loss D: 0.3473, Loss G: 2.7501\n",
      "Epoch [42/85] Batch 860/938 Loss D: 0.1933, Loss G: 2.7698\n",
      "Epoch [42/85] Batch 870/938 Loss D: 0.3513, Loss G: 1.7848\n",
      "Epoch [42/85] Batch 880/938 Loss D: 0.3508, Loss G: 1.8537\n",
      "Epoch [42/85] Batch 890/938 Loss D: 0.2687, Loss G: 2.4363\n",
      "Epoch [42/85] Batch 900/938 Loss D: 0.2972, Loss G: 2.3647\n",
      "Epoch [42/85] Batch 910/938 Loss D: 0.2227, Loss G: 2.4250\n",
      "Epoch [42/85] Batch 920/938 Loss D: 0.3951, Loss G: 2.0493\n",
      "Epoch [42/85] Batch 930/938 Loss D: 0.5348, Loss G: 1.9679\n",
      "Epoch [43/85] Batch 0/938 Loss D: 0.2632, Loss G: 3.3044\n",
      "Epoch [43/85] Batch 10/938 Loss D: 0.2857, Loss G: 2.2910\n",
      "Epoch [43/85] Batch 20/938 Loss D: 0.2356, Loss G: 2.5538\n",
      "Epoch [43/85] Batch 30/938 Loss D: 0.3039, Loss G: 2.2217\n",
      "Epoch [43/85] Batch 40/938 Loss D: 0.4677, Loss G: 1.4951\n",
      "Epoch [43/85] Batch 50/938 Loss D: 0.2179, Loss G: 2.2501\n",
      "Epoch [43/85] Batch 60/938 Loss D: 0.3028, Loss G: 1.7642\n",
      "Epoch [43/85] Batch 70/938 Loss D: 0.2032, Loss G: 2.2741\n",
      "Epoch [43/85] Batch 80/938 Loss D: 0.2861, Loss G: 2.5107\n",
      "Epoch [43/85] Batch 90/938 Loss D: 0.2858, Loss G: 2.5382\n",
      "Epoch [43/85] Batch 100/938 Loss D: 0.2877, Loss G: 2.3785\n",
      "Epoch [43/85] Batch 110/938 Loss D: 0.3444, Loss G: 1.4543\n",
      "Epoch [43/85] Batch 120/938 Loss D: 0.2832, Loss G: 1.9510\n",
      "Epoch [43/85] Batch 130/938 Loss D: 0.3368, Loss G: 3.2869\n",
      "Epoch [43/85] Batch 140/938 Loss D: 0.3777, Loss G: 3.4736\n",
      "Epoch [43/85] Batch 150/938 Loss D: 0.2165, Loss G: 3.2123\n",
      "Epoch [43/85] Batch 160/938 Loss D: 0.2524, Loss G: 2.3445\n",
      "Epoch [43/85] Batch 170/938 Loss D: 0.2453, Loss G: 2.4933\n",
      "Epoch [43/85] Batch 180/938 Loss D: 0.4215, Loss G: 2.3248\n",
      "Epoch [43/85] Batch 190/938 Loss D: 0.2693, Loss G: 2.7270\n",
      "Epoch [43/85] Batch 200/938 Loss D: 0.3902, Loss G: 2.4208\n",
      "Epoch [43/85] Batch 210/938 Loss D: 0.2435, Loss G: 2.8632\n",
      "Epoch [43/85] Batch 220/938 Loss D: 0.2759, Loss G: 2.3933\n",
      "Epoch [43/85] Batch 230/938 Loss D: 0.2552, Loss G: 2.1889\n",
      "Epoch [43/85] Batch 240/938 Loss D: 0.2516, Loss G: 2.7679\n",
      "Epoch [43/85] Batch 250/938 Loss D: 0.2770, Loss G: 2.3249\n",
      "Epoch [43/85] Batch 260/938 Loss D: 0.3896, Loss G: 2.0950\n",
      "Epoch [43/85] Batch 270/938 Loss D: 0.3777, Loss G: 1.7907\n",
      "Epoch [43/85] Batch 280/938 Loss D: 0.5489, Loss G: 1.3532\n",
      "Epoch [43/85] Batch 290/938 Loss D: 0.3168, Loss G: 2.0146\n",
      "Epoch [43/85] Batch 300/938 Loss D: 0.2302, Loss G: 2.4713\n",
      "Epoch [43/85] Batch 310/938 Loss D: 0.3704, Loss G: 1.8318\n",
      "Epoch [43/85] Batch 320/938 Loss D: 0.4894, Loss G: 1.9300\n",
      "Epoch [43/85] Batch 330/938 Loss D: 0.2377, Loss G: 2.7457\n",
      "Epoch [43/85] Batch 340/938 Loss D: 0.2380, Loss G: 2.2494\n",
      "Epoch [43/85] Batch 350/938 Loss D: 0.2483, Loss G: 2.4027\n",
      "Epoch [43/85] Batch 360/938 Loss D: 0.3393, Loss G: 2.4419\n",
      "Epoch [43/85] Batch 370/938 Loss D: 0.3032, Loss G: 2.0001\n",
      "Epoch [43/85] Batch 380/938 Loss D: 0.2600, Loss G: 2.6033\n",
      "Epoch [43/85] Batch 390/938 Loss D: 0.2536, Loss G: 2.3177\n",
      "Epoch [43/85] Batch 400/938 Loss D: 0.2903, Loss G: 2.1677\n",
      "Epoch [43/85] Batch 410/938 Loss D: 0.2203, Loss G: 2.3585\n",
      "Epoch [43/85] Batch 420/938 Loss D: 0.4656, Loss G: 1.6173\n",
      "Epoch [43/85] Batch 430/938 Loss D: 0.2743, Loss G: 1.7900\n",
      "Epoch [43/85] Batch 440/938 Loss D: 0.2914, Loss G: 2.2963\n",
      "Epoch [43/85] Batch 450/938 Loss D: 0.1542, Loss G: 2.7186\n",
      "Epoch [43/85] Batch 460/938 Loss D: 0.1933, Loss G: 2.6777\n",
      "Epoch [43/85] Batch 470/938 Loss D: 0.2573, Loss G: 2.5461\n",
      "Epoch [43/85] Batch 480/938 Loss D: 0.3429, Loss G: 2.5609\n",
      "Epoch [43/85] Batch 490/938 Loss D: 0.3203, Loss G: 2.6045\n",
      "Epoch [43/85] Batch 500/938 Loss D: 0.2992, Loss G: 1.8781\n",
      "Epoch [43/85] Batch 510/938 Loss D: 0.2573, Loss G: 2.2757\n",
      "Epoch [43/85] Batch 520/938 Loss D: 0.3033, Loss G: 2.1601\n",
      "Epoch [43/85] Batch 530/938 Loss D: 0.2920, Loss G: 1.6617\n",
      "Epoch [43/85] Batch 540/938 Loss D: 0.2802, Loss G: 2.3852\n",
      "Epoch [43/85] Batch 550/938 Loss D: 0.4709, Loss G: 2.2357\n",
      "Epoch [43/85] Batch 560/938 Loss D: 0.3231, Loss G: 1.8884\n",
      "Epoch [43/85] Batch 570/938 Loss D: 0.3177, Loss G: 2.4126\n",
      "Epoch [43/85] Batch 580/938 Loss D: 0.3057, Loss G: 2.7138\n",
      "Epoch [43/85] Batch 590/938 Loss D: 0.2831, Loss G: 2.5902\n",
      "Epoch [43/85] Batch 600/938 Loss D: 0.3161, Loss G: 2.1444\n",
      "Epoch [43/85] Batch 610/938 Loss D: 0.2855, Loss G: 2.4753\n",
      "Epoch [43/85] Batch 620/938 Loss D: 0.3441, Loss G: 2.8821\n",
      "Epoch [43/85] Batch 630/938 Loss D: 0.3568, Loss G: 2.1129\n",
      "Epoch [43/85] Batch 640/938 Loss D: 0.1644, Loss G: 2.7065\n",
      "Epoch [43/85] Batch 650/938 Loss D: 0.3155, Loss G: 2.4553\n",
      "Epoch [43/85] Batch 660/938 Loss D: 0.2429, Loss G: 2.4204\n",
      "Epoch [43/85] Batch 670/938 Loss D: 0.2424, Loss G: 2.5652\n",
      "Epoch [43/85] Batch 680/938 Loss D: 0.3911, Loss G: 2.3891\n",
      "Epoch [43/85] Batch 690/938 Loss D: 0.4799, Loss G: 1.8764\n",
      "Epoch [43/85] Batch 700/938 Loss D: 0.3543, Loss G: 1.7534\n",
      "Epoch [43/85] Batch 710/938 Loss D: 0.2357, Loss G: 2.4018\n",
      "Epoch [43/85] Batch 720/938 Loss D: 0.4035, Loss G: 2.0224\n",
      "Epoch [43/85] Batch 730/938 Loss D: 0.2971, Loss G: 1.8777\n",
      "Epoch [43/85] Batch 740/938 Loss D: 0.2740, Loss G: 2.2603\n",
      "Epoch [43/85] Batch 750/938 Loss D: 0.2797, Loss G: 2.3647\n",
      "Epoch [43/85] Batch 760/938 Loss D: 0.3115, Loss G: 2.3873\n",
      "Epoch [43/85] Batch 770/938 Loss D: 0.3093, Loss G: 1.9418\n",
      "Epoch [43/85] Batch 780/938 Loss D: 0.3568, Loss G: 1.7214\n",
      "Epoch [43/85] Batch 790/938 Loss D: 0.2864, Loss G: 2.0419\n",
      "Epoch [43/85] Batch 800/938 Loss D: 0.3775, Loss G: 2.5392\n",
      "Epoch [43/85] Batch 810/938 Loss D: 0.3614, Loss G: 3.0466\n",
      "Epoch [43/85] Batch 820/938 Loss D: 0.2372, Loss G: 2.4037\n",
      "Epoch [43/85] Batch 830/938 Loss D: 0.4205, Loss G: 1.5877\n",
      "Epoch [43/85] Batch 840/938 Loss D: 0.3780, Loss G: 1.9382\n",
      "Epoch [43/85] Batch 850/938 Loss D: 0.3360, Loss G: 2.1628\n",
      "Epoch [43/85] Batch 860/938 Loss D: 0.3019, Loss G: 2.7978\n",
      "Epoch [43/85] Batch 870/938 Loss D: 0.3709, Loss G: 2.7628\n",
      "Epoch [43/85] Batch 880/938 Loss D: 0.3376, Loss G: 2.6794\n",
      "Epoch [43/85] Batch 890/938 Loss D: 0.3184, Loss G: 2.7072\n",
      "Epoch [43/85] Batch 900/938 Loss D: 0.1857, Loss G: 2.6637\n",
      "Epoch [43/85] Batch 910/938 Loss D: 0.4447, Loss G: 1.7142\n",
      "Epoch [43/85] Batch 920/938 Loss D: 0.3395, Loss G: 2.4688\n",
      "Epoch [43/85] Batch 930/938 Loss D: 0.2956, Loss G: 2.6403\n",
      "Epoch [44/85] Batch 0/938 Loss D: 0.2938, Loss G: 2.2055\n",
      "Epoch [44/85] Batch 10/938 Loss D: 0.3284, Loss G: 2.0709\n",
      "Epoch [44/85] Batch 20/938 Loss D: 0.2931, Loss G: 2.5739\n",
      "Epoch [44/85] Batch 30/938 Loss D: 0.2524, Loss G: 2.4903\n",
      "Epoch [44/85] Batch 40/938 Loss D: 0.2580, Loss G: 2.0894\n",
      "Epoch [44/85] Batch 50/938 Loss D: 0.2310, Loss G: 2.9658\n",
      "Epoch [44/85] Batch 60/938 Loss D: 0.2563, Loss G: 2.4375\n",
      "Epoch [44/85] Batch 70/938 Loss D: 0.3504, Loss G: 2.4142\n",
      "Epoch [44/85] Batch 80/938 Loss D: 0.2956, Loss G: 2.5508\n",
      "Epoch [44/85] Batch 90/938 Loss D: 0.3203, Loss G: 2.4964\n",
      "Epoch [44/85] Batch 100/938 Loss D: 0.2823, Loss G: 3.3962\n",
      "Epoch [44/85] Batch 110/938 Loss D: 0.3373, Loss G: 2.2713\n",
      "Epoch [44/85] Batch 120/938 Loss D: 0.2298, Loss G: 2.8237\n",
      "Epoch [44/85] Batch 130/938 Loss D: 0.2639, Loss G: 3.0637\n",
      "Epoch [44/85] Batch 140/938 Loss D: 0.2508, Loss G: 2.9314\n",
      "Epoch [44/85] Batch 150/938 Loss D: 0.3627, Loss G: 2.0296\n",
      "Epoch [44/85] Batch 160/938 Loss D: 0.3103, Loss G: 1.5870\n",
      "Epoch [44/85] Batch 170/938 Loss D: 0.2544, Loss G: 2.4610\n",
      "Epoch [44/85] Batch 180/938 Loss D: 0.3816, Loss G: 2.8480\n",
      "Epoch [44/85] Batch 190/938 Loss D: 0.2778, Loss G: 2.7077\n",
      "Epoch [44/85] Batch 200/938 Loss D: 0.1787, Loss G: 3.1972\n",
      "Epoch [44/85] Batch 210/938 Loss D: 0.2127, Loss G: 2.9159\n",
      "Epoch [44/85] Batch 220/938 Loss D: 0.3485, Loss G: 2.3584\n",
      "Epoch [44/85] Batch 230/938 Loss D: 0.2270, Loss G: 2.6913\n",
      "Epoch [44/85] Batch 240/938 Loss D: 0.3380, Loss G: 3.0712\n",
      "Epoch [44/85] Batch 250/938 Loss D: 0.4380, Loss G: 2.2948\n",
      "Epoch [44/85] Batch 260/938 Loss D: 0.2422, Loss G: 2.9994\n",
      "Epoch [44/85] Batch 270/938 Loss D: 0.2575, Loss G: 2.4888\n",
      "Epoch [44/85] Batch 280/938 Loss D: 0.2553, Loss G: 2.9213\n",
      "Epoch [44/85] Batch 290/938 Loss D: 0.2580, Loss G: 2.8916\n",
      "Epoch [44/85] Batch 300/938 Loss D: 0.3152, Loss G: 2.5169\n",
      "Epoch [44/85] Batch 310/938 Loss D: 0.2278, Loss G: 3.3204\n",
      "Epoch [44/85] Batch 320/938 Loss D: 0.3452, Loss G: 2.6051\n",
      "Epoch [44/85] Batch 330/938 Loss D: 0.2764, Loss G: 2.5857\n",
      "Epoch [44/85] Batch 340/938 Loss D: 0.2138, Loss G: 2.5205\n",
      "Epoch [44/85] Batch 350/938 Loss D: 0.2894, Loss G: 2.3787\n",
      "Epoch [44/85] Batch 360/938 Loss D: 0.3582, Loss G: 2.7743\n",
      "Epoch [44/85] Batch 370/938 Loss D: 0.2565, Loss G: 2.5170\n",
      "Epoch [44/85] Batch 380/938 Loss D: 0.2117, Loss G: 2.4692\n",
      "Epoch [44/85] Batch 390/938 Loss D: 0.1951, Loss G: 2.4403\n",
      "Epoch [44/85] Batch 400/938 Loss D: 0.2758, Loss G: 2.1291\n",
      "Epoch [44/85] Batch 410/938 Loss D: 0.3195, Loss G: 2.2726\n",
      "Epoch [44/85] Batch 420/938 Loss D: 0.5128, Loss G: 1.8466\n",
      "Epoch [44/85] Batch 430/938 Loss D: 0.3144, Loss G: 1.9305\n",
      "Epoch [44/85] Batch 440/938 Loss D: 0.3760, Loss G: 2.2392\n",
      "Epoch [44/85] Batch 450/938 Loss D: 0.2774, Loss G: 2.4370\n",
      "Epoch [44/85] Batch 460/938 Loss D: 0.2977, Loss G: 2.7954\n",
      "Epoch [44/85] Batch 470/938 Loss D: 0.2875, Loss G: 2.3091\n",
      "Epoch [44/85] Batch 480/938 Loss D: 0.2409, Loss G: 2.4574\n",
      "Epoch [44/85] Batch 490/938 Loss D: 0.2723, Loss G: 2.3868\n",
      "Epoch [44/85] Batch 500/938 Loss D: 0.3745, Loss G: 2.0893\n",
      "Epoch [44/85] Batch 510/938 Loss D: 0.3677, Loss G: 2.2339\n",
      "Epoch [44/85] Batch 520/938 Loss D: 0.2223, Loss G: 2.6683\n",
      "Epoch [44/85] Batch 530/938 Loss D: 0.2206, Loss G: 2.7872\n",
      "Epoch [44/85] Batch 540/938 Loss D: 0.2759, Loss G: 1.9599\n",
      "Epoch [44/85] Batch 550/938 Loss D: 0.3324, Loss G: 1.6630\n",
      "Epoch [44/85] Batch 560/938 Loss D: 0.2572, Loss G: 2.1519\n",
      "Epoch [44/85] Batch 570/938 Loss D: 0.3792, Loss G: 2.7639\n",
      "Epoch [44/85] Batch 580/938 Loss D: 0.3914, Loss G: 2.4940\n",
      "Epoch [44/85] Batch 590/938 Loss D: 0.4802, Loss G: 1.9838\n",
      "Epoch [44/85] Batch 600/938 Loss D: 0.2057, Loss G: 2.9402\n",
      "Epoch [44/85] Batch 610/938 Loss D: 0.1776, Loss G: 3.1618\n",
      "Epoch [44/85] Batch 620/938 Loss D: 0.3794, Loss G: 2.1673\n",
      "Epoch [44/85] Batch 630/938 Loss D: 0.3455, Loss G: 2.2805\n",
      "Epoch [44/85] Batch 640/938 Loss D: 0.2909, Loss G: 2.3084\n",
      "Epoch [44/85] Batch 650/938 Loss D: 0.3907, Loss G: 2.6942\n",
      "Epoch [44/85] Batch 660/938 Loss D: 0.4236, Loss G: 2.5829\n",
      "Epoch [44/85] Batch 670/938 Loss D: 0.3494, Loss G: 3.0689\n",
      "Epoch [44/85] Batch 680/938 Loss D: 0.2428, Loss G: 2.6051\n",
      "Epoch [44/85] Batch 690/938 Loss D: 0.2722, Loss G: 2.2632\n",
      "Epoch [44/85] Batch 700/938 Loss D: 0.3583, Loss G: 2.2530\n",
      "Epoch [44/85] Batch 710/938 Loss D: 0.2277, Loss G: 2.4513\n",
      "Epoch [44/85] Batch 720/938 Loss D: 0.3472, Loss G: 2.0615\n",
      "Epoch [44/85] Batch 730/938 Loss D: 0.2848, Loss G: 2.2009\n",
      "Epoch [44/85] Batch 740/938 Loss D: 0.2357, Loss G: 2.0803\n",
      "Epoch [44/85] Batch 750/938 Loss D: 0.3915, Loss G: 1.9116\n",
      "Epoch [44/85] Batch 760/938 Loss D: 0.2483, Loss G: 2.6969\n",
      "Epoch [44/85] Batch 770/938 Loss D: 0.2472, Loss G: 2.6196\n",
      "Epoch [44/85] Batch 780/938 Loss D: 0.2259, Loss G: 2.0578\n",
      "Epoch [44/85] Batch 790/938 Loss D: 0.2893, Loss G: 1.9843\n",
      "Epoch [44/85] Batch 800/938 Loss D: 0.3467, Loss G: 2.5235\n",
      "Epoch [44/85] Batch 810/938 Loss D: 0.3406, Loss G: 2.0414\n",
      "Epoch [44/85] Batch 820/938 Loss D: 0.4752, Loss G: 2.2430\n",
      "Epoch [44/85] Batch 830/938 Loss D: 0.3491, Loss G: 2.9430\n",
      "Epoch [44/85] Batch 840/938 Loss D: 0.3385, Loss G: 2.4413\n",
      "Epoch [44/85] Batch 850/938 Loss D: 0.2810, Loss G: 2.6092\n",
      "Epoch [44/85] Batch 860/938 Loss D: 0.2978, Loss G: 3.0159\n",
      "Epoch [44/85] Batch 870/938 Loss D: 0.3239, Loss G: 2.5593\n",
      "Epoch [44/85] Batch 880/938 Loss D: 0.2999, Loss G: 2.3559\n",
      "Epoch [44/85] Batch 890/938 Loss D: 0.3522, Loss G: 2.4493\n",
      "Epoch [44/85] Batch 900/938 Loss D: 0.3550, Loss G: 2.2127\n",
      "Epoch [44/85] Batch 910/938 Loss D: 0.2347, Loss G: 2.6989\n",
      "Epoch [44/85] Batch 920/938 Loss D: 0.3170, Loss G: 2.0888\n",
      "Epoch [44/85] Batch 930/938 Loss D: 0.2962, Loss G: 2.3321\n",
      "Epoch [45/85] Batch 0/938 Loss D: 0.3669, Loss G: 2.5761\n",
      "Epoch [45/85] Batch 10/938 Loss D: 0.2739, Loss G: 2.9049\n",
      "Epoch [45/85] Batch 20/938 Loss D: 0.2758, Loss G: 2.2510\n",
      "Epoch [45/85] Batch 30/938 Loss D: 0.2883, Loss G: 2.2763\n",
      "Epoch [45/85] Batch 40/938 Loss D: 0.3470, Loss G: 1.8248\n",
      "Epoch [45/85] Batch 50/938 Loss D: 0.1983, Loss G: 2.3212\n",
      "Epoch [45/85] Batch 60/938 Loss D: 0.2482, Loss G: 2.0905\n",
      "Epoch [45/85] Batch 70/938 Loss D: 0.3355, Loss G: 2.4247\n",
      "Epoch [45/85] Batch 80/938 Loss D: 0.2317, Loss G: 2.6881\n",
      "Epoch [45/85] Batch 90/938 Loss D: 0.3043, Loss G: 2.9737\n",
      "Epoch [45/85] Batch 100/938 Loss D: 0.2992, Loss G: 2.5427\n",
      "Epoch [45/85] Batch 110/938 Loss D: 0.2633, Loss G: 2.5557\n",
      "Epoch [45/85] Batch 120/938 Loss D: 0.2104, Loss G: 2.9503\n",
      "Epoch [45/85] Batch 130/938 Loss D: 0.3281, Loss G: 1.9457\n",
      "Epoch [45/85] Batch 140/938 Loss D: 0.3760, Loss G: 1.8586\n",
      "Epoch [45/85] Batch 150/938 Loss D: 0.2500, Loss G: 1.8856\n",
      "Epoch [45/85] Batch 160/938 Loss D: 0.2932, Loss G: 2.4877\n",
      "Epoch [45/85] Batch 170/938 Loss D: 0.4117, Loss G: 1.8321\n",
      "Epoch [45/85] Batch 180/938 Loss D: 0.2741, Loss G: 2.8525\n",
      "Epoch [45/85] Batch 190/938 Loss D: 0.3369, Loss G: 2.9049\n",
      "Epoch [45/85] Batch 200/938 Loss D: 0.3131, Loss G: 2.6074\n",
      "Epoch [45/85] Batch 210/938 Loss D: 0.3078, Loss G: 3.3625\n",
      "Epoch [45/85] Batch 220/938 Loss D: 0.3251, Loss G: 2.1857\n",
      "Epoch [45/85] Batch 230/938 Loss D: 0.2740, Loss G: 2.4018\n",
      "Epoch [45/85] Batch 240/938 Loss D: 0.3143, Loss G: 2.2636\n",
      "Epoch [45/85] Batch 250/938 Loss D: 0.2644, Loss G: 2.3707\n",
      "Epoch [45/85] Batch 260/938 Loss D: 0.2169, Loss G: 2.5145\n",
      "Epoch [45/85] Batch 270/938 Loss D: 0.2883, Loss G: 1.7626\n",
      "Epoch [45/85] Batch 280/938 Loss D: 0.2740, Loss G: 2.6189\n",
      "Epoch [45/85] Batch 290/938 Loss D: 0.3113, Loss G: 2.9706\n",
      "Epoch [45/85] Batch 300/938 Loss D: 0.2085, Loss G: 2.8513\n",
      "Epoch [45/85] Batch 310/938 Loss D: 0.2569, Loss G: 3.0593\n",
      "Epoch [45/85] Batch 320/938 Loss D: 0.2126, Loss G: 3.1716\n",
      "Epoch [45/85] Batch 330/938 Loss D: 0.3091, Loss G: 2.4330\n",
      "Epoch [45/85] Batch 340/938 Loss D: 0.2369, Loss G: 2.7538\n",
      "Epoch [45/85] Batch 350/938 Loss D: 0.1562, Loss G: 3.3161\n",
      "Epoch [45/85] Batch 360/938 Loss D: 0.2634, Loss G: 2.0290\n",
      "Epoch [45/85] Batch 370/938 Loss D: 0.3041, Loss G: 2.0129\n",
      "Epoch [45/85] Batch 380/938 Loss D: 0.3056, Loss G: 2.3933\n",
      "Epoch [45/85] Batch 390/938 Loss D: 0.1870, Loss G: 2.9117\n",
      "Epoch [45/85] Batch 400/938 Loss D: 0.3198, Loss G: 2.3043\n",
      "Epoch [45/85] Batch 410/938 Loss D: 0.2527, Loss G: 1.9579\n",
      "Epoch [45/85] Batch 420/938 Loss D: 0.2980, Loss G: 2.5341\n",
      "Epoch [45/85] Batch 430/938 Loss D: 0.2210, Loss G: 2.6956\n",
      "Epoch [45/85] Batch 440/938 Loss D: 0.3127, Loss G: 2.7185\n",
      "Epoch [45/85] Batch 450/938 Loss D: 0.3168, Loss G: 1.9626\n",
      "Epoch [45/85] Batch 460/938 Loss D: 0.3025, Loss G: 2.4872\n",
      "Epoch [45/85] Batch 470/938 Loss D: 0.3063, Loss G: 2.5061\n",
      "Epoch [45/85] Batch 480/938 Loss D: 0.2363, Loss G: 1.8450\n",
      "Epoch [45/85] Batch 490/938 Loss D: 0.3734, Loss G: 2.1751\n",
      "Epoch [45/85] Batch 500/938 Loss D: 0.3497, Loss G: 2.6115\n",
      "Epoch [45/85] Batch 510/938 Loss D: 0.3945, Loss G: 2.1881\n",
      "Epoch [45/85] Batch 520/938 Loss D: 0.3425, Loss G: 2.1716\n",
      "Epoch [45/85] Batch 530/938 Loss D: 0.3618, Loss G: 2.5541\n",
      "Epoch [45/85] Batch 540/938 Loss D: 0.5141, Loss G: 1.5576\n",
      "Epoch [45/85] Batch 550/938 Loss D: 0.2766, Loss G: 2.2704\n",
      "Epoch [45/85] Batch 560/938 Loss D: 0.3219, Loss G: 2.3261\n",
      "Epoch [45/85] Batch 570/938 Loss D: 0.3112, Loss G: 1.9741\n",
      "Epoch [45/85] Batch 580/938 Loss D: 0.3899, Loss G: 1.4664\n",
      "Epoch [45/85] Batch 590/938 Loss D: 0.3731, Loss G: 1.7063\n",
      "Epoch [45/85] Batch 600/938 Loss D: 0.3066, Loss G: 2.7227\n",
      "Epoch [45/85] Batch 610/938 Loss D: 0.2822, Loss G: 2.4279\n",
      "Epoch [45/85] Batch 620/938 Loss D: 0.4625, Loss G: 2.2682\n",
      "Epoch [45/85] Batch 630/938 Loss D: 0.2211, Loss G: 2.6969\n",
      "Epoch [45/85] Batch 640/938 Loss D: 0.3852, Loss G: 2.3845\n",
      "Epoch [45/85] Batch 650/938 Loss D: 0.2435, Loss G: 2.7347\n",
      "Epoch [45/85] Batch 660/938 Loss D: 0.2373, Loss G: 2.5164\n",
      "Epoch [45/85] Batch 670/938 Loss D: 0.4091, Loss G: 2.1382\n",
      "Epoch [45/85] Batch 680/938 Loss D: 0.3763, Loss G: 1.9149\n",
      "Epoch [45/85] Batch 690/938 Loss D: 0.2920, Loss G: 2.4483\n",
      "Epoch [45/85] Batch 700/938 Loss D: 0.1871, Loss G: 3.1726\n",
      "Epoch [45/85] Batch 710/938 Loss D: 0.3342, Loss G: 2.3757\n",
      "Epoch [45/85] Batch 720/938 Loss D: 0.3748, Loss G: 2.1163\n",
      "Epoch [45/85] Batch 730/938 Loss D: 0.3153, Loss G: 2.0637\n",
      "Epoch [45/85] Batch 740/938 Loss D: 0.3269, Loss G: 1.9127\n",
      "Epoch [45/85] Batch 750/938 Loss D: 0.3289, Loss G: 2.0004\n",
      "Epoch [45/85] Batch 760/938 Loss D: 0.2328, Loss G: 2.2969\n",
      "Epoch [45/85] Batch 770/938 Loss D: 0.2260, Loss G: 2.5630\n",
      "Epoch [45/85] Batch 780/938 Loss D: 0.3180, Loss G: 2.3907\n",
      "Epoch [45/85] Batch 790/938 Loss D: 0.3120, Loss G: 2.6910\n",
      "Epoch [45/85] Batch 800/938 Loss D: 0.3061, Loss G: 2.2941\n",
      "Epoch [45/85] Batch 810/938 Loss D: 0.3250, Loss G: 2.9293\n",
      "Epoch [45/85] Batch 820/938 Loss D: 0.2805, Loss G: 2.2136\n",
      "Epoch [45/85] Batch 830/938 Loss D: 0.2962, Loss G: 1.8544\n",
      "Epoch [45/85] Batch 840/938 Loss D: 0.2359, Loss G: 2.4135\n",
      "Epoch [45/85] Batch 850/938 Loss D: 0.3349, Loss G: 2.0099\n",
      "Epoch [45/85] Batch 860/938 Loss D: 0.2586, Loss G: 2.6002\n",
      "Epoch [45/85] Batch 870/938 Loss D: 0.3358, Loss G: 2.6022\n",
      "Epoch [45/85] Batch 880/938 Loss D: 0.3499, Loss G: 2.0815\n",
      "Epoch [45/85] Batch 890/938 Loss D: 0.4302, Loss G: 1.8700\n",
      "Epoch [45/85] Batch 900/938 Loss D: 0.2958, Loss G: 2.3393\n",
      "Epoch [45/85] Batch 910/938 Loss D: 0.2516, Loss G: 2.2328\n",
      "Epoch [45/85] Batch 920/938 Loss D: 0.3243, Loss G: 1.7741\n",
      "Epoch [45/85] Batch 930/938 Loss D: 0.2517, Loss G: 2.5033\n",
      "Epoch [46/85] Batch 0/938 Loss D: 0.3044, Loss G: 2.1761\n",
      "Epoch [46/85] Batch 10/938 Loss D: 0.3757, Loss G: 2.0020\n",
      "Epoch [46/85] Batch 20/938 Loss D: 0.2661, Loss G: 2.7799\n",
      "Epoch [46/85] Batch 30/938 Loss D: 0.2048, Loss G: 2.7986\n",
      "Epoch [46/85] Batch 40/938 Loss D: 0.3346, Loss G: 2.5882\n",
      "Epoch [46/85] Batch 50/938 Loss D: 0.2087, Loss G: 2.4869\n",
      "Epoch [46/85] Batch 60/938 Loss D: 0.2622, Loss G: 2.0663\n",
      "Epoch [46/85] Batch 70/938 Loss D: 0.2797, Loss G: 2.2833\n",
      "Epoch [46/85] Batch 80/938 Loss D: 0.2710, Loss G: 2.5106\n",
      "Epoch [46/85] Batch 90/938 Loss D: 0.2435, Loss G: 2.8541\n",
      "Epoch [46/85] Batch 100/938 Loss D: 0.4709, Loss G: 2.6245\n",
      "Epoch [46/85] Batch 110/938 Loss D: 0.2930, Loss G: 2.7443\n",
      "Epoch [46/85] Batch 120/938 Loss D: 0.2722, Loss G: 3.1419\n",
      "Epoch [46/85] Batch 130/938 Loss D: 0.3323, Loss G: 1.9535\n",
      "Epoch [46/85] Batch 140/938 Loss D: 0.3881, Loss G: 2.4804\n",
      "Epoch [46/85] Batch 150/938 Loss D: 0.2208, Loss G: 2.8876\n",
      "Epoch [46/85] Batch 160/938 Loss D: 0.3790, Loss G: 2.4695\n",
      "Epoch [46/85] Batch 170/938 Loss D: 0.2781, Loss G: 2.2821\n",
      "Epoch [46/85] Batch 180/938 Loss D: 0.3695, Loss G: 1.7339\n",
      "Epoch [46/85] Batch 190/938 Loss D: 0.3161, Loss G: 2.5132\n",
      "Epoch [46/85] Batch 200/938 Loss D: 0.3044, Loss G: 2.5749\n",
      "Epoch [46/85] Batch 210/938 Loss D: 0.2441, Loss G: 2.6438\n",
      "Epoch [46/85] Batch 220/938 Loss D: 0.1695, Loss G: 2.7819\n",
      "Epoch [46/85] Batch 230/938 Loss D: 0.4352, Loss G: 1.7601\n",
      "Epoch [46/85] Batch 240/938 Loss D: 0.3314, Loss G: 2.9057\n",
      "Epoch [46/85] Batch 250/938 Loss D: 0.2770, Loss G: 3.0567\n",
      "Epoch [46/85] Batch 260/938 Loss D: 0.3285, Loss G: 2.0485\n",
      "Epoch [46/85] Batch 270/938 Loss D: 0.2326, Loss G: 1.9805\n",
      "Epoch [46/85] Batch 280/938 Loss D: 0.3227, Loss G: 2.6970\n",
      "Epoch [46/85] Batch 290/938 Loss D: 0.2577, Loss G: 2.2752\n",
      "Epoch [46/85] Batch 300/938 Loss D: 0.3117, Loss G: 2.1457\n",
      "Epoch [46/85] Batch 310/938 Loss D: 0.2624, Loss G: 2.8129\n",
      "Epoch [46/85] Batch 320/938 Loss D: 0.3223, Loss G: 2.4161\n",
      "Epoch [46/85] Batch 330/938 Loss D: 0.2227, Loss G: 2.3135\n",
      "Epoch [46/85] Batch 340/938 Loss D: 0.3409, Loss G: 2.5087\n",
      "Epoch [46/85] Batch 350/938 Loss D: 0.2271, Loss G: 2.7083\n",
      "Epoch [46/85] Batch 360/938 Loss D: 0.2184, Loss G: 3.0564\n",
      "Epoch [46/85] Batch 370/938 Loss D: 0.4009, Loss G: 2.2087\n",
      "Epoch [46/85] Batch 380/938 Loss D: 0.3840, Loss G: 2.4966\n",
      "Epoch [46/85] Batch 390/938 Loss D: 0.4295, Loss G: 1.4883\n",
      "Epoch [46/85] Batch 400/938 Loss D: 0.4274, Loss G: 1.5817\n",
      "Epoch [46/85] Batch 410/938 Loss D: 0.3495, Loss G: 2.4685\n",
      "Epoch [46/85] Batch 420/938 Loss D: 0.2022, Loss G: 3.1197\n",
      "Epoch [46/85] Batch 430/938 Loss D: 0.2305, Loss G: 3.1892\n",
      "Epoch [46/85] Batch 440/938 Loss D: 0.3939, Loss G: 2.0552\n",
      "Epoch [46/85] Batch 450/938 Loss D: 0.2215, Loss G: 2.1166\n",
      "Epoch [46/85] Batch 460/938 Loss D: 0.2717, Loss G: 2.3064\n",
      "Epoch [46/85] Batch 470/938 Loss D: 0.2689, Loss G: 2.3396\n",
      "Epoch [46/85] Batch 480/938 Loss D: 0.2639, Loss G: 2.6155\n",
      "Epoch [46/85] Batch 490/938 Loss D: 0.3421, Loss G: 2.3427\n",
      "Epoch [46/85] Batch 500/938 Loss D: 0.2217, Loss G: 2.7126\n",
      "Epoch [46/85] Batch 510/938 Loss D: 0.2112, Loss G: 2.5286\n",
      "Epoch [46/85] Batch 520/938 Loss D: 0.5151, Loss G: 2.1218\n",
      "Epoch [46/85] Batch 530/938 Loss D: 0.2873, Loss G: 2.0313\n",
      "Epoch [46/85] Batch 540/938 Loss D: 0.5557, Loss G: 1.8239\n",
      "Epoch [46/85] Batch 550/938 Loss D: 0.4309, Loss G: 1.6145\n",
      "Epoch [46/85] Batch 560/938 Loss D: 0.3011, Loss G: 2.7320\n",
      "Epoch [46/85] Batch 570/938 Loss D: 0.2458, Loss G: 2.3525\n",
      "Epoch [46/85] Batch 580/938 Loss D: 0.2188, Loss G: 2.4036\n",
      "Epoch [46/85] Batch 590/938 Loss D: 0.2891, Loss G: 2.9646\n",
      "Epoch [46/85] Batch 600/938 Loss D: 0.1372, Loss G: 3.3816\n",
      "Epoch [46/85] Batch 610/938 Loss D: 0.2023, Loss G: 2.4344\n",
      "Epoch [46/85] Batch 620/938 Loss D: 0.3089, Loss G: 2.0440\n",
      "Epoch [46/85] Batch 630/938 Loss D: 0.3646, Loss G: 2.2045\n",
      "Epoch [46/85] Batch 640/938 Loss D: 0.1870, Loss G: 2.6935\n",
      "Epoch [46/85] Batch 650/938 Loss D: 0.1931, Loss G: 2.3632\n",
      "Epoch [46/85] Batch 660/938 Loss D: 0.2407, Loss G: 2.3646\n",
      "Epoch [46/85] Batch 670/938 Loss D: 0.3082, Loss G: 2.0133\n",
      "Epoch [46/85] Batch 680/938 Loss D: 0.2341, Loss G: 2.7277\n",
      "Epoch [46/85] Batch 690/938 Loss D: 0.2903, Loss G: 2.9741\n",
      "Epoch [46/85] Batch 700/938 Loss D: 0.4185, Loss G: 2.4573\n",
      "Epoch [46/85] Batch 710/938 Loss D: 0.2605, Loss G: 2.2114\n",
      "Epoch [46/85] Batch 720/938 Loss D: 0.3528, Loss G: 1.9610\n",
      "Epoch [46/85] Batch 730/938 Loss D: 0.2866, Loss G: 3.0955\n",
      "Epoch [46/85] Batch 740/938 Loss D: 0.3204, Loss G: 2.5950\n",
      "Epoch [46/85] Batch 750/938 Loss D: 0.2359, Loss G: 2.8933\n",
      "Epoch [46/85] Batch 760/938 Loss D: 0.3218, Loss G: 2.6441\n",
      "Epoch [46/85] Batch 770/938 Loss D: 0.1569, Loss G: 3.2065\n",
      "Epoch [46/85] Batch 780/938 Loss D: 0.2710, Loss G: 2.8683\n",
      "Epoch [46/85] Batch 790/938 Loss D: 0.3151, Loss G: 2.3405\n",
      "Epoch [46/85] Batch 800/938 Loss D: 0.3520, Loss G: 2.1058\n",
      "Epoch [46/85] Batch 810/938 Loss D: 0.2940, Loss G: 2.8938\n",
      "Epoch [46/85] Batch 820/938 Loss D: 0.3141, Loss G: 2.5911\n",
      "Epoch [46/85] Batch 830/938 Loss D: 0.1414, Loss G: 3.5163\n",
      "Epoch [46/85] Batch 840/938 Loss D: 0.2763, Loss G: 2.1494\n",
      "Epoch [46/85] Batch 850/938 Loss D: 0.2305, Loss G: 2.5851\n",
      "Epoch [46/85] Batch 860/938 Loss D: 0.3030, Loss G: 2.3410\n",
      "Epoch [46/85] Batch 870/938 Loss D: 0.2888, Loss G: 2.8841\n",
      "Epoch [46/85] Batch 880/938 Loss D: 0.3206, Loss G: 2.1656\n",
      "Epoch [46/85] Batch 890/938 Loss D: 0.2623, Loss G: 2.0297\n",
      "Epoch [46/85] Batch 900/938 Loss D: 0.3279, Loss G: 1.8291\n",
      "Epoch [46/85] Batch 910/938 Loss D: 0.2601, Loss G: 2.3086\n",
      "Epoch [46/85] Batch 920/938 Loss D: 0.2062, Loss G: 2.6302\n",
      "Epoch [46/85] Batch 930/938 Loss D: 0.2312, Loss G: 2.5100\n",
      "Epoch [47/85] Batch 0/938 Loss D: 0.3868, Loss G: 1.5917\n",
      "Epoch [47/85] Batch 10/938 Loss D: 0.3212, Loss G: 2.5364\n",
      "Epoch [47/85] Batch 20/938 Loss D: 0.3321, Loss G: 2.6133\n",
      "Epoch [47/85] Batch 30/938 Loss D: 0.3198, Loss G: 2.0960\n",
      "Epoch [47/85] Batch 40/938 Loss D: 0.4901, Loss G: 2.1359\n",
      "Epoch [47/85] Batch 50/938 Loss D: 0.3356, Loss G: 2.4899\n",
      "Epoch [47/85] Batch 60/938 Loss D: 0.2045, Loss G: 2.9432\n",
      "Epoch [47/85] Batch 70/938 Loss D: 0.1873, Loss G: 2.6887\n",
      "Epoch [47/85] Batch 80/938 Loss D: 0.2459, Loss G: 2.3219\n",
      "Epoch [47/85] Batch 90/938 Loss D: 0.3149, Loss G: 2.6691\n",
      "Epoch [47/85] Batch 100/938 Loss D: 0.2543, Loss G: 2.4194\n",
      "Epoch [47/85] Batch 110/938 Loss D: 0.3272, Loss G: 2.0012\n",
      "Epoch [47/85] Batch 120/938 Loss D: 0.4262, Loss G: 1.5965\n",
      "Epoch [47/85] Batch 130/938 Loss D: 0.2496, Loss G: 2.3804\n",
      "Epoch [47/85] Batch 140/938 Loss D: 0.3019, Loss G: 2.4699\n",
      "Epoch [47/85] Batch 150/938 Loss D: 0.3730, Loss G: 2.3197\n",
      "Epoch [47/85] Batch 160/938 Loss D: 0.3614, Loss G: 2.7081\n",
      "Epoch [47/85] Batch 170/938 Loss D: 0.3207, Loss G: 2.5751\n",
      "Epoch [47/85] Batch 180/938 Loss D: 0.2197, Loss G: 3.0746\n",
      "Epoch [47/85] Batch 190/938 Loss D: 0.3215, Loss G: 2.5247\n",
      "Epoch [47/85] Batch 200/938 Loss D: 0.2401, Loss G: 2.4703\n",
      "Epoch [47/85] Batch 210/938 Loss D: 0.4030, Loss G: 2.0858\n",
      "Epoch [47/85] Batch 220/938 Loss D: 0.2210, Loss G: 2.3831\n",
      "Epoch [47/85] Batch 230/938 Loss D: 0.3497, Loss G: 2.2871\n",
      "Epoch [47/85] Batch 240/938 Loss D: 0.2588, Loss G: 2.6731\n",
      "Epoch [47/85] Batch 250/938 Loss D: 0.3470, Loss G: 2.8409\n",
      "Epoch [47/85] Batch 260/938 Loss D: 0.2939, Loss G: 1.9570\n",
      "Epoch [47/85] Batch 270/938 Loss D: 0.3731, Loss G: 2.6923\n",
      "Epoch [47/85] Batch 280/938 Loss D: 0.3521, Loss G: 2.5423\n",
      "Epoch [47/85] Batch 290/938 Loss D: 0.3009, Loss G: 2.5768\n",
      "Epoch [47/85] Batch 300/938 Loss D: 0.4448, Loss G: 2.7611\n",
      "Epoch [47/85] Batch 310/938 Loss D: 0.3697, Loss G: 2.3061\n",
      "Epoch [47/85] Batch 320/938 Loss D: 0.3050, Loss G: 2.5087\n",
      "Epoch [47/85] Batch 330/938 Loss D: 0.2441, Loss G: 2.9189\n",
      "Epoch [47/85] Batch 340/938 Loss D: 0.2541, Loss G: 2.7415\n",
      "Epoch [47/85] Batch 350/938 Loss D: 0.2586, Loss G: 2.2871\n",
      "Epoch [47/85] Batch 360/938 Loss D: 0.3691, Loss G: 2.1565\n",
      "Epoch [47/85] Batch 370/938 Loss D: 0.3388, Loss G: 2.2096\n",
      "Epoch [47/85] Batch 380/938 Loss D: 0.3028, Loss G: 2.2240\n",
      "Epoch [47/85] Batch 390/938 Loss D: 0.3394, Loss G: 1.8955\n",
      "Epoch [47/85] Batch 400/938 Loss D: 0.2955, Loss G: 1.8068\n",
      "Epoch [47/85] Batch 410/938 Loss D: 0.3320, Loss G: 2.4066\n",
      "Epoch [47/85] Batch 420/938 Loss D: 0.2504, Loss G: 2.8657\n",
      "Epoch [47/85] Batch 430/938 Loss D: 0.2398, Loss G: 2.7843\n",
      "Epoch [47/85] Batch 440/938 Loss D: 0.3193, Loss G: 2.3156\n",
      "Epoch [47/85] Batch 450/938 Loss D: 0.4251, Loss G: 2.3672\n",
      "Epoch [47/85] Batch 460/938 Loss D: 0.3028, Loss G: 2.2376\n",
      "Epoch [47/85] Batch 470/938 Loss D: 0.3311, Loss G: 1.9609\n",
      "Epoch [47/85] Batch 480/938 Loss D: 0.4021, Loss G: 1.8550\n",
      "Epoch [47/85] Batch 490/938 Loss D: 0.4571, Loss G: 2.0073\n",
      "Epoch [47/85] Batch 500/938 Loss D: 0.3785, Loss G: 1.8867\n",
      "Epoch [47/85] Batch 510/938 Loss D: 0.2045, Loss G: 3.2959\n",
      "Epoch [47/85] Batch 520/938 Loss D: 0.3509, Loss G: 2.0342\n",
      "Epoch [47/85] Batch 530/938 Loss D: 0.2659, Loss G: 2.2548\n",
      "Epoch [47/85] Batch 540/938 Loss D: 0.3692, Loss G: 2.0446\n",
      "Epoch [47/85] Batch 550/938 Loss D: 0.3164, Loss G: 2.3397\n",
      "Epoch [47/85] Batch 560/938 Loss D: 0.3650, Loss G: 2.2629\n",
      "Epoch [47/85] Batch 570/938 Loss D: 0.4104, Loss G: 2.1784\n",
      "Epoch [47/85] Batch 580/938 Loss D: 0.3365, Loss G: 1.8648\n",
      "Epoch [47/85] Batch 590/938 Loss D: 0.3379, Loss G: 1.5878\n",
      "Epoch [47/85] Batch 600/938 Loss D: 0.2642, Loss G: 2.2529\n",
      "Epoch [47/85] Batch 610/938 Loss D: 0.2710, Loss G: 2.8097\n",
      "Epoch [47/85] Batch 620/938 Loss D: 0.3365, Loss G: 2.4061\n",
      "Epoch [47/85] Batch 630/938 Loss D: 0.2961, Loss G: 2.2945\n",
      "Epoch [47/85] Batch 640/938 Loss D: 0.3135, Loss G: 2.1133\n",
      "Epoch [47/85] Batch 650/938 Loss D: 0.2998, Loss G: 2.7112\n",
      "Epoch [47/85] Batch 660/938 Loss D: 0.2303, Loss G: 2.6104\n",
      "Epoch [47/85] Batch 670/938 Loss D: 0.3308, Loss G: 2.3288\n",
      "Epoch [47/85] Batch 680/938 Loss D: 0.4334, Loss G: 2.5418\n",
      "Epoch [47/85] Batch 690/938 Loss D: 0.2553, Loss G: 2.7889\n",
      "Epoch [47/85] Batch 700/938 Loss D: 0.4239, Loss G: 1.7453\n",
      "Epoch [47/85] Batch 710/938 Loss D: 0.2917, Loss G: 1.9045\n",
      "Epoch [47/85] Batch 720/938 Loss D: 0.3290, Loss G: 2.2945\n",
      "Epoch [47/85] Batch 730/938 Loss D: 0.3640, Loss G: 2.7771\n",
      "Epoch [47/85] Batch 740/938 Loss D: 0.4531, Loss G: 2.3929\n",
      "Epoch [47/85] Batch 750/938 Loss D: 0.3857, Loss G: 2.6757\n",
      "Epoch [47/85] Batch 760/938 Loss D: 0.3086, Loss G: 2.2434\n",
      "Epoch [47/85] Batch 770/938 Loss D: 0.3287, Loss G: 2.0999\n",
      "Epoch [47/85] Batch 780/938 Loss D: 0.3600, Loss G: 1.9559\n",
      "Epoch [47/85] Batch 790/938 Loss D: 0.2544, Loss G: 2.6590\n",
      "Epoch [47/85] Batch 800/938 Loss D: 0.2229, Loss G: 3.0672\n",
      "Epoch [47/85] Batch 810/938 Loss D: 0.3239, Loss G: 2.1792\n",
      "Epoch [47/85] Batch 820/938 Loss D: 0.3656, Loss G: 1.9297\n",
      "Epoch [47/85] Batch 830/938 Loss D: 0.3422, Loss G: 2.0234\n",
      "Epoch [47/85] Batch 840/938 Loss D: 0.1997, Loss G: 2.9775\n",
      "Epoch [47/85] Batch 850/938 Loss D: 0.2907, Loss G: 2.5655\n",
      "Epoch [47/85] Batch 860/938 Loss D: 0.2984, Loss G: 2.3066\n",
      "Epoch [47/85] Batch 870/938 Loss D: 0.3265, Loss G: 1.7793\n",
      "Epoch [47/85] Batch 880/938 Loss D: 0.2066, Loss G: 2.8541\n",
      "Epoch [47/85] Batch 890/938 Loss D: 0.3767, Loss G: 2.0165\n",
      "Epoch [47/85] Batch 900/938 Loss D: 0.2130, Loss G: 2.2162\n",
      "Epoch [47/85] Batch 910/938 Loss D: 0.2671, Loss G: 2.5010\n",
      "Epoch [47/85] Batch 920/938 Loss D: 0.3058, Loss G: 3.0126\n",
      "Epoch [47/85] Batch 930/938 Loss D: 0.3640, Loss G: 2.6645\n",
      "Epoch [48/85] Batch 0/938 Loss D: 0.2413, Loss G: 2.6739\n",
      "Epoch [48/85] Batch 10/938 Loss D: 0.2605, Loss G: 2.4965\n",
      "Epoch [48/85] Batch 20/938 Loss D: 0.2636, Loss G: 1.9938\n",
      "Epoch [48/85] Batch 30/938 Loss D: 0.3007, Loss G: 2.2459\n",
      "Epoch [48/85] Batch 40/938 Loss D: 0.3793, Loss G: 1.7747\n",
      "Epoch [48/85] Batch 50/938 Loss D: 0.4348, Loss G: 1.7010\n",
      "Epoch [48/85] Batch 60/938 Loss D: 0.4062, Loss G: 2.3813\n",
      "Epoch [48/85] Batch 70/938 Loss D: 0.3292, Loss G: 2.9282\n",
      "Epoch [48/85] Batch 80/938 Loss D: 0.2426, Loss G: 2.6492\n",
      "Epoch [48/85] Batch 90/938 Loss D: 0.3882, Loss G: 2.2539\n",
      "Epoch [48/85] Batch 100/938 Loss D: 0.2827, Loss G: 2.3260\n",
      "Epoch [48/85] Batch 110/938 Loss D: 0.3112, Loss G: 2.5724\n",
      "Epoch [48/85] Batch 120/938 Loss D: 0.2268, Loss G: 2.7232\n",
      "Epoch [48/85] Batch 130/938 Loss D: 0.2556, Loss G: 2.7364\n",
      "Epoch [48/85] Batch 140/938 Loss D: 0.2388, Loss G: 2.3515\n",
      "Epoch [48/85] Batch 150/938 Loss D: 0.2230, Loss G: 2.7113\n",
      "Epoch [48/85] Batch 160/938 Loss D: 0.2143, Loss G: 2.6606\n",
      "Epoch [48/85] Batch 170/938 Loss D: 0.2779, Loss G: 2.3265\n",
      "Epoch [48/85] Batch 180/938 Loss D: 0.2217, Loss G: 2.6702\n",
      "Epoch [48/85] Batch 190/938 Loss D: 0.2995, Loss G: 1.8216\n",
      "Epoch [48/85] Batch 200/938 Loss D: 0.3148, Loss G: 2.6786\n",
      "Epoch [48/85] Batch 210/938 Loss D: 0.2885, Loss G: 2.1864\n",
      "Epoch [48/85] Batch 220/938 Loss D: 0.1985, Loss G: 2.7797\n",
      "Epoch [48/85] Batch 230/938 Loss D: 0.2334, Loss G: 2.3014\n",
      "Epoch [48/85] Batch 240/938 Loss D: 0.2806, Loss G: 2.9820\n",
      "Epoch [48/85] Batch 250/938 Loss D: 0.2895, Loss G: 1.9028\n",
      "Epoch [48/85] Batch 260/938 Loss D: 0.3462, Loss G: 2.5455\n",
      "Epoch [48/85] Batch 270/938 Loss D: 0.2158, Loss G: 3.4379\n",
      "Epoch [48/85] Batch 280/938 Loss D: 0.3546, Loss G: 2.9133\n",
      "Epoch [48/85] Batch 290/938 Loss D: 0.3296, Loss G: 2.0029\n",
      "Epoch [48/85] Batch 300/938 Loss D: 0.3200, Loss G: 1.8935\n",
      "Epoch [48/85] Batch 310/938 Loss D: 0.2277, Loss G: 2.4783\n",
      "Epoch [48/85] Batch 320/938 Loss D: 0.2939, Loss G: 2.5589\n",
      "Epoch [48/85] Batch 330/938 Loss D: 0.2713, Loss G: 2.7911\n",
      "Epoch [48/85] Batch 340/938 Loss D: 0.2558, Loss G: 2.3769\n",
      "Epoch [48/85] Batch 350/938 Loss D: 0.4448, Loss G: 1.6588\n",
      "Epoch [48/85] Batch 360/938 Loss D: 0.2201, Loss G: 2.3744\n",
      "Epoch [48/85] Batch 370/938 Loss D: 0.2889, Loss G: 2.4439\n",
      "Epoch [48/85] Batch 380/938 Loss D: 0.2652, Loss G: 2.3233\n",
      "Epoch [48/85] Batch 390/938 Loss D: 0.4046, Loss G: 1.9725\n",
      "Epoch [48/85] Batch 400/938 Loss D: 0.3418, Loss G: 2.4087\n",
      "Epoch [48/85] Batch 410/938 Loss D: 0.3138, Loss G: 1.9731\n",
      "Epoch [48/85] Batch 420/938 Loss D: 0.2239, Loss G: 2.4217\n",
      "Epoch [48/85] Batch 430/938 Loss D: 0.2814, Loss G: 2.3077\n",
      "Epoch [48/85] Batch 440/938 Loss D: 0.2575, Loss G: 2.0218\n",
      "Epoch [48/85] Batch 450/938 Loss D: 0.4066, Loss G: 1.5874\n",
      "Epoch [48/85] Batch 460/938 Loss D: 0.3428, Loss G: 1.9158\n",
      "Epoch [48/85] Batch 470/938 Loss D: 0.2955, Loss G: 2.2793\n",
      "Epoch [48/85] Batch 480/938 Loss D: 0.2876, Loss G: 2.4339\n",
      "Epoch [48/85] Batch 490/938 Loss D: 0.2581, Loss G: 2.0394\n",
      "Epoch [48/85] Batch 500/938 Loss D: 0.3818, Loss G: 1.5449\n",
      "Epoch [48/85] Batch 510/938 Loss D: 0.3321, Loss G: 2.0036\n",
      "Epoch [48/85] Batch 520/938 Loss D: 0.3933, Loss G: 1.9609\n",
      "Epoch [48/85] Batch 530/938 Loss D: 0.3355, Loss G: 2.4182\n",
      "Epoch [48/85] Batch 540/938 Loss D: 0.2348, Loss G: 3.5205\n",
      "Epoch [48/85] Batch 550/938 Loss D: 0.2227, Loss G: 3.1940\n",
      "Epoch [48/85] Batch 560/938 Loss D: 0.3728, Loss G: 1.9474\n",
      "Epoch [48/85] Batch 570/938 Loss D: 0.2385, Loss G: 2.6025\n",
      "Epoch [48/85] Batch 580/938 Loss D: 0.3601, Loss G: 2.0278\n",
      "Epoch [48/85] Batch 590/938 Loss D: 0.3615, Loss G: 2.0780\n",
      "Epoch [48/85] Batch 600/938 Loss D: 0.3501, Loss G: 2.6347\n",
      "Epoch [48/85] Batch 610/938 Loss D: 0.2760, Loss G: 2.4154\n",
      "Epoch [48/85] Batch 620/938 Loss D: 0.2937, Loss G: 2.6769\n",
      "Epoch [48/85] Batch 630/938 Loss D: 0.2465, Loss G: 2.1372\n",
      "Epoch [48/85] Batch 640/938 Loss D: 0.3763, Loss G: 2.2637\n",
      "Epoch [48/85] Batch 650/938 Loss D: 0.2919, Loss G: 2.5041\n",
      "Epoch [48/85] Batch 660/938 Loss D: 0.3225, Loss G: 2.2420\n",
      "Epoch [48/85] Batch 670/938 Loss D: 0.2420, Loss G: 2.7962\n",
      "Epoch [48/85] Batch 680/938 Loss D: 0.3155, Loss G: 2.3500\n",
      "Epoch [48/85] Batch 690/938 Loss D: 0.2691, Loss G: 2.9029\n",
      "Epoch [48/85] Batch 700/938 Loss D: 0.2955, Loss G: 2.4998\n",
      "Epoch [48/85] Batch 710/938 Loss D: 0.3321, Loss G: 2.4498\n",
      "Epoch [48/85] Batch 720/938 Loss D: 0.2222, Loss G: 2.8384\n",
      "Epoch [48/85] Batch 730/938 Loss D: 0.3190, Loss G: 2.5059\n",
      "Epoch [48/85] Batch 740/938 Loss D: 0.2563, Loss G: 2.6371\n",
      "Epoch [48/85] Batch 750/938 Loss D: 0.2674, Loss G: 3.2132\n",
      "Epoch [48/85] Batch 760/938 Loss D: 0.3141, Loss G: 2.0913\n",
      "Epoch [48/85] Batch 770/938 Loss D: 0.3791, Loss G: 1.9855\n",
      "Epoch [48/85] Batch 780/938 Loss D: 0.2369, Loss G: 2.5980\n",
      "Epoch [48/85] Batch 790/938 Loss D: 0.3426, Loss G: 1.8888\n",
      "Epoch [48/85] Batch 800/938 Loss D: 0.3199, Loss G: 2.1196\n",
      "Epoch [48/85] Batch 810/938 Loss D: 0.3068, Loss G: 1.8083\n",
      "Epoch [48/85] Batch 820/938 Loss D: 0.3230, Loss G: 2.0170\n",
      "Epoch [48/85] Batch 830/938 Loss D: 0.2654, Loss G: 2.5987\n",
      "Epoch [48/85] Batch 840/938 Loss D: 0.3021, Loss G: 2.4151\n",
      "Epoch [48/85] Batch 850/938 Loss D: 0.2733, Loss G: 2.0898\n",
      "Epoch [48/85] Batch 860/938 Loss D: 0.3723, Loss G: 2.0902\n",
      "Epoch [48/85] Batch 870/938 Loss D: 0.2912, Loss G: 2.0977\n",
      "Epoch [48/85] Batch 880/938 Loss D: 0.2916, Loss G: 2.6828\n",
      "Epoch [48/85] Batch 890/938 Loss D: 0.2537, Loss G: 2.4981\n",
      "Epoch [48/85] Batch 900/938 Loss D: 0.2602, Loss G: 2.6845\n",
      "Epoch [48/85] Batch 910/938 Loss D: 0.2429, Loss G: 2.4777\n",
      "Epoch [48/85] Batch 920/938 Loss D: 0.3002, Loss G: 1.8781\n",
      "Epoch [48/85] Batch 930/938 Loss D: 0.2373, Loss G: 2.4372\n",
      "Epoch [49/85] Batch 0/938 Loss D: 0.2789, Loss G: 2.4738\n",
      "Epoch [49/85] Batch 10/938 Loss D: 0.3463, Loss G: 2.1225\n",
      "Epoch [49/85] Batch 20/938 Loss D: 0.2671, Loss G: 2.2876\n",
      "Epoch [49/85] Batch 30/938 Loss D: 0.2534, Loss G: 2.0646\n",
      "Epoch [49/85] Batch 40/938 Loss D: 0.2549, Loss G: 2.9131\n",
      "Epoch [49/85] Batch 50/938 Loss D: 0.3157, Loss G: 2.7349\n",
      "Epoch [49/85] Batch 60/938 Loss D: 0.3099, Loss G: 2.4725\n",
      "Epoch [49/85] Batch 70/938 Loss D: 0.2867, Loss G: 2.3867\n",
      "Epoch [49/85] Batch 80/938 Loss D: 0.2712, Loss G: 2.2098\n",
      "Epoch [49/85] Batch 90/938 Loss D: 0.2880, Loss G: 2.3599\n",
      "Epoch [49/85] Batch 100/938 Loss D: 0.3320, Loss G: 1.9502\n",
      "Epoch [49/85] Batch 110/938 Loss D: 0.2499, Loss G: 2.6172\n",
      "Epoch [49/85] Batch 120/938 Loss D: 0.2706, Loss G: 2.5374\n",
      "Epoch [49/85] Batch 130/938 Loss D: 0.3241, Loss G: 2.4181\n",
      "Epoch [49/85] Batch 140/938 Loss D: 0.1917, Loss G: 3.1499\n",
      "Epoch [49/85] Batch 150/938 Loss D: 0.3724, Loss G: 2.2606\n",
      "Epoch [49/85] Batch 160/938 Loss D: 0.3206, Loss G: 2.1241\n",
      "Epoch [49/85] Batch 170/938 Loss D: 0.2307, Loss G: 2.3974\n",
      "Epoch [49/85] Batch 180/938 Loss D: 0.3232, Loss G: 2.5536\n",
      "Epoch [49/85] Batch 190/938 Loss D: 0.2966, Loss G: 2.6584\n",
      "Epoch [49/85] Batch 200/938 Loss D: 0.3324, Loss G: 2.6497\n",
      "Epoch [49/85] Batch 210/938 Loss D: 0.4216, Loss G: 2.2287\n",
      "Epoch [49/85] Batch 220/938 Loss D: 0.4180, Loss G: 1.6765\n",
      "Epoch [49/85] Batch 230/938 Loss D: 0.2568, Loss G: 2.1312\n",
      "Epoch [49/85] Batch 240/938 Loss D: 0.3106, Loss G: 2.3197\n",
      "Epoch [49/85] Batch 250/938 Loss D: 0.2939, Loss G: 2.3046\n",
      "Epoch [49/85] Batch 260/938 Loss D: 0.3052, Loss G: 3.3958\n",
      "Epoch [49/85] Batch 270/938 Loss D: 0.3162, Loss G: 3.1248\n",
      "Epoch [49/85] Batch 280/938 Loss D: 0.4916, Loss G: 2.4129\n",
      "Epoch [49/85] Batch 290/938 Loss D: 0.3377, Loss G: 2.2375\n",
      "Epoch [49/85] Batch 300/938 Loss D: 0.2829, Loss G: 2.6414\n",
      "Epoch [49/85] Batch 310/938 Loss D: 0.3589, Loss G: 1.9217\n",
      "Epoch [49/85] Batch 320/938 Loss D: 0.3182, Loss G: 2.0614\n",
      "Epoch [49/85] Batch 330/938 Loss D: 0.1916, Loss G: 2.4632\n",
      "Epoch [49/85] Batch 340/938 Loss D: 0.3818, Loss G: 2.1294\n",
      "Epoch [49/85] Batch 350/938 Loss D: 0.4271, Loss G: 2.5473\n",
      "Epoch [49/85] Batch 360/938 Loss D: 0.1798, Loss G: 3.3668\n",
      "Epoch [49/85] Batch 370/938 Loss D: 0.5267, Loss G: 2.3887\n",
      "Epoch [49/85] Batch 380/938 Loss D: 0.2889, Loss G: 2.3422\n",
      "Epoch [49/85] Batch 390/938 Loss D: 0.2783, Loss G: 2.4456\n",
      "Epoch [49/85] Batch 400/938 Loss D: 0.3422, Loss G: 1.8904\n",
      "Epoch [49/85] Batch 410/938 Loss D: 0.2908, Loss G: 2.1120\n",
      "Epoch [49/85] Batch 420/938 Loss D: 0.3871, Loss G: 2.6840\n",
      "Epoch [49/85] Batch 430/938 Loss D: 0.2858, Loss G: 2.2777\n",
      "Epoch [49/85] Batch 440/938 Loss D: 0.2912, Loss G: 1.9181\n",
      "Epoch [49/85] Batch 450/938 Loss D: 0.2696, Loss G: 2.0390\n",
      "Epoch [49/85] Batch 460/938 Loss D: 0.2480, Loss G: 2.1933\n",
      "Epoch [49/85] Batch 470/938 Loss D: 0.2607, Loss G: 2.3471\n",
      "Epoch [49/85] Batch 480/938 Loss D: 0.2373, Loss G: 3.4361\n",
      "Epoch [49/85] Batch 490/938 Loss D: 0.4209, Loss G: 2.0175\n",
      "Epoch [49/85] Batch 500/938 Loss D: 0.3001, Loss G: 1.9616\n",
      "Epoch [49/85] Batch 510/938 Loss D: 0.3181, Loss G: 1.8869\n",
      "Epoch [49/85] Batch 520/938 Loss D: 0.3534, Loss G: 2.0015\n",
      "Epoch [49/85] Batch 530/938 Loss D: 0.3262, Loss G: 1.8018\n",
      "Epoch [49/85] Batch 540/938 Loss D: 0.1789, Loss G: 2.8512\n",
      "Epoch [49/85] Batch 550/938 Loss D: 0.2985, Loss G: 2.3770\n",
      "Epoch [49/85] Batch 560/938 Loss D: 0.2676, Loss G: 2.5529\n",
      "Epoch [49/85] Batch 570/938 Loss D: 0.3285, Loss G: 2.2086\n",
      "Epoch [49/85] Batch 580/938 Loss D: 0.2522, Loss G: 2.3508\n",
      "Epoch [49/85] Batch 590/938 Loss D: 0.2192, Loss G: 2.4104\n",
      "Epoch [49/85] Batch 600/938 Loss D: 0.3408, Loss G: 2.5998\n",
      "Epoch [49/85] Batch 610/938 Loss D: 0.2704, Loss G: 2.3506\n",
      "Epoch [49/85] Batch 620/938 Loss D: 0.3180, Loss G: 2.3018\n",
      "Epoch [49/85] Batch 630/938 Loss D: 0.2494, Loss G: 2.9623\n",
      "Epoch [49/85] Batch 640/938 Loss D: 0.2344, Loss G: 2.3708\n",
      "Epoch [49/85] Batch 650/938 Loss D: 0.2680, Loss G: 1.9547\n",
      "Epoch [49/85] Batch 660/938 Loss D: 0.2139, Loss G: 2.8180\n",
      "Epoch [49/85] Batch 670/938 Loss D: 0.4295, Loss G: 2.6063\n",
      "Epoch [49/85] Batch 680/938 Loss D: 0.4944, Loss G: 2.1285\n",
      "Epoch [49/85] Batch 690/938 Loss D: 0.3264, Loss G: 2.4892\n",
      "Epoch [49/85] Batch 700/938 Loss D: 0.2736, Loss G: 3.0772\n",
      "Epoch [49/85] Batch 710/938 Loss D: 0.3013, Loss G: 2.2820\n",
      "Epoch [49/85] Batch 720/938 Loss D: 0.3759, Loss G: 2.4132\n",
      "Epoch [49/85] Batch 730/938 Loss D: 0.3070, Loss G: 2.0712\n",
      "Epoch [49/85] Batch 740/938 Loss D: 0.2730, Loss G: 2.2024\n",
      "Epoch [49/85] Batch 750/938 Loss D: 0.3832, Loss G: 2.3151\n",
      "Epoch [49/85] Batch 760/938 Loss D: 0.2931, Loss G: 2.8798\n",
      "Epoch [49/85] Batch 770/938 Loss D: 0.3064, Loss G: 2.9944\n",
      "Epoch [49/85] Batch 780/938 Loss D: 0.2746, Loss G: 1.9882\n",
      "Epoch [49/85] Batch 790/938 Loss D: 0.3090, Loss G: 1.7680\n",
      "Epoch [49/85] Batch 800/938 Loss D: 0.3179, Loss G: 1.9759\n",
      "Epoch [49/85] Batch 810/938 Loss D: 0.3468, Loss G: 1.8325\n",
      "Epoch [49/85] Batch 820/938 Loss D: 0.3055, Loss G: 2.1603\n",
      "Epoch [49/85] Batch 830/938 Loss D: 0.3594, Loss G: 2.2994\n",
      "Epoch [49/85] Batch 840/938 Loss D: 0.2610, Loss G: 2.7370\n",
      "Epoch [49/85] Batch 850/938 Loss D: 0.2720, Loss G: 2.4082\n",
      "Epoch [49/85] Batch 860/938 Loss D: 0.3470, Loss G: 2.6629\n",
      "Epoch [49/85] Batch 870/938 Loss D: 0.3017, Loss G: 2.6720\n",
      "Epoch [49/85] Batch 880/938 Loss D: 0.3152, Loss G: 2.6989\n",
      "Epoch [49/85] Batch 890/938 Loss D: 0.2190, Loss G: 2.3230\n",
      "Epoch [49/85] Batch 900/938 Loss D: 0.3888, Loss G: 2.6827\n",
      "Epoch [49/85] Batch 910/938 Loss D: 0.3565, Loss G: 2.6539\n",
      "Epoch [49/85] Batch 920/938 Loss D: 0.3235, Loss G: 2.2925\n",
      "Epoch [49/85] Batch 930/938 Loss D: 0.2469, Loss G: 3.1135\n",
      "Epoch [50/85] Batch 0/938 Loss D: 0.3882, Loss G: 1.8856\n",
      "Epoch [50/85] Batch 10/938 Loss D: 0.3303, Loss G: 1.9774\n",
      "Epoch [50/85] Batch 20/938 Loss D: 0.2995, Loss G: 2.3323\n",
      "Epoch [50/85] Batch 30/938 Loss D: 0.3973, Loss G: 1.9603\n",
      "Epoch [50/85] Batch 40/938 Loss D: 0.1857, Loss G: 2.5973\n",
      "Epoch [50/85] Batch 50/938 Loss D: 0.3001, Loss G: 2.1498\n",
      "Epoch [50/85] Batch 60/938 Loss D: 0.3841, Loss G: 1.7855\n",
      "Epoch [50/85] Batch 70/938 Loss D: 0.3285, Loss G: 1.8052\n",
      "Epoch [50/85] Batch 80/938 Loss D: 0.2840, Loss G: 2.3525\n",
      "Epoch [50/85] Batch 90/938 Loss D: 0.2665, Loss G: 2.7763\n",
      "Epoch [50/85] Batch 100/938 Loss D: 0.2863, Loss G: 2.3419\n",
      "Epoch [50/85] Batch 110/938 Loss D: 0.4537, Loss G: 1.9617\n",
      "Epoch [50/85] Batch 120/938 Loss D: 0.3911, Loss G: 1.7809\n",
      "Epoch [50/85] Batch 130/938 Loss D: 0.3005, Loss G: 2.0097\n",
      "Epoch [50/85] Batch 140/938 Loss D: 0.3790, Loss G: 1.9863\n",
      "Epoch [50/85] Batch 150/938 Loss D: 0.3799, Loss G: 2.1004\n",
      "Epoch [50/85] Batch 160/938 Loss D: 0.2219, Loss G: 2.2418\n",
      "Epoch [50/85] Batch 170/938 Loss D: 0.3305, Loss G: 1.8055\n",
      "Epoch [50/85] Batch 180/938 Loss D: 0.3147, Loss G: 1.8927\n",
      "Epoch [50/85] Batch 190/938 Loss D: 0.4100, Loss G: 2.5099\n",
      "Epoch [50/85] Batch 200/938 Loss D: 0.3741, Loss G: 2.7939\n",
      "Epoch [50/85] Batch 210/938 Loss D: 0.3642, Loss G: 2.7843\n",
      "Epoch [50/85] Batch 220/938 Loss D: 0.2572, Loss G: 1.9814\n",
      "Epoch [50/85] Batch 230/938 Loss D: 0.3051, Loss G: 2.4380\n",
      "Epoch [50/85] Batch 240/938 Loss D: 0.3170, Loss G: 2.1656\n",
      "Epoch [50/85] Batch 250/938 Loss D: 0.2445, Loss G: 2.4257\n",
      "Epoch [50/85] Batch 260/938 Loss D: 0.2427, Loss G: 2.4091\n",
      "Epoch [50/85] Batch 270/938 Loss D: 0.2942, Loss G: 2.6295\n",
      "Epoch [50/85] Batch 280/938 Loss D: 0.2401, Loss G: 3.0006\n",
      "Epoch [50/85] Batch 290/938 Loss D: 0.3208, Loss G: 2.4530\n",
      "Epoch [50/85] Batch 300/938 Loss D: 0.3236, Loss G: 2.3908\n",
      "Epoch [50/85] Batch 310/938 Loss D: 0.3326, Loss G: 2.0540\n",
      "Epoch [50/85] Batch 320/938 Loss D: 0.2669, Loss G: 2.3943\n",
      "Epoch [50/85] Batch 330/938 Loss D: 0.3196, Loss G: 1.7049\n",
      "Epoch [50/85] Batch 340/938 Loss D: 0.3019, Loss G: 1.6684\n",
      "Epoch [50/85] Batch 350/938 Loss D: 0.3360, Loss G: 2.4072\n",
      "Epoch [50/85] Batch 360/938 Loss D: 0.2616, Loss G: 2.5344\n",
      "Epoch [50/85] Batch 370/938 Loss D: 0.3052, Loss G: 2.1070\n",
      "Epoch [50/85] Batch 380/938 Loss D: 0.4685, Loss G: 1.6851\n",
      "Epoch [50/85] Batch 390/938 Loss D: 0.3320, Loss G: 2.0168\n",
      "Epoch [50/85] Batch 400/938 Loss D: 0.3524, Loss G: 2.3955\n",
      "Epoch [50/85] Batch 410/938 Loss D: 0.2346, Loss G: 2.7616\n",
      "Epoch [50/85] Batch 420/938 Loss D: 0.2875, Loss G: 2.5436\n",
      "Epoch [50/85] Batch 430/938 Loss D: 0.2582, Loss G: 2.4702\n",
      "Epoch [50/85] Batch 440/938 Loss D: 0.2291, Loss G: 2.2875\n",
      "Epoch [50/85] Batch 450/938 Loss D: 0.3915, Loss G: 2.6692\n",
      "Epoch [50/85] Batch 460/938 Loss D: 0.2391, Loss G: 3.0527\n",
      "Epoch [50/85] Batch 470/938 Loss D: 0.3165, Loss G: 1.8026\n",
      "Epoch [50/85] Batch 480/938 Loss D: 0.2657, Loss G: 2.4204\n",
      "Epoch [50/85] Batch 490/938 Loss D: 0.2659, Loss G: 2.4440\n",
      "Epoch [50/85] Batch 500/938 Loss D: 0.3125, Loss G: 1.9786\n",
      "Epoch [50/85] Batch 510/938 Loss D: 0.3009, Loss G: 2.2176\n",
      "Epoch [50/85] Batch 520/938 Loss D: 0.2973, Loss G: 2.1951\n",
      "Epoch [50/85] Batch 530/938 Loss D: 0.2750, Loss G: 2.4560\n",
      "Epoch [50/85] Batch 540/938 Loss D: 0.2822, Loss G: 2.3898\n",
      "Epoch [50/85] Batch 550/938 Loss D: 0.2236, Loss G: 2.8202\n",
      "Epoch [50/85] Batch 560/938 Loss D: 0.2487, Loss G: 1.9834\n",
      "Epoch [50/85] Batch 570/938 Loss D: 0.3579, Loss G: 1.9507\n",
      "Epoch [50/85] Batch 580/938 Loss D: 0.2862, Loss G: 2.7938\n",
      "Epoch [50/85] Batch 590/938 Loss D: 0.2291, Loss G: 3.0082\n",
      "Epoch [50/85] Batch 600/938 Loss D: 0.3291, Loss G: 2.6157\n",
      "Epoch [50/85] Batch 610/938 Loss D: 0.2190, Loss G: 2.3731\n",
      "Epoch [50/85] Batch 620/938 Loss D: 0.2751, Loss G: 3.0736\n",
      "Epoch [50/85] Batch 630/938 Loss D: 0.3127, Loss G: 2.5100\n",
      "Epoch [50/85] Batch 640/938 Loss D: 0.2696, Loss G: 2.6812\n",
      "Epoch [50/85] Batch 650/938 Loss D: 0.3996, Loss G: 2.3159\n",
      "Epoch [50/85] Batch 660/938 Loss D: 0.3411, Loss G: 2.2030\n",
      "Epoch [50/85] Batch 670/938 Loss D: 0.3515, Loss G: 2.0814\n",
      "Epoch [50/85] Batch 680/938 Loss D: 0.3828, Loss G: 2.4513\n",
      "Epoch [50/85] Batch 690/938 Loss D: 0.2993, Loss G: 2.5782\n",
      "Epoch [50/85] Batch 700/938 Loss D: 0.4461, Loss G: 2.9299\n",
      "Epoch [50/85] Batch 710/938 Loss D: 0.2670, Loss G: 2.9786\n",
      "Epoch [50/85] Batch 720/938 Loss D: 0.2308, Loss G: 2.4741\n",
      "Epoch [50/85] Batch 730/938 Loss D: 0.2327, Loss G: 2.3482\n",
      "Epoch [50/85] Batch 740/938 Loss D: 0.2614, Loss G: 2.3855\n",
      "Epoch [50/85] Batch 750/938 Loss D: 0.3999, Loss G: 2.9588\n",
      "Epoch [50/85] Batch 760/938 Loss D: 0.2030, Loss G: 3.2402\n",
      "Epoch [50/85] Batch 770/938 Loss D: 0.4227, Loss G: 2.9709\n",
      "Epoch [50/85] Batch 780/938 Loss D: 0.6108, Loss G: 2.7544\n",
      "Epoch [50/85] Batch 790/938 Loss D: 0.3368, Loss G: 4.0692\n",
      "Epoch [50/85] Batch 800/938 Loss D: 0.3038, Loss G: 2.4452\n",
      "Epoch [50/85] Batch 810/938 Loss D: 0.3635, Loss G: 2.1819\n",
      "Epoch [50/85] Batch 820/938 Loss D: 0.3913, Loss G: 2.1628\n",
      "Epoch [50/85] Batch 830/938 Loss D: 0.3022, Loss G: 1.9123\n",
      "Epoch [50/85] Batch 840/938 Loss D: 0.2701, Loss G: 2.2386\n",
      "Epoch [50/85] Batch 850/938 Loss D: 0.3139, Loss G: 3.1463\n",
      "Epoch [50/85] Batch 860/938 Loss D: 0.2809, Loss G: 2.4763\n",
      "Epoch [50/85] Batch 870/938 Loss D: 0.2706, Loss G: 2.1344\n",
      "Epoch [50/85] Batch 880/938 Loss D: 0.3181, Loss G: 2.2284\n",
      "Epoch [50/85] Batch 890/938 Loss D: 0.3718, Loss G: 2.1236\n",
      "Epoch [50/85] Batch 900/938 Loss D: 0.3849, Loss G: 2.2455\n",
      "Epoch [50/85] Batch 910/938 Loss D: 0.3097, Loss G: 1.9864\n",
      "Epoch [50/85] Batch 920/938 Loss D: 0.3348, Loss G: 2.1168\n",
      "Epoch [50/85] Batch 930/938 Loss D: 0.2568, Loss G: 2.1673\n",
      "Epoch [51/85] Batch 0/938 Loss D: 0.2992, Loss G: 2.5143\n",
      "Epoch [51/85] Batch 10/938 Loss D: 0.3240, Loss G: 2.1236\n",
      "Epoch [51/85] Batch 20/938 Loss D: 0.3340, Loss G: 2.9938\n",
      "Epoch [51/85] Batch 30/938 Loss D: 0.3248, Loss G: 2.0554\n",
      "Epoch [51/85] Batch 40/938 Loss D: 0.2321, Loss G: 2.6083\n",
      "Epoch [51/85] Batch 50/938 Loss D: 0.2711, Loss G: 3.2494\n",
      "Epoch [51/85] Batch 60/938 Loss D: 0.2273, Loss G: 2.5382\n",
      "Epoch [51/85] Batch 70/938 Loss D: 0.2878, Loss G: 2.0696\n",
      "Epoch [51/85] Batch 80/938 Loss D: 0.2548, Loss G: 2.1908\n",
      "Epoch [51/85] Batch 90/938 Loss D: 0.2718, Loss G: 2.0973\n",
      "Epoch [51/85] Batch 100/938 Loss D: 0.4501, Loss G: 2.1001\n",
      "Epoch [51/85] Batch 110/938 Loss D: 0.3248, Loss G: 2.1430\n",
      "Epoch [51/85] Batch 120/938 Loss D: 0.2786, Loss G: 2.2745\n",
      "Epoch [51/85] Batch 130/938 Loss D: 0.3390, Loss G: 1.8685\n",
      "Epoch [51/85] Batch 140/938 Loss D: 0.2678, Loss G: 2.2579\n",
      "Epoch [51/85] Batch 150/938 Loss D: 0.3115, Loss G: 2.6205\n",
      "Epoch [51/85] Batch 160/938 Loss D: 0.2766, Loss G: 2.3690\n",
      "Epoch [51/85] Batch 170/938 Loss D: 0.3812, Loss G: 1.8289\n",
      "Epoch [51/85] Batch 180/938 Loss D: 0.2893, Loss G: 2.0738\n",
      "Epoch [51/85] Batch 190/938 Loss D: 0.2815, Loss G: 2.8639\n",
      "Epoch [51/85] Batch 200/938 Loss D: 0.2581, Loss G: 2.6350\n",
      "Epoch [51/85] Batch 210/938 Loss D: 0.2807, Loss G: 2.6381\n",
      "Epoch [51/85] Batch 220/938 Loss D: 0.1930, Loss G: 2.5673\n",
      "Epoch [51/85] Batch 230/938 Loss D: 0.2276, Loss G: 2.3084\n",
      "Epoch [51/85] Batch 240/938 Loss D: 0.2932, Loss G: 2.3965\n",
      "Epoch [51/85] Batch 250/938 Loss D: 0.1983, Loss G: 3.2711\n",
      "Epoch [51/85] Batch 260/938 Loss D: 0.2632, Loss G: 2.8888\n",
      "Epoch [51/85] Batch 270/938 Loss D: 0.2893, Loss G: 2.1160\n",
      "Epoch [51/85] Batch 280/938 Loss D: 0.2758, Loss G: 2.4571\n",
      "Epoch [51/85] Batch 290/938 Loss D: 0.2352, Loss G: 2.3538\n",
      "Epoch [51/85] Batch 300/938 Loss D: 0.2979, Loss G: 2.5335\n",
      "Epoch [51/85] Batch 310/938 Loss D: 0.3830, Loss G: 2.3559\n",
      "Epoch [51/85] Batch 320/938 Loss D: 0.5092, Loss G: 2.6468\n",
      "Epoch [51/85] Batch 330/938 Loss D: 0.2076, Loss G: 3.3331\n",
      "Epoch [51/85] Batch 340/938 Loss D: 0.2422, Loss G: 2.2420\n",
      "Epoch [51/85] Batch 350/938 Loss D: 0.2619, Loss G: 2.0271\n",
      "Epoch [51/85] Batch 360/938 Loss D: 0.3209, Loss G: 2.0108\n",
      "Epoch [51/85] Batch 370/938 Loss D: 0.2996, Loss G: 2.7548\n",
      "Epoch [51/85] Batch 380/938 Loss D: 0.2390, Loss G: 2.6681\n",
      "Epoch [51/85] Batch 390/938 Loss D: 0.4324, Loss G: 1.6266\n",
      "Epoch [51/85] Batch 400/938 Loss D: 0.3053, Loss G: 1.9638\n",
      "Epoch [51/85] Batch 410/938 Loss D: 0.2507, Loss G: 2.4884\n",
      "Epoch [51/85] Batch 420/938 Loss D: 0.3592, Loss G: 1.8080\n",
      "Epoch [51/85] Batch 430/938 Loss D: 0.2243, Loss G: 2.7656\n",
      "Epoch [51/85] Batch 440/938 Loss D: 0.3602, Loss G: 1.9771\n",
      "Epoch [51/85] Batch 450/938 Loss D: 0.3619, Loss G: 2.8856\n",
      "Epoch [51/85] Batch 460/938 Loss D: 0.3352, Loss G: 3.2805\n",
      "Epoch [51/85] Batch 470/938 Loss D: 0.3352, Loss G: 2.5795\n",
      "Epoch [51/85] Batch 480/938 Loss D: 0.3295, Loss G: 1.9381\n",
      "Epoch [51/85] Batch 490/938 Loss D: 0.3946, Loss G: 1.7597\n",
      "Epoch [51/85] Batch 500/938 Loss D: 0.3296, Loss G: 2.0409\n",
      "Epoch [51/85] Batch 510/938 Loss D: 0.5103, Loss G: 1.9349\n",
      "Epoch [51/85] Batch 520/938 Loss D: 0.3456, Loss G: 2.1934\n",
      "Epoch [51/85] Batch 530/938 Loss D: 0.4376, Loss G: 2.4315\n",
      "Epoch [51/85] Batch 540/938 Loss D: 0.3633, Loss G: 2.5886\n",
      "Epoch [51/85] Batch 550/938 Loss D: 0.2430, Loss G: 2.7781\n",
      "Epoch [51/85] Batch 560/938 Loss D: 0.2712, Loss G: 2.7914\n",
      "Epoch [51/85] Batch 570/938 Loss D: 0.3982, Loss G: 2.0254\n",
      "Epoch [51/85] Batch 580/938 Loss D: 0.2755, Loss G: 1.9948\n",
      "Epoch [51/85] Batch 590/938 Loss D: 0.2475, Loss G: 2.6253\n",
      "Epoch [51/85] Batch 600/938 Loss D: 0.4104, Loss G: 1.6489\n",
      "Epoch [51/85] Batch 610/938 Loss D: 0.2908, Loss G: 2.4437\n",
      "Epoch [51/85] Batch 620/938 Loss D: 0.3780, Loss G: 2.8692\n",
      "Epoch [51/85] Batch 630/938 Loss D: 0.4272, Loss G: 2.7096\n",
      "Epoch [51/85] Batch 640/938 Loss D: 0.3421, Loss G: 2.0239\n",
      "Epoch [51/85] Batch 650/938 Loss D: 0.2201, Loss G: 2.5313\n",
      "Epoch [51/85] Batch 660/938 Loss D: 0.2928, Loss G: 2.7135\n",
      "Epoch [51/85] Batch 670/938 Loss D: 0.2296, Loss G: 3.0902\n",
      "Epoch [51/85] Batch 680/938 Loss D: 0.3455, Loss G: 1.8713\n",
      "Epoch [51/85] Batch 690/938 Loss D: 0.2373, Loss G: 2.6766\n",
      "Epoch [51/85] Batch 700/938 Loss D: 0.2441, Loss G: 2.1288\n",
      "Epoch [51/85] Batch 710/938 Loss D: 0.2700, Loss G: 2.7950\n",
      "Epoch [51/85] Batch 720/938 Loss D: 0.2478, Loss G: 3.5176\n",
      "Epoch [51/85] Batch 730/938 Loss D: 0.4291, Loss G: 2.1918\n",
      "Epoch [51/85] Batch 740/938 Loss D: 0.2409, Loss G: 2.6986\n",
      "Epoch [51/85] Batch 750/938 Loss D: 0.2719, Loss G: 2.4283\n",
      "Epoch [51/85] Batch 760/938 Loss D: 0.3272, Loss G: 2.3372\n",
      "Epoch [51/85] Batch 770/938 Loss D: 0.2469, Loss G: 2.4374\n",
      "Epoch [51/85] Batch 780/938 Loss D: 0.4355, Loss G: 2.3343\n",
      "Epoch [51/85] Batch 790/938 Loss D: 0.3141, Loss G: 2.7034\n",
      "Epoch [51/85] Batch 800/938 Loss D: 0.2164, Loss G: 2.9146\n",
      "Epoch [51/85] Batch 810/938 Loss D: 0.2612, Loss G: 2.4509\n",
      "Epoch [51/85] Batch 820/938 Loss D: 0.2127, Loss G: 2.3080\n",
      "Epoch [51/85] Batch 830/938 Loss D: 0.3758, Loss G: 1.9401\n",
      "Epoch [51/85] Batch 840/938 Loss D: 0.2627, Loss G: 2.4699\n",
      "Epoch [51/85] Batch 850/938 Loss D: 0.3190, Loss G: 2.3129\n",
      "Epoch [51/85] Batch 860/938 Loss D: 0.2854, Loss G: 2.2872\n",
      "Epoch [51/85] Batch 870/938 Loss D: 0.2678, Loss G: 2.3626\n",
      "Epoch [51/85] Batch 880/938 Loss D: 0.2802, Loss G: 2.9832\n",
      "Epoch [51/85] Batch 890/938 Loss D: 0.4449, Loss G: 2.4177\n",
      "Epoch [51/85] Batch 900/938 Loss D: 0.2625, Loss G: 2.3531\n",
      "Epoch [51/85] Batch 910/938 Loss D: 0.3035, Loss G: 2.0156\n",
      "Epoch [51/85] Batch 920/938 Loss D: 0.2701, Loss G: 2.5736\n",
      "Epoch [51/85] Batch 930/938 Loss D: 0.4771, Loss G: 2.2315\n",
      "Epoch [52/85] Batch 0/938 Loss D: 0.2748, Loss G: 2.7146\n",
      "Epoch [52/85] Batch 10/938 Loss D: 0.2443, Loss G: 2.9746\n",
      "Epoch [52/85] Batch 20/938 Loss D: 0.3455, Loss G: 2.6965\n",
      "Epoch [52/85] Batch 30/938 Loss D: 0.2116, Loss G: 2.5547\n",
      "Epoch [52/85] Batch 40/938 Loss D: 0.3640, Loss G: 1.9999\n",
      "Epoch [52/85] Batch 50/938 Loss D: 0.2745, Loss G: 2.2305\n",
      "Epoch [52/85] Batch 60/938 Loss D: 0.3424, Loss G: 1.8591\n",
      "Epoch [52/85] Batch 70/938 Loss D: 0.3753, Loss G: 2.1257\n",
      "Epoch [52/85] Batch 80/938 Loss D: 0.3227, Loss G: 2.7462\n",
      "Epoch [52/85] Batch 90/938 Loss D: 0.2429, Loss G: 2.4932\n",
      "Epoch [52/85] Batch 100/938 Loss D: 0.3950, Loss G: 2.8411\n",
      "Epoch [52/85] Batch 110/938 Loss D: 0.2128, Loss G: 2.8800\n",
      "Epoch [52/85] Batch 120/938 Loss D: 0.3181, Loss G: 1.9688\n",
      "Epoch [52/85] Batch 130/938 Loss D: 0.2496, Loss G: 2.9610\n",
      "Epoch [52/85] Batch 140/938 Loss D: 0.2826, Loss G: 2.8693\n",
      "Epoch [52/85] Batch 150/938 Loss D: 0.3075, Loss G: 2.9359\n",
      "Epoch [52/85] Batch 160/938 Loss D: 0.3877, Loss G: 3.3306\n",
      "Epoch [52/85] Batch 170/938 Loss D: 0.3216, Loss G: 2.4415\n",
      "Epoch [52/85] Batch 180/938 Loss D: 0.2548, Loss G: 2.4375\n",
      "Epoch [52/85] Batch 190/938 Loss D: 0.3653, Loss G: 2.3304\n",
      "Epoch [52/85] Batch 200/938 Loss D: 0.3433, Loss G: 2.4307\n",
      "Epoch [52/85] Batch 210/938 Loss D: 0.3878, Loss G: 1.6916\n",
      "Epoch [52/85] Batch 220/938 Loss D: 0.2819, Loss G: 3.6519\n",
      "Epoch [52/85] Batch 230/938 Loss D: 0.2507, Loss G: 3.5252\n",
      "Epoch [52/85] Batch 240/938 Loss D: 0.3020, Loss G: 2.0582\n",
      "Epoch [52/85] Batch 250/938 Loss D: 0.3020, Loss G: 2.6038\n",
      "Epoch [52/85] Batch 260/938 Loss D: 0.3034, Loss G: 2.1632\n",
      "Epoch [52/85] Batch 270/938 Loss D: 0.3329, Loss G: 1.8384\n",
      "Epoch [52/85] Batch 280/938 Loss D: 0.3414, Loss G: 2.1601\n",
      "Epoch [52/85] Batch 290/938 Loss D: 0.2417, Loss G: 2.6407\n",
      "Epoch [52/85] Batch 300/938 Loss D: 0.3687, Loss G: 2.0571\n",
      "Epoch [52/85] Batch 310/938 Loss D: 0.4389, Loss G: 2.7486\n",
      "Epoch [52/85] Batch 320/938 Loss D: 0.3053, Loss G: 2.2709\n",
      "Epoch [52/85] Batch 330/938 Loss D: 0.4878, Loss G: 2.1545\n",
      "Epoch [52/85] Batch 340/938 Loss D: 0.2781, Loss G: 2.2666\n",
      "Epoch [52/85] Batch 350/938 Loss D: 0.3006, Loss G: 2.7060\n",
      "Epoch [52/85] Batch 360/938 Loss D: 0.3403, Loss G: 2.8181\n",
      "Epoch [52/85] Batch 370/938 Loss D: 0.2696, Loss G: 2.4769\n",
      "Epoch [52/85] Batch 380/938 Loss D: 0.3120, Loss G: 2.4996\n",
      "Epoch [52/85] Batch 390/938 Loss D: 0.3941, Loss G: 2.0856\n",
      "Epoch [52/85] Batch 400/938 Loss D: 0.3660, Loss G: 2.9722\n",
      "Epoch [52/85] Batch 410/938 Loss D: 0.3563, Loss G: 3.0068\n",
      "Epoch [52/85] Batch 420/938 Loss D: 0.3098, Loss G: 2.5373\n",
      "Epoch [52/85] Batch 430/938 Loss D: 0.3973, Loss G: 2.1766\n",
      "Epoch [52/85] Batch 440/938 Loss D: 0.2935, Loss G: 2.0016\n",
      "Epoch [52/85] Batch 450/938 Loss D: 0.2416, Loss G: 2.1727\n",
      "Epoch [52/85] Batch 460/938 Loss D: 0.4002, Loss G: 2.2507\n",
      "Epoch [52/85] Batch 470/938 Loss D: 0.4065, Loss G: 2.0648\n",
      "Epoch [52/85] Batch 480/938 Loss D: 0.4800, Loss G: 2.4885\n",
      "Epoch [52/85] Batch 490/938 Loss D: 0.2948, Loss G: 2.4664\n",
      "Epoch [52/85] Batch 500/938 Loss D: 0.3120, Loss G: 2.4984\n",
      "Epoch [52/85] Batch 510/938 Loss D: 0.3695, Loss G: 1.7517\n",
      "Epoch [52/85] Batch 520/938 Loss D: 0.4131, Loss G: 1.7186\n",
      "Epoch [52/85] Batch 530/938 Loss D: 0.2878, Loss G: 2.0015\n",
      "Epoch [52/85] Batch 540/938 Loss D: 0.3649, Loss G: 2.0838\n",
      "Epoch [52/85] Batch 550/938 Loss D: 0.3774, Loss G: 2.1156\n",
      "Epoch [52/85] Batch 560/938 Loss D: 0.2473, Loss G: 2.5733\n",
      "Epoch [52/85] Batch 570/938 Loss D: 0.2594, Loss G: 2.9185\n",
      "Epoch [52/85] Batch 580/938 Loss D: 0.4440, Loss G: 1.8821\n",
      "Epoch [52/85] Batch 590/938 Loss D: 0.2818, Loss G: 2.4335\n",
      "Epoch [52/85] Batch 600/938 Loss D: 0.3440, Loss G: 2.3725\n",
      "Epoch [52/85] Batch 610/938 Loss D: 0.2753, Loss G: 2.3958\n",
      "Epoch [52/85] Batch 620/938 Loss D: 0.2315, Loss G: 2.7734\n",
      "Epoch [52/85] Batch 630/938 Loss D: 0.3059, Loss G: 2.8127\n",
      "Epoch [52/85] Batch 640/938 Loss D: 0.3828, Loss G: 2.5184\n",
      "Epoch [52/85] Batch 650/938 Loss D: 0.3214, Loss G: 2.5515\n",
      "Epoch [52/85] Batch 660/938 Loss D: 0.4823, Loss G: 1.9865\n",
      "Epoch [52/85] Batch 670/938 Loss D: 0.2284, Loss G: 2.5531\n",
      "Epoch [52/85] Batch 680/938 Loss D: 0.3474, Loss G: 1.8853\n",
      "Epoch [52/85] Batch 690/938 Loss D: 0.2142, Loss G: 2.4715\n",
      "Epoch [52/85] Batch 700/938 Loss D: 0.3808, Loss G: 1.7357\n",
      "Epoch [52/85] Batch 710/938 Loss D: 0.3342, Loss G: 2.4315\n",
      "Epoch [52/85] Batch 720/938 Loss D: 0.3505, Loss G: 2.7710\n",
      "Epoch [52/85] Batch 730/938 Loss D: 0.3752, Loss G: 3.1145\n",
      "Epoch [52/85] Batch 740/938 Loss D: 0.2659, Loss G: 2.6881\n",
      "Epoch [52/85] Batch 750/938 Loss D: 0.2712, Loss G: 2.2370\n",
      "Epoch [52/85] Batch 760/938 Loss D: 0.4472, Loss G: 1.5423\n",
      "Epoch [52/85] Batch 770/938 Loss D: 0.2927, Loss G: 2.2283\n",
      "Epoch [52/85] Batch 780/938 Loss D: 0.2598, Loss G: 2.3058\n",
      "Epoch [52/85] Batch 790/938 Loss D: 0.2247, Loss G: 2.3164\n",
      "Epoch [52/85] Batch 800/938 Loss D: 0.3068, Loss G: 2.0282\n",
      "Epoch [52/85] Batch 810/938 Loss D: 0.3046, Loss G: 2.4611\n",
      "Epoch [52/85] Batch 820/938 Loss D: 0.5959, Loss G: 2.1953\n",
      "Epoch [52/85] Batch 830/938 Loss D: 0.3129, Loss G: 2.3002\n",
      "Epoch [52/85] Batch 840/938 Loss D: 0.2914, Loss G: 2.4769\n",
      "Epoch [52/85] Batch 850/938 Loss D: 0.1860, Loss G: 2.7413\n",
      "Epoch [52/85] Batch 860/938 Loss D: 0.2481, Loss G: 2.1848\n",
      "Epoch [52/85] Batch 870/938 Loss D: 0.3015, Loss G: 2.4136\n",
      "Epoch [52/85] Batch 880/938 Loss D: 0.4250, Loss G: 2.5751\n",
      "Epoch [52/85] Batch 890/938 Loss D: 0.3637, Loss G: 2.6110\n",
      "Epoch [52/85] Batch 900/938 Loss D: 0.4380, Loss G: 2.3235\n",
      "Epoch [52/85] Batch 910/938 Loss D: 0.1411, Loss G: 3.6857\n",
      "Epoch [52/85] Batch 920/938 Loss D: 0.3260, Loss G: 2.9840\n",
      "Epoch [52/85] Batch 930/938 Loss D: 0.2675, Loss G: 2.8783\n",
      "Epoch [53/85] Batch 0/938 Loss D: 0.3779, Loss G: 1.5788\n",
      "Epoch [53/85] Batch 10/938 Loss D: 0.2662, Loss G: 2.1373\n",
      "Epoch [53/85] Batch 20/938 Loss D: 0.3048, Loss G: 1.9614\n",
      "Epoch [53/85] Batch 30/938 Loss D: 0.3502, Loss G: 1.8530\n",
      "Epoch [53/85] Batch 40/938 Loss D: 0.2822, Loss G: 2.3632\n",
      "Epoch [53/85] Batch 50/938 Loss D: 0.2887, Loss G: 2.0618\n",
      "Epoch [53/85] Batch 60/938 Loss D: 0.3521, Loss G: 1.7201\n",
      "Epoch [53/85] Batch 70/938 Loss D: 0.3181, Loss G: 2.1064\n",
      "Epoch [53/85] Batch 80/938 Loss D: 0.2686, Loss G: 2.4859\n",
      "Epoch [53/85] Batch 90/938 Loss D: 0.3884, Loss G: 1.7461\n",
      "Epoch [53/85] Batch 100/938 Loss D: 0.3626, Loss G: 1.6970\n",
      "Epoch [53/85] Batch 110/938 Loss D: 0.3719, Loss G: 2.1633\n",
      "Epoch [53/85] Batch 120/938 Loss D: 0.3414, Loss G: 2.1865\n",
      "Epoch [53/85] Batch 130/938 Loss D: 0.3281, Loss G: 2.2632\n",
      "Epoch [53/85] Batch 140/938 Loss D: 0.2533, Loss G: 2.6988\n",
      "Epoch [53/85] Batch 150/938 Loss D: 0.3977, Loss G: 2.4146\n",
      "Epoch [53/85] Batch 160/938 Loss D: 0.2810, Loss G: 2.7473\n",
      "Epoch [53/85] Batch 170/938 Loss D: 0.4007, Loss G: 2.1710\n",
      "Epoch [53/85] Batch 180/938 Loss D: 0.2935, Loss G: 2.3441\n",
      "Epoch [53/85] Batch 190/938 Loss D: 0.4312, Loss G: 1.4308\n",
      "Epoch [53/85] Batch 200/938 Loss D: 0.3070, Loss G: 2.0750\n",
      "Epoch [53/85] Batch 210/938 Loss D: 0.3543, Loss G: 1.7213\n",
      "Epoch [53/85] Batch 220/938 Loss D: 0.3343, Loss G: 2.2762\n",
      "Epoch [53/85] Batch 230/938 Loss D: 0.2752, Loss G: 2.0913\n",
      "Epoch [53/85] Batch 240/938 Loss D: 0.2404, Loss G: 2.2613\n",
      "Epoch [53/85] Batch 250/938 Loss D: 0.3299, Loss G: 2.9918\n",
      "Epoch [53/85] Batch 260/938 Loss D: 0.3847, Loss G: 2.1416\n",
      "Epoch [53/85] Batch 270/938 Loss D: 0.2869, Loss G: 2.5285\n",
      "Epoch [53/85] Batch 280/938 Loss D: 0.3500, Loss G: 2.6155\n",
      "Epoch [53/85] Batch 290/938 Loss D: 0.3418, Loss G: 1.8811\n",
      "Epoch [53/85] Batch 300/938 Loss D: 0.2789, Loss G: 2.2323\n",
      "Epoch [53/85] Batch 310/938 Loss D: 0.2924, Loss G: 2.2158\n",
      "Epoch [53/85] Batch 320/938 Loss D: 0.3155, Loss G: 2.2583\n",
      "Epoch [53/85] Batch 330/938 Loss D: 0.3682, Loss G: 1.9176\n",
      "Epoch [53/85] Batch 340/938 Loss D: 0.3417, Loss G: 2.0852\n",
      "Epoch [53/85] Batch 350/938 Loss D: 0.3425, Loss G: 2.1633\n",
      "Epoch [53/85] Batch 360/938 Loss D: 0.3119, Loss G: 2.1554\n",
      "Epoch [53/85] Batch 370/938 Loss D: 0.4466, Loss G: 2.3588\n",
      "Epoch [53/85] Batch 380/938 Loss D: 0.4672, Loss G: 2.5664\n",
      "Epoch [53/85] Batch 390/938 Loss D: 0.2616, Loss G: 2.5610\n",
      "Epoch [53/85] Batch 400/938 Loss D: 0.2862, Loss G: 2.4430\n",
      "Epoch [53/85] Batch 410/938 Loss D: 0.2975, Loss G: 2.5828\n",
      "Epoch [53/85] Batch 420/938 Loss D: 0.2701, Loss G: 2.6288\n",
      "Epoch [53/85] Batch 430/938 Loss D: 0.2857, Loss G: 2.5567\n",
      "Epoch [53/85] Batch 440/938 Loss D: 0.2836, Loss G: 2.1163\n",
      "Epoch [53/85] Batch 450/938 Loss D: 0.2832, Loss G: 2.3717\n",
      "Epoch [53/85] Batch 460/938 Loss D: 0.3164, Loss G: 2.1067\n",
      "Epoch [53/85] Batch 470/938 Loss D: 0.2745, Loss G: 2.3584\n",
      "Epoch [53/85] Batch 480/938 Loss D: 0.2838, Loss G: 2.3520\n",
      "Epoch [53/85] Batch 490/938 Loss D: 0.2772, Loss G: 2.9628\n",
      "Epoch [53/85] Batch 500/938 Loss D: 0.2992, Loss G: 2.3540\n",
      "Epoch [53/85] Batch 510/938 Loss D: 0.2790, Loss G: 2.3706\n",
      "Epoch [53/85] Batch 520/938 Loss D: 0.2944, Loss G: 2.0267\n",
      "Epoch [53/85] Batch 530/938 Loss D: 0.2599, Loss G: 2.4257\n",
      "Epoch [53/85] Batch 540/938 Loss D: 0.2897, Loss G: 2.5144\n",
      "Epoch [53/85] Batch 550/938 Loss D: 0.3447, Loss G: 2.1631\n",
      "Epoch [53/85] Batch 560/938 Loss D: 0.3433, Loss G: 1.7626\n",
      "Epoch [53/85] Batch 570/938 Loss D: 0.2101, Loss G: 2.6574\n",
      "Epoch [53/85] Batch 580/938 Loss D: 0.3232, Loss G: 2.0757\n",
      "Epoch [53/85] Batch 590/938 Loss D: 0.3287, Loss G: 2.2772\n",
      "Epoch [53/85] Batch 600/938 Loss D: 0.3308, Loss G: 2.0754\n",
      "Epoch [53/85] Batch 610/938 Loss D: 0.3877, Loss G: 2.4183\n",
      "Epoch [53/85] Batch 620/938 Loss D: 0.2316, Loss G: 2.4338\n",
      "Epoch [53/85] Batch 630/938 Loss D: 0.2849, Loss G: 2.5422\n",
      "Epoch [53/85] Batch 640/938 Loss D: 0.2937, Loss G: 2.6455\n",
      "Epoch [53/85] Batch 650/938 Loss D: 0.2540, Loss G: 2.6321\n",
      "Epoch [53/85] Batch 660/938 Loss D: 0.2897, Loss G: 2.6667\n",
      "Epoch [53/85] Batch 670/938 Loss D: 0.2950, Loss G: 2.1395\n",
      "Epoch [53/85] Batch 680/938 Loss D: 0.2787, Loss G: 1.9156\n",
      "Epoch [53/85] Batch 690/938 Loss D: 0.4137, Loss G: 1.7772\n",
      "Epoch [53/85] Batch 700/938 Loss D: 0.3425, Loss G: 2.5690\n",
      "Epoch [53/85] Batch 710/938 Loss D: 0.3850, Loss G: 2.4258\n",
      "Epoch [53/85] Batch 720/938 Loss D: 0.2077, Loss G: 2.8916\n",
      "Epoch [53/85] Batch 730/938 Loss D: 0.3389, Loss G: 2.7794\n",
      "Epoch [53/85] Batch 740/938 Loss D: 0.3247, Loss G: 2.4905\n",
      "Epoch [53/85] Batch 750/938 Loss D: 0.3438, Loss G: 2.0395\n",
      "Epoch [53/85] Batch 760/938 Loss D: 0.2629, Loss G: 2.3690\n",
      "Epoch [53/85] Batch 770/938 Loss D: 0.3079, Loss G: 2.4727\n",
      "Epoch [53/85] Batch 780/938 Loss D: 0.3296, Loss G: 2.0801\n",
      "Epoch [53/85] Batch 790/938 Loss D: 0.2965, Loss G: 2.3513\n",
      "Epoch [53/85] Batch 800/938 Loss D: 0.2479, Loss G: 2.1084\n",
      "Epoch [53/85] Batch 810/938 Loss D: 0.3626, Loss G: 2.2282\n",
      "Epoch [53/85] Batch 820/938 Loss D: 0.4648, Loss G: 1.9871\n",
      "Epoch [53/85] Batch 830/938 Loss D: 0.3763, Loss G: 2.4569\n",
      "Epoch [53/85] Batch 840/938 Loss D: 0.3241, Loss G: 3.0833\n",
      "Epoch [53/85] Batch 850/938 Loss D: 0.3542, Loss G: 2.2862\n",
      "Epoch [53/85] Batch 860/938 Loss D: 0.4328, Loss G: 1.8982\n",
      "Epoch [53/85] Batch 870/938 Loss D: 0.4430, Loss G: 2.1437\n",
      "Epoch [53/85] Batch 880/938 Loss D: 0.2623, Loss G: 2.0708\n",
      "Epoch [53/85] Batch 890/938 Loss D: 0.5054, Loss G: 1.7413\n",
      "Epoch [53/85] Batch 900/938 Loss D: 0.3799, Loss G: 2.3277\n",
      "Epoch [53/85] Batch 910/938 Loss D: 0.2544, Loss G: 2.4726\n",
      "Epoch [53/85] Batch 920/938 Loss D: 0.1633, Loss G: 2.6599\n",
      "Epoch [53/85] Batch 930/938 Loss D: 0.2651, Loss G: 2.8387\n",
      "Epoch [54/85] Batch 0/938 Loss D: 0.3771, Loss G: 2.1381\n",
      "Epoch [54/85] Batch 10/938 Loss D: 0.2814, Loss G: 1.9414\n",
      "Epoch [54/85] Batch 20/938 Loss D: 0.3162, Loss G: 2.6437\n",
      "Epoch [54/85] Batch 30/938 Loss D: 0.2620, Loss G: 1.6351\n",
      "Epoch [54/85] Batch 40/938 Loss D: 0.3429, Loss G: 2.2927\n",
      "Epoch [54/85] Batch 50/938 Loss D: 0.3396, Loss G: 2.6160\n",
      "Epoch [54/85] Batch 60/938 Loss D: 0.2439, Loss G: 3.8285\n",
      "Epoch [54/85] Batch 70/938 Loss D: 0.2261, Loss G: 3.0564\n",
      "Epoch [54/85] Batch 80/938 Loss D: 0.3668, Loss G: 2.5221\n",
      "Epoch [54/85] Batch 90/938 Loss D: 0.2967, Loss G: 2.1612\n",
      "Epoch [54/85] Batch 100/938 Loss D: 0.3228, Loss G: 2.2591\n",
      "Epoch [54/85] Batch 110/938 Loss D: 0.4007, Loss G: 1.8444\n",
      "Epoch [54/85] Batch 120/938 Loss D: 0.4527, Loss G: 2.4268\n",
      "Epoch [54/85] Batch 130/938 Loss D: 0.3787, Loss G: 2.0900\n",
      "Epoch [54/85] Batch 140/938 Loss D: 0.2665, Loss G: 2.5332\n",
      "Epoch [54/85] Batch 150/938 Loss D: 0.3358, Loss G: 3.0429\n",
      "Epoch [54/85] Batch 160/938 Loss D: 0.2856, Loss G: 2.6202\n",
      "Epoch [54/85] Batch 170/938 Loss D: 0.3384, Loss G: 2.7207\n",
      "Epoch [54/85] Batch 180/938 Loss D: 0.3122, Loss G: 2.7932\n",
      "Epoch [54/85] Batch 190/938 Loss D: 0.3467, Loss G: 2.6410\n",
      "Epoch [54/85] Batch 200/938 Loss D: 0.2740, Loss G: 3.1936\n",
      "Epoch [54/85] Batch 210/938 Loss D: 0.2354, Loss G: 2.2669\n",
      "Epoch [54/85] Batch 220/938 Loss D: 0.3389, Loss G: 2.1984\n",
      "Epoch [54/85] Batch 230/938 Loss D: 0.1811, Loss G: 3.3436\n",
      "Epoch [54/85] Batch 240/938 Loss D: 0.3584, Loss G: 2.1956\n",
      "Epoch [54/85] Batch 250/938 Loss D: 0.3815, Loss G: 1.8881\n",
      "Epoch [54/85] Batch 260/938 Loss D: 0.2683, Loss G: 1.8843\n",
      "Epoch [54/85] Batch 270/938 Loss D: 0.2786, Loss G: 2.1681\n",
      "Epoch [54/85] Batch 280/938 Loss D: 0.2302, Loss G: 3.1454\n",
      "Epoch [54/85] Batch 290/938 Loss D: 0.6143, Loss G: 2.4919\n",
      "Epoch [54/85] Batch 300/938 Loss D: 0.4748, Loss G: 2.3110\n",
      "Epoch [54/85] Batch 310/938 Loss D: 0.2702, Loss G: 2.7417\n",
      "Epoch [54/85] Batch 320/938 Loss D: 0.4570, Loss G: 1.7069\n",
      "Epoch [54/85] Batch 330/938 Loss D: 0.3829, Loss G: 2.2055\n",
      "Epoch [54/85] Batch 340/938 Loss D: 0.2929, Loss G: 2.3341\n",
      "Epoch [54/85] Batch 350/938 Loss D: 0.3367, Loss G: 2.0922\n",
      "Epoch [54/85] Batch 360/938 Loss D: 0.4049, Loss G: 1.7356\n",
      "Epoch [54/85] Batch 370/938 Loss D: 0.3233, Loss G: 2.4499\n",
      "Epoch [54/85] Batch 380/938 Loss D: 0.3706, Loss G: 1.9564\n",
      "Epoch [54/85] Batch 390/938 Loss D: 0.3410, Loss G: 2.6054\n",
      "Epoch [54/85] Batch 400/938 Loss D: 0.4127, Loss G: 1.9801\n",
      "Epoch [54/85] Batch 410/938 Loss D: 0.3119, Loss G: 1.6787\n",
      "Epoch [54/85] Batch 420/938 Loss D: 0.2863, Loss G: 2.0126\n",
      "Epoch [54/85] Batch 430/938 Loss D: 0.3135, Loss G: 2.9714\n",
      "Epoch [54/85] Batch 440/938 Loss D: 0.3098, Loss G: 2.2880\n",
      "Epoch [54/85] Batch 450/938 Loss D: 0.4660, Loss G: 2.2981\n",
      "Epoch [54/85] Batch 460/938 Loss D: 0.3014, Loss G: 2.1306\n",
      "Epoch [54/85] Batch 470/938 Loss D: 0.2858, Loss G: 2.1991\n",
      "Epoch [54/85] Batch 480/938 Loss D: 0.2219, Loss G: 2.8003\n",
      "Epoch [54/85] Batch 490/938 Loss D: 0.1825, Loss G: 2.7429\n",
      "Epoch [54/85] Batch 500/938 Loss D: 0.2627, Loss G: 2.1701\n",
      "Epoch [54/85] Batch 510/938 Loss D: 0.2785, Loss G: 1.9135\n",
      "Epoch [54/85] Batch 520/938 Loss D: 0.3218, Loss G: 2.5178\n",
      "Epoch [54/85] Batch 530/938 Loss D: 0.4006, Loss G: 2.3369\n",
      "Epoch [54/85] Batch 540/938 Loss D: 0.4794, Loss G: 2.1635\n",
      "Epoch [54/85] Batch 550/938 Loss D: 0.2422, Loss G: 2.8066\n",
      "Epoch [54/85] Batch 560/938 Loss D: 0.1976, Loss G: 3.0155\n",
      "Epoch [54/85] Batch 570/938 Loss D: 0.2271, Loss G: 2.5711\n",
      "Epoch [54/85] Batch 580/938 Loss D: 0.3436, Loss G: 2.3875\n",
      "Epoch [54/85] Batch 590/938 Loss D: 0.2533, Loss G: 2.8765\n",
      "Epoch [54/85] Batch 600/938 Loss D: 0.3263, Loss G: 2.6999\n",
      "Epoch [54/85] Batch 610/938 Loss D: 0.2049, Loss G: 2.8166\n",
      "Epoch [54/85] Batch 620/938 Loss D: 0.2458, Loss G: 2.6432\n",
      "Epoch [54/85] Batch 630/938 Loss D: 0.2351, Loss G: 2.4651\n",
      "Epoch [54/85] Batch 640/938 Loss D: 0.2476, Loss G: 2.1745\n",
      "Epoch [54/85] Batch 650/938 Loss D: 0.2182, Loss G: 2.4716\n",
      "Epoch [54/85] Batch 660/938 Loss D: 0.5401, Loss G: 1.8996\n",
      "Epoch [54/85] Batch 670/938 Loss D: 0.3360, Loss G: 2.4963\n",
      "Epoch [54/85] Batch 680/938 Loss D: 0.3101, Loss G: 2.0419\n",
      "Epoch [54/85] Batch 690/938 Loss D: 0.2591, Loss G: 2.4657\n",
      "Epoch [54/85] Batch 700/938 Loss D: 0.4266, Loss G: 2.3810\n",
      "Epoch [54/85] Batch 710/938 Loss D: 0.1702, Loss G: 3.5840\n",
      "Epoch [54/85] Batch 720/938 Loss D: 0.1771, Loss G: 2.8208\n",
      "Epoch [54/85] Batch 730/938 Loss D: 0.2913, Loss G: 2.3030\n",
      "Epoch [54/85] Batch 740/938 Loss D: 0.3661, Loss G: 1.9236\n",
      "Epoch [54/85] Batch 750/938 Loss D: 0.3809, Loss G: 1.7141\n",
      "Epoch [54/85] Batch 760/938 Loss D: 0.3199, Loss G: 1.8785\n",
      "Epoch [54/85] Batch 770/938 Loss D: 0.2670, Loss G: 2.6766\n",
      "Epoch [54/85] Batch 780/938 Loss D: 0.2736, Loss G: 2.7628\n",
      "Epoch [54/85] Batch 790/938 Loss D: 0.2788, Loss G: 2.1393\n",
      "Epoch [54/85] Batch 800/938 Loss D: 0.3340, Loss G: 2.1636\n",
      "Epoch [54/85] Batch 810/938 Loss D: 0.3582, Loss G: 1.8598\n",
      "Epoch [54/85] Batch 820/938 Loss D: 0.2794, Loss G: 2.1102\n",
      "Epoch [54/85] Batch 830/938 Loss D: 0.2991, Loss G: 2.0043\n",
      "Epoch [54/85] Batch 840/938 Loss D: 0.3509, Loss G: 1.9319\n",
      "Epoch [54/85] Batch 850/938 Loss D: 0.2874, Loss G: 2.2134\n",
      "Epoch [54/85] Batch 860/938 Loss D: 0.1781, Loss G: 2.9253\n",
      "Epoch [54/85] Batch 870/938 Loss D: 0.3767, Loss G: 2.1457\n",
      "Epoch [54/85] Batch 880/938 Loss D: 0.2179, Loss G: 2.6850\n",
      "Epoch [54/85] Batch 890/938 Loss D: 0.2710, Loss G: 3.2797\n",
      "Epoch [54/85] Batch 900/938 Loss D: 0.2468, Loss G: 2.9274\n",
      "Epoch [54/85] Batch 910/938 Loss D: 0.1684, Loss G: 2.9721\n",
      "Epoch [54/85] Batch 920/938 Loss D: 0.4376, Loss G: 1.9114\n",
      "Epoch [54/85] Batch 930/938 Loss D: 0.2094, Loss G: 2.5872\n",
      "Epoch [55/85] Batch 0/938 Loss D: 0.3701, Loss G: 2.6652\n",
      "Epoch [55/85] Batch 10/938 Loss D: 0.2954, Loss G: 3.0279\n",
      "Epoch [55/85] Batch 20/938 Loss D: 0.3891, Loss G: 1.9663\n",
      "Epoch [55/85] Batch 30/938 Loss D: 0.2918, Loss G: 2.7360\n",
      "Epoch [55/85] Batch 40/938 Loss D: 0.4943, Loss G: 1.5498\n",
      "Epoch [55/85] Batch 50/938 Loss D: 0.4344, Loss G: 1.2802\n",
      "Epoch [55/85] Batch 60/938 Loss D: 0.2540, Loss G: 2.1539\n",
      "Epoch [55/85] Batch 70/938 Loss D: 0.3517, Loss G: 2.9091\n",
      "Epoch [55/85] Batch 80/938 Loss D: 0.4103, Loss G: 2.7275\n",
      "Epoch [55/85] Batch 90/938 Loss D: 0.2938, Loss G: 2.5558\n",
      "Epoch [55/85] Batch 100/938 Loss D: 0.4770, Loss G: 1.3879\n",
      "Epoch [55/85] Batch 110/938 Loss D: 0.2656, Loss G: 2.4887\n",
      "Epoch [55/85] Batch 120/938 Loss D: 0.3049, Loss G: 2.4887\n",
      "Epoch [55/85] Batch 130/938 Loss D: 0.2288, Loss G: 2.6034\n",
      "Epoch [55/85] Batch 140/938 Loss D: 0.2841, Loss G: 2.2027\n",
      "Epoch [55/85] Batch 150/938 Loss D: 0.3101, Loss G: 2.1106\n",
      "Epoch [55/85] Batch 160/938 Loss D: 0.2770, Loss G: 1.9953\n",
      "Epoch [55/85] Batch 170/938 Loss D: 0.3075, Loss G: 1.9984\n",
      "Epoch [55/85] Batch 180/938 Loss D: 0.3452, Loss G: 1.9455\n",
      "Epoch [55/85] Batch 190/938 Loss D: 0.3259, Loss G: 2.0182\n",
      "Epoch [55/85] Batch 200/938 Loss D: 0.2177, Loss G: 2.5233\n",
      "Epoch [55/85] Batch 210/938 Loss D: 0.3082, Loss G: 2.3347\n",
      "Epoch [55/85] Batch 220/938 Loss D: 0.3585, Loss G: 2.9477\n",
      "Epoch [55/85] Batch 230/938 Loss D: 0.2837, Loss G: 3.4827\n",
      "Epoch [55/85] Batch 240/938 Loss D: 0.3017, Loss G: 2.4136\n",
      "Epoch [55/85] Batch 250/938 Loss D: 0.3624, Loss G: 1.8228\n",
      "Epoch [55/85] Batch 260/938 Loss D: 0.3202, Loss G: 1.9556\n",
      "Epoch [55/85] Batch 270/938 Loss D: 0.2492, Loss G: 2.2951\n",
      "Epoch [55/85] Batch 280/938 Loss D: 0.1974, Loss G: 3.5723\n",
      "Epoch [55/85] Batch 290/938 Loss D: 0.4832, Loss G: 1.6973\n",
      "Epoch [55/85] Batch 300/938 Loss D: 0.2499, Loss G: 2.9388\n",
      "Epoch [55/85] Batch 310/938 Loss D: 0.2817, Loss G: 3.0496\n",
      "Epoch [55/85] Batch 320/938 Loss D: 0.2792, Loss G: 2.0143\n",
      "Epoch [55/85] Batch 330/938 Loss D: 0.3573, Loss G: 1.9143\n",
      "Epoch [55/85] Batch 340/938 Loss D: 0.3841, Loss G: 2.0120\n",
      "Epoch [55/85] Batch 350/938 Loss D: 0.3970, Loss G: 2.4039\n",
      "Epoch [55/85] Batch 360/938 Loss D: 0.2529, Loss G: 2.4966\n",
      "Epoch [55/85] Batch 370/938 Loss D: 0.3659, Loss G: 2.3553\n",
      "Epoch [55/85] Batch 380/938 Loss D: 0.4187, Loss G: 2.1468\n",
      "Epoch [55/85] Batch 390/938 Loss D: 0.2712, Loss G: 1.8494\n",
      "Epoch [55/85] Batch 400/938 Loss D: 0.3198, Loss G: 2.5919\n",
      "Epoch [55/85] Batch 410/938 Loss D: 0.1993, Loss G: 3.0979\n",
      "Epoch [55/85] Batch 420/938 Loss D: 0.3663, Loss G: 2.8697\n",
      "Epoch [55/85] Batch 430/938 Loss D: 0.1985, Loss G: 2.5650\n",
      "Epoch [55/85] Batch 440/938 Loss D: 0.3120, Loss G: 2.0479\n",
      "Epoch [55/85] Batch 450/938 Loss D: 0.4123, Loss G: 1.9871\n",
      "Epoch [55/85] Batch 460/938 Loss D: 0.4225, Loss G: 2.2421\n",
      "Epoch [55/85] Batch 470/938 Loss D: 0.2684, Loss G: 2.6061\n",
      "Epoch [55/85] Batch 480/938 Loss D: 0.2842, Loss G: 3.1355\n",
      "Epoch [55/85] Batch 490/938 Loss D: 0.4478, Loss G: 2.0769\n",
      "Epoch [55/85] Batch 500/938 Loss D: 0.3132, Loss G: 2.3571\n",
      "Epoch [55/85] Batch 510/938 Loss D: 0.3361, Loss G: 1.7257\n",
      "Epoch [55/85] Batch 520/938 Loss D: 0.2755, Loss G: 1.9951\n",
      "Epoch [55/85] Batch 530/938 Loss D: 0.4091, Loss G: 2.1473\n",
      "Epoch [55/85] Batch 540/938 Loss D: 0.2972, Loss G: 2.2318\n",
      "Epoch [55/85] Batch 550/938 Loss D: 0.4723, Loss G: 1.9056\n",
      "Epoch [55/85] Batch 560/938 Loss D: 0.2988, Loss G: 2.1661\n",
      "Epoch [55/85] Batch 570/938 Loss D: 0.2269, Loss G: 2.7856\n",
      "Epoch [55/85] Batch 580/938 Loss D: 0.4460, Loss G: 2.1035\n",
      "Epoch [55/85] Batch 590/938 Loss D: 0.4295, Loss G: 2.1847\n",
      "Epoch [55/85] Batch 600/938 Loss D: 0.2562, Loss G: 2.7900\n",
      "Epoch [55/85] Batch 610/938 Loss D: 0.2428, Loss G: 2.5021\n",
      "Epoch [55/85] Batch 620/938 Loss D: 0.3971, Loss G: 2.0621\n",
      "Epoch [55/85] Batch 630/938 Loss D: 0.3183, Loss G: 2.0086\n",
      "Epoch [55/85] Batch 640/938 Loss D: 0.3054, Loss G: 2.1519\n",
      "Epoch [55/85] Batch 650/938 Loss D: 0.3637, Loss G: 1.9767\n",
      "Epoch [55/85] Batch 660/938 Loss D: 0.2827, Loss G: 2.5893\n",
      "Epoch [55/85] Batch 670/938 Loss D: 0.3356, Loss G: 2.7935\n",
      "Epoch [55/85] Batch 680/938 Loss D: 0.2846, Loss G: 2.6256\n",
      "Epoch [55/85] Batch 690/938 Loss D: 0.2887, Loss G: 2.4773\n",
      "Epoch [55/85] Batch 700/938 Loss D: 0.3801, Loss G: 2.4094\n",
      "Epoch [55/85] Batch 710/938 Loss D: 0.2919, Loss G: 2.2091\n",
      "Epoch [55/85] Batch 720/938 Loss D: 0.3165, Loss G: 2.1908\n",
      "Epoch [55/85] Batch 730/938 Loss D: 0.3411, Loss G: 2.0359\n",
      "Epoch [55/85] Batch 740/938 Loss D: 0.3086, Loss G: 2.1408\n",
      "Epoch [55/85] Batch 750/938 Loss D: 0.3970, Loss G: 2.4479\n",
      "Epoch [55/85] Batch 760/938 Loss D: 0.3048, Loss G: 2.1171\n",
      "Epoch [55/85] Batch 770/938 Loss D: 0.3004, Loss G: 2.3540\n",
      "Epoch [55/85] Batch 780/938 Loss D: 0.2904, Loss G: 2.5473\n",
      "Epoch [55/85] Batch 790/938 Loss D: 0.2351, Loss G: 2.5451\n",
      "Epoch [55/85] Batch 800/938 Loss D: 0.4469, Loss G: 2.3187\n",
      "Epoch [55/85] Batch 810/938 Loss D: 0.3684, Loss G: 2.7121\n",
      "Epoch [55/85] Batch 820/938 Loss D: 0.2574, Loss G: 2.9436\n",
      "Epoch [55/85] Batch 830/938 Loss D: 0.4195, Loss G: 2.1142\n",
      "Epoch [55/85] Batch 840/938 Loss D: 0.2532, Loss G: 2.8960\n",
      "Epoch [55/85] Batch 850/938 Loss D: 0.2517, Loss G: 2.8889\n",
      "Epoch [55/85] Batch 860/938 Loss D: 0.3169, Loss G: 2.5729\n",
      "Epoch [55/85] Batch 870/938 Loss D: 0.2717, Loss G: 2.6555\n",
      "Epoch [55/85] Batch 880/938 Loss D: 0.3649, Loss G: 2.7347\n",
      "Epoch [55/85] Batch 890/938 Loss D: 0.3477, Loss G: 2.0559\n",
      "Epoch [55/85] Batch 900/938 Loss D: 0.2296, Loss G: 3.0873\n",
      "Epoch [55/85] Batch 910/938 Loss D: 0.5003, Loss G: 1.7416\n",
      "Epoch [55/85] Batch 920/938 Loss D: 0.3284, Loss G: 2.1160\n",
      "Epoch [55/85] Batch 930/938 Loss D: 0.1850, Loss G: 3.2373\n",
      "Epoch [56/85] Batch 0/938 Loss D: 0.2694, Loss G: 2.5791\n",
      "Epoch [56/85] Batch 10/938 Loss D: 0.2836, Loss G: 2.1522\n",
      "Epoch [56/85] Batch 20/938 Loss D: 0.3383, Loss G: 1.6538\n",
      "Epoch [56/85] Batch 30/938 Loss D: 0.3135, Loss G: 2.3168\n",
      "Epoch [56/85] Batch 40/938 Loss D: 0.2899, Loss G: 2.1355\n",
      "Epoch [56/85] Batch 50/938 Loss D: 0.2386, Loss G: 3.3335\n",
      "Epoch [56/85] Batch 60/938 Loss D: 0.2519, Loss G: 3.1215\n",
      "Epoch [56/85] Batch 70/938 Loss D: 0.3503, Loss G: 2.5883\n",
      "Epoch [56/85] Batch 80/938 Loss D: 0.2919, Loss G: 2.0414\n",
      "Epoch [56/85] Batch 90/938 Loss D: 0.3476, Loss G: 2.2658\n",
      "Epoch [56/85] Batch 100/938 Loss D: 0.3147, Loss G: 1.8340\n",
      "Epoch [56/85] Batch 110/938 Loss D: 0.3825, Loss G: 1.8633\n",
      "Epoch [56/85] Batch 120/938 Loss D: 0.5074, Loss G: 2.1173\n",
      "Epoch [56/85] Batch 130/938 Loss D: 0.1488, Loss G: 3.5294\n",
      "Epoch [56/85] Batch 140/938 Loss D: 0.3323, Loss G: 2.8580\n",
      "Epoch [56/85] Batch 150/938 Loss D: 0.3007, Loss G: 2.7208\n",
      "Epoch [56/85] Batch 160/938 Loss D: 0.4933, Loss G: 2.3902\n",
      "Epoch [56/85] Batch 170/938 Loss D: 0.3176, Loss G: 2.3322\n",
      "Epoch [56/85] Batch 180/938 Loss D: 0.3471, Loss G: 2.5154\n",
      "Epoch [56/85] Batch 190/938 Loss D: 0.3290, Loss G: 1.9917\n",
      "Epoch [56/85] Batch 200/938 Loss D: 0.3080, Loss G: 1.8712\n",
      "Epoch [56/85] Batch 210/938 Loss D: 0.3201, Loss G: 2.2899\n",
      "Epoch [56/85] Batch 220/938 Loss D: 0.2857, Loss G: 2.2318\n",
      "Epoch [56/85] Batch 230/938 Loss D: 0.3326, Loss G: 1.7967\n",
      "Epoch [56/85] Batch 240/938 Loss D: 0.3036, Loss G: 2.1861\n",
      "Epoch [56/85] Batch 250/938 Loss D: 0.3206, Loss G: 2.0142\n",
      "Epoch [56/85] Batch 260/938 Loss D: 0.3488, Loss G: 2.0201\n",
      "Epoch [56/85] Batch 270/938 Loss D: 0.2668, Loss G: 2.3832\n",
      "Epoch [56/85] Batch 280/938 Loss D: 0.3701, Loss G: 2.4305\n",
      "Epoch [56/85] Batch 290/938 Loss D: 0.2268, Loss G: 2.5591\n",
      "Epoch [56/85] Batch 300/938 Loss D: 0.3657, Loss G: 2.2928\n",
      "Epoch [56/85] Batch 310/938 Loss D: 0.1748, Loss G: 2.9811\n",
      "Epoch [56/85] Batch 320/938 Loss D: 0.1942, Loss G: 3.1302\n",
      "Epoch [56/85] Batch 330/938 Loss D: 0.2506, Loss G: 2.7432\n",
      "Epoch [56/85] Batch 340/938 Loss D: 0.3751, Loss G: 1.8702\n",
      "Epoch [56/85] Batch 350/938 Loss D: 0.3289, Loss G: 2.2596\n",
      "Epoch [56/85] Batch 360/938 Loss D: 0.1600, Loss G: 2.9022\n",
      "Epoch [56/85] Batch 370/938 Loss D: 0.2529, Loss G: 2.4630\n",
      "Epoch [56/85] Batch 380/938 Loss D: 0.2255, Loss G: 2.5858\n",
      "Epoch [56/85] Batch 390/938 Loss D: 0.3006, Loss G: 2.5327\n",
      "Epoch [56/85] Batch 400/938 Loss D: 0.3210, Loss G: 2.7569\n",
      "Epoch [56/85] Batch 410/938 Loss D: 0.4099, Loss G: 2.4275\n",
      "Epoch [56/85] Batch 420/938 Loss D: 0.2465, Loss G: 2.7767\n",
      "Epoch [56/85] Batch 430/938 Loss D: 0.2995, Loss G: 2.0822\n",
      "Epoch [56/85] Batch 440/938 Loss D: 0.3671, Loss G: 1.9990\n",
      "Epoch [56/85] Batch 450/938 Loss D: 0.2391, Loss G: 2.6117\n",
      "Epoch [56/85] Batch 460/938 Loss D: 0.4212, Loss G: 2.0734\n",
      "Epoch [56/85] Batch 470/938 Loss D: 0.3669, Loss G: 2.1931\n",
      "Epoch [56/85] Batch 480/938 Loss D: 0.4217, Loss G: 1.7570\n",
      "Epoch [56/85] Batch 490/938 Loss D: 0.2796, Loss G: 2.1526\n",
      "Epoch [56/85] Batch 500/938 Loss D: 0.1972, Loss G: 2.6011\n",
      "Epoch [56/85] Batch 510/938 Loss D: 0.3952, Loss G: 1.9025\n",
      "Epoch [56/85] Batch 520/938 Loss D: 0.2340, Loss G: 3.2350\n",
      "Epoch [56/85] Batch 530/938 Loss D: 0.3221, Loss G: 2.5324\n",
      "Epoch [56/85] Batch 540/938 Loss D: 0.2097, Loss G: 2.7965\n",
      "Epoch [56/85] Batch 550/938 Loss D: 0.2663, Loss G: 2.2303\n",
      "Epoch [56/85] Batch 560/938 Loss D: 0.3219, Loss G: 2.4050\n",
      "Epoch [56/85] Batch 570/938 Loss D: 0.3219, Loss G: 2.7068\n",
      "Epoch [56/85] Batch 580/938 Loss D: 0.4184, Loss G: 2.1280\n",
      "Epoch [56/85] Batch 590/938 Loss D: 0.3063, Loss G: 1.9060\n",
      "Epoch [56/85] Batch 600/938 Loss D: 0.3829, Loss G: 1.6603\n",
      "Epoch [56/85] Batch 610/938 Loss D: 0.2783, Loss G: 1.9809\n",
      "Epoch [56/85] Batch 620/938 Loss D: 0.2653, Loss G: 2.5738\n",
      "Epoch [56/85] Batch 630/938 Loss D: 0.3533, Loss G: 2.4707\n",
      "Epoch [56/85] Batch 640/938 Loss D: 0.3453, Loss G: 2.4709\n",
      "Epoch [56/85] Batch 650/938 Loss D: 0.2957, Loss G: 2.5275\n",
      "Epoch [56/85] Batch 660/938 Loss D: 0.2977, Loss G: 2.2916\n",
      "Epoch [56/85] Batch 670/938 Loss D: 0.3208, Loss G: 2.3736\n",
      "Epoch [56/85] Batch 680/938 Loss D: 0.3097, Loss G: 2.5669\n",
      "Epoch [56/85] Batch 690/938 Loss D: 0.2507, Loss G: 2.1263\n",
      "Epoch [56/85] Batch 700/938 Loss D: 0.2356, Loss G: 2.3727\n",
      "Epoch [56/85] Batch 710/938 Loss D: 0.3264, Loss G: 2.2638\n",
      "Epoch [56/85] Batch 720/938 Loss D: 0.2901, Loss G: 2.9838\n",
      "Epoch [56/85] Batch 730/938 Loss D: 0.2968, Loss G: 2.2234\n",
      "Epoch [56/85] Batch 740/938 Loss D: 0.2290, Loss G: 3.4659\n",
      "Epoch [56/85] Batch 750/938 Loss D: 0.2308, Loss G: 2.8993\n",
      "Epoch [56/85] Batch 760/938 Loss D: 0.4366, Loss G: 2.4871\n",
      "Epoch [56/85] Batch 770/938 Loss D: 0.3492, Loss G: 3.0407\n",
      "Epoch [56/85] Batch 780/938 Loss D: 0.3545, Loss G: 2.1088\n",
      "Epoch [56/85] Batch 790/938 Loss D: 0.3459, Loss G: 1.9552\n",
      "Epoch [56/85] Batch 800/938 Loss D: 0.4682, Loss G: 1.9674\n",
      "Epoch [56/85] Batch 810/938 Loss D: 0.4113, Loss G: 2.2419\n",
      "Epoch [56/85] Batch 820/938 Loss D: 0.4281, Loss G: 1.7577\n",
      "Epoch [56/85] Batch 830/938 Loss D: 0.3185, Loss G: 1.8780\n",
      "Epoch [56/85] Batch 840/938 Loss D: 0.4221, Loss G: 2.5221\n",
      "Epoch [56/85] Batch 850/938 Loss D: 0.3823, Loss G: 2.1198\n",
      "Epoch [56/85] Batch 860/938 Loss D: 0.2820, Loss G: 2.0952\n",
      "Epoch [56/85] Batch 870/938 Loss D: 0.1952, Loss G: 2.4661\n",
      "Epoch [56/85] Batch 880/938 Loss D: 0.3489, Loss G: 1.7719\n",
      "Epoch [56/85] Batch 890/938 Loss D: 0.3745, Loss G: 2.6991\n",
      "Epoch [56/85] Batch 900/938 Loss D: 0.2829, Loss G: 2.3251\n",
      "Epoch [56/85] Batch 910/938 Loss D: 0.3415, Loss G: 2.8688\n",
      "Epoch [56/85] Batch 920/938 Loss D: 0.2941, Loss G: 2.6429\n",
      "Epoch [56/85] Batch 930/938 Loss D: 0.2096, Loss G: 2.5876\n",
      "Epoch [57/85] Batch 0/938 Loss D: 0.4869, Loss G: 1.9530\n",
      "Epoch [57/85] Batch 10/938 Loss D: 0.3557, Loss G: 2.4100\n",
      "Epoch [57/85] Batch 20/938 Loss D: 0.2565, Loss G: 2.5819\n",
      "Epoch [57/85] Batch 30/938 Loss D: 0.3466, Loss G: 2.0143\n",
      "Epoch [57/85] Batch 40/938 Loss D: 0.3227, Loss G: 3.1345\n",
      "Epoch [57/85] Batch 50/938 Loss D: 0.2738, Loss G: 2.7698\n",
      "Epoch [57/85] Batch 60/938 Loss D: 0.2841, Loss G: 2.1577\n",
      "Epoch [57/85] Batch 70/938 Loss D: 0.3056, Loss G: 2.5609\n",
      "Epoch [57/85] Batch 80/938 Loss D: 0.3850, Loss G: 1.9792\n",
      "Epoch [57/85] Batch 90/938 Loss D: 0.2435, Loss G: 2.4520\n",
      "Epoch [57/85] Batch 100/938 Loss D: 0.2495, Loss G: 2.2570\n",
      "Epoch [57/85] Batch 110/938 Loss D: 0.2651, Loss G: 2.2497\n",
      "Epoch [57/85] Batch 120/938 Loss D: 0.3273, Loss G: 1.9335\n",
      "Epoch [57/85] Batch 130/938 Loss D: 0.2617, Loss G: 2.3520\n",
      "Epoch [57/85] Batch 140/938 Loss D: 0.2453, Loss G: 2.2450\n",
      "Epoch [57/85] Batch 150/938 Loss D: 0.2375, Loss G: 2.4460\n",
      "Epoch [57/85] Batch 160/938 Loss D: 0.3002, Loss G: 2.2168\n",
      "Epoch [57/85] Batch 170/938 Loss D: 0.3553, Loss G: 1.9140\n",
      "Epoch [57/85] Batch 180/938 Loss D: 0.2737, Loss G: 2.0985\n",
      "Epoch [57/85] Batch 190/938 Loss D: 0.3372, Loss G: 2.0656\n",
      "Epoch [57/85] Batch 200/938 Loss D: 0.2916, Loss G: 2.4806\n",
      "Epoch [57/85] Batch 210/938 Loss D: 0.2736, Loss G: 2.4662\n",
      "Epoch [57/85] Batch 220/938 Loss D: 0.2824, Loss G: 2.1793\n",
      "Epoch [57/85] Batch 230/938 Loss D: 0.2524, Loss G: 2.2702\n",
      "Epoch [57/85] Batch 240/938 Loss D: 0.2860, Loss G: 2.4224\n",
      "Epoch [57/85] Batch 250/938 Loss D: 0.3459, Loss G: 2.7688\n",
      "Epoch [57/85] Batch 260/938 Loss D: 0.2229, Loss G: 3.0627\n",
      "Epoch [57/85] Batch 270/938 Loss D: 0.3467, Loss G: 2.3254\n",
      "Epoch [57/85] Batch 280/938 Loss D: 0.3298, Loss G: 1.9822\n",
      "Epoch [57/85] Batch 290/938 Loss D: 0.3558, Loss G: 2.0508\n",
      "Epoch [57/85] Batch 300/938 Loss D: 0.3042, Loss G: 2.3119\n",
      "Epoch [57/85] Batch 310/938 Loss D: 0.2902, Loss G: 2.2667\n",
      "Epoch [57/85] Batch 320/938 Loss D: 0.3479, Loss G: 2.3975\n",
      "Epoch [57/85] Batch 330/938 Loss D: 0.2995, Loss G: 2.5138\n",
      "Epoch [57/85] Batch 340/938 Loss D: 0.3133, Loss G: 2.0506\n",
      "Epoch [57/85] Batch 350/938 Loss D: 0.2832, Loss G: 2.4037\n",
      "Epoch [57/85] Batch 360/938 Loss D: 0.3840, Loss G: 2.7891\n",
      "Epoch [57/85] Batch 370/938 Loss D: 0.3215, Loss G: 1.9876\n",
      "Epoch [57/85] Batch 380/938 Loss D: 0.3029, Loss G: 2.4304\n",
      "Epoch [57/85] Batch 390/938 Loss D: 0.3718, Loss G: 2.2745\n",
      "Epoch [57/85] Batch 400/938 Loss D: 0.3358, Loss G: 2.4688\n",
      "Epoch [57/85] Batch 410/938 Loss D: 0.3768, Loss G: 3.6048\n",
      "Epoch [57/85] Batch 420/938 Loss D: 0.2540, Loss G: 2.9155\n",
      "Epoch [57/85] Batch 430/938 Loss D: 0.4018, Loss G: 2.6666\n",
      "Epoch [57/85] Batch 440/938 Loss D: 0.2739, Loss G: 2.7002\n",
      "Epoch [57/85] Batch 450/938 Loss D: 0.4061, Loss G: 2.4079\n",
      "Epoch [57/85] Batch 460/938 Loss D: 0.2663, Loss G: 2.0337\n",
      "Epoch [57/85] Batch 470/938 Loss D: 0.3186, Loss G: 1.9217\n",
      "Epoch [57/85] Batch 480/938 Loss D: 0.3156, Loss G: 1.8338\n",
      "Epoch [57/85] Batch 490/938 Loss D: 0.3343, Loss G: 2.0471\n",
      "Epoch [57/85] Batch 500/938 Loss D: 0.4614, Loss G: 1.7215\n",
      "Epoch [57/85] Batch 510/938 Loss D: 0.4161, Loss G: 1.8222\n",
      "Epoch [57/85] Batch 520/938 Loss D: 0.3431, Loss G: 2.0575\n",
      "Epoch [57/85] Batch 530/938 Loss D: 0.2101, Loss G: 2.6558\n",
      "Epoch [57/85] Batch 540/938 Loss D: 0.3622, Loss G: 2.0262\n",
      "Epoch [57/85] Batch 550/938 Loss D: 0.2871, Loss G: 2.3885\n",
      "Epoch [57/85] Batch 560/938 Loss D: 0.1890, Loss G: 3.0891\n",
      "Epoch [57/85] Batch 570/938 Loss D: 0.5317, Loss G: 2.0941\n",
      "Epoch [57/85] Batch 580/938 Loss D: 0.4858, Loss G: 1.3646\n",
      "Epoch [57/85] Batch 590/938 Loss D: 0.3770, Loss G: 1.7686\n",
      "Epoch [57/85] Batch 600/938 Loss D: 0.4230, Loss G: 1.6507\n",
      "Epoch [57/85] Batch 610/938 Loss D: 0.3522, Loss G: 3.0675\n",
      "Epoch [57/85] Batch 620/938 Loss D: 0.3335, Loss G: 2.6069\n",
      "Epoch [57/85] Batch 630/938 Loss D: 0.2541, Loss G: 2.6781\n",
      "Epoch [57/85] Batch 640/938 Loss D: 0.3278, Loss G: 2.0536\n",
      "Epoch [57/85] Batch 650/938 Loss D: 0.2855, Loss G: 2.2337\n",
      "Epoch [57/85] Batch 660/938 Loss D: 0.3033, Loss G: 2.2941\n",
      "Epoch [57/85] Batch 670/938 Loss D: 0.3749, Loss G: 2.4209\n",
      "Epoch [57/85] Batch 680/938 Loss D: 0.3601, Loss G: 2.3955\n",
      "Epoch [57/85] Batch 690/938 Loss D: 0.2223, Loss G: 2.6446\n",
      "Epoch [57/85] Batch 700/938 Loss D: 0.4309, Loss G: 2.4001\n",
      "Epoch [57/85] Batch 710/938 Loss D: 0.2811, Loss G: 2.4391\n",
      "Epoch [57/85] Batch 720/938 Loss D: 0.3736, Loss G: 2.2148\n",
      "Epoch [57/85] Batch 730/938 Loss D: 0.3462, Loss G: 2.0754\n",
      "Epoch [57/85] Batch 740/938 Loss D: 0.2229, Loss G: 2.8927\n",
      "Epoch [57/85] Batch 750/938 Loss D: 0.2965, Loss G: 2.4471\n",
      "Epoch [57/85] Batch 760/938 Loss D: 0.3819, Loss G: 2.5191\n",
      "Epoch [57/85] Batch 770/938 Loss D: 0.2587, Loss G: 2.3368\n",
      "Epoch [57/85] Batch 780/938 Loss D: 0.3534, Loss G: 2.0628\n",
      "Epoch [57/85] Batch 790/938 Loss D: 0.3708, Loss G: 1.7307\n",
      "Epoch [57/85] Batch 800/938 Loss D: 0.5173, Loss G: 1.6522\n",
      "Epoch [57/85] Batch 810/938 Loss D: 0.3168, Loss G: 2.0065\n",
      "Epoch [57/85] Batch 820/938 Loss D: 0.3007, Loss G: 2.4801\n",
      "Epoch [57/85] Batch 830/938 Loss D: 0.3702, Loss G: 2.2679\n",
      "Epoch [57/85] Batch 840/938 Loss D: 0.3885, Loss G: 2.0033\n",
      "Epoch [57/85] Batch 850/938 Loss D: 0.2958, Loss G: 2.2617\n",
      "Epoch [57/85] Batch 860/938 Loss D: 0.4244, Loss G: 1.6935\n",
      "Epoch [57/85] Batch 870/938 Loss D: 0.3398, Loss G: 2.0199\n",
      "Epoch [57/85] Batch 880/938 Loss D: 0.3145, Loss G: 2.3984\n",
      "Epoch [57/85] Batch 890/938 Loss D: 0.3348, Loss G: 2.1082\n",
      "Epoch [57/85] Batch 900/938 Loss D: 0.3134, Loss G: 2.2103\n",
      "Epoch [57/85] Batch 910/938 Loss D: 0.3384, Loss G: 1.9819\n",
      "Epoch [57/85] Batch 920/938 Loss D: 0.2412, Loss G: 2.5653\n",
      "Epoch [57/85] Batch 930/938 Loss D: 0.3591, Loss G: 2.5734\n",
      "Epoch [58/85] Batch 0/938 Loss D: 0.5067, Loss G: 2.7160\n",
      "Epoch [58/85] Batch 10/938 Loss D: 0.3611, Loss G: 2.6181\n",
      "Epoch [58/85] Batch 20/938 Loss D: 0.3019, Loss G: 2.7258\n",
      "Epoch [58/85] Batch 30/938 Loss D: 0.3216, Loss G: 2.4775\n",
      "Epoch [58/85] Batch 40/938 Loss D: 0.2451, Loss G: 2.5515\n",
      "Epoch [58/85] Batch 50/938 Loss D: 0.3766, Loss G: 2.2320\n",
      "Epoch [58/85] Batch 60/938 Loss D: 0.3192, Loss G: 2.2428\n",
      "Epoch [58/85] Batch 70/938 Loss D: 0.2320, Loss G: 2.9080\n",
      "Epoch [58/85] Batch 80/938 Loss D: 0.2606, Loss G: 1.9325\n",
      "Epoch [58/85] Batch 90/938 Loss D: 0.3654, Loss G: 2.0254\n",
      "Epoch [58/85] Batch 100/938 Loss D: 0.3050, Loss G: 2.2942\n",
      "Epoch [58/85] Batch 110/938 Loss D: 0.2517, Loss G: 2.5274\n",
      "Epoch [58/85] Batch 120/938 Loss D: 0.2212, Loss G: 2.9179\n",
      "Epoch [58/85] Batch 130/938 Loss D: 0.4117, Loss G: 2.0035\n",
      "Epoch [58/85] Batch 140/938 Loss D: 0.3724, Loss G: 1.5315\n",
      "Epoch [58/85] Batch 150/938 Loss D: 0.2892, Loss G: 1.9458\n",
      "Epoch [58/85] Batch 160/938 Loss D: 0.3034, Loss G: 2.4697\n",
      "Epoch [58/85] Batch 170/938 Loss D: 0.5060, Loss G: 2.3249\n",
      "Epoch [58/85] Batch 180/938 Loss D: 0.3278, Loss G: 2.3128\n",
      "Epoch [58/85] Batch 190/938 Loss D: 0.3622, Loss G: 2.5777\n",
      "Epoch [58/85] Batch 200/938 Loss D: 0.3338, Loss G: 2.1910\n",
      "Epoch [58/85] Batch 210/938 Loss D: 0.2438, Loss G: 2.4255\n",
      "Epoch [58/85] Batch 220/938 Loss D: 0.4725, Loss G: 1.8841\n",
      "Epoch [58/85] Batch 230/938 Loss D: 0.3775, Loss G: 1.9774\n",
      "Epoch [58/85] Batch 240/938 Loss D: 0.2234, Loss G: 2.8519\n",
      "Epoch [58/85] Batch 250/938 Loss D: 0.3252, Loss G: 2.7041\n",
      "Epoch [58/85] Batch 260/938 Loss D: 0.3200, Loss G: 2.1625\n",
      "Epoch [58/85] Batch 270/938 Loss D: 0.2513, Loss G: 2.3235\n",
      "Epoch [58/85] Batch 280/938 Loss D: 0.2699, Loss G: 2.7394\n",
      "Epoch [58/85] Batch 290/938 Loss D: 0.2876, Loss G: 2.4371\n",
      "Epoch [58/85] Batch 300/938 Loss D: 0.2265, Loss G: 2.1355\n",
      "Epoch [58/85] Batch 310/938 Loss D: 0.1790, Loss G: 3.5862\n",
      "Epoch [58/85] Batch 320/938 Loss D: 0.2466, Loss G: 3.0089\n",
      "Epoch [58/85] Batch 330/938 Loss D: 0.3564, Loss G: 3.0107\n",
      "Epoch [58/85] Batch 340/938 Loss D: 0.3300, Loss G: 2.5395\n",
      "Epoch [58/85] Batch 350/938 Loss D: 0.2305, Loss G: 2.5483\n",
      "Epoch [58/85] Batch 360/938 Loss D: 0.3550, Loss G: 1.9024\n",
      "Epoch [58/85] Batch 370/938 Loss D: 0.1802, Loss G: 2.7751\n",
      "Epoch [58/85] Batch 380/938 Loss D: 0.1914, Loss G: 2.7849\n",
      "Epoch [58/85] Batch 390/938 Loss D: 0.3984, Loss G: 1.9233\n",
      "Epoch [58/85] Batch 400/938 Loss D: 0.2621, Loss G: 2.3693\n",
      "Epoch [58/85] Batch 410/938 Loss D: 0.2833, Loss G: 2.3293\n",
      "Epoch [58/85] Batch 420/938 Loss D: 0.3292, Loss G: 2.9107\n",
      "Epoch [58/85] Batch 430/938 Loss D: 0.3584, Loss G: 2.7542\n",
      "Epoch [58/85] Batch 440/938 Loss D: 0.1954, Loss G: 2.6421\n",
      "Epoch [58/85] Batch 450/938 Loss D: 0.3313, Loss G: 1.9244\n",
      "Epoch [58/85] Batch 460/938 Loss D: 0.2882, Loss G: 2.4277\n",
      "Epoch [58/85] Batch 470/938 Loss D: 0.2544, Loss G: 2.4094\n",
      "Epoch [58/85] Batch 480/938 Loss D: 0.2655, Loss G: 2.9460\n",
      "Epoch [58/85] Batch 490/938 Loss D: 0.2766, Loss G: 2.7797\n",
      "Epoch [58/85] Batch 500/938 Loss D: 0.2421, Loss G: 2.6908\n",
      "Epoch [58/85] Batch 510/938 Loss D: 0.3343, Loss G: 2.1094\n",
      "Epoch [58/85] Batch 520/938 Loss D: 0.2677, Loss G: 2.2084\n",
      "Epoch [58/85] Batch 530/938 Loss D: 0.2950, Loss G: 2.4411\n",
      "Epoch [58/85] Batch 540/938 Loss D: 0.3383, Loss G: 2.1356\n",
      "Epoch [58/85] Batch 550/938 Loss D: 0.2665, Loss G: 2.7753\n",
      "Epoch [58/85] Batch 560/938 Loss D: 0.3248, Loss G: 2.4957\n",
      "Epoch [58/85] Batch 570/938 Loss D: 0.3229, Loss G: 2.6950\n",
      "Epoch [58/85] Batch 580/938 Loss D: 0.3290, Loss G: 2.2811\n",
      "Epoch [58/85] Batch 590/938 Loss D: 0.2965, Loss G: 1.8579\n",
      "Epoch [58/85] Batch 600/938 Loss D: 0.2935, Loss G: 2.3225\n",
      "Epoch [58/85] Batch 610/938 Loss D: 0.4273, Loss G: 1.6125\n",
      "Epoch [58/85] Batch 620/938 Loss D: 0.4569, Loss G: 1.8730\n",
      "Epoch [58/85] Batch 630/938 Loss D: 0.2703, Loss G: 2.1859\n",
      "Epoch [58/85] Batch 640/938 Loss D: 0.1844, Loss G: 2.9104\n",
      "Epoch [58/85] Batch 650/938 Loss D: 0.2725, Loss G: 2.8090\n",
      "Epoch [58/85] Batch 660/938 Loss D: 0.3734, Loss G: 1.8307\n",
      "Epoch [58/85] Batch 670/938 Loss D: 0.2255, Loss G: 2.0679\n",
      "Epoch [58/85] Batch 680/938 Loss D: 0.2255, Loss G: 2.1225\n",
      "Epoch [58/85] Batch 690/938 Loss D: 0.2055, Loss G: 2.3673\n",
      "Epoch [58/85] Batch 700/938 Loss D: 0.4401, Loss G: 1.6269\n",
      "Epoch [58/85] Batch 710/938 Loss D: 0.2570, Loss G: 2.6267\n",
      "Epoch [58/85] Batch 720/938 Loss D: 0.2596, Loss G: 2.4949\n",
      "Epoch [58/85] Batch 730/938 Loss D: 0.3561, Loss G: 1.8893\n",
      "Epoch [58/85] Batch 740/938 Loss D: 0.4014, Loss G: 1.6662\n",
      "Epoch [58/85] Batch 750/938 Loss D: 0.3914, Loss G: 1.8672\n",
      "Epoch [58/85] Batch 760/938 Loss D: 0.3477, Loss G: 1.8464\n",
      "Epoch [58/85] Batch 770/938 Loss D: 0.3655, Loss G: 2.9438\n",
      "Epoch [58/85] Batch 780/938 Loss D: 0.3926, Loss G: 2.8170\n",
      "Epoch [58/85] Batch 790/938 Loss D: 0.3068, Loss G: 2.4755\n",
      "Epoch [58/85] Batch 800/938 Loss D: 0.3429, Loss G: 2.7438\n",
      "Epoch [58/85] Batch 810/938 Loss D: 0.4119, Loss G: 1.8769\n",
      "Epoch [58/85] Batch 820/938 Loss D: 0.2548, Loss G: 2.7894\n",
      "Epoch [58/85] Batch 830/938 Loss D: 0.1632, Loss G: 3.2851\n",
      "Epoch [58/85] Batch 840/938 Loss D: 0.3347, Loss G: 3.0109\n",
      "Epoch [58/85] Batch 850/938 Loss D: 0.3252, Loss G: 2.5997\n",
      "Epoch [58/85] Batch 860/938 Loss D: 0.2798, Loss G: 1.8364\n",
      "Epoch [58/85] Batch 870/938 Loss D: 0.1734, Loss G: 3.5307\n",
      "Epoch [58/85] Batch 880/938 Loss D: 0.5176, Loss G: 2.0705\n",
      "Epoch [58/85] Batch 890/938 Loss D: 0.2753, Loss G: 2.0505\n",
      "Epoch [58/85] Batch 900/938 Loss D: 0.3709, Loss G: 2.3581\n",
      "Epoch [58/85] Batch 910/938 Loss D: 0.3281, Loss G: 1.8315\n",
      "Epoch [58/85] Batch 920/938 Loss D: 0.3336, Loss G: 2.1455\n",
      "Epoch [58/85] Batch 930/938 Loss D: 0.4383, Loss G: 2.6734\n",
      "Epoch [59/85] Batch 0/938 Loss D: 0.2211, Loss G: 2.5808\n",
      "Epoch [59/85] Batch 10/938 Loss D: 0.3087, Loss G: 2.0122\n",
      "Epoch [59/85] Batch 20/938 Loss D: 0.2157, Loss G: 2.6780\n",
      "Epoch [59/85] Batch 30/938 Loss D: 0.3753, Loss G: 1.4360\n",
      "Epoch [59/85] Batch 40/938 Loss D: 0.3109, Loss G: 2.1157\n",
      "Epoch [59/85] Batch 50/938 Loss D: 0.2997, Loss G: 2.0267\n",
      "Epoch [59/85] Batch 60/938 Loss D: 0.2840, Loss G: 2.2425\n",
      "Epoch [59/85] Batch 70/938 Loss D: 0.2574, Loss G: 2.7412\n",
      "Epoch [59/85] Batch 80/938 Loss D: 0.2893, Loss G: 2.7474\n",
      "Epoch [59/85] Batch 90/938 Loss D: 0.2778, Loss G: 2.7906\n",
      "Epoch [59/85] Batch 100/938 Loss D: 0.3143, Loss G: 2.6181\n",
      "Epoch [59/85] Batch 110/938 Loss D: 0.3552, Loss G: 1.7497\n",
      "Epoch [59/85] Batch 120/938 Loss D: 0.2079, Loss G: 2.5069\n",
      "Epoch [59/85] Batch 130/938 Loss D: 0.3152, Loss G: 1.6861\n",
      "Epoch [59/85] Batch 140/938 Loss D: 0.3715, Loss G: 2.4848\n",
      "Epoch [59/85] Batch 150/938 Loss D: 0.2473, Loss G: 2.4019\n",
      "Epoch [59/85] Batch 160/938 Loss D: 0.3464, Loss G: 2.1200\n",
      "Epoch [59/85] Batch 170/938 Loss D: 0.2254, Loss G: 2.7904\n",
      "Epoch [59/85] Batch 180/938 Loss D: 0.2677, Loss G: 2.9748\n",
      "Epoch [59/85] Batch 190/938 Loss D: 0.3329, Loss G: 2.8288\n",
      "Epoch [59/85] Batch 200/938 Loss D: 0.3244, Loss G: 2.0478\n",
      "Epoch [59/85] Batch 210/938 Loss D: 0.2296, Loss G: 2.4279\n",
      "Epoch [59/85] Batch 220/938 Loss D: 0.2010, Loss G: 3.0835\n",
      "Epoch [59/85] Batch 230/938 Loss D: 0.2629, Loss G: 2.9910\n",
      "Epoch [59/85] Batch 240/938 Loss D: 0.3280, Loss G: 3.0494\n",
      "Epoch [59/85] Batch 250/938 Loss D: 0.3041, Loss G: 2.2571\n",
      "Epoch [59/85] Batch 260/938 Loss D: 0.3191, Loss G: 1.8881\n",
      "Epoch [59/85] Batch 270/938 Loss D: 0.4687, Loss G: 1.9008\n",
      "Epoch [59/85] Batch 280/938 Loss D: 0.3042, Loss G: 2.7726\n",
      "Epoch [59/85] Batch 290/938 Loss D: 0.2672, Loss G: 2.7444\n",
      "Epoch [59/85] Batch 300/938 Loss D: 0.3648, Loss G: 2.2968\n",
      "Epoch [59/85] Batch 310/938 Loss D: 0.2883, Loss G: 1.9084\n",
      "Epoch [59/85] Batch 320/938 Loss D: 0.3322, Loss G: 2.4581\n",
      "Epoch [59/85] Batch 330/938 Loss D: 0.3965, Loss G: 1.9242\n",
      "Epoch [59/85] Batch 340/938 Loss D: 0.2832, Loss G: 2.0716\n",
      "Epoch [59/85] Batch 350/938 Loss D: 0.2246, Loss G: 2.7002\n",
      "Epoch [59/85] Batch 360/938 Loss D: 0.2775, Loss G: 2.5263\n",
      "Epoch [59/85] Batch 370/938 Loss D: 0.2050, Loss G: 2.4393\n",
      "Epoch [59/85] Batch 380/938 Loss D: 0.3580, Loss G: 2.3062\n",
      "Epoch [59/85] Batch 390/938 Loss D: 0.3132, Loss G: 2.1003\n",
      "Epoch [59/85] Batch 400/938 Loss D: 0.1689, Loss G: 3.1989\n",
      "Epoch [59/85] Batch 410/938 Loss D: 0.2641, Loss G: 2.7712\n",
      "Epoch [59/85] Batch 420/938 Loss D: 0.2500, Loss G: 2.7142\n",
      "Epoch [59/85] Batch 430/938 Loss D: 0.3109, Loss G: 2.1429\n",
      "Epoch [59/85] Batch 440/938 Loss D: 0.3294, Loss G: 2.4846\n",
      "Epoch [59/85] Batch 450/938 Loss D: 0.4083, Loss G: 2.1581\n",
      "Epoch [59/85] Batch 460/938 Loss D: 0.3256, Loss G: 2.3019\n",
      "Epoch [59/85] Batch 470/938 Loss D: 0.2389, Loss G: 2.5941\n",
      "Epoch [59/85] Batch 480/938 Loss D: 0.4228, Loss G: 2.3629\n",
      "Epoch [59/85] Batch 490/938 Loss D: 0.3084, Loss G: 2.2732\n",
      "Epoch [59/85] Batch 500/938 Loss D: 0.2277, Loss G: 2.9455\n",
      "Epoch [59/85] Batch 510/938 Loss D: 0.2123, Loss G: 2.8413\n",
      "Epoch [59/85] Batch 520/938 Loss D: 0.2051, Loss G: 2.4784\n",
      "Epoch [59/85] Batch 530/938 Loss D: 0.3149, Loss G: 2.9815\n",
      "Epoch [59/85] Batch 540/938 Loss D: 0.3302, Loss G: 2.1735\n",
      "Epoch [59/85] Batch 550/938 Loss D: 0.4414, Loss G: 1.7774\n",
      "Epoch [59/85] Batch 560/938 Loss D: 0.2088, Loss G: 2.6164\n",
      "Epoch [59/85] Batch 570/938 Loss D: 0.3016, Loss G: 3.0505\n",
      "Epoch [59/85] Batch 580/938 Loss D: 0.3379, Loss G: 2.7622\n",
      "Epoch [59/85] Batch 590/938 Loss D: 0.2341, Loss G: 2.5261\n",
      "Epoch [59/85] Batch 600/938 Loss D: 0.2747, Loss G: 3.0563\n",
      "Epoch [59/85] Batch 610/938 Loss D: 0.2404, Loss G: 3.1797\n",
      "Epoch [59/85] Batch 620/938 Loss D: 0.3914, Loss G: 2.4503\n",
      "Epoch [59/85] Batch 630/938 Loss D: 0.3960, Loss G: 1.7183\n",
      "Epoch [59/85] Batch 640/938 Loss D: 0.1588, Loss G: 2.5211\n",
      "Epoch [59/85] Batch 650/938 Loss D: 0.3156, Loss G: 2.0734\n",
      "Epoch [59/85] Batch 660/938 Loss D: 0.2524, Loss G: 2.5579\n",
      "Epoch [59/85] Batch 670/938 Loss D: 0.3029, Loss G: 2.0346\n",
      "Epoch [59/85] Batch 680/938 Loss D: 0.2266, Loss G: 2.3007\n",
      "Epoch [59/85] Batch 690/938 Loss D: 0.2686, Loss G: 2.7749\n",
      "Epoch [59/85] Batch 700/938 Loss D: 0.3669, Loss G: 2.6791\n",
      "Epoch [59/85] Batch 710/938 Loss D: 0.2896, Loss G: 2.7136\n",
      "Epoch [59/85] Batch 720/938 Loss D: 0.2413, Loss G: 2.8923\n",
      "Epoch [59/85] Batch 730/938 Loss D: 0.4395, Loss G: 2.0644\n",
      "Epoch [59/85] Batch 740/938 Loss D: 0.3679, Loss G: 1.7982\n",
      "Epoch [59/85] Batch 750/938 Loss D: 0.3666, Loss G: 2.3260\n",
      "Epoch [59/85] Batch 760/938 Loss D: 0.2822, Loss G: 2.0816\n",
      "Epoch [59/85] Batch 770/938 Loss D: 0.2336, Loss G: 2.2127\n",
      "Epoch [59/85] Batch 780/938 Loss D: 0.4134, Loss G: 2.0680\n",
      "Epoch [59/85] Batch 790/938 Loss D: 0.1905, Loss G: 2.7439\n",
      "Epoch [59/85] Batch 800/938 Loss D: 0.3765, Loss G: 2.2271\n",
      "Epoch [59/85] Batch 810/938 Loss D: 0.2043, Loss G: 2.4728\n",
      "Epoch [59/85] Batch 820/938 Loss D: 0.3212, Loss G: 2.3012\n",
      "Epoch [59/85] Batch 830/938 Loss D: 0.2624, Loss G: 2.1183\n",
      "Epoch [59/85] Batch 840/938 Loss D: 0.2941, Loss G: 1.7130\n",
      "Epoch [59/85] Batch 850/938 Loss D: 0.3886, Loss G: 1.7302\n",
      "Epoch [59/85] Batch 860/938 Loss D: 0.3069, Loss G: 2.3787\n",
      "Epoch [59/85] Batch 870/938 Loss D: 0.2402, Loss G: 2.3889\n",
      "Epoch [59/85] Batch 880/938 Loss D: 0.2869, Loss G: 3.5277\n",
      "Epoch [59/85] Batch 890/938 Loss D: 0.2715, Loss G: 2.6419\n",
      "Epoch [59/85] Batch 900/938 Loss D: 0.3837, Loss G: 1.9215\n",
      "Epoch [59/85] Batch 910/938 Loss D: 0.4197, Loss G: 1.8854\n",
      "Epoch [59/85] Batch 920/938 Loss D: 0.2878, Loss G: 2.1716\n",
      "Epoch [59/85] Batch 930/938 Loss D: 0.3365, Loss G: 1.5007\n",
      "Epoch [60/85] Batch 0/938 Loss D: 0.2700, Loss G: 2.9392\n",
      "Epoch [60/85] Batch 10/938 Loss D: 0.2246, Loss G: 2.7801\n",
      "Epoch [60/85] Batch 20/938 Loss D: 0.2695, Loss G: 2.0589\n",
      "Epoch [60/85] Batch 30/938 Loss D: 0.3287, Loss G: 1.6671\n",
      "Epoch [60/85] Batch 40/938 Loss D: 0.2453, Loss G: 2.7958\n",
      "Epoch [60/85] Batch 50/938 Loss D: 0.4782, Loss G: 1.8722\n",
      "Epoch [60/85] Batch 60/938 Loss D: 0.1988, Loss G: 2.9060\n",
      "Epoch [60/85] Batch 70/938 Loss D: 0.3572, Loss G: 2.2928\n",
      "Epoch [60/85] Batch 80/938 Loss D: 0.1736, Loss G: 3.1296\n",
      "Epoch [60/85] Batch 90/938 Loss D: 0.1841, Loss G: 3.4523\n",
      "Epoch [60/85] Batch 100/938 Loss D: 0.3574, Loss G: 2.3987\n",
      "Epoch [60/85] Batch 110/938 Loss D: 0.2972, Loss G: 2.2990\n",
      "Epoch [60/85] Batch 120/938 Loss D: 0.3176, Loss G: 2.1185\n",
      "Epoch [60/85] Batch 130/938 Loss D: 0.3183, Loss G: 2.2581\n",
      "Epoch [60/85] Batch 140/938 Loss D: 0.2678, Loss G: 2.6677\n",
      "Epoch [60/85] Batch 150/938 Loss D: 0.2358, Loss G: 2.3297\n",
      "Epoch [60/85] Batch 160/938 Loss D: 0.3837, Loss G: 2.1130\n",
      "Epoch [60/85] Batch 170/938 Loss D: 0.2878, Loss G: 2.5498\n",
      "Epoch [60/85] Batch 180/938 Loss D: 0.2325, Loss G: 2.8039\n",
      "Epoch [60/85] Batch 190/938 Loss D: 0.2927, Loss G: 2.1559\n",
      "Epoch [60/85] Batch 200/938 Loss D: 0.2521, Loss G: 3.2476\n",
      "Epoch [60/85] Batch 210/938 Loss D: 0.3082, Loss G: 2.9100\n",
      "Epoch [60/85] Batch 220/938 Loss D: 0.2741, Loss G: 2.3177\n",
      "Epoch [60/85] Batch 230/938 Loss D: 0.2299, Loss G: 2.4918\n",
      "Epoch [60/85] Batch 240/938 Loss D: 0.2417, Loss G: 2.6225\n",
      "Epoch [60/85] Batch 250/938 Loss D: 0.3378, Loss G: 2.0877\n",
      "Epoch [60/85] Batch 260/938 Loss D: 0.2608, Loss G: 2.4870\n",
      "Epoch [60/85] Batch 270/938 Loss D: 0.4971, Loss G: 2.4566\n",
      "Epoch [60/85] Batch 280/938 Loss D: 0.3155, Loss G: 2.7132\n",
      "Epoch [60/85] Batch 290/938 Loss D: 0.3008, Loss G: 2.3300\n",
      "Epoch [60/85] Batch 300/938 Loss D: 0.3264, Loss G: 2.3350\n",
      "Epoch [60/85] Batch 310/938 Loss D: 0.2730, Loss G: 2.4527\n",
      "Epoch [60/85] Batch 320/938 Loss D: 0.2921, Loss G: 2.2136\n",
      "Epoch [60/85] Batch 330/938 Loss D: 0.3028, Loss G: 2.0512\n",
      "Epoch [60/85] Batch 340/938 Loss D: 0.2714, Loss G: 3.1111\n",
      "Epoch [60/85] Batch 350/938 Loss D: 0.3593, Loss G: 2.5165\n",
      "Epoch [60/85] Batch 360/938 Loss D: 0.3024, Loss G: 2.6789\n",
      "Epoch [60/85] Batch 370/938 Loss D: 0.5151, Loss G: 2.7303\n",
      "Epoch [60/85] Batch 380/938 Loss D: 0.4438, Loss G: 2.4630\n",
      "Epoch [60/85] Batch 390/938 Loss D: 0.2220, Loss G: 3.2822\n",
      "Epoch [60/85] Batch 400/938 Loss D: 0.3981, Loss G: 2.5098\n",
      "Epoch [60/85] Batch 410/938 Loss D: 0.2718, Loss G: 2.5707\n",
      "Epoch [60/85] Batch 420/938 Loss D: 0.4393, Loss G: 2.1655\n",
      "Epoch [60/85] Batch 430/938 Loss D: 0.2993, Loss G: 2.2290\n",
      "Epoch [60/85] Batch 440/938 Loss D: 0.2860, Loss G: 1.9581\n",
      "Epoch [60/85] Batch 450/938 Loss D: 0.3825, Loss G: 2.3202\n",
      "Epoch [60/85] Batch 460/938 Loss D: 0.4419, Loss G: 2.2644\n",
      "Epoch [60/85] Batch 470/938 Loss D: 0.3180, Loss G: 2.2418\n",
      "Epoch [60/85] Batch 480/938 Loss D: 0.1800, Loss G: 3.3605\n",
      "Epoch [60/85] Batch 490/938 Loss D: 0.3539, Loss G: 2.1088\n",
      "Epoch [60/85] Batch 500/938 Loss D: 0.2146, Loss G: 2.9129\n",
      "Epoch [60/85] Batch 510/938 Loss D: 0.2565, Loss G: 2.6320\n",
      "Epoch [60/85] Batch 520/938 Loss D: 0.3582, Loss G: 3.2000\n",
      "Epoch [60/85] Batch 530/938 Loss D: 0.2821, Loss G: 3.2308\n",
      "Epoch [60/85] Batch 540/938 Loss D: 0.2100, Loss G: 3.3187\n",
      "Epoch [60/85] Batch 550/938 Loss D: 0.1888, Loss G: 3.5371\n",
      "Epoch [60/85] Batch 560/938 Loss D: 0.2000, Loss G: 2.8860\n",
      "Epoch [60/85] Batch 570/938 Loss D: 0.3297, Loss G: 2.2188\n",
      "Epoch [60/85] Batch 580/938 Loss D: 0.4223, Loss G: 2.3009\n",
      "Epoch [60/85] Batch 590/938 Loss D: 0.4190, Loss G: 2.2797\n",
      "Epoch [60/85] Batch 600/938 Loss D: 0.3457, Loss G: 2.8754\n",
      "Epoch [60/85] Batch 610/938 Loss D: 0.4633, Loss G: 2.4242\n",
      "Epoch [60/85] Batch 620/938 Loss D: 0.2245, Loss G: 3.4938\n",
      "Epoch [60/85] Batch 630/938 Loss D: 0.2419, Loss G: 2.3043\n",
      "Epoch [60/85] Batch 640/938 Loss D: 0.3223, Loss G: 2.1866\n",
      "Epoch [60/85] Batch 650/938 Loss D: 0.4536, Loss G: 1.7181\n",
      "Epoch [60/85] Batch 660/938 Loss D: 0.4118, Loss G: 1.7308\n",
      "Epoch [60/85] Batch 670/938 Loss D: 0.2048, Loss G: 2.4389\n",
      "Epoch [60/85] Batch 680/938 Loss D: 0.2829, Loss G: 2.0438\n",
      "Epoch [60/85] Batch 690/938 Loss D: 0.3892, Loss G: 1.7359\n",
      "Epoch [60/85] Batch 700/938 Loss D: 0.2563, Loss G: 2.3469\n",
      "Epoch [60/85] Batch 710/938 Loss D: 0.2797, Loss G: 2.7912\n",
      "Epoch [60/85] Batch 720/938 Loss D: 0.2244, Loss G: 2.5240\n",
      "Epoch [60/85] Batch 730/938 Loss D: 0.4023, Loss G: 2.1264\n",
      "Epoch [60/85] Batch 740/938 Loss D: 0.2200, Loss G: 2.6937\n",
      "Epoch [60/85] Batch 750/938 Loss D: 0.1899, Loss G: 3.2666\n",
      "Epoch [60/85] Batch 760/938 Loss D: 0.2030, Loss G: 2.9341\n",
      "Epoch [60/85] Batch 770/938 Loss D: 0.2328, Loss G: 3.3346\n",
      "Epoch [60/85] Batch 780/938 Loss D: 0.3231, Loss G: 2.4712\n",
      "Epoch [60/85] Batch 790/938 Loss D: 0.3054, Loss G: 1.9547\n",
      "Epoch [60/85] Batch 800/938 Loss D: 0.2664, Loss G: 2.1719\n",
      "Epoch [60/85] Batch 810/938 Loss D: 0.3649, Loss G: 2.1127\n",
      "Epoch [60/85] Batch 820/938 Loss D: 0.2587, Loss G: 2.9361\n",
      "Epoch [60/85] Batch 830/938 Loss D: 0.2523, Loss G: 2.8195\n",
      "Epoch [60/85] Batch 840/938 Loss D: 0.3058, Loss G: 1.9695\n",
      "Epoch [60/85] Batch 850/938 Loss D: 0.2872, Loss G: 1.9271\n",
      "Epoch [60/85] Batch 860/938 Loss D: 0.2576, Loss G: 2.2025\n",
      "Epoch [60/85] Batch 870/938 Loss D: 0.2106, Loss G: 2.6270\n",
      "Epoch [60/85] Batch 880/938 Loss D: 0.2804, Loss G: 2.2248\n",
      "Epoch [60/85] Batch 890/938 Loss D: 0.3198, Loss G: 2.2050\n",
      "Epoch [60/85] Batch 900/938 Loss D: 0.3016, Loss G: 2.6583\n",
      "Epoch [60/85] Batch 910/938 Loss D: 0.2800, Loss G: 2.8674\n",
      "Epoch [60/85] Batch 920/938 Loss D: 0.3574, Loss G: 2.5792\n",
      "Epoch [60/85] Batch 930/938 Loss D: 0.4263, Loss G: 1.8349\n",
      "Epoch [61/85] Batch 0/938 Loss D: 0.2911, Loss G: 1.6845\n",
      "Epoch [61/85] Batch 10/938 Loss D: 0.2445, Loss G: 1.9587\n",
      "Epoch [61/85] Batch 20/938 Loss D: 0.2087, Loss G: 3.0485\n",
      "Epoch [61/85] Batch 30/938 Loss D: 0.3187, Loss G: 2.2188\n",
      "Epoch [61/85] Batch 40/938 Loss D: 0.2783, Loss G: 1.8422\n",
      "Epoch [61/85] Batch 50/938 Loss D: 0.2903, Loss G: 2.2455\n",
      "Epoch [61/85] Batch 60/938 Loss D: 0.1983, Loss G: 2.5561\n",
      "Epoch [61/85] Batch 70/938 Loss D: 0.2192, Loss G: 3.5556\n",
      "Epoch [61/85] Batch 80/938 Loss D: 0.2484, Loss G: 2.4219\n",
      "Epoch [61/85] Batch 90/938 Loss D: 0.1709, Loss G: 3.1675\n",
      "Epoch [61/85] Batch 100/938 Loss D: 0.2869, Loss G: 2.1489\n",
      "Epoch [61/85] Batch 110/938 Loss D: 0.4645, Loss G: 2.1328\n",
      "Epoch [61/85] Batch 120/938 Loss D: 0.2564, Loss G: 2.7473\n",
      "Epoch [61/85] Batch 130/938 Loss D: 0.4127, Loss G: 2.0585\n",
      "Epoch [61/85] Batch 140/938 Loss D: 0.3183, Loss G: 2.0981\n",
      "Epoch [61/85] Batch 150/938 Loss D: 0.2715, Loss G: 2.4946\n",
      "Epoch [61/85] Batch 160/938 Loss D: 0.3458, Loss G: 3.1342\n",
      "Epoch [61/85] Batch 170/938 Loss D: 0.2613, Loss G: 2.6360\n",
      "Epoch [61/85] Batch 180/938 Loss D: 0.3429, Loss G: 2.8903\n",
      "Epoch [61/85] Batch 190/938 Loss D: 0.2853, Loss G: 2.4624\n",
      "Epoch [61/85] Batch 200/938 Loss D: 0.2812, Loss G: 2.6304\n",
      "Epoch [61/85] Batch 210/938 Loss D: 0.2462, Loss G: 2.8992\n",
      "Epoch [61/85] Batch 220/938 Loss D: 0.2431, Loss G: 2.7753\n",
      "Epoch [61/85] Batch 230/938 Loss D: 0.2082, Loss G: 2.4670\n",
      "Epoch [61/85] Batch 240/938 Loss D: 0.3247, Loss G: 1.8792\n",
      "Epoch [61/85] Batch 250/938 Loss D: 0.2407, Loss G: 2.9298\n",
      "Epoch [61/85] Batch 260/938 Loss D: 0.3683, Loss G: 2.7766\n",
      "Epoch [61/85] Batch 270/938 Loss D: 0.3254, Loss G: 2.2749\n",
      "Epoch [61/85] Batch 280/938 Loss D: 0.2957, Loss G: 2.8673\n",
      "Epoch [61/85] Batch 290/938 Loss D: 0.4090, Loss G: 2.3297\n",
      "Epoch [61/85] Batch 300/938 Loss D: 0.3151, Loss G: 1.9916\n",
      "Epoch [61/85] Batch 310/938 Loss D: 0.1695, Loss G: 2.9150\n",
      "Epoch [61/85] Batch 320/938 Loss D: 0.1690, Loss G: 2.6495\n",
      "Epoch [61/85] Batch 330/938 Loss D: 0.1689, Loss G: 3.3341\n",
      "Epoch [61/85] Batch 340/938 Loss D: 0.2138, Loss G: 3.0704\n",
      "Epoch [61/85] Batch 350/938 Loss D: 0.2549, Loss G: 3.3417\n",
      "Epoch [61/85] Batch 360/938 Loss D: 0.2334, Loss G: 2.4759\n",
      "Epoch [61/85] Batch 370/938 Loss D: 0.2715, Loss G: 3.1989\n",
      "Epoch [61/85] Batch 380/938 Loss D: 0.3250, Loss G: 3.5502\n",
      "Epoch [61/85] Batch 390/938 Loss D: 0.1915, Loss G: 3.2286\n",
      "Epoch [61/85] Batch 400/938 Loss D: 0.2929, Loss G: 2.2519\n",
      "Epoch [61/85] Batch 410/938 Loss D: 0.3062, Loss G: 2.1020\n",
      "Epoch [61/85] Batch 420/938 Loss D: 0.2858, Loss G: 2.5760\n",
      "Epoch [61/85] Batch 430/938 Loss D: 0.2772, Loss G: 2.3818\n",
      "Epoch [61/85] Batch 440/938 Loss D: 0.3295, Loss G: 2.0591\n",
      "Epoch [61/85] Batch 450/938 Loss D: 0.2575, Loss G: 2.1508\n",
      "Epoch [61/85] Batch 460/938 Loss D: 0.2564, Loss G: 2.9642\n",
      "Epoch [61/85] Batch 470/938 Loss D: 0.2982, Loss G: 2.4173\n",
      "Epoch [61/85] Batch 480/938 Loss D: 0.2829, Loss G: 3.1259\n",
      "Epoch [61/85] Batch 490/938 Loss D: 0.2180, Loss G: 2.5492\n",
      "Epoch [61/85] Batch 500/938 Loss D: 0.3407, Loss G: 2.4314\n",
      "Epoch [61/85] Batch 510/938 Loss D: 0.3802, Loss G: 2.4306\n",
      "Epoch [61/85] Batch 520/938 Loss D: 0.4410, Loss G: 1.9044\n",
      "Epoch [61/85] Batch 530/938 Loss D: 0.2979, Loss G: 2.0247\n",
      "Epoch [61/85] Batch 540/938 Loss D: 0.2357, Loss G: 2.7126\n",
      "Epoch [61/85] Batch 550/938 Loss D: 0.3464, Loss G: 2.1222\n",
      "Epoch [61/85] Batch 560/938 Loss D: 0.2436, Loss G: 3.1565\n",
      "Epoch [61/85] Batch 570/938 Loss D: 0.2797, Loss G: 2.8116\n",
      "Epoch [61/85] Batch 580/938 Loss D: 0.2830, Loss G: 2.5218\n",
      "Epoch [61/85] Batch 590/938 Loss D: 0.2859, Loss G: 2.1236\n",
      "Epoch [61/85] Batch 600/938 Loss D: 0.4272, Loss G: 2.0172\n",
      "Epoch [61/85] Batch 610/938 Loss D: 0.2384, Loss G: 2.7129\n",
      "Epoch [61/85] Batch 620/938 Loss D: 0.3344, Loss G: 2.7300\n",
      "Epoch [61/85] Batch 630/938 Loss D: 0.2330, Loss G: 2.5780\n",
      "Epoch [61/85] Batch 640/938 Loss D: 0.2819, Loss G: 2.6807\n",
      "Epoch [61/85] Batch 650/938 Loss D: 0.3422, Loss G: 2.3401\n",
      "Epoch [61/85] Batch 660/938 Loss D: 0.2649, Loss G: 2.9100\n",
      "Epoch [61/85] Batch 670/938 Loss D: 0.1619, Loss G: 3.2864\n",
      "Epoch [61/85] Batch 680/938 Loss D: 0.2246, Loss G: 2.5825\n",
      "Epoch [61/85] Batch 690/938 Loss D: 0.3012, Loss G: 2.2888\n",
      "Epoch [61/85] Batch 700/938 Loss D: 0.2961, Loss G: 2.5898\n",
      "Epoch [61/85] Batch 710/938 Loss D: 0.3304, Loss G: 3.4080\n",
      "Epoch [61/85] Batch 720/938 Loss D: 0.2978, Loss G: 2.2452\n",
      "Epoch [61/85] Batch 730/938 Loss D: 0.2037, Loss G: 2.9440\n",
      "Epoch [61/85] Batch 740/938 Loss D: 0.2399, Loss G: 2.9362\n",
      "Epoch [61/85] Batch 750/938 Loss D: 0.1588, Loss G: 3.4388\n",
      "Epoch [61/85] Batch 760/938 Loss D: 0.2008, Loss G: 3.2155\n",
      "Epoch [61/85] Batch 770/938 Loss D: 0.2512, Loss G: 2.6373\n",
      "Epoch [61/85] Batch 780/938 Loss D: 0.3078, Loss G: 1.8676\n",
      "Epoch [61/85] Batch 790/938 Loss D: 0.2723, Loss G: 2.1765\n",
      "Epoch [61/85] Batch 800/938 Loss D: 0.2265, Loss G: 3.0400\n",
      "Epoch [61/85] Batch 810/938 Loss D: 0.2998, Loss G: 2.3552\n",
      "Epoch [61/85] Batch 820/938 Loss D: 0.2467, Loss G: 2.2610\n",
      "Epoch [61/85] Batch 830/938 Loss D: 0.3560, Loss G: 2.0806\n",
      "Epoch [61/85] Batch 840/938 Loss D: 0.2816, Loss G: 2.6985\n",
      "Epoch [61/85] Batch 850/938 Loss D: 0.3274, Loss G: 2.5132\n",
      "Epoch [61/85] Batch 860/938 Loss D: 0.3005, Loss G: 2.6691\n",
      "Epoch [61/85] Batch 870/938 Loss D: 0.2413, Loss G: 2.7470\n",
      "Epoch [61/85] Batch 880/938 Loss D: 0.2853, Loss G: 1.9790\n",
      "Epoch [61/85] Batch 890/938 Loss D: 0.2747, Loss G: 2.4299\n",
      "Epoch [61/85] Batch 900/938 Loss D: 0.3832, Loss G: 2.3125\n",
      "Epoch [61/85] Batch 910/938 Loss D: 0.3059, Loss G: 2.4255\n",
      "Epoch [61/85] Batch 920/938 Loss D: 0.2181, Loss G: 2.5442\n",
      "Epoch [61/85] Batch 930/938 Loss D: 0.3470, Loss G: 2.6336\n",
      "Epoch [62/85] Batch 0/938 Loss D: 0.4461, Loss G: 1.5819\n",
      "Epoch [62/85] Batch 10/938 Loss D: 0.2624, Loss G: 2.0624\n",
      "Epoch [62/85] Batch 20/938 Loss D: 0.2974, Loss G: 2.0227\n",
      "Epoch [62/85] Batch 30/938 Loss D: 0.4111, Loss G: 2.1371\n",
      "Epoch [62/85] Batch 40/938 Loss D: 0.3390, Loss G: 2.0989\n",
      "Epoch [62/85] Batch 50/938 Loss D: 0.3230, Loss G: 2.4841\n",
      "Epoch [62/85] Batch 60/938 Loss D: 0.2664, Loss G: 2.3249\n",
      "Epoch [62/85] Batch 70/938 Loss D: 0.2068, Loss G: 2.9911\n",
      "Epoch [62/85] Batch 80/938 Loss D: 0.3725, Loss G: 1.9108\n",
      "Epoch [62/85] Batch 90/938 Loss D: 0.2286, Loss G: 2.0533\n",
      "Epoch [62/85] Batch 100/938 Loss D: 0.3358, Loss G: 1.6566\n",
      "Epoch [62/85] Batch 110/938 Loss D: 0.2931, Loss G: 2.2480\n",
      "Epoch [62/85] Batch 120/938 Loss D: 0.2746, Loss G: 2.7960\n",
      "Epoch [62/85] Batch 130/938 Loss D: 0.3452, Loss G: 2.2292\n",
      "Epoch [62/85] Batch 140/938 Loss D: 0.3116, Loss G: 2.5466\n",
      "Epoch [62/85] Batch 150/938 Loss D: 0.2771, Loss G: 2.1981\n",
      "Epoch [62/85] Batch 160/938 Loss D: 0.2560, Loss G: 2.5380\n",
      "Epoch [62/85] Batch 170/938 Loss D: 0.2579, Loss G: 2.9203\n",
      "Epoch [62/85] Batch 180/938 Loss D: 0.2829, Loss G: 2.9000\n",
      "Epoch [62/85] Batch 190/938 Loss D: 0.2264, Loss G: 2.8076\n",
      "Epoch [62/85] Batch 200/938 Loss D: 0.2411, Loss G: 2.6328\n",
      "Epoch [62/85] Batch 210/938 Loss D: 0.3455, Loss G: 2.4113\n",
      "Epoch [62/85] Batch 220/938 Loss D: 0.4219, Loss G: 2.2304\n",
      "Epoch [62/85] Batch 230/938 Loss D: 0.3314, Loss G: 2.1854\n",
      "Epoch [62/85] Batch 240/938 Loss D: 0.2629, Loss G: 3.0847\n",
      "Epoch [62/85] Batch 250/938 Loss D: 0.2368, Loss G: 2.7095\n",
      "Epoch [62/85] Batch 260/938 Loss D: 0.2719, Loss G: 2.9507\n",
      "Epoch [62/85] Batch 270/938 Loss D: 0.2687, Loss G: 1.9776\n",
      "Epoch [62/85] Batch 280/938 Loss D: 0.2800, Loss G: 2.3788\n",
      "Epoch [62/85] Batch 290/938 Loss D: 0.3128, Loss G: 2.3589\n",
      "Epoch [62/85] Batch 300/938 Loss D: 0.2652, Loss G: 2.1825\n",
      "Epoch [62/85] Batch 310/938 Loss D: 0.3086, Loss G: 2.4902\n",
      "Epoch [62/85] Batch 320/938 Loss D: 0.3992, Loss G: 2.6898\n",
      "Epoch [62/85] Batch 330/938 Loss D: 0.3299, Loss G: 1.8260\n",
      "Epoch [62/85] Batch 340/938 Loss D: 0.2464, Loss G: 2.4060\n",
      "Epoch [62/85] Batch 350/938 Loss D: 0.2467, Loss G: 2.7745\n",
      "Epoch [62/85] Batch 360/938 Loss D: 0.2712, Loss G: 2.5479\n",
      "Epoch [62/85] Batch 370/938 Loss D: 0.3380, Loss G: 2.5148\n",
      "Epoch [62/85] Batch 380/938 Loss D: 0.3559, Loss G: 2.5513\n",
      "Epoch [62/85] Batch 390/938 Loss D: 0.4840, Loss G: 1.9932\n",
      "Epoch [62/85] Batch 400/938 Loss D: 0.2073, Loss G: 3.4240\n",
      "Epoch [62/85] Batch 410/938 Loss D: 0.3255, Loss G: 2.0866\n",
      "Epoch [62/85] Batch 420/938 Loss D: 0.3046, Loss G: 2.4286\n",
      "Epoch [62/85] Batch 430/938 Loss D: 0.3151, Loss G: 2.2898\n",
      "Epoch [62/85] Batch 440/938 Loss D: 0.3311, Loss G: 2.4674\n",
      "Epoch [62/85] Batch 450/938 Loss D: 0.2476, Loss G: 2.2670\n",
      "Epoch [62/85] Batch 460/938 Loss D: 0.4237, Loss G: 2.1135\n",
      "Epoch [62/85] Batch 470/938 Loss D: 0.5230, Loss G: 2.2656\n",
      "Epoch [62/85] Batch 480/938 Loss D: 0.3530, Loss G: 2.0565\n",
      "Epoch [62/85] Batch 490/938 Loss D: 0.3052, Loss G: 2.3764\n",
      "Epoch [62/85] Batch 500/938 Loss D: 0.2690, Loss G: 2.3783\n",
      "Epoch [62/85] Batch 510/938 Loss D: 0.2727, Loss G: 2.5800\n",
      "Epoch [62/85] Batch 520/938 Loss D: 0.2903, Loss G: 2.1931\n",
      "Epoch [62/85] Batch 530/938 Loss D: 0.2662, Loss G: 2.3608\n",
      "Epoch [62/85] Batch 540/938 Loss D: 0.3330, Loss G: 2.4153\n",
      "Epoch [62/85] Batch 550/938 Loss D: 0.2596, Loss G: 2.6551\n",
      "Epoch [62/85] Batch 560/938 Loss D: 0.3098, Loss G: 2.4892\n",
      "Epoch [62/85] Batch 570/938 Loss D: 0.2633, Loss G: 2.3122\n",
      "Epoch [62/85] Batch 580/938 Loss D: 0.3023, Loss G: 2.3318\n",
      "Epoch [62/85] Batch 590/938 Loss D: 0.3232, Loss G: 2.4413\n",
      "Epoch [62/85] Batch 600/938 Loss D: 0.2382, Loss G: 2.7350\n",
      "Epoch [62/85] Batch 610/938 Loss D: 0.3090, Loss G: 1.8495\n",
      "Epoch [62/85] Batch 620/938 Loss D: 0.3378, Loss G: 1.6734\n",
      "Epoch [62/85] Batch 630/938 Loss D: 0.3195, Loss G: 1.6028\n",
      "Epoch [62/85] Batch 640/938 Loss D: 0.1908, Loss G: 3.1424\n",
      "Epoch [62/85] Batch 650/938 Loss D: 0.2950, Loss G: 2.2446\n",
      "Epoch [62/85] Batch 660/938 Loss D: 0.2744, Loss G: 2.0119\n",
      "Epoch [62/85] Batch 670/938 Loss D: 0.3085, Loss G: 2.2761\n",
      "Epoch [62/85] Batch 680/938 Loss D: 0.1966, Loss G: 3.0588\n",
      "Epoch [62/85] Batch 690/938 Loss D: 0.2970, Loss G: 2.6748\n",
      "Epoch [62/85] Batch 700/938 Loss D: 0.2518, Loss G: 2.3172\n",
      "Epoch [62/85] Batch 710/938 Loss D: 0.3409, Loss G: 2.0585\n",
      "Epoch [62/85] Batch 720/938 Loss D: 0.4842, Loss G: 1.8277\n",
      "Epoch [62/85] Batch 730/938 Loss D: 0.3020, Loss G: 2.2008\n",
      "Epoch [62/85] Batch 740/938 Loss D: 0.3126, Loss G: 2.5973\n",
      "Epoch [62/85] Batch 750/938 Loss D: 0.3146, Loss G: 1.8815\n",
      "Epoch [62/85] Batch 760/938 Loss D: 0.3707, Loss G: 1.7429\n",
      "Epoch [62/85] Batch 770/938 Loss D: 0.3420, Loss G: 2.6684\n",
      "Epoch [62/85] Batch 780/938 Loss D: 0.3571, Loss G: 3.0511\n",
      "Epoch [62/85] Batch 790/938 Loss D: 0.2788, Loss G: 2.3491\n",
      "Epoch [62/85] Batch 800/938 Loss D: 0.2937, Loss G: 2.8985\n",
      "Epoch [62/85] Batch 810/938 Loss D: 0.2446, Loss G: 2.5367\n",
      "Epoch [62/85] Batch 820/938 Loss D: 0.3602, Loss G: 1.6245\n",
      "Epoch [62/85] Batch 830/938 Loss D: 0.2842, Loss G: 2.7446\n",
      "Epoch [62/85] Batch 840/938 Loss D: 0.1840, Loss G: 3.6005\n",
      "Epoch [62/85] Batch 850/938 Loss D: 0.3903, Loss G: 2.3987\n",
      "Epoch [62/85] Batch 860/938 Loss D: 0.2565, Loss G: 2.4191\n",
      "Epoch [62/85] Batch 870/938 Loss D: 0.2513, Loss G: 2.4242\n",
      "Epoch [62/85] Batch 880/938 Loss D: 0.3768, Loss G: 2.0427\n",
      "Epoch [62/85] Batch 890/938 Loss D: 0.2736, Loss G: 2.5784\n",
      "Epoch [62/85] Batch 900/938 Loss D: 0.1733, Loss G: 3.1811\n",
      "Epoch [62/85] Batch 910/938 Loss D: 0.4476, Loss G: 1.9330\n",
      "Epoch [62/85] Batch 920/938 Loss D: 0.3204, Loss G: 2.0179\n",
      "Epoch [62/85] Batch 930/938 Loss D: 0.2499, Loss G: 1.7283\n",
      "Epoch [63/85] Batch 0/938 Loss D: 0.2987, Loss G: 2.3043\n",
      "Epoch [63/85] Batch 10/938 Loss D: 0.1996, Loss G: 2.8893\n",
      "Epoch [63/85] Batch 20/938 Loss D: 0.3885, Loss G: 2.5972\n",
      "Epoch [63/85] Batch 30/938 Loss D: 0.2042, Loss G: 3.0101\n",
      "Epoch [63/85] Batch 40/938 Loss D: 0.3094, Loss G: 2.3490\n",
      "Epoch [63/85] Batch 50/938 Loss D: 0.2727, Loss G: 1.7039\n",
      "Epoch [63/85] Batch 60/938 Loss D: 0.3099, Loss G: 2.5439\n",
      "Epoch [63/85] Batch 70/938 Loss D: 0.2107, Loss G: 3.0521\n",
      "Epoch [63/85] Batch 80/938 Loss D: 0.2688, Loss G: 2.2890\n",
      "Epoch [63/85] Batch 90/938 Loss D: 0.2320, Loss G: 2.9539\n",
      "Epoch [63/85] Batch 100/938 Loss D: 0.2340, Loss G: 3.0744\n",
      "Epoch [63/85] Batch 110/938 Loss D: 0.3753, Loss G: 2.0123\n",
      "Epoch [63/85] Batch 120/938 Loss D: 0.3294, Loss G: 2.8240\n",
      "Epoch [63/85] Batch 130/938 Loss D: 0.3361, Loss G: 2.2538\n",
      "Epoch [63/85] Batch 140/938 Loss D: 0.3324, Loss G: 2.6723\n",
      "Epoch [63/85] Batch 150/938 Loss D: 0.2902, Loss G: 2.1862\n",
      "Epoch [63/85] Batch 160/938 Loss D: 0.3196, Loss G: 2.5280\n",
      "Epoch [63/85] Batch 170/938 Loss D: 0.3339, Loss G: 2.0267\n",
      "Epoch [63/85] Batch 180/938 Loss D: 0.2540, Loss G: 2.0918\n",
      "Epoch [63/85] Batch 190/938 Loss D: 0.3173, Loss G: 1.8972\n",
      "Epoch [63/85] Batch 200/938 Loss D: 0.2704, Loss G: 2.1990\n",
      "Epoch [63/85] Batch 210/938 Loss D: 0.2145, Loss G: 2.5510\n",
      "Epoch [63/85] Batch 220/938 Loss D: 0.3440, Loss G: 4.4487\n",
      "Epoch [63/85] Batch 230/938 Loss D: 0.2707, Loss G: 3.7907\n",
      "Epoch [63/85] Batch 240/938 Loss D: 0.3229, Loss G: 2.5612\n",
      "Epoch [63/85] Batch 250/938 Loss D: 0.2561, Loss G: 2.5543\n",
      "Epoch [63/85] Batch 260/938 Loss D: 0.2088, Loss G: 2.7918\n",
      "Epoch [63/85] Batch 270/938 Loss D: 0.3812, Loss G: 2.1594\n",
      "Epoch [63/85] Batch 280/938 Loss D: 0.2079, Loss G: 2.7068\n",
      "Epoch [63/85] Batch 290/938 Loss D: 0.2408, Loss G: 2.8017\n",
      "Epoch [63/85] Batch 300/938 Loss D: 0.3667, Loss G: 2.6341\n",
      "Epoch [63/85] Batch 310/938 Loss D: 0.2894, Loss G: 2.4535\n",
      "Epoch [63/85] Batch 320/938 Loss D: 0.3327, Loss G: 1.9821\n",
      "Epoch [63/85] Batch 330/938 Loss D: 0.3789, Loss G: 1.9309\n",
      "Epoch [63/85] Batch 340/938 Loss D: 0.3108, Loss G: 2.6196\n",
      "Epoch [63/85] Batch 350/938 Loss D: 0.2689, Loss G: 2.4158\n",
      "Epoch [63/85] Batch 360/938 Loss D: 0.3223, Loss G: 2.0455\n",
      "Epoch [63/85] Batch 370/938 Loss D: 0.3091, Loss G: 1.6660\n",
      "Epoch [63/85] Batch 380/938 Loss D: 0.3789, Loss G: 1.4431\n",
      "Epoch [63/85] Batch 390/938 Loss D: 0.2341, Loss G: 2.5713\n",
      "Epoch [63/85] Batch 400/938 Loss D: 0.2219, Loss G: 2.7242\n",
      "Epoch [63/85] Batch 410/938 Loss D: 0.3127, Loss G: 2.5030\n",
      "Epoch [63/85] Batch 420/938 Loss D: 0.3177, Loss G: 2.1314\n",
      "Epoch [63/85] Batch 430/938 Loss D: 0.3086, Loss G: 2.2935\n",
      "Epoch [63/85] Batch 440/938 Loss D: 0.2172, Loss G: 2.8792\n",
      "Epoch [63/85] Batch 450/938 Loss D: 0.2553, Loss G: 2.1048\n",
      "Epoch [63/85] Batch 460/938 Loss D: 0.4183, Loss G: 1.9850\n",
      "Epoch [63/85] Batch 470/938 Loss D: 0.3396, Loss G: 2.7055\n",
      "Epoch [63/85] Batch 480/938 Loss D: 0.3390, Loss G: 2.6571\n",
      "Epoch [63/85] Batch 490/938 Loss D: 0.4983, Loss G: 1.7489\n",
      "Epoch [63/85] Batch 500/938 Loss D: 0.3222, Loss G: 2.6603\n",
      "Epoch [63/85] Batch 510/938 Loss D: 0.2966, Loss G: 2.7463\n",
      "Epoch [63/85] Batch 520/938 Loss D: 0.3849, Loss G: 2.1063\n",
      "Epoch [63/85] Batch 530/938 Loss D: 0.3683, Loss G: 2.0157\n",
      "Epoch [63/85] Batch 540/938 Loss D: 0.4342, Loss G: 2.1102\n",
      "Epoch [63/85] Batch 550/938 Loss D: 0.2941, Loss G: 2.9115\n",
      "Epoch [63/85] Batch 560/938 Loss D: 0.3170, Loss G: 2.7930\n",
      "Epoch [63/85] Batch 570/938 Loss D: 0.3547, Loss G: 1.8236\n",
      "Epoch [63/85] Batch 580/938 Loss D: 0.1739, Loss G: 3.0614\n",
      "Epoch [63/85] Batch 590/938 Loss D: 0.2315, Loss G: 2.5326\n",
      "Epoch [63/85] Batch 600/938 Loss D: 0.2613, Loss G: 2.5910\n",
      "Epoch [63/85] Batch 610/938 Loss D: 0.2359, Loss G: 2.2899\n",
      "Epoch [63/85] Batch 620/938 Loss D: 0.2669, Loss G: 1.8724\n",
      "Epoch [63/85] Batch 630/938 Loss D: 0.2431, Loss G: 1.9811\n",
      "Epoch [63/85] Batch 640/938 Loss D: 0.2729, Loss G: 1.9484\n",
      "Epoch [63/85] Batch 650/938 Loss D: 0.2782, Loss G: 2.5498\n",
      "Epoch [63/85] Batch 660/938 Loss D: 0.3567, Loss G: 3.0207\n",
      "Epoch [63/85] Batch 670/938 Loss D: 0.2744, Loss G: 2.9325\n",
      "Epoch [63/85] Batch 680/938 Loss D: 0.2766, Loss G: 2.4217\n",
      "Epoch [63/85] Batch 690/938 Loss D: 0.4436, Loss G: 1.7810\n",
      "Epoch [63/85] Batch 700/938 Loss D: 0.4482, Loss G: 1.2432\n",
      "Epoch [63/85] Batch 710/938 Loss D: 0.3232, Loss G: 1.9230\n",
      "Epoch [63/85] Batch 720/938 Loss D: 0.3655, Loss G: 2.1352\n",
      "Epoch [63/85] Batch 730/938 Loss D: 0.3526, Loss G: 1.9807\n",
      "Epoch [63/85] Batch 740/938 Loss D: 0.2714, Loss G: 1.9745\n",
      "Epoch [63/85] Batch 750/938 Loss D: 0.2425, Loss G: 2.0139\n",
      "Epoch [63/85] Batch 760/938 Loss D: 0.3888, Loss G: 2.0826\n",
      "Epoch [63/85] Batch 770/938 Loss D: 0.2271, Loss G: 2.3536\n",
      "Epoch [63/85] Batch 780/938 Loss D: 0.2673, Loss G: 2.3173\n",
      "Epoch [63/85] Batch 790/938 Loss D: 0.2132, Loss G: 2.7688\n",
      "Epoch [63/85] Batch 800/938 Loss D: 0.4590, Loss G: 2.4087\n",
      "Epoch [63/85] Batch 810/938 Loss D: 0.3070, Loss G: 2.6301\n",
      "Epoch [63/85] Batch 820/938 Loss D: 0.4222, Loss G: 1.7276\n",
      "Epoch [63/85] Batch 830/938 Loss D: 0.3035, Loss G: 1.9240\n",
      "Epoch [63/85] Batch 840/938 Loss D: 0.3670, Loss G: 2.0726\n",
      "Epoch [63/85] Batch 850/938 Loss D: 0.3536, Loss G: 3.2279\n",
      "Epoch [63/85] Batch 860/938 Loss D: 0.3317, Loss G: 2.4013\n",
      "Epoch [63/85] Batch 870/938 Loss D: 0.3194, Loss G: 1.6337\n",
      "Epoch [63/85] Batch 880/938 Loss D: 0.3501, Loss G: 2.2845\n",
      "Epoch [63/85] Batch 890/938 Loss D: 0.2914, Loss G: 2.7391\n",
      "Epoch [63/85] Batch 900/938 Loss D: 0.2478, Loss G: 2.3288\n",
      "Epoch [63/85] Batch 910/938 Loss D: 0.2581, Loss G: 2.4408\n",
      "Epoch [63/85] Batch 920/938 Loss D: 0.2368, Loss G: 2.2901\n",
      "Epoch [63/85] Batch 930/938 Loss D: 0.3074, Loss G: 2.1274\n",
      "Epoch [64/85] Batch 0/938 Loss D: 0.3976, Loss G: 2.1174\n",
      "Epoch [64/85] Batch 10/938 Loss D: 0.2568, Loss G: 2.6198\n",
      "Epoch [64/85] Batch 20/938 Loss D: 0.3428, Loss G: 2.4047\n",
      "Epoch [64/85] Batch 30/938 Loss D: 0.2453, Loss G: 2.5564\n",
      "Epoch [64/85] Batch 40/938 Loss D: 0.2853, Loss G: 2.5281\n",
      "Epoch [64/85] Batch 50/938 Loss D: 0.1848, Loss G: 2.7061\n",
      "Epoch [64/85] Batch 60/938 Loss D: 0.1352, Loss G: 3.6700\n",
      "Epoch [64/85] Batch 70/938 Loss D: 0.1728, Loss G: 3.3366\n",
      "Epoch [64/85] Batch 80/938 Loss D: 0.3055, Loss G: 3.4538\n",
      "Epoch [64/85] Batch 90/938 Loss D: 0.2782, Loss G: 4.3600\n",
      "Epoch [64/85] Batch 100/938 Loss D: 0.1821, Loss G: 3.2830\n",
      "Epoch [64/85] Batch 110/938 Loss D: 0.2598, Loss G: 2.4266\n",
      "Epoch [64/85] Batch 120/938 Loss D: 0.4020, Loss G: 1.9639\n",
      "Epoch [64/85] Batch 130/938 Loss D: 0.2983, Loss G: 2.7467\n",
      "Epoch [64/85] Batch 140/938 Loss D: 0.2357, Loss G: 2.1141\n",
      "Epoch [64/85] Batch 150/938 Loss D: 0.2741, Loss G: 2.2362\n",
      "Epoch [64/85] Batch 160/938 Loss D: 0.3230, Loss G: 1.9970\n",
      "Epoch [64/85] Batch 170/938 Loss D: 0.2752, Loss G: 2.3171\n",
      "Epoch [64/85] Batch 180/938 Loss D: 0.2877, Loss G: 2.7445\n",
      "Epoch [64/85] Batch 190/938 Loss D: 0.1893, Loss G: 3.0214\n",
      "Epoch [64/85] Batch 200/938 Loss D: 0.2730, Loss G: 2.6966\n",
      "Epoch [64/85] Batch 210/938 Loss D: 0.2512, Loss G: 2.4338\n",
      "Epoch [64/85] Batch 220/938 Loss D: 0.3498, Loss G: 2.2568\n",
      "Epoch [64/85] Batch 230/938 Loss D: 0.2709, Loss G: 2.5696\n",
      "Epoch [64/85] Batch 240/938 Loss D: 0.2376, Loss G: 2.5130\n",
      "Epoch [64/85] Batch 250/938 Loss D: 0.4549, Loss G: 2.3227\n",
      "Epoch [64/85] Batch 260/938 Loss D: 0.4747, Loss G: 2.9551\n",
      "Epoch [64/85] Batch 270/938 Loss D: 0.3077, Loss G: 2.9409\n",
      "Epoch [64/85] Batch 280/938 Loss D: 0.3826, Loss G: 2.4070\n",
      "Epoch [64/85] Batch 290/938 Loss D: 0.2565, Loss G: 2.6109\n",
      "Epoch [64/85] Batch 300/938 Loss D: 0.3803, Loss G: 2.4354\n",
      "Epoch [64/85] Batch 310/938 Loss D: 0.4047, Loss G: 1.9121\n",
      "Epoch [64/85] Batch 320/938 Loss D: 0.3631, Loss G: 1.7264\n",
      "Epoch [64/85] Batch 330/938 Loss D: 0.3054, Loss G: 2.2429\n",
      "Epoch [64/85] Batch 340/938 Loss D: 0.3712, Loss G: 2.6549\n",
      "Epoch [64/85] Batch 350/938 Loss D: 0.3826, Loss G: 1.9508\n",
      "Epoch [64/85] Batch 360/938 Loss D: 0.3715, Loss G: 2.7782\n",
      "Epoch [64/85] Batch 370/938 Loss D: 0.3106, Loss G: 2.5403\n",
      "Epoch [64/85] Batch 380/938 Loss D: 0.2422, Loss G: 3.1160\n",
      "Epoch [64/85] Batch 390/938 Loss D: 0.2155, Loss G: 2.4167\n",
      "Epoch [64/85] Batch 400/938 Loss D: 0.2964, Loss G: 2.3011\n",
      "Epoch [64/85] Batch 410/938 Loss D: 0.4443, Loss G: 1.7823\n",
      "Epoch [64/85] Batch 420/938 Loss D: 0.2306, Loss G: 2.6651\n",
      "Epoch [64/85] Batch 430/938 Loss D: 0.2985, Loss G: 2.0880\n",
      "Epoch [64/85] Batch 440/938 Loss D: 0.3298, Loss G: 2.0336\n",
      "Epoch [64/85] Batch 450/938 Loss D: 0.2632, Loss G: 2.6904\n",
      "Epoch [64/85] Batch 460/938 Loss D: 0.2044, Loss G: 3.0400\n",
      "Epoch [64/85] Batch 470/938 Loss D: 0.3774, Loss G: 2.0641\n",
      "Epoch [64/85] Batch 480/938 Loss D: 0.3299, Loss G: 2.7290\n",
      "Epoch [64/85] Batch 490/938 Loss D: 0.3825, Loss G: 2.4783\n",
      "Epoch [64/85] Batch 500/938 Loss D: 0.2504, Loss G: 2.6796\n",
      "Epoch [64/85] Batch 510/938 Loss D: 0.1965, Loss G: 2.4279\n",
      "Epoch [64/85] Batch 520/938 Loss D: 0.1411, Loss G: 3.1307\n",
      "Epoch [64/85] Batch 530/938 Loss D: 0.2832, Loss G: 3.6684\n",
      "Epoch [64/85] Batch 540/938 Loss D: 0.2377, Loss G: 3.1058\n",
      "Epoch [64/85] Batch 550/938 Loss D: 0.2689, Loss G: 2.6968\n",
      "Epoch [64/85] Batch 560/938 Loss D: 0.2333, Loss G: 2.4382\n",
      "Epoch [64/85] Batch 570/938 Loss D: 0.1709, Loss G: 2.8668\n",
      "Epoch [64/85] Batch 580/938 Loss D: 0.1471, Loss G: 2.9652\n",
      "Epoch [64/85] Batch 590/938 Loss D: 0.2978, Loss G: 2.1555\n",
      "Epoch [64/85] Batch 600/938 Loss D: 0.3893, Loss G: 1.7141\n",
      "Epoch [64/85] Batch 610/938 Loss D: 0.3082, Loss G: 2.2613\n",
      "Epoch [64/85] Batch 620/938 Loss D: 0.2360, Loss G: 2.5045\n",
      "Epoch [64/85] Batch 630/938 Loss D: 0.4134, Loss G: 2.5453\n",
      "Epoch [64/85] Batch 640/938 Loss D: 0.3508, Loss G: 2.2932\n",
      "Epoch [64/85] Batch 650/938 Loss D: 0.3281, Loss G: 2.4880\n",
      "Epoch [64/85] Batch 660/938 Loss D: 0.3817, Loss G: 2.0767\n",
      "Epoch [64/85] Batch 670/938 Loss D: 0.2302, Loss G: 3.3565\n",
      "Epoch [64/85] Batch 680/938 Loss D: 0.2389, Loss G: 2.5702\n",
      "Epoch [64/85] Batch 690/938 Loss D: 0.3925, Loss G: 1.3836\n",
      "Epoch [64/85] Batch 700/938 Loss D: 0.2601, Loss G: 2.4972\n",
      "Epoch [64/85] Batch 710/938 Loss D: 0.1811, Loss G: 2.8885\n",
      "Epoch [64/85] Batch 720/938 Loss D: 0.2718, Loss G: 2.5793\n",
      "Epoch [64/85] Batch 730/938 Loss D: 0.3639, Loss G: 2.6098\n",
      "Epoch [64/85] Batch 740/938 Loss D: 0.2837, Loss G: 2.4009\n",
      "Epoch [64/85] Batch 750/938 Loss D: 0.1866, Loss G: 2.7132\n",
      "Epoch [64/85] Batch 760/938 Loss D: 0.2548, Loss G: 2.2584\n",
      "Epoch [64/85] Batch 770/938 Loss D: 0.2065, Loss G: 2.5961\n",
      "Epoch [64/85] Batch 780/938 Loss D: 0.3048, Loss G: 2.3247\n",
      "Epoch [64/85] Batch 790/938 Loss D: 0.3481, Loss G: 2.0822\n",
      "Epoch [64/85] Batch 800/938 Loss D: 0.2942, Loss G: 2.9067\n",
      "Epoch [64/85] Batch 810/938 Loss D: 0.1950, Loss G: 3.3129\n",
      "Epoch [64/85] Batch 820/938 Loss D: 0.2982, Loss G: 2.0558\n",
      "Epoch [64/85] Batch 830/938 Loss D: 0.3551, Loss G: 2.4820\n",
      "Epoch [64/85] Batch 840/938 Loss D: 0.2323, Loss G: 3.0771\n",
      "Epoch [64/85] Batch 850/938 Loss D: 0.4220, Loss G: 3.2548\n",
      "Epoch [64/85] Batch 860/938 Loss D: 0.2903, Loss G: 2.2637\n",
      "Epoch [64/85] Batch 870/938 Loss D: 0.3726, Loss G: 1.9318\n",
      "Epoch [64/85] Batch 880/938 Loss D: 0.4256, Loss G: 1.5907\n",
      "Epoch [64/85] Batch 890/938 Loss D: 0.3713, Loss G: 1.9761\n",
      "Epoch [64/85] Batch 900/938 Loss D: 0.1932, Loss G: 2.9136\n",
      "Epoch [64/85] Batch 910/938 Loss D: 0.1858, Loss G: 2.5880\n",
      "Epoch [64/85] Batch 920/938 Loss D: 0.2782, Loss G: 2.4869\n",
      "Epoch [64/85] Batch 930/938 Loss D: 0.2658, Loss G: 2.5759\n",
      "Epoch [65/85] Batch 0/938 Loss D: 0.2112, Loss G: 2.8783\n",
      "Epoch [65/85] Batch 10/938 Loss D: 0.2077, Loss G: 3.3707\n",
      "Epoch [65/85] Batch 20/938 Loss D: 0.2264, Loss G: 3.1106\n",
      "Epoch [65/85] Batch 30/938 Loss D: 0.3158, Loss G: 1.9670\n",
      "Epoch [65/85] Batch 40/938 Loss D: 0.3125, Loss G: 1.9659\n",
      "Epoch [65/85] Batch 50/938 Loss D: 0.2480, Loss G: 2.3096\n",
      "Epoch [65/85] Batch 60/938 Loss D: 0.2205, Loss G: 3.4243\n",
      "Epoch [65/85] Batch 70/938 Loss D: 0.2690, Loss G: 2.4421\n",
      "Epoch [65/85] Batch 80/938 Loss D: 0.2653, Loss G: 2.8427\n",
      "Epoch [65/85] Batch 90/938 Loss D: 0.1581, Loss G: 2.4405\n",
      "Epoch [65/85] Batch 100/938 Loss D: 0.2271, Loss G: 2.4465\n",
      "Epoch [65/85] Batch 110/938 Loss D: 0.2436, Loss G: 2.2865\n",
      "Epoch [65/85] Batch 120/938 Loss D: 0.2738, Loss G: 2.3676\n",
      "Epoch [65/85] Batch 130/938 Loss D: 0.2346, Loss G: 2.9607\n",
      "Epoch [65/85] Batch 140/938 Loss D: 0.2860, Loss G: 2.0983\n",
      "Epoch [65/85] Batch 150/938 Loss D: 0.2890, Loss G: 2.0761\n",
      "Epoch [65/85] Batch 160/938 Loss D: 0.2734, Loss G: 2.3436\n",
      "Epoch [65/85] Batch 170/938 Loss D: 0.4078, Loss G: 1.9268\n",
      "Epoch [65/85] Batch 180/938 Loss D: 0.3098, Loss G: 2.0647\n",
      "Epoch [65/85] Batch 190/938 Loss D: 0.3529, Loss G: 2.0448\n",
      "Epoch [65/85] Batch 200/938 Loss D: 0.2190, Loss G: 2.7603\n",
      "Epoch [65/85] Batch 210/938 Loss D: 0.2690, Loss G: 2.7790\n",
      "Epoch [65/85] Batch 220/938 Loss D: 0.2330, Loss G: 3.1656\n",
      "Epoch [65/85] Batch 230/938 Loss D: 0.3378, Loss G: 2.3399\n",
      "Epoch [65/85] Batch 240/938 Loss D: 0.2704, Loss G: 2.1500\n",
      "Epoch [65/85] Batch 250/938 Loss D: 0.2750, Loss G: 2.7634\n",
      "Epoch [65/85] Batch 260/938 Loss D: 0.2859, Loss G: 2.7051\n",
      "Epoch [65/85] Batch 270/938 Loss D: 0.3298, Loss G: 2.6958\n",
      "Epoch [65/85] Batch 280/938 Loss D: 0.3155, Loss G: 1.9678\n",
      "Epoch [65/85] Batch 290/938 Loss D: 0.2722, Loss G: 2.5713\n",
      "Epoch [65/85] Batch 300/938 Loss D: 0.3198, Loss G: 2.1987\n",
      "Epoch [65/85] Batch 310/938 Loss D: 0.3305, Loss G: 2.3956\n",
      "Epoch [65/85] Batch 320/938 Loss D: 0.2188, Loss G: 2.4992\n",
      "Epoch [65/85] Batch 330/938 Loss D: 0.4383, Loss G: 1.9705\n",
      "Epoch [65/85] Batch 340/938 Loss D: 0.3097, Loss G: 2.3591\n",
      "Epoch [65/85] Batch 350/938 Loss D: 0.1802, Loss G: 3.0682\n",
      "Epoch [65/85] Batch 360/938 Loss D: 0.2863, Loss G: 2.5627\n",
      "Epoch [65/85] Batch 370/938 Loss D: 0.2694, Loss G: 2.6888\n",
      "Epoch [65/85] Batch 380/938 Loss D: 0.3429, Loss G: 1.7861\n",
      "Epoch [65/85] Batch 390/938 Loss D: 0.2559, Loss G: 2.3103\n",
      "Epoch [65/85] Batch 400/938 Loss D: 0.2451, Loss G: 3.4453\n",
      "Epoch [65/85] Batch 410/938 Loss D: 0.4771, Loss G: 2.8875\n",
      "Epoch [65/85] Batch 420/938 Loss D: 0.3673, Loss G: 3.2873\n",
      "Epoch [65/85] Batch 430/938 Loss D: 0.1963, Loss G: 3.2461\n",
      "Epoch [65/85] Batch 440/938 Loss D: 0.2565, Loss G: 2.9901\n",
      "Epoch [65/85] Batch 450/938 Loss D: 0.4650, Loss G: 1.8366\n",
      "Epoch [65/85] Batch 460/938 Loss D: 0.3167, Loss G: 1.8499\n",
      "Epoch [65/85] Batch 470/938 Loss D: 0.3132, Loss G: 2.0185\n",
      "Epoch [65/85] Batch 480/938 Loss D: 0.2758, Loss G: 2.9298\n",
      "Epoch [65/85] Batch 490/938 Loss D: 0.3095, Loss G: 2.1206\n",
      "Epoch [65/85] Batch 500/938 Loss D: 0.3621, Loss G: 2.4066\n",
      "Epoch [65/85] Batch 510/938 Loss D: 0.3354, Loss G: 1.8859\n",
      "Epoch [65/85] Batch 520/938 Loss D: 0.3424, Loss G: 2.2312\n",
      "Epoch [65/85] Batch 530/938 Loss D: 0.2564, Loss G: 2.3036\n",
      "Epoch [65/85] Batch 540/938 Loss D: 0.2431, Loss G: 2.7857\n",
      "Epoch [65/85] Batch 550/938 Loss D: 0.3137, Loss G: 2.9356\n",
      "Epoch [65/85] Batch 560/938 Loss D: 0.2959, Loss G: 2.5657\n",
      "Epoch [65/85] Batch 570/938 Loss D: 0.3836, Loss G: 2.3037\n",
      "Epoch [65/85] Batch 580/938 Loss D: 0.3299, Loss G: 2.2761\n",
      "Epoch [65/85] Batch 590/938 Loss D: 0.3817, Loss G: 2.3132\n",
      "Epoch [65/85] Batch 600/938 Loss D: 0.2125, Loss G: 3.0715\n",
      "Epoch [65/85] Batch 610/938 Loss D: 0.2447, Loss G: 3.4284\n",
      "Epoch [65/85] Batch 620/938 Loss D: 0.1966, Loss G: 2.9691\n",
      "Epoch [65/85] Batch 630/938 Loss D: 0.3170, Loss G: 2.0605\n",
      "Epoch [65/85] Batch 640/938 Loss D: 0.2117, Loss G: 2.2242\n",
      "Epoch [65/85] Batch 650/938 Loss D: 0.3560, Loss G: 2.7350\n",
      "Epoch [65/85] Batch 660/938 Loss D: 0.3454, Loss G: 2.1702\n",
      "Epoch [65/85] Batch 670/938 Loss D: 0.3176, Loss G: 1.8732\n",
      "Epoch [65/85] Batch 680/938 Loss D: 0.2717, Loss G: 2.5642\n",
      "Epoch [65/85] Batch 690/938 Loss D: 0.3035, Loss G: 2.3464\n",
      "Epoch [65/85] Batch 700/938 Loss D: 0.3884, Loss G: 2.5301\n",
      "Epoch [65/85] Batch 710/938 Loss D: 0.3945, Loss G: 2.2850\n",
      "Epoch [65/85] Batch 720/938 Loss D: 0.2909, Loss G: 2.3380\n",
      "Epoch [65/85] Batch 730/938 Loss D: 0.3202, Loss G: 2.9837\n",
      "Epoch [65/85] Batch 740/938 Loss D: 0.2687, Loss G: 2.3052\n",
      "Epoch [65/85] Batch 750/938 Loss D: 0.2903, Loss G: 1.7784\n",
      "Epoch [65/85] Batch 760/938 Loss D: 0.3667, Loss G: 2.5970\n",
      "Epoch [65/85] Batch 770/938 Loss D: 0.3400, Loss G: 2.7725\n",
      "Epoch [65/85] Batch 780/938 Loss D: 0.4442, Loss G: 2.7257\n",
      "Epoch [65/85] Batch 790/938 Loss D: 0.3574, Loss G: 2.9528\n",
      "Epoch [65/85] Batch 800/938 Loss D: 0.3306, Loss G: 2.1217\n",
      "Epoch [65/85] Batch 810/938 Loss D: 0.2620, Loss G: 2.7860\n",
      "Epoch [65/85] Batch 820/938 Loss D: 0.2965, Loss G: 2.6633\n",
      "Epoch [65/85] Batch 830/938 Loss D: 0.4389, Loss G: 1.7092\n",
      "Epoch [65/85] Batch 840/938 Loss D: 0.2474, Loss G: 2.2186\n",
      "Epoch [65/85] Batch 850/938 Loss D: 0.3084, Loss G: 2.0721\n",
      "Epoch [65/85] Batch 860/938 Loss D: 0.4229, Loss G: 2.2564\n",
      "Epoch [65/85] Batch 870/938 Loss D: 0.3503, Loss G: 1.7434\n",
      "Epoch [65/85] Batch 880/938 Loss D: 0.4207, Loss G: 1.6393\n",
      "Epoch [65/85] Batch 890/938 Loss D: 0.3523, Loss G: 1.9378\n",
      "Epoch [65/85] Batch 900/938 Loss D: 0.2687, Loss G: 2.7458\n",
      "Epoch [65/85] Batch 910/938 Loss D: 0.3146, Loss G: 2.1754\n",
      "Epoch [65/85] Batch 920/938 Loss D: 0.3226, Loss G: 2.4818\n",
      "Epoch [65/85] Batch 930/938 Loss D: 0.2692, Loss G: 2.2042\n",
      "Epoch [66/85] Batch 0/938 Loss D: 0.2748, Loss G: 2.3555\n",
      "Epoch [66/85] Batch 10/938 Loss D: 0.3499, Loss G: 2.1418\n",
      "Epoch [66/85] Batch 20/938 Loss D: 0.1355, Loss G: 4.3149\n",
      "Epoch [66/85] Batch 30/938 Loss D: 0.2439, Loss G: 2.7715\n",
      "Epoch [66/85] Batch 40/938 Loss D: 0.2568, Loss G: 2.2242\n",
      "Epoch [66/85] Batch 50/938 Loss D: 0.3447, Loss G: 1.9371\n",
      "Epoch [66/85] Batch 60/938 Loss D: 0.2370, Loss G: 2.4269\n",
      "Epoch [66/85] Batch 70/938 Loss D: 0.3714, Loss G: 2.0810\n",
      "Epoch [66/85] Batch 80/938 Loss D: 0.2328, Loss G: 2.9285\n",
      "Epoch [66/85] Batch 90/938 Loss D: 0.2457, Loss G: 3.0293\n",
      "Epoch [66/85] Batch 100/938 Loss D: 0.2710, Loss G: 2.5221\n",
      "Epoch [66/85] Batch 110/938 Loss D: 0.3622, Loss G: 2.4889\n",
      "Epoch [66/85] Batch 120/938 Loss D: 0.2555, Loss G: 2.6133\n",
      "Epoch [66/85] Batch 130/938 Loss D: 0.4975, Loss G: 2.3698\n",
      "Epoch [66/85] Batch 140/938 Loss D: 0.3124, Loss G: 2.2160\n",
      "Epoch [66/85] Batch 150/938 Loss D: 0.3265, Loss G: 2.4390\n",
      "Epoch [66/85] Batch 160/938 Loss D: 0.2573, Loss G: 2.5526\n",
      "Epoch [66/85] Batch 170/938 Loss D: 0.2721, Loss G: 2.3902\n",
      "Epoch [66/85] Batch 180/938 Loss D: 0.3240, Loss G: 2.2930\n",
      "Epoch [66/85] Batch 190/938 Loss D: 0.2617, Loss G: 1.8935\n",
      "Epoch [66/85] Batch 200/938 Loss D: 0.5373, Loss G: 1.9611\n",
      "Epoch [66/85] Batch 210/938 Loss D: 0.1422, Loss G: 2.5437\n",
      "Epoch [66/85] Batch 220/938 Loss D: 0.2587, Loss G: 2.7826\n",
      "Epoch [66/85] Batch 230/938 Loss D: 0.2472, Loss G: 2.9068\n",
      "Epoch [66/85] Batch 240/938 Loss D: 0.5234, Loss G: 1.9662\n",
      "Epoch [66/85] Batch 250/938 Loss D: 0.2881, Loss G: 2.1840\n",
      "Epoch [66/85] Batch 260/938 Loss D: 0.3425, Loss G: 2.3256\n",
      "Epoch [66/85] Batch 270/938 Loss D: 0.2694, Loss G: 2.7026\n",
      "Epoch [66/85] Batch 280/938 Loss D: 0.2931, Loss G: 2.2555\n",
      "Epoch [66/85] Batch 290/938 Loss D: 0.1924, Loss G: 2.6001\n",
      "Epoch [66/85] Batch 300/938 Loss D: 0.3286, Loss G: 2.3612\n",
      "Epoch [66/85] Batch 310/938 Loss D: 0.3767, Loss G: 3.0607\n",
      "Epoch [66/85] Batch 320/938 Loss D: 0.2043, Loss G: 2.4616\n",
      "Epoch [66/85] Batch 330/938 Loss D: 0.2244, Loss G: 2.7379\n",
      "Epoch [66/85] Batch 340/938 Loss D: 0.1328, Loss G: 3.2380\n",
      "Epoch [66/85] Batch 350/938 Loss D: 0.1961, Loss G: 3.4481\n",
      "Epoch [66/85] Batch 360/938 Loss D: 0.3264, Loss G: 2.8610\n",
      "Epoch [66/85] Batch 370/938 Loss D: 0.3117, Loss G: 2.5726\n",
      "Epoch [66/85] Batch 380/938 Loss D: 0.4048, Loss G: 2.3746\n",
      "Epoch [66/85] Batch 390/938 Loss D: 0.2801, Loss G: 2.1884\n",
      "Epoch [66/85] Batch 400/938 Loss D: 0.2198, Loss G: 2.8037\n",
      "Epoch [66/85] Batch 410/938 Loss D: 0.4419, Loss G: 1.5624\n",
      "Epoch [66/85] Batch 420/938 Loss D: 0.2774, Loss G: 2.3852\n",
      "Epoch [66/85] Batch 430/938 Loss D: 0.4349, Loss G: 1.8062\n",
      "Epoch [66/85] Batch 440/938 Loss D: 0.4754, Loss G: 1.5368\n",
      "Epoch [66/85] Batch 450/938 Loss D: 0.2336, Loss G: 2.6225\n",
      "Epoch [66/85] Batch 460/938 Loss D: 0.2891, Loss G: 2.1714\n",
      "Epoch [66/85] Batch 470/938 Loss D: 0.2907, Loss G: 2.5938\n",
      "Epoch [66/85] Batch 480/938 Loss D: 0.2890, Loss G: 2.6350\n",
      "Epoch [66/85] Batch 490/938 Loss D: 0.2969, Loss G: 2.7513\n",
      "Epoch [66/85] Batch 500/938 Loss D: 0.3073, Loss G: 2.2391\n",
      "Epoch [66/85] Batch 510/938 Loss D: 0.3155, Loss G: 2.1546\n",
      "Epoch [66/85] Batch 520/938 Loss D: 0.3669, Loss G: 2.2796\n",
      "Epoch [66/85] Batch 530/938 Loss D: 0.3492, Loss G: 2.0404\n",
      "Epoch [66/85] Batch 540/938 Loss D: 0.4116, Loss G: 2.5190\n",
      "Epoch [66/85] Batch 550/938 Loss D: 0.2228, Loss G: 2.2501\n",
      "Epoch [66/85] Batch 560/938 Loss D: 0.3283, Loss G: 2.1263\n",
      "Epoch [66/85] Batch 570/938 Loss D: 0.3288, Loss G: 2.2751\n",
      "Epoch [66/85] Batch 580/938 Loss D: 0.2996, Loss G: 3.1743\n",
      "Epoch [66/85] Batch 590/938 Loss D: 0.3536, Loss G: 3.9745\n",
      "Epoch [66/85] Batch 600/938 Loss D: 0.1979, Loss G: 3.4261\n",
      "Epoch [66/85] Batch 610/938 Loss D: 0.2711, Loss G: 2.5152\n",
      "Epoch [66/85] Batch 620/938 Loss D: 0.3946, Loss G: 1.8610\n",
      "Epoch [66/85] Batch 630/938 Loss D: 0.2848, Loss G: 2.4789\n",
      "Epoch [66/85] Batch 640/938 Loss D: 0.2151, Loss G: 2.4019\n",
      "Epoch [66/85] Batch 650/938 Loss D: 0.4393, Loss G: 2.2948\n",
      "Epoch [66/85] Batch 660/938 Loss D: 0.2622, Loss G: 2.5737\n",
      "Epoch [66/85] Batch 670/938 Loss D: 0.2169, Loss G: 2.1861\n",
      "Epoch [66/85] Batch 680/938 Loss D: 0.1487, Loss G: 3.1996\n",
      "Epoch [66/85] Batch 690/938 Loss D: 0.2245, Loss G: 2.8471\n",
      "Epoch [66/85] Batch 700/938 Loss D: 0.2699, Loss G: 2.0687\n",
      "Epoch [66/85] Batch 710/938 Loss D: 0.2629, Loss G: 2.4789\n",
      "Epoch [66/85] Batch 720/938 Loss D: 0.3192, Loss G: 2.5674\n",
      "Epoch [66/85] Batch 730/938 Loss D: 0.3089, Loss G: 2.7845\n",
      "Epoch [66/85] Batch 740/938 Loss D: 0.3371, Loss G: 2.4631\n",
      "Epoch [66/85] Batch 750/938 Loss D: 0.2469, Loss G: 2.5309\n",
      "Epoch [66/85] Batch 760/938 Loss D: 0.3422, Loss G: 2.2202\n",
      "Epoch [66/85] Batch 770/938 Loss D: 0.2868, Loss G: 2.5028\n",
      "Epoch [66/85] Batch 780/938 Loss D: 0.4147, Loss G: 2.4198\n",
      "Epoch [66/85] Batch 790/938 Loss D: 0.2512, Loss G: 2.8415\n",
      "Epoch [66/85] Batch 800/938 Loss D: 0.3201, Loss G: 2.1217\n",
      "Epoch [66/85] Batch 810/938 Loss D: 0.4082, Loss G: 1.3106\n",
      "Epoch [66/85] Batch 820/938 Loss D: 0.2510, Loss G: 1.8628\n",
      "Epoch [66/85] Batch 830/938 Loss D: 0.2009, Loss G: 2.6041\n",
      "Epoch [66/85] Batch 840/938 Loss D: 0.2765, Loss G: 2.7201\n",
      "Epoch [66/85] Batch 850/938 Loss D: 0.3076, Loss G: 2.3467\n",
      "Epoch [66/85] Batch 860/938 Loss D: 0.2552, Loss G: 2.0828\n",
      "Epoch [66/85] Batch 870/938 Loss D: 0.3581, Loss G: 2.2228\n",
      "Epoch [66/85] Batch 880/938 Loss D: 0.2856, Loss G: 1.9901\n",
      "Epoch [66/85] Batch 890/938 Loss D: 0.2146, Loss G: 2.7731\n",
      "Epoch [66/85] Batch 900/938 Loss D: 0.4512, Loss G: 2.0653\n",
      "Epoch [66/85] Batch 910/938 Loss D: 0.3512, Loss G: 1.9779\n",
      "Epoch [66/85] Batch 920/938 Loss D: 0.2935, Loss G: 2.3013\n",
      "Epoch [66/85] Batch 930/938 Loss D: 0.3041, Loss G: 2.2907\n",
      "Epoch [67/85] Batch 0/938 Loss D: 0.3092, Loss G: 2.0589\n",
      "Epoch [67/85] Batch 10/938 Loss D: 0.4295, Loss G: 2.4382\n",
      "Epoch [67/85] Batch 20/938 Loss D: 0.2888, Loss G: 2.6251\n",
      "Epoch [67/85] Batch 30/938 Loss D: 0.2272, Loss G: 2.2267\n",
      "Epoch [67/85] Batch 40/938 Loss D: 0.2686, Loss G: 2.6351\n",
      "Epoch [67/85] Batch 50/938 Loss D: 0.2508, Loss G: 2.4546\n",
      "Epoch [67/85] Batch 60/938 Loss D: 0.2178, Loss G: 2.7794\n",
      "Epoch [67/85] Batch 70/938 Loss D: 0.3941, Loss G: 1.8661\n",
      "Epoch [67/85] Batch 80/938 Loss D: 0.3538, Loss G: 2.5921\n",
      "Epoch [67/85] Batch 90/938 Loss D: 0.4201, Loss G: 3.2218\n",
      "Epoch [67/85] Batch 100/938 Loss D: 0.2525, Loss G: 3.1098\n",
      "Epoch [67/85] Batch 110/938 Loss D: 0.2046, Loss G: 2.9709\n",
      "Epoch [67/85] Batch 120/938 Loss D: 0.2417, Loss G: 2.3663\n",
      "Epoch [67/85] Batch 130/938 Loss D: 0.4139, Loss G: 1.7018\n",
      "Epoch [67/85] Batch 140/938 Loss D: 0.3031, Loss G: 2.8248\n",
      "Epoch [67/85] Batch 150/938 Loss D: 0.2701, Loss G: 2.8215\n",
      "Epoch [67/85] Batch 160/938 Loss D: 0.4972, Loss G: 2.8464\n",
      "Epoch [67/85] Batch 170/938 Loss D: 0.2751, Loss G: 3.2473\n",
      "Epoch [67/85] Batch 180/938 Loss D: 0.1813, Loss G: 3.4491\n",
      "Epoch [67/85] Batch 190/938 Loss D: 0.3079, Loss G: 2.1253\n",
      "Epoch [67/85] Batch 200/938 Loss D: 0.3123, Loss G: 3.6963\n",
      "Epoch [67/85] Batch 210/938 Loss D: 0.3025, Loss G: 3.1023\n",
      "Epoch [67/85] Batch 220/938 Loss D: 0.4237, Loss G: 1.8773\n",
      "Epoch [67/85] Batch 230/938 Loss D: 0.3364, Loss G: 1.9063\n",
      "Epoch [67/85] Batch 240/938 Loss D: 0.3709, Loss G: 2.1371\n",
      "Epoch [67/85] Batch 250/938 Loss D: 0.3422, Loss G: 2.0453\n",
      "Epoch [67/85] Batch 260/938 Loss D: 0.2516, Loss G: 2.5061\n",
      "Epoch [67/85] Batch 270/938 Loss D: 0.1865, Loss G: 2.5997\n",
      "Epoch [67/85] Batch 280/938 Loss D: 0.3365, Loss G: 1.7890\n",
      "Epoch [67/85] Batch 290/938 Loss D: 0.2407, Loss G: 2.8488\n",
      "Epoch [67/85] Batch 300/938 Loss D: 0.2008, Loss G: 3.6138\n",
      "Epoch [67/85] Batch 310/938 Loss D: 0.3593, Loss G: 1.9981\n",
      "Epoch [67/85] Batch 320/938 Loss D: 0.3140, Loss G: 2.1218\n",
      "Epoch [67/85] Batch 330/938 Loss D: 0.2964, Loss G: 2.5900\n",
      "Epoch [67/85] Batch 340/938 Loss D: 0.3069, Loss G: 2.4612\n",
      "Epoch [67/85] Batch 350/938 Loss D: 0.2452, Loss G: 3.1006\n",
      "Epoch [67/85] Batch 360/938 Loss D: 0.3280, Loss G: 2.9033\n",
      "Epoch [67/85] Batch 370/938 Loss D: 0.2318, Loss G: 2.4017\n",
      "Epoch [67/85] Batch 380/938 Loss D: 0.3625, Loss G: 1.8554\n",
      "Epoch [67/85] Batch 390/938 Loss D: 0.3194, Loss G: 2.2434\n",
      "Epoch [67/85] Batch 400/938 Loss D: 0.2965, Loss G: 2.4095\n",
      "Epoch [67/85] Batch 410/938 Loss D: 0.1714, Loss G: 3.1075\n",
      "Epoch [67/85] Batch 420/938 Loss D: 0.2432, Loss G: 2.3731\n",
      "Epoch [67/85] Batch 430/938 Loss D: 0.1909, Loss G: 3.2631\n",
      "Epoch [67/85] Batch 440/938 Loss D: 0.2128, Loss G: 2.6534\n",
      "Epoch [67/85] Batch 450/938 Loss D: 0.4388, Loss G: 1.9585\n",
      "Epoch [67/85] Batch 460/938 Loss D: 0.4033, Loss G: 2.7765\n",
      "Epoch [67/85] Batch 470/938 Loss D: 0.3615, Loss G: 2.8954\n",
      "Epoch [67/85] Batch 480/938 Loss D: 0.3905, Loss G: 3.3219\n",
      "Epoch [67/85] Batch 490/938 Loss D: 0.3731, Loss G: 2.2935\n",
      "Epoch [67/85] Batch 500/938 Loss D: 0.2948, Loss G: 2.4086\n",
      "Epoch [67/85] Batch 510/938 Loss D: 0.2869, Loss G: 2.8766\n",
      "Epoch [67/85] Batch 520/938 Loss D: 0.3176, Loss G: 3.1629\n",
      "Epoch [67/85] Batch 530/938 Loss D: 0.2133, Loss G: 2.5546\n",
      "Epoch [67/85] Batch 540/938 Loss D: 0.3668, Loss G: 2.1443\n",
      "Epoch [67/85] Batch 550/938 Loss D: 0.2051, Loss G: 2.6667\n",
      "Epoch [67/85] Batch 560/938 Loss D: 0.2394, Loss G: 2.3576\n",
      "Epoch [67/85] Batch 570/938 Loss D: 0.2439, Loss G: 3.2660\n",
      "Epoch [67/85] Batch 580/938 Loss D: 0.4080, Loss G: 2.2111\n",
      "Epoch [67/85] Batch 590/938 Loss D: 0.3418, Loss G: 2.1339\n",
      "Epoch [67/85] Batch 600/938 Loss D: 0.3345, Loss G: 2.3156\n",
      "Epoch [67/85] Batch 610/938 Loss D: 0.2324, Loss G: 3.2567\n",
      "Epoch [67/85] Batch 620/938 Loss D: 0.3064, Loss G: 2.6568\n",
      "Epoch [67/85] Batch 630/938 Loss D: 0.1990, Loss G: 2.7350\n",
      "Epoch [67/85] Batch 640/938 Loss D: 0.2488, Loss G: 2.6197\n",
      "Epoch [67/85] Batch 650/938 Loss D: 0.1966, Loss G: 3.4888\n",
      "Epoch [67/85] Batch 660/938 Loss D: 0.3220, Loss G: 1.7671\n",
      "Epoch [67/85] Batch 670/938 Loss D: 0.2486, Loss G: 2.7150\n",
      "Epoch [67/85] Batch 680/938 Loss D: 0.2067, Loss G: 3.2054\n",
      "Epoch [67/85] Batch 690/938 Loss D: 0.2943, Loss G: 3.4592\n",
      "Epoch [67/85] Batch 700/938 Loss D: 0.2998, Loss G: 2.4246\n",
      "Epoch [67/85] Batch 710/938 Loss D: 0.2721, Loss G: 1.9025\n",
      "Epoch [67/85] Batch 720/938 Loss D: 0.3410, Loss G: 2.4642\n",
      "Epoch [67/85] Batch 730/938 Loss D: 0.2059, Loss G: 2.6693\n",
      "Epoch [67/85] Batch 740/938 Loss D: 0.3773, Loss G: 2.4112\n",
      "Epoch [67/85] Batch 750/938 Loss D: 0.3455, Loss G: 2.6022\n",
      "Epoch [67/85] Batch 760/938 Loss D: 0.2243, Loss G: 3.1193\n",
      "Epoch [67/85] Batch 770/938 Loss D: 0.3999, Loss G: 1.8248\n",
      "Epoch [67/85] Batch 780/938 Loss D: 0.2565, Loss G: 2.7379\n",
      "Epoch [67/85] Batch 790/938 Loss D: 0.2458, Loss G: 2.3434\n",
      "Epoch [67/85] Batch 800/938 Loss D: 0.3248, Loss G: 2.5105\n",
      "Epoch [67/85] Batch 810/938 Loss D: 0.1787, Loss G: 2.6275\n",
      "Epoch [67/85] Batch 820/938 Loss D: 0.2925, Loss G: 1.9531\n",
      "Epoch [67/85] Batch 830/938 Loss D: 0.3132, Loss G: 2.0518\n",
      "Epoch [67/85] Batch 840/938 Loss D: 0.3239, Loss G: 2.2535\n",
      "Epoch [67/85] Batch 850/938 Loss D: 0.3060, Loss G: 2.4025\n",
      "Epoch [67/85] Batch 860/938 Loss D: 0.3218, Loss G: 2.4281\n",
      "Epoch [67/85] Batch 870/938 Loss D: 0.3139, Loss G: 2.5181\n",
      "Epoch [67/85] Batch 880/938 Loss D: 0.3330, Loss G: 1.9518\n",
      "Epoch [67/85] Batch 890/938 Loss D: 0.2996, Loss G: 3.2247\n",
      "Epoch [67/85] Batch 900/938 Loss D: 0.2368, Loss G: 2.6636\n",
      "Epoch [67/85] Batch 910/938 Loss D: 0.3012, Loss G: 2.2342\n",
      "Epoch [67/85] Batch 920/938 Loss D: 0.3028, Loss G: 1.9153\n",
      "Epoch [67/85] Batch 930/938 Loss D: 0.2964, Loss G: 2.8259\n",
      "Epoch [68/85] Batch 0/938 Loss D: 0.3081, Loss G: 2.2083\n",
      "Epoch [68/85] Batch 10/938 Loss D: 0.3351, Loss G: 2.2785\n",
      "Epoch [68/85] Batch 20/938 Loss D: 0.4988, Loss G: 1.5461\n",
      "Epoch [68/85] Batch 30/938 Loss D: 0.3750, Loss G: 2.1142\n",
      "Epoch [68/85] Batch 40/938 Loss D: 0.3794, Loss G: 2.2223\n",
      "Epoch [68/85] Batch 50/938 Loss D: 0.2926, Loss G: 2.4862\n",
      "Epoch [68/85] Batch 60/938 Loss D: 0.2943, Loss G: 2.3900\n",
      "Epoch [68/85] Batch 70/938 Loss D: 0.2149, Loss G: 3.2702\n",
      "Epoch [68/85] Batch 80/938 Loss D: 0.3496, Loss G: 2.1299\n",
      "Epoch [68/85] Batch 90/938 Loss D: 0.3447, Loss G: 2.0061\n",
      "Epoch [68/85] Batch 100/938 Loss D: 0.2884, Loss G: 2.2764\n",
      "Epoch [68/85] Batch 110/938 Loss D: 0.2286, Loss G: 2.8633\n",
      "Epoch [68/85] Batch 120/938 Loss D: 0.2609, Loss G: 2.8932\n",
      "Epoch [68/85] Batch 130/938 Loss D: 0.3401, Loss G: 2.2009\n",
      "Epoch [68/85] Batch 140/938 Loss D: 0.3016, Loss G: 2.3386\n",
      "Epoch [68/85] Batch 150/938 Loss D: 0.5190, Loss G: 2.2739\n",
      "Epoch [68/85] Batch 160/938 Loss D: 0.1990, Loss G: 3.4303\n",
      "Epoch [68/85] Batch 170/938 Loss D: 0.3321, Loss G: 2.3161\n",
      "Epoch [68/85] Batch 180/938 Loss D: 0.4617, Loss G: 2.6916\n",
      "Epoch [68/85] Batch 190/938 Loss D: 0.3703, Loss G: 2.4178\n",
      "Epoch [68/85] Batch 200/938 Loss D: 0.2478, Loss G: 2.7923\n",
      "Epoch [68/85] Batch 210/938 Loss D: 0.3336, Loss G: 2.3837\n",
      "Epoch [68/85] Batch 220/938 Loss D: 0.3574, Loss G: 2.3755\n",
      "Epoch [68/85] Batch 230/938 Loss D: 0.2274, Loss G: 2.5651\n",
      "Epoch [68/85] Batch 240/938 Loss D: 0.2418, Loss G: 2.4898\n",
      "Epoch [68/85] Batch 250/938 Loss D: 0.3687, Loss G: 2.4851\n",
      "Epoch [68/85] Batch 260/938 Loss D: 0.3186, Loss G: 3.6153\n",
      "Epoch [68/85] Batch 270/938 Loss D: 0.3176, Loss G: 2.6151\n",
      "Epoch [68/85] Batch 280/938 Loss D: 0.2575, Loss G: 2.5164\n",
      "Epoch [68/85] Batch 290/938 Loss D: 0.3099, Loss G: 1.9169\n",
      "Epoch [68/85] Batch 300/938 Loss D: 0.2370, Loss G: 2.7955\n",
      "Epoch [68/85] Batch 310/938 Loss D: 0.4271, Loss G: 3.1138\n",
      "Epoch [68/85] Batch 320/938 Loss D: 0.2037, Loss G: 3.1358\n",
      "Epoch [68/85] Batch 330/938 Loss D: 0.2870, Loss G: 2.2559\n",
      "Epoch [68/85] Batch 340/938 Loss D: 0.3116, Loss G: 2.2893\n",
      "Epoch [68/85] Batch 350/938 Loss D: 0.2807, Loss G: 2.5536\n",
      "Epoch [68/85] Batch 360/938 Loss D: 0.3443, Loss G: 2.0065\n",
      "Epoch [68/85] Batch 370/938 Loss D: 0.2550, Loss G: 2.6961\n",
      "Epoch [68/85] Batch 380/938 Loss D: 0.2961, Loss G: 1.9435\n",
      "Epoch [68/85] Batch 390/938 Loss D: 0.2133, Loss G: 2.4127\n",
      "Epoch [68/85] Batch 400/938 Loss D: 0.2553, Loss G: 3.1004\n",
      "Epoch [68/85] Batch 410/938 Loss D: 0.2670, Loss G: 2.8668\n",
      "Epoch [68/85] Batch 420/938 Loss D: 0.2796, Loss G: 1.9721\n",
      "Epoch [68/85] Batch 430/938 Loss D: 0.3182, Loss G: 2.1015\n",
      "Epoch [68/85] Batch 440/938 Loss D: 0.3442, Loss G: 2.3666\n",
      "Epoch [68/85] Batch 450/938 Loss D: 0.3859, Loss G: 2.1775\n",
      "Epoch [68/85] Batch 460/938 Loss D: 0.2403, Loss G: 2.0740\n",
      "Epoch [68/85] Batch 470/938 Loss D: 0.2203, Loss G: 2.5695\n",
      "Epoch [68/85] Batch 480/938 Loss D: 0.2984, Loss G: 2.5183\n",
      "Epoch [68/85] Batch 490/938 Loss D: 0.3580, Loss G: 2.1578\n",
      "Epoch [68/85] Batch 500/938 Loss D: 0.4335, Loss G: 2.1773\n",
      "Epoch [68/85] Batch 510/938 Loss D: 0.1918, Loss G: 3.2678\n",
      "Epoch [68/85] Batch 520/938 Loss D: 0.3806, Loss G: 2.3724\n",
      "Epoch [68/85] Batch 530/938 Loss D: 0.3083, Loss G: 2.4275\n",
      "Epoch [68/85] Batch 540/938 Loss D: 0.3412, Loss G: 1.8092\n",
      "Epoch [68/85] Batch 550/938 Loss D: 0.2518, Loss G: 2.4128\n",
      "Epoch [68/85] Batch 560/938 Loss D: 0.3924, Loss G: 1.9838\n",
      "Epoch [68/85] Batch 570/938 Loss D: 0.1606, Loss G: 3.4080\n",
      "Epoch [68/85] Batch 580/938 Loss D: 0.2479, Loss G: 2.6550\n",
      "Epoch [68/85] Batch 590/938 Loss D: 0.2093, Loss G: 3.0543\n",
      "Epoch [68/85] Batch 600/938 Loss D: 0.2670, Loss G: 2.6670\n",
      "Epoch [68/85] Batch 610/938 Loss D: 0.2130, Loss G: 2.1600\n",
      "Epoch [68/85] Batch 620/938 Loss D: 0.2581, Loss G: 2.6332\n",
      "Epoch [68/85] Batch 630/938 Loss D: 0.4017, Loss G: 2.0404\n",
      "Epoch [68/85] Batch 640/938 Loss D: 0.3220, Loss G: 2.0338\n",
      "Epoch [68/85] Batch 650/938 Loss D: 0.2158, Loss G: 2.7191\n",
      "Epoch [68/85] Batch 660/938 Loss D: 0.2563, Loss G: 3.4172\n",
      "Epoch [68/85] Batch 670/938 Loss D: 0.2354, Loss G: 3.7982\n",
      "Epoch [68/85] Batch 680/938 Loss D: 0.3237, Loss G: 2.4672\n",
      "Epoch [68/85] Batch 690/938 Loss D: 0.3438, Loss G: 2.4544\n",
      "Epoch [68/85] Batch 700/938 Loss D: 0.2224, Loss G: 3.0352\n",
      "Epoch [68/85] Batch 710/938 Loss D: 0.3251, Loss G: 2.0008\n",
      "Epoch [68/85] Batch 720/938 Loss D: 0.3173, Loss G: 2.4193\n",
      "Epoch [68/85] Batch 730/938 Loss D: 0.3935, Loss G: 2.6234\n",
      "Epoch [68/85] Batch 740/938 Loss D: 0.2887, Loss G: 2.5834\n",
      "Epoch [68/85] Batch 750/938 Loss D: 0.2598, Loss G: 2.4970\n",
      "Epoch [68/85] Batch 760/938 Loss D: 0.3046, Loss G: 2.1854\n",
      "Epoch [68/85] Batch 770/938 Loss D: 0.2681, Loss G: 2.1083\n",
      "Epoch [68/85] Batch 780/938 Loss D: 0.1074, Loss G: 3.1221\n",
      "Epoch [68/85] Batch 790/938 Loss D: 0.2600, Loss G: 2.8779\n",
      "Epoch [68/85] Batch 800/938 Loss D: 0.2252, Loss G: 2.2948\n",
      "Epoch [68/85] Batch 810/938 Loss D: 0.2819, Loss G: 2.9677\n",
      "Epoch [68/85] Batch 820/938 Loss D: 0.3277, Loss G: 2.1011\n",
      "Epoch [68/85] Batch 830/938 Loss D: 0.3798, Loss G: 2.0887\n",
      "Epoch [68/85] Batch 840/938 Loss D: 0.3778, Loss G: 1.9966\n",
      "Epoch [68/85] Batch 850/938 Loss D: 0.2340, Loss G: 2.4203\n",
      "Epoch [68/85] Batch 860/938 Loss D: 0.2839, Loss G: 2.3817\n",
      "Epoch [68/85] Batch 870/938 Loss D: 0.1768, Loss G: 3.0966\n",
      "Epoch [68/85] Batch 880/938 Loss D: 0.2700, Loss G: 2.6225\n",
      "Epoch [68/85] Batch 890/938 Loss D: 0.3341, Loss G: 2.3851\n",
      "Epoch [68/85] Batch 900/938 Loss D: 0.2387, Loss G: 3.2356\n",
      "Epoch [68/85] Batch 910/938 Loss D: 0.2106, Loss G: 3.2333\n",
      "Epoch [68/85] Batch 920/938 Loss D: 0.2449, Loss G: 2.6203\n",
      "Epoch [68/85] Batch 930/938 Loss D: 0.3469, Loss G: 2.6134\n",
      "Epoch [69/85] Batch 0/938 Loss D: 0.2461, Loss G: 2.5107\n",
      "Epoch [69/85] Batch 10/938 Loss D: 0.2877, Loss G: 2.0159\n",
      "Epoch [69/85] Batch 20/938 Loss D: 0.2147, Loss G: 2.9134\n",
      "Epoch [69/85] Batch 30/938 Loss D: 0.3623, Loss G: 1.9174\n",
      "Epoch [69/85] Batch 40/938 Loss D: 0.3244, Loss G: 2.5393\n",
      "Epoch [69/85] Batch 50/938 Loss D: 0.4079, Loss G: 2.7323\n",
      "Epoch [69/85] Batch 60/938 Loss D: 0.4095, Loss G: 2.2737\n",
      "Epoch [69/85] Batch 70/938 Loss D: 0.2005, Loss G: 2.2222\n",
      "Epoch [69/85] Batch 80/938 Loss D: 0.2363, Loss G: 2.1846\n",
      "Epoch [69/85] Batch 90/938 Loss D: 0.3122, Loss G: 2.2577\n",
      "Epoch [69/85] Batch 100/938 Loss D: 0.4416, Loss G: 2.6162\n",
      "Epoch [69/85] Batch 110/938 Loss D: 0.2185, Loss G: 2.3385\n",
      "Epoch [69/85] Batch 120/938 Loss D: 0.2809, Loss G: 2.2026\n",
      "Epoch [69/85] Batch 130/938 Loss D: 0.2176, Loss G: 3.1254\n",
      "Epoch [69/85] Batch 140/938 Loss D: 0.3187, Loss G: 3.1895\n",
      "Epoch [69/85] Batch 150/938 Loss D: 0.2851, Loss G: 3.3609\n",
      "Epoch [69/85] Batch 160/938 Loss D: 0.2904, Loss G: 2.7282\n",
      "Epoch [69/85] Batch 170/938 Loss D: 0.2544, Loss G: 2.9283\n",
      "Epoch [69/85] Batch 180/938 Loss D: 0.2320, Loss G: 3.2815\n",
      "Epoch [69/85] Batch 190/938 Loss D: 0.2865, Loss G: 3.4747\n",
      "Epoch [69/85] Batch 200/938 Loss D: 0.2355, Loss G: 2.6031\n",
      "Epoch [69/85] Batch 210/938 Loss D: 0.3214, Loss G: 2.2673\n",
      "Epoch [69/85] Batch 220/938 Loss D: 0.2334, Loss G: 2.4617\n",
      "Epoch [69/85] Batch 230/938 Loss D: 0.2697, Loss G: 2.2629\n",
      "Epoch [69/85] Batch 240/938 Loss D: 0.3442, Loss G: 2.3539\n",
      "Epoch [69/85] Batch 250/938 Loss D: 0.3861, Loss G: 2.2614\n",
      "Epoch [69/85] Batch 260/938 Loss D: 0.3351, Loss G: 1.9227\n",
      "Epoch [69/85] Batch 270/938 Loss D: 0.2781, Loss G: 2.0393\n",
      "Epoch [69/85] Batch 280/938 Loss D: 0.2389, Loss G: 2.4948\n",
      "Epoch [69/85] Batch 290/938 Loss D: 0.3185, Loss G: 2.0094\n",
      "Epoch [69/85] Batch 300/938 Loss D: 0.3710, Loss G: 2.9553\n",
      "Epoch [69/85] Batch 310/938 Loss D: 0.2262, Loss G: 2.6981\n",
      "Epoch [69/85] Batch 320/938 Loss D: 0.2399, Loss G: 3.1347\n",
      "Epoch [69/85] Batch 330/938 Loss D: 0.2764, Loss G: 2.0500\n",
      "Epoch [69/85] Batch 340/938 Loss D: 0.2281, Loss G: 2.4159\n",
      "Epoch [69/85] Batch 350/938 Loss D: 0.3070, Loss G: 2.1273\n",
      "Epoch [69/85] Batch 360/938 Loss D: 0.3045, Loss G: 2.5033\n",
      "Epoch [69/85] Batch 370/938 Loss D: 0.2665, Loss G: 3.3322\n",
      "Epoch [69/85] Batch 380/938 Loss D: 0.3879, Loss G: 2.3460\n",
      "Epoch [69/85] Batch 390/938 Loss D: 0.3140, Loss G: 2.2976\n",
      "Epoch [69/85] Batch 400/938 Loss D: 0.2123, Loss G: 2.3663\n",
      "Epoch [69/85] Batch 410/938 Loss D: 0.3041, Loss G: 1.8320\n",
      "Epoch [69/85] Batch 420/938 Loss D: 0.3702, Loss G: 2.4861\n",
      "Epoch [69/85] Batch 430/938 Loss D: 0.2295, Loss G: 2.7365\n",
      "Epoch [69/85] Batch 440/938 Loss D: 0.2718, Loss G: 1.9129\n",
      "Epoch [69/85] Batch 450/938 Loss D: 0.3676, Loss G: 1.9912\n",
      "Epoch [69/85] Batch 460/938 Loss D: 0.2814, Loss G: 2.9254\n",
      "Epoch [69/85] Batch 470/938 Loss D: 0.1790, Loss G: 2.7688\n",
      "Epoch [69/85] Batch 480/938 Loss D: 0.2946, Loss G: 1.9330\n",
      "Epoch [69/85] Batch 490/938 Loss D: 0.4884, Loss G: 1.6529\n",
      "Epoch [69/85] Batch 500/938 Loss D: 0.3250, Loss G: 2.1114\n",
      "Epoch [69/85] Batch 510/938 Loss D: 0.2880, Loss G: 2.2557\n",
      "Epoch [69/85] Batch 520/938 Loss D: 0.3553, Loss G: 3.1965\n",
      "Epoch [69/85] Batch 530/938 Loss D: 0.1774, Loss G: 3.7645\n",
      "Epoch [69/85] Batch 540/938 Loss D: 0.5131, Loss G: 2.6318\n",
      "Epoch [69/85] Batch 550/938 Loss D: 0.3244, Loss G: 1.9138\n",
      "Epoch [69/85] Batch 560/938 Loss D: 0.2236, Loss G: 2.4284\n",
      "Epoch [69/85] Batch 570/938 Loss D: 0.1533, Loss G: 3.3274\n",
      "Epoch [69/85] Batch 580/938 Loss D: 0.2868, Loss G: 2.3276\n",
      "Epoch [69/85] Batch 590/938 Loss D: 0.2500, Loss G: 2.4997\n",
      "Epoch [69/85] Batch 600/938 Loss D: 0.2470, Loss G: 2.2193\n",
      "Epoch [69/85] Batch 610/938 Loss D: 0.2436, Loss G: 2.5123\n",
      "Epoch [69/85] Batch 620/938 Loss D: 0.2576, Loss G: 2.6661\n",
      "Epoch [69/85] Batch 630/938 Loss D: 0.3218, Loss G: 2.0341\n",
      "Epoch [69/85] Batch 640/938 Loss D: 0.4069, Loss G: 1.6427\n",
      "Epoch [69/85] Batch 650/938 Loss D: 0.3145, Loss G: 2.2915\n",
      "Epoch [69/85] Batch 660/938 Loss D: 0.3584, Loss G: 2.0052\n",
      "Epoch [69/85] Batch 670/938 Loss D: 0.2426, Loss G: 2.3614\n",
      "Epoch [69/85] Batch 680/938 Loss D: 0.2861, Loss G: 2.3259\n",
      "Epoch [69/85] Batch 690/938 Loss D: 0.3499, Loss G: 2.1543\n",
      "Epoch [69/85] Batch 700/938 Loss D: 0.3639, Loss G: 2.1690\n",
      "Epoch [69/85] Batch 710/938 Loss D: 0.2911, Loss G: 2.5186\n",
      "Epoch [69/85] Batch 720/938 Loss D: 0.3088, Loss G: 2.3597\n",
      "Epoch [69/85] Batch 730/938 Loss D: 0.1834, Loss G: 3.2456\n",
      "Epoch [69/85] Batch 740/938 Loss D: 0.4818, Loss G: 2.1373\n",
      "Epoch [69/85] Batch 750/938 Loss D: 0.3271, Loss G: 2.8071\n",
      "Epoch [69/85] Batch 760/938 Loss D: 0.2496, Loss G: 2.5795\n",
      "Epoch [69/85] Batch 770/938 Loss D: 0.3531, Loss G: 2.6526\n",
      "Epoch [69/85] Batch 780/938 Loss D: 0.2074, Loss G: 2.8367\n",
      "Epoch [69/85] Batch 790/938 Loss D: 0.3851, Loss G: 2.1551\n",
      "Epoch [69/85] Batch 800/938 Loss D: 0.2698, Loss G: 2.6851\n",
      "Epoch [69/85] Batch 810/938 Loss D: 0.2781, Loss G: 2.7836\n",
      "Epoch [69/85] Batch 820/938 Loss D: 0.2748, Loss G: 3.4176\n",
      "Epoch [69/85] Batch 830/938 Loss D: 0.2552, Loss G: 3.6683\n",
      "Epoch [69/85] Batch 840/938 Loss D: 0.3014, Loss G: 2.6330\n",
      "Epoch [69/85] Batch 850/938 Loss D: 0.1341, Loss G: 3.4630\n",
      "Epoch [69/85] Batch 860/938 Loss D: 0.2493, Loss G: 2.4261\n",
      "Epoch [69/85] Batch 870/938 Loss D: 0.1650, Loss G: 2.6356\n",
      "Epoch [69/85] Batch 880/938 Loss D: 0.3341, Loss G: 2.9258\n",
      "Epoch [69/85] Batch 890/938 Loss D: 0.3265, Loss G: 3.0817\n",
      "Epoch [69/85] Batch 900/938 Loss D: 0.2651, Loss G: 2.5877\n",
      "Epoch [69/85] Batch 910/938 Loss D: 0.2447, Loss G: 2.2460\n",
      "Epoch [69/85] Batch 920/938 Loss D: 0.2304, Loss G: 2.9219\n",
      "Epoch [69/85] Batch 930/938 Loss D: 0.2872, Loss G: 2.4176\n",
      "Epoch [70/85] Batch 0/938 Loss D: 0.1898, Loss G: 2.7964\n",
      "Epoch [70/85] Batch 10/938 Loss D: 0.3185, Loss G: 2.1170\n",
      "Epoch [70/85] Batch 20/938 Loss D: 0.2402, Loss G: 3.5008\n",
      "Epoch [70/85] Batch 30/938 Loss D: 0.3406, Loss G: 2.2627\n",
      "Epoch [70/85] Batch 40/938 Loss D: 0.3833, Loss G: 1.8195\n",
      "Epoch [70/85] Batch 50/938 Loss D: 0.3501, Loss G: 2.3400\n",
      "Epoch [70/85] Batch 60/938 Loss D: 0.2600, Loss G: 2.4864\n",
      "Epoch [70/85] Batch 70/938 Loss D: 0.3458, Loss G: 1.9058\n",
      "Epoch [70/85] Batch 80/938 Loss D: 0.1871, Loss G: 2.4844\n",
      "Epoch [70/85] Batch 90/938 Loss D: 0.3985, Loss G: 2.1829\n",
      "Epoch [70/85] Batch 100/938 Loss D: 0.2129, Loss G: 2.7985\n",
      "Epoch [70/85] Batch 110/938 Loss D: 0.2809, Loss G: 2.0113\n",
      "Epoch [70/85] Batch 120/938 Loss D: 0.2561, Loss G: 2.0059\n",
      "Epoch [70/85] Batch 130/938 Loss D: 0.2544, Loss G: 2.6957\n",
      "Epoch [70/85] Batch 140/938 Loss D: 0.3095, Loss G: 2.3714\n",
      "Epoch [70/85] Batch 150/938 Loss D: 0.3694, Loss G: 1.8705\n",
      "Epoch [70/85] Batch 160/938 Loss D: 0.3340, Loss G: 2.2182\n",
      "Epoch [70/85] Batch 170/938 Loss D: 0.3515, Loss G: 2.4802\n",
      "Epoch [70/85] Batch 180/938 Loss D: 0.4513, Loss G: 2.0676\n",
      "Epoch [70/85] Batch 190/938 Loss D: 0.3322, Loss G: 2.5256\n",
      "Epoch [70/85] Batch 200/938 Loss D: 0.3127, Loss G: 2.7805\n",
      "Epoch [70/85] Batch 210/938 Loss D: 0.3787, Loss G: 2.2539\n",
      "Epoch [70/85] Batch 220/938 Loss D: 0.2200, Loss G: 2.6027\n",
      "Epoch [70/85] Batch 230/938 Loss D: 0.2452, Loss G: 2.3422\n",
      "Epoch [70/85] Batch 240/938 Loss D: 0.4058, Loss G: 2.2071\n",
      "Epoch [70/85] Batch 250/938 Loss D: 0.2442, Loss G: 2.1638\n",
      "Epoch [70/85] Batch 260/938 Loss D: 0.2292, Loss G: 2.8179\n",
      "Epoch [70/85] Batch 270/938 Loss D: 0.2504, Loss G: 2.4049\n",
      "Epoch [70/85] Batch 280/938 Loss D: 0.3908, Loss G: 4.0740\n",
      "Epoch [70/85] Batch 290/938 Loss D: 0.2868, Loss G: 2.6478\n",
      "Epoch [70/85] Batch 300/938 Loss D: 0.3175, Loss G: 2.6795\n",
      "Epoch [70/85] Batch 310/938 Loss D: 0.2093, Loss G: 3.2570\n",
      "Epoch [70/85] Batch 320/938 Loss D: 0.5150, Loss G: 2.4738\n",
      "Epoch [70/85] Batch 330/938 Loss D: 0.4450, Loss G: 3.2128\n",
      "Epoch [70/85] Batch 340/938 Loss D: 0.1955, Loss G: 2.9531\n",
      "Epoch [70/85] Batch 350/938 Loss D: 0.4300, Loss G: 1.7812\n",
      "Epoch [70/85] Batch 360/938 Loss D: 0.2820, Loss G: 2.1815\n",
      "Epoch [70/85] Batch 370/938 Loss D: 0.2192, Loss G: 2.7118\n",
      "Epoch [70/85] Batch 380/938 Loss D: 0.3353, Loss G: 2.1163\n",
      "Epoch [70/85] Batch 390/938 Loss D: 0.3095, Loss G: 2.1280\n",
      "Epoch [70/85] Batch 400/938 Loss D: 0.1718, Loss G: 3.1609\n",
      "Epoch [70/85] Batch 410/938 Loss D: 0.2778, Loss G: 2.9659\n",
      "Epoch [70/85] Batch 420/938 Loss D: 0.2631, Loss G: 2.6469\n",
      "Epoch [70/85] Batch 430/938 Loss D: 0.3189, Loss G: 2.2446\n",
      "Epoch [70/85] Batch 440/938 Loss D: 0.3067, Loss G: 2.3059\n",
      "Epoch [70/85] Batch 450/938 Loss D: 0.1673, Loss G: 2.8240\n",
      "Epoch [70/85] Batch 460/938 Loss D: 0.2750, Loss G: 2.8720\n",
      "Epoch [70/85] Batch 470/938 Loss D: 0.2544, Loss G: 2.4624\n",
      "Epoch [70/85] Batch 480/938 Loss D: 0.2353, Loss G: 2.3315\n",
      "Epoch [70/85] Batch 490/938 Loss D: 0.2922, Loss G: 1.9821\n",
      "Epoch [70/85] Batch 500/938 Loss D: 0.4264, Loss G: 1.8681\n",
      "Epoch [70/85] Batch 510/938 Loss D: 0.3080, Loss G: 2.1805\n",
      "Epoch [70/85] Batch 520/938 Loss D: 0.2955, Loss G: 1.8095\n",
      "Epoch [70/85] Batch 530/938 Loss D: 0.3414, Loss G: 2.6572\n",
      "Epoch [70/85] Batch 540/938 Loss D: 0.2478, Loss G: 2.4003\n",
      "Epoch [70/85] Batch 550/938 Loss D: 0.2759, Loss G: 2.5825\n",
      "Epoch [70/85] Batch 560/938 Loss D: 0.3659, Loss G: 2.8210\n",
      "Epoch [70/85] Batch 570/938 Loss D: 0.2970, Loss G: 2.7909\n",
      "Epoch [70/85] Batch 580/938 Loss D: 0.2955, Loss G: 2.4896\n",
      "Epoch [70/85] Batch 590/938 Loss D: 0.2537, Loss G: 2.9152\n",
      "Epoch [70/85] Batch 600/938 Loss D: 0.2702, Loss G: 2.1522\n",
      "Epoch [70/85] Batch 610/938 Loss D: 0.2591, Loss G: 2.4546\n",
      "Epoch [70/85] Batch 620/938 Loss D: 0.2762, Loss G: 2.6204\n",
      "Epoch [70/85] Batch 630/938 Loss D: 0.2739, Loss G: 2.2401\n",
      "Epoch [70/85] Batch 640/938 Loss D: 0.2458, Loss G: 2.1874\n",
      "Epoch [70/85] Batch 650/938 Loss D: 0.3607, Loss G: 3.1583\n",
      "Epoch [70/85] Batch 660/938 Loss D: 0.3646, Loss G: 3.3347\n",
      "Epoch [70/85] Batch 670/938 Loss D: 0.3179, Loss G: 2.5771\n",
      "Epoch [70/85] Batch 680/938 Loss D: 0.3268, Loss G: 2.0845\n",
      "Epoch [70/85] Batch 690/938 Loss D: 0.3055, Loss G: 1.9009\n",
      "Epoch [70/85] Batch 700/938 Loss D: 0.2587, Loss G: 3.1166\n",
      "Epoch [70/85] Batch 710/938 Loss D: 0.2224, Loss G: 3.0625\n",
      "Epoch [70/85] Batch 720/938 Loss D: 0.4701, Loss G: 3.0134\n",
      "Epoch [70/85] Batch 730/938 Loss D: 0.2404, Loss G: 3.2820\n",
      "Epoch [70/85] Batch 740/938 Loss D: 0.2014, Loss G: 2.4231\n",
      "Epoch [70/85] Batch 750/938 Loss D: 0.1201, Loss G: 3.6248\n",
      "Epoch [70/85] Batch 760/938 Loss D: 0.2347, Loss G: 2.5856\n",
      "Epoch [70/85] Batch 770/938 Loss D: 0.2046, Loss G: 3.4770\n",
      "Epoch [70/85] Batch 780/938 Loss D: 0.2429, Loss G: 2.6163\n",
      "Epoch [70/85] Batch 790/938 Loss D: 0.2390, Loss G: 2.2337\n",
      "Epoch [70/85] Batch 800/938 Loss D: 0.3318, Loss G: 2.0416\n",
      "Epoch [70/85] Batch 810/938 Loss D: 0.2367, Loss G: 3.5400\n",
      "Epoch [70/85] Batch 820/938 Loss D: 0.2453, Loss G: 2.9428\n",
      "Epoch [70/85] Batch 830/938 Loss D: 0.3205, Loss G: 2.5402\n",
      "Epoch [70/85] Batch 840/938 Loss D: 0.3755, Loss G: 2.0209\n",
      "Epoch [70/85] Batch 850/938 Loss D: 0.2669, Loss G: 2.3434\n",
      "Epoch [70/85] Batch 860/938 Loss D: 0.3259, Loss G: 2.0561\n",
      "Epoch [70/85] Batch 870/938 Loss D: 0.3401, Loss G: 2.2832\n",
      "Epoch [70/85] Batch 880/938 Loss D: 0.2412, Loss G: 2.4230\n",
      "Epoch [70/85] Batch 890/938 Loss D: 0.2169, Loss G: 3.0547\n",
      "Epoch [70/85] Batch 900/938 Loss D: 0.2295, Loss G: 3.1257\n",
      "Epoch [70/85] Batch 910/938 Loss D: 0.2230, Loss G: 2.4258\n",
      "Epoch [70/85] Batch 920/938 Loss D: 0.3714, Loss G: 2.1381\n",
      "Epoch [70/85] Batch 930/938 Loss D: 0.2715, Loss G: 2.7857\n",
      "Epoch [71/85] Batch 0/938 Loss D: 0.3133, Loss G: 2.1233\n",
      "Epoch [71/85] Batch 10/938 Loss D: 0.2711, Loss G: 2.4056\n",
      "Epoch [71/85] Batch 20/938 Loss D: 0.2474, Loss G: 1.9207\n",
      "Epoch [71/85] Batch 30/938 Loss D: 0.4131, Loss G: 2.0311\n",
      "Epoch [71/85] Batch 40/938 Loss D: 0.2504, Loss G: 2.9957\n",
      "Epoch [71/85] Batch 50/938 Loss D: 0.2737, Loss G: 2.6738\n",
      "Epoch [71/85] Batch 60/938 Loss D: 0.2728, Loss G: 2.1456\n",
      "Epoch [71/85] Batch 70/938 Loss D: 0.3766, Loss G: 1.9597\n",
      "Epoch [71/85] Batch 80/938 Loss D: 0.3371, Loss G: 2.1057\n",
      "Epoch [71/85] Batch 90/938 Loss D: 0.3348, Loss G: 2.6004\n",
      "Epoch [71/85] Batch 100/938 Loss D: 0.3079, Loss G: 2.1229\n",
      "Epoch [71/85] Batch 110/938 Loss D: 0.2504, Loss G: 2.0122\n",
      "Epoch [71/85] Batch 120/938 Loss D: 0.2452, Loss G: 2.3543\n",
      "Epoch [71/85] Batch 130/938 Loss D: 0.2887, Loss G: 2.5608\n",
      "Epoch [71/85] Batch 140/938 Loss D: 0.2421, Loss G: 2.3037\n",
      "Epoch [71/85] Batch 150/938 Loss D: 0.2026, Loss G: 2.8446\n",
      "Epoch [71/85] Batch 160/938 Loss D: 0.2215, Loss G: 3.3387\n",
      "Epoch [71/85] Batch 170/938 Loss D: 0.3268, Loss G: 2.3373\n",
      "Epoch [71/85] Batch 180/938 Loss D: 0.3741, Loss G: 1.7662\n",
      "Epoch [71/85] Batch 190/938 Loss D: 0.2958, Loss G: 2.2217\n",
      "Epoch [71/85] Batch 200/938 Loss D: 0.2678, Loss G: 2.9096\n",
      "Epoch [71/85] Batch 210/938 Loss D: 0.2506, Loss G: 2.3328\n",
      "Epoch [71/85] Batch 220/938 Loss D: 0.2384, Loss G: 2.6771\n",
      "Epoch [71/85] Batch 230/938 Loss D: 0.3114, Loss G: 2.1297\n",
      "Epoch [71/85] Batch 240/938 Loss D: 0.2536, Loss G: 2.8082\n",
      "Epoch [71/85] Batch 250/938 Loss D: 0.4732, Loss G: 2.1242\n",
      "Epoch [71/85] Batch 260/938 Loss D: 0.2292, Loss G: 3.2493\n",
      "Epoch [71/85] Batch 270/938 Loss D: 0.2692, Loss G: 2.3875\n",
      "Epoch [71/85] Batch 280/938 Loss D: 0.3321, Loss G: 1.7237\n",
      "Epoch [71/85] Batch 290/938 Loss D: 0.2455, Loss G: 2.5551\n",
      "Epoch [71/85] Batch 300/938 Loss D: 0.3480, Loss G: 2.2117\n",
      "Epoch [71/85] Batch 310/938 Loss D: 0.1702, Loss G: 3.1064\n",
      "Epoch [71/85] Batch 320/938 Loss D: 0.2432, Loss G: 2.2086\n",
      "Epoch [71/85] Batch 330/938 Loss D: 0.2929, Loss G: 2.2811\n",
      "Epoch [71/85] Batch 340/938 Loss D: 0.3596, Loss G: 2.1299\n",
      "Epoch [71/85] Batch 350/938 Loss D: 0.3013, Loss G: 1.9654\n",
      "Epoch [71/85] Batch 360/938 Loss D: 0.2523, Loss G: 2.4326\n",
      "Epoch [71/85] Batch 370/938 Loss D: 0.3184, Loss G: 2.8251\n",
      "Epoch [71/85] Batch 380/938 Loss D: 0.3304, Loss G: 2.5284\n",
      "Epoch [71/85] Batch 390/938 Loss D: 0.3696, Loss G: 2.1144\n",
      "Epoch [71/85] Batch 400/938 Loss D: 0.2979, Loss G: 2.8221\n",
      "Epoch [71/85] Batch 410/938 Loss D: 0.3843, Loss G: 2.0379\n",
      "Epoch [71/85] Batch 420/938 Loss D: 0.3550, Loss G: 2.3425\n",
      "Epoch [71/85] Batch 430/938 Loss D: 0.2670, Loss G: 2.2262\n",
      "Epoch [71/85] Batch 440/938 Loss D: 0.2643, Loss G: 3.2612\n",
      "Epoch [71/85] Batch 450/938 Loss D: 0.4032, Loss G: 1.9558\n",
      "Epoch [71/85] Batch 460/938 Loss D: 0.3530, Loss G: 2.3997\n",
      "Epoch [71/85] Batch 470/938 Loss D: 0.3696, Loss G: 2.9952\n",
      "Epoch [71/85] Batch 480/938 Loss D: 0.3714, Loss G: 2.1872\n",
      "Epoch [71/85] Batch 490/938 Loss D: 0.1996, Loss G: 2.3950\n",
      "Epoch [71/85] Batch 500/938 Loss D: 0.2140, Loss G: 2.9721\n",
      "Epoch [71/85] Batch 510/938 Loss D: 0.4291, Loss G: 1.8472\n",
      "Epoch [71/85] Batch 520/938 Loss D: 0.3116, Loss G: 2.2042\n",
      "Epoch [71/85] Batch 530/938 Loss D: 0.2961, Loss G: 2.8528\n",
      "Epoch [71/85] Batch 540/938 Loss D: 0.2510, Loss G: 2.8449\n",
      "Epoch [71/85] Batch 550/938 Loss D: 0.3221, Loss G: 2.2597\n",
      "Epoch [71/85] Batch 560/938 Loss D: 0.2001, Loss G: 2.3353\n",
      "Epoch [71/85] Batch 570/938 Loss D: 0.5390, Loss G: 2.7878\n",
      "Epoch [71/85] Batch 580/938 Loss D: 0.1790, Loss G: 3.5258\n",
      "Epoch [71/85] Batch 590/938 Loss D: 0.3084, Loss G: 3.2554\n",
      "Epoch [71/85] Batch 600/938 Loss D: 0.1361, Loss G: 3.5112\n",
      "Epoch [71/85] Batch 610/938 Loss D: 0.1547, Loss G: 3.2399\n",
      "Epoch [71/85] Batch 620/938 Loss D: 0.3132, Loss G: 2.2554\n",
      "Epoch [71/85] Batch 630/938 Loss D: 0.2494, Loss G: 2.4020\n",
      "Epoch [71/85] Batch 640/938 Loss D: 0.3543, Loss G: 1.7015\n",
      "Epoch [71/85] Batch 650/938 Loss D: 0.2673, Loss G: 2.3766\n",
      "Epoch [71/85] Batch 660/938 Loss D: 0.2506, Loss G: 2.5414\n",
      "Epoch [71/85] Batch 670/938 Loss D: 0.3305, Loss G: 2.1621\n",
      "Epoch [71/85] Batch 680/938 Loss D: 0.2961, Loss G: 2.2804\n",
      "Epoch [71/85] Batch 690/938 Loss D: 0.3025, Loss G: 3.0304\n",
      "Epoch [71/85] Batch 700/938 Loss D: 0.3012, Loss G: 2.7105\n",
      "Epoch [71/85] Batch 710/938 Loss D: 0.4557, Loss G: 1.7975\n",
      "Epoch [71/85] Batch 720/938 Loss D: 0.3715, Loss G: 2.0636\n",
      "Epoch [71/85] Batch 730/938 Loss D: 0.2408, Loss G: 2.5365\n",
      "Epoch [71/85] Batch 740/938 Loss D: 0.3063, Loss G: 2.9278\n",
      "Epoch [71/85] Batch 750/938 Loss D: 0.2230, Loss G: 3.0002\n",
      "Epoch [71/85] Batch 760/938 Loss D: 0.2507, Loss G: 4.8894\n",
      "Epoch [71/85] Batch 770/938 Loss D: 0.3101, Loss G: 2.8536\n",
      "Epoch [71/85] Batch 780/938 Loss D: 0.2035, Loss G: 3.4061\n",
      "Epoch [71/85] Batch 790/938 Loss D: 0.3369, Loss G: 2.2294\n",
      "Epoch [71/85] Batch 800/938 Loss D: 0.3481, Loss G: 1.9080\n",
      "Epoch [71/85] Batch 810/938 Loss D: 0.1864, Loss G: 2.5950\n",
      "Epoch [71/85] Batch 820/938 Loss D: 0.3079, Loss G: 2.3267\n",
      "Epoch [71/85] Batch 830/938 Loss D: 0.2767, Loss G: 2.8610\n",
      "Epoch [71/85] Batch 840/938 Loss D: 0.5332, Loss G: 2.1400\n",
      "Epoch [71/85] Batch 850/938 Loss D: 0.1624, Loss G: 4.2368\n",
      "Epoch [71/85] Batch 860/938 Loss D: 0.3182, Loss G: 2.1687\n",
      "Epoch [71/85] Batch 870/938 Loss D: 0.3180, Loss G: 2.1563\n",
      "Epoch [71/85] Batch 880/938 Loss D: 0.2482, Loss G: 2.4698\n",
      "Epoch [71/85] Batch 890/938 Loss D: 0.3369, Loss G: 1.8247\n",
      "Epoch [71/85] Batch 900/938 Loss D: 0.3085, Loss G: 2.7976\n",
      "Epoch [71/85] Batch 910/938 Loss D: 0.2232, Loss G: 2.8347\n",
      "Epoch [71/85] Batch 920/938 Loss D: 0.2300, Loss G: 2.9162\n",
      "Epoch [71/85] Batch 930/938 Loss D: 0.2702, Loss G: 2.6076\n",
      "Epoch [72/85] Batch 0/938 Loss D: 0.3577, Loss G: 1.9449\n",
      "Epoch [72/85] Batch 10/938 Loss D: 0.3686, Loss G: 1.5527\n",
      "Epoch [72/85] Batch 20/938 Loss D: 0.3496, Loss G: 2.5321\n",
      "Epoch [72/85] Batch 30/938 Loss D: 0.2869, Loss G: 3.8502\n",
      "Epoch [72/85] Batch 40/938 Loss D: 0.2436, Loss G: 2.9266\n",
      "Epoch [72/85] Batch 50/938 Loss D: 0.3125, Loss G: 2.4141\n",
      "Epoch [72/85] Batch 60/938 Loss D: 0.2728, Loss G: 2.6265\n",
      "Epoch [72/85] Batch 70/938 Loss D: 0.2945, Loss G: 2.0638\n",
      "Epoch [72/85] Batch 80/938 Loss D: 0.3059, Loss G: 2.4687\n",
      "Epoch [72/85] Batch 90/938 Loss D: 0.3803, Loss G: 2.0079\n",
      "Epoch [72/85] Batch 100/938 Loss D: 0.3392, Loss G: 2.2453\n",
      "Epoch [72/85] Batch 110/938 Loss D: 0.3357, Loss G: 2.7481\n",
      "Epoch [72/85] Batch 120/938 Loss D: 0.1962, Loss G: 2.9713\n",
      "Epoch [72/85] Batch 130/938 Loss D: 0.3427, Loss G: 2.3675\n",
      "Epoch [72/85] Batch 140/938 Loss D: 0.3779, Loss G: 1.8665\n",
      "Epoch [72/85] Batch 150/938 Loss D: 0.3123, Loss G: 2.1151\n",
      "Epoch [72/85] Batch 160/938 Loss D: 0.3126, Loss G: 1.8853\n",
      "Epoch [72/85] Batch 170/938 Loss D: 0.3677, Loss G: 2.4364\n",
      "Epoch [72/85] Batch 180/938 Loss D: 0.2767, Loss G: 2.4268\n",
      "Epoch [72/85] Batch 190/938 Loss D: 0.4704, Loss G: 2.1153\n",
      "Epoch [72/85] Batch 200/938 Loss D: 0.2389, Loss G: 2.6539\n",
      "Epoch [72/85] Batch 210/938 Loss D: 0.3102, Loss G: 2.7831\n",
      "Epoch [72/85] Batch 220/938 Loss D: 0.2828, Loss G: 2.3277\n",
      "Epoch [72/85] Batch 230/938 Loss D: 0.2950, Loss G: 2.5364\n",
      "Epoch [72/85] Batch 240/938 Loss D: 0.3485, Loss G: 1.8949\n",
      "Epoch [72/85] Batch 250/938 Loss D: 0.2018, Loss G: 3.3042\n",
      "Epoch [72/85] Batch 260/938 Loss D: 0.3125, Loss G: 2.2259\n",
      "Epoch [72/85] Batch 270/938 Loss D: 0.1674, Loss G: 2.8941\n",
      "Epoch [72/85] Batch 280/938 Loss D: 0.3039, Loss G: 2.3401\n",
      "Epoch [72/85] Batch 290/938 Loss D: 0.3017, Loss G: 1.9733\n",
      "Epoch [72/85] Batch 300/938 Loss D: 0.2415, Loss G: 2.6024\n",
      "Epoch [72/85] Batch 310/938 Loss D: 0.1850, Loss G: 2.9132\n",
      "Epoch [72/85] Batch 320/938 Loss D: 0.3482, Loss G: 2.9923\n",
      "Epoch [72/85] Batch 330/938 Loss D: 0.3317, Loss G: 3.0050\n",
      "Epoch [72/85] Batch 340/938 Loss D: 0.2289, Loss G: 2.6938\n",
      "Epoch [72/85] Batch 350/938 Loss D: 0.2239, Loss G: 2.4443\n",
      "Epoch [72/85] Batch 360/938 Loss D: 0.2928, Loss G: 2.1629\n",
      "Epoch [72/85] Batch 370/938 Loss D: 0.3001, Loss G: 2.3391\n",
      "Epoch [72/85] Batch 380/938 Loss D: 0.3966, Loss G: 2.2923\n",
      "Epoch [72/85] Batch 390/938 Loss D: 0.2383, Loss G: 3.1696\n",
      "Epoch [72/85] Batch 400/938 Loss D: 0.3519, Loss G: 2.2993\n",
      "Epoch [72/85] Batch 410/938 Loss D: 0.2778, Loss G: 2.7432\n",
      "Epoch [72/85] Batch 420/938 Loss D: 0.3017, Loss G: 2.7873\n",
      "Epoch [72/85] Batch 430/938 Loss D: 0.2356, Loss G: 2.9578\n",
      "Epoch [72/85] Batch 440/938 Loss D: 0.5325, Loss G: 1.5520\n",
      "Epoch [72/85] Batch 450/938 Loss D: 0.1856, Loss G: 3.0235\n",
      "Epoch [72/85] Batch 460/938 Loss D: 0.2596, Loss G: 2.6390\n",
      "Epoch [72/85] Batch 470/938 Loss D: 0.2044, Loss G: 2.6206\n",
      "Epoch [72/85] Batch 480/938 Loss D: 0.2679, Loss G: 2.0899\n",
      "Epoch [72/85] Batch 490/938 Loss D: 0.2761, Loss G: 2.5678\n",
      "Epoch [72/85] Batch 500/938 Loss D: 0.5055, Loss G: 1.9283\n",
      "Epoch [72/85] Batch 510/938 Loss D: 0.2694, Loss G: 3.0501\n",
      "Epoch [72/85] Batch 520/938 Loss D: 0.5157, Loss G: 3.4862\n",
      "Epoch [72/85] Batch 530/938 Loss D: 0.3145, Loss G: 3.1269\n",
      "Epoch [72/85] Batch 540/938 Loss D: 0.4089, Loss G: 2.5682\n",
      "Epoch [72/85] Batch 550/938 Loss D: 0.3109, Loss G: 2.2170\n",
      "Epoch [72/85] Batch 560/938 Loss D: 0.1882, Loss G: 2.6571\n",
      "Epoch [72/85] Batch 570/938 Loss D: 0.2899, Loss G: 3.2659\n",
      "Epoch [72/85] Batch 580/938 Loss D: 0.2099, Loss G: 2.6618\n",
      "Epoch [72/85] Batch 590/938 Loss D: 0.2782, Loss G: 2.8124\n",
      "Epoch [72/85] Batch 600/938 Loss D: 0.2657, Loss G: 2.3039\n",
      "Epoch [72/85] Batch 610/938 Loss D: 0.2633, Loss G: 2.4861\n",
      "Epoch [72/85] Batch 620/938 Loss D: 0.5335, Loss G: 1.6382\n",
      "Epoch [72/85] Batch 630/938 Loss D: 0.3868, Loss G: 2.1651\n",
      "Epoch [72/85] Batch 640/938 Loss D: 0.3650, Loss G: 2.1639\n",
      "Epoch [72/85] Batch 650/938 Loss D: 0.3108, Loss G: 2.3058\n",
      "Epoch [72/85] Batch 660/938 Loss D: 0.2923, Loss G: 2.4170\n",
      "Epoch [72/85] Batch 670/938 Loss D: 0.3728, Loss G: 1.8348\n",
      "Epoch [72/85] Batch 680/938 Loss D: 0.3362, Loss G: 2.4906\n",
      "Epoch [72/85] Batch 690/938 Loss D: 0.3268, Loss G: 2.7280\n",
      "Epoch [72/85] Batch 700/938 Loss D: 0.3690, Loss G: 2.1405\n",
      "Epoch [72/85] Batch 710/938 Loss D: 0.2983, Loss G: 2.3741\n",
      "Epoch [72/85] Batch 720/938 Loss D: 0.2796, Loss G: 2.1366\n",
      "Epoch [72/85] Batch 730/938 Loss D: 0.3515, Loss G: 2.1499\n",
      "Epoch [72/85] Batch 740/938 Loss D: 0.3265, Loss G: 2.0690\n",
      "Epoch [72/85] Batch 750/938 Loss D: 0.2529, Loss G: 2.4414\n",
      "Epoch [72/85] Batch 760/938 Loss D: 0.2207, Loss G: 2.9967\n",
      "Epoch [72/85] Batch 770/938 Loss D: 0.3306, Loss G: 2.6237\n",
      "Epoch [72/85] Batch 780/938 Loss D: 0.3676, Loss G: 2.3619\n",
      "Epoch [72/85] Batch 790/938 Loss D: 0.2372, Loss G: 2.6436\n",
      "Epoch [72/85] Batch 800/938 Loss D: 0.2844, Loss G: 2.2498\n",
      "Epoch [72/85] Batch 810/938 Loss D: 0.2826, Loss G: 2.4415\n",
      "Epoch [72/85] Batch 820/938 Loss D: 0.3049, Loss G: 2.8602\n",
      "Epoch [72/85] Batch 830/938 Loss D: 0.3949, Loss G: 2.2970\n",
      "Epoch [72/85] Batch 840/938 Loss D: 0.2974, Loss G: 1.7963\n",
      "Epoch [72/85] Batch 850/938 Loss D: 0.3138, Loss G: 2.8568\n",
      "Epoch [72/85] Batch 860/938 Loss D: 0.3260, Loss G: 2.9475\n",
      "Epoch [72/85] Batch 870/938 Loss D: 0.2757, Loss G: 2.6983\n",
      "Epoch [72/85] Batch 880/938 Loss D: 0.4145, Loss G: 1.8431\n",
      "Epoch [72/85] Batch 890/938 Loss D: 0.1513, Loss G: 3.3676\n",
      "Epoch [72/85] Batch 900/938 Loss D: 0.2693, Loss G: 3.1915\n",
      "Epoch [72/85] Batch 910/938 Loss D: 0.3231, Loss G: 2.2416\n",
      "Epoch [72/85] Batch 920/938 Loss D: 0.2403, Loss G: 2.4083\n",
      "Epoch [72/85] Batch 930/938 Loss D: 0.2224, Loss G: 2.7190\n",
      "Epoch [73/85] Batch 0/938 Loss D: 0.3184, Loss G: 2.1716\n",
      "Epoch [73/85] Batch 10/938 Loss D: 0.2926, Loss G: 1.9447\n",
      "Epoch [73/85] Batch 20/938 Loss D: 0.2654, Loss G: 3.1650\n",
      "Epoch [73/85] Batch 30/938 Loss D: 0.4113, Loss G: 2.1482\n",
      "Epoch [73/85] Batch 40/938 Loss D: 0.2856, Loss G: 2.6472\n",
      "Epoch [73/85] Batch 50/938 Loss D: 0.2652, Loss G: 2.1311\n",
      "Epoch [73/85] Batch 60/938 Loss D: 0.2357, Loss G: 2.2211\n",
      "Epoch [73/85] Batch 70/938 Loss D: 0.2682, Loss G: 2.5597\n",
      "Epoch [73/85] Batch 80/938 Loss D: 0.3700, Loss G: 2.3055\n",
      "Epoch [73/85] Batch 90/938 Loss D: 0.2795, Loss G: 2.0538\n",
      "Epoch [73/85] Batch 100/938 Loss D: 0.4068, Loss G: 2.0502\n",
      "Epoch [73/85] Batch 110/938 Loss D: 0.2914, Loss G: 2.7690\n",
      "Epoch [73/85] Batch 120/938 Loss D: 0.2573, Loss G: 2.6233\n",
      "Epoch [73/85] Batch 130/938 Loss D: 0.3613, Loss G: 1.9637\n",
      "Epoch [73/85] Batch 140/938 Loss D: 0.3448, Loss G: 2.3854\n",
      "Epoch [73/85] Batch 150/938 Loss D: 0.2752, Loss G: 2.1068\n",
      "Epoch [73/85] Batch 160/938 Loss D: 0.1767, Loss G: 2.7478\n",
      "Epoch [73/85] Batch 170/938 Loss D: 0.3522, Loss G: 2.2164\n",
      "Epoch [73/85] Batch 180/938 Loss D: 0.3427, Loss G: 2.0410\n",
      "Epoch [73/85] Batch 190/938 Loss D: 0.2708, Loss G: 2.4210\n",
      "Epoch [73/85] Batch 200/938 Loss D: 0.2863, Loss G: 2.9196\n",
      "Epoch [73/85] Batch 210/938 Loss D: 0.2398, Loss G: 2.9028\n",
      "Epoch [73/85] Batch 220/938 Loss D: 0.2888, Loss G: 3.0049\n",
      "Epoch [73/85] Batch 230/938 Loss D: 0.2866, Loss G: 2.3505\n",
      "Epoch [73/85] Batch 240/938 Loss D: 0.1555, Loss G: 2.9074\n",
      "Epoch [73/85] Batch 250/938 Loss D: 0.2295, Loss G: 2.9308\n",
      "Epoch [73/85] Batch 260/938 Loss D: 0.2226, Loss G: 3.5310\n",
      "Epoch [73/85] Batch 270/938 Loss D: 0.2047, Loss G: 2.3062\n",
      "Epoch [73/85] Batch 280/938 Loss D: 0.3093, Loss G: 2.3606\n",
      "Epoch [73/85] Batch 290/938 Loss D: 0.2930, Loss G: 2.6249\n",
      "Epoch [73/85] Batch 300/938 Loss D: 0.1692, Loss G: 3.5926\n",
      "Epoch [73/85] Batch 310/938 Loss D: 0.2694, Loss G: 2.4231\n",
      "Epoch [73/85] Batch 320/938 Loss D: 0.3354, Loss G: 2.0592\n",
      "Epoch [73/85] Batch 330/938 Loss D: 0.2348, Loss G: 3.3411\n",
      "Epoch [73/85] Batch 340/938 Loss D: 0.2804, Loss G: 2.8698\n",
      "Epoch [73/85] Batch 350/938 Loss D: 0.1232, Loss G: 3.8593\n",
      "Epoch [73/85] Batch 360/938 Loss D: 0.2387, Loss G: 2.6615\n",
      "Epoch [73/85] Batch 370/938 Loss D: 0.3459, Loss G: 2.1469\n",
      "Epoch [73/85] Batch 380/938 Loss D: 0.3258, Loss G: 1.8761\n",
      "Epoch [73/85] Batch 390/938 Loss D: 0.3109, Loss G: 2.5963\n",
      "Epoch [73/85] Batch 400/938 Loss D: 0.2778, Loss G: 2.3711\n",
      "Epoch [73/85] Batch 410/938 Loss D: 0.2230, Loss G: 2.4293\n",
      "Epoch [73/85] Batch 420/938 Loss D: 0.2805, Loss G: 1.8168\n",
      "Epoch [73/85] Batch 430/938 Loss D: 0.2897, Loss G: 2.1972\n",
      "Epoch [73/85] Batch 440/938 Loss D: 0.3978, Loss G: 2.4627\n",
      "Epoch [73/85] Batch 450/938 Loss D: 0.3077, Loss G: 3.0897\n",
      "Epoch [73/85] Batch 460/938 Loss D: 0.2730, Loss G: 2.5995\n",
      "Epoch [73/85] Batch 470/938 Loss D: 0.2434, Loss G: 2.5396\n",
      "Epoch [73/85] Batch 480/938 Loss D: 0.2106, Loss G: 2.2365\n",
      "Epoch [73/85] Batch 490/938 Loss D: 0.2295, Loss G: 2.5423\n",
      "Epoch [73/85] Batch 500/938 Loss D: 0.2779, Loss G: 2.7403\n",
      "Epoch [73/85] Batch 510/938 Loss D: 0.2499, Loss G: 2.1966\n",
      "Epoch [73/85] Batch 520/938 Loss D: 0.2194, Loss G: 2.2167\n",
      "Epoch [73/85] Batch 530/938 Loss D: 0.2397, Loss G: 3.2839\n",
      "Epoch [73/85] Batch 540/938 Loss D: 0.3077, Loss G: 2.4304\n",
      "Epoch [73/85] Batch 550/938 Loss D: 0.3891, Loss G: 2.1202\n",
      "Epoch [73/85] Batch 560/938 Loss D: 0.1809, Loss G: 2.3191\n",
      "Epoch [73/85] Batch 570/938 Loss D: 0.3172, Loss G: 1.7875\n",
      "Epoch [73/85] Batch 580/938 Loss D: 0.2293, Loss G: 2.9217\n",
      "Epoch [73/85] Batch 590/938 Loss D: 0.4217, Loss G: 2.8573\n",
      "Epoch [73/85] Batch 600/938 Loss D: 0.2568, Loss G: 2.8750\n",
      "Epoch [73/85] Batch 610/938 Loss D: 0.2381, Loss G: 2.6704\n",
      "Epoch [73/85] Batch 620/938 Loss D: 0.1486, Loss G: 2.5184\n",
      "Epoch [73/85] Batch 630/938 Loss D: 0.1940, Loss G: 3.3802\n",
      "Epoch [73/85] Batch 640/938 Loss D: 0.3069, Loss G: 2.8664\n",
      "Epoch [73/85] Batch 650/938 Loss D: 0.2290, Loss G: 2.9319\n",
      "Epoch [73/85] Batch 660/938 Loss D: 0.2238, Loss G: 3.5980\n",
      "Epoch [73/85] Batch 670/938 Loss D: 0.1546, Loss G: 3.9651\n",
      "Epoch [73/85] Batch 680/938 Loss D: 0.2324, Loss G: 3.1893\n",
      "Epoch [73/85] Batch 690/938 Loss D: 0.2899, Loss G: 2.6713\n",
      "Epoch [73/85] Batch 700/938 Loss D: 0.3214, Loss G: 2.5640\n",
      "Epoch [73/85] Batch 710/938 Loss D: 0.2669, Loss G: 2.3250\n",
      "Epoch [73/85] Batch 720/938 Loss D: 0.5223, Loss G: 1.5690\n",
      "Epoch [73/85] Batch 730/938 Loss D: 0.3473, Loss G: 2.6087\n",
      "Epoch [73/85] Batch 740/938 Loss D: 0.2419, Loss G: 2.5708\n",
      "Epoch [73/85] Batch 750/938 Loss D: 0.2982, Loss G: 3.0120\n",
      "Epoch [73/85] Batch 760/938 Loss D: 0.3381, Loss G: 1.9817\n",
      "Epoch [73/85] Batch 770/938 Loss D: 0.3071, Loss G: 2.3203\n",
      "Epoch [73/85] Batch 780/938 Loss D: 0.2803, Loss G: 3.2837\n",
      "Epoch [73/85] Batch 790/938 Loss D: 0.2519, Loss G: 2.4546\n",
      "Epoch [73/85] Batch 800/938 Loss D: 0.2698, Loss G: 3.0022\n",
      "Epoch [73/85] Batch 810/938 Loss D: 0.3065, Loss G: 2.7624\n",
      "Epoch [73/85] Batch 820/938 Loss D: 0.3454, Loss G: 2.5433\n",
      "Epoch [73/85] Batch 830/938 Loss D: 0.2370, Loss G: 2.3631\n",
      "Epoch [73/85] Batch 840/938 Loss D: 0.3372, Loss G: 2.3899\n",
      "Epoch [73/85] Batch 850/938 Loss D: 0.2518, Loss G: 3.3245\n",
      "Epoch [73/85] Batch 860/938 Loss D: 0.2481, Loss G: 3.0130\n",
      "Epoch [73/85] Batch 870/938 Loss D: 0.2748, Loss G: 2.3997\n",
      "Epoch [73/85] Batch 880/938 Loss D: 0.3624, Loss G: 1.9179\n",
      "Epoch [73/85] Batch 890/938 Loss D: 0.3234, Loss G: 1.8465\n",
      "Epoch [73/85] Batch 900/938 Loss D: 0.1877, Loss G: 3.0270\n",
      "Epoch [73/85] Batch 910/938 Loss D: 0.4167, Loss G: 3.2006\n",
      "Epoch [73/85] Batch 920/938 Loss D: 0.2440, Loss G: 3.3231\n",
      "Epoch [73/85] Batch 930/938 Loss D: 0.3274, Loss G: 2.7152\n",
      "Epoch [74/85] Batch 0/938 Loss D: 0.3798, Loss G: 1.5539\n",
      "Epoch [74/85] Batch 10/938 Loss D: 0.3225, Loss G: 2.1586\n",
      "Epoch [74/85] Batch 20/938 Loss D: 0.2501, Loss G: 3.6362\n",
      "Epoch [74/85] Batch 30/938 Loss D: 0.2111, Loss G: 2.9383\n",
      "Epoch [74/85] Batch 40/938 Loss D: 0.2509, Loss G: 2.7014\n",
      "Epoch [74/85] Batch 50/938 Loss D: 0.2236, Loss G: 2.5532\n",
      "Epoch [74/85] Batch 60/938 Loss D: 0.3636, Loss G: 2.3875\n",
      "Epoch [74/85] Batch 70/938 Loss D: 0.2273, Loss G: 3.1324\n",
      "Epoch [74/85] Batch 80/938 Loss D: 0.3098, Loss G: 3.1642\n",
      "Epoch [74/85] Batch 90/938 Loss D: 0.2682, Loss G: 2.2958\n",
      "Epoch [74/85] Batch 100/938 Loss D: 0.1988, Loss G: 2.7411\n",
      "Epoch [74/85] Batch 110/938 Loss D: 0.5076, Loss G: 2.0148\n",
      "Epoch [74/85] Batch 120/938 Loss D: 0.3561, Loss G: 2.7450\n",
      "Epoch [74/85] Batch 130/938 Loss D: 0.3153, Loss G: 2.1967\n",
      "Epoch [74/85] Batch 140/938 Loss D: 0.5098, Loss G: 2.2702\n",
      "Epoch [74/85] Batch 150/938 Loss D: 0.4171, Loss G: 2.2650\n",
      "Epoch [74/85] Batch 160/938 Loss D: 0.2808, Loss G: 3.0831\n",
      "Epoch [74/85] Batch 170/938 Loss D: 0.2036, Loss G: 3.2235\n",
      "Epoch [74/85] Batch 180/938 Loss D: 0.2386, Loss G: 2.3742\n",
      "Epoch [74/85] Batch 190/938 Loss D: 0.2184, Loss G: 2.6960\n",
      "Epoch [74/85] Batch 200/938 Loss D: 0.1889, Loss G: 3.4632\n",
      "Epoch [74/85] Batch 210/938 Loss D: 0.2814, Loss G: 2.5996\n",
      "Epoch [74/85] Batch 220/938 Loss D: 0.3771, Loss G: 2.2039\n",
      "Epoch [74/85] Batch 230/938 Loss D: 0.2376, Loss G: 2.5106\n",
      "Epoch [74/85] Batch 240/938 Loss D: 0.2788, Loss G: 2.3066\n",
      "Epoch [74/85] Batch 250/938 Loss D: 0.1287, Loss G: 3.0056\n",
      "Epoch [74/85] Batch 260/938 Loss D: 0.2468, Loss G: 2.5630\n",
      "Epoch [74/85] Batch 270/938 Loss D: 0.3653, Loss G: 2.4403\n",
      "Epoch [74/85] Batch 280/938 Loss D: 0.4584, Loss G: 2.1819\n",
      "Epoch [74/85] Batch 290/938 Loss D: 0.2848, Loss G: 2.5237\n",
      "Epoch [74/85] Batch 300/938 Loss D: 0.2860, Loss G: 2.2788\n",
      "Epoch [74/85] Batch 310/938 Loss D: 0.3936, Loss G: 1.9860\n",
      "Epoch [74/85] Batch 320/938 Loss D: 0.2912, Loss G: 2.5449\n",
      "Epoch [74/85] Batch 330/938 Loss D: 0.2932, Loss G: 2.1236\n",
      "Epoch [74/85] Batch 340/938 Loss D: 0.2553, Loss G: 2.9406\n",
      "Epoch [74/85] Batch 350/938 Loss D: 0.3781, Loss G: 2.1359\n",
      "Epoch [74/85] Batch 360/938 Loss D: 0.2389, Loss G: 2.2012\n",
      "Epoch [74/85] Batch 370/938 Loss D: 0.2930, Loss G: 2.1144\n",
      "Epoch [74/85] Batch 380/938 Loss D: 0.2985, Loss G: 3.1433\n",
      "Epoch [74/85] Batch 390/938 Loss D: 0.2103, Loss G: 3.2790\n",
      "Epoch [74/85] Batch 400/938 Loss D: 0.2789, Loss G: 3.6054\n",
      "Epoch [74/85] Batch 410/938 Loss D: 0.2314, Loss G: 2.4870\n",
      "Epoch [74/85] Batch 420/938 Loss D: 0.2143, Loss G: 2.6199\n",
      "Epoch [74/85] Batch 430/938 Loss D: 0.1690, Loss G: 3.7670\n",
      "Epoch [74/85] Batch 440/938 Loss D: 0.2122, Loss G: 3.5131\n",
      "Epoch [74/85] Batch 450/938 Loss D: 0.3456, Loss G: 2.3025\n",
      "Epoch [74/85] Batch 460/938 Loss D: 0.3378, Loss G: 2.0012\n",
      "Epoch [74/85] Batch 470/938 Loss D: 0.3422, Loss G: 3.1487\n",
      "Epoch [74/85] Batch 480/938 Loss D: 0.4150, Loss G: 2.2457\n",
      "Epoch [74/85] Batch 490/938 Loss D: 0.2886, Loss G: 2.1696\n",
      "Epoch [74/85] Batch 500/938 Loss D: 0.4543, Loss G: 1.9723\n",
      "Epoch [74/85] Batch 510/938 Loss D: 0.2808, Loss G: 2.1276\n",
      "Epoch [74/85] Batch 520/938 Loss D: 0.4785, Loss G: 1.4747\n",
      "Epoch [74/85] Batch 530/938 Loss D: 0.3216, Loss G: 2.0449\n",
      "Epoch [74/85] Batch 540/938 Loss D: 0.2988, Loss G: 2.5063\n",
      "Epoch [74/85] Batch 550/938 Loss D: 0.2919, Loss G: 2.4389\n",
      "Epoch [74/85] Batch 560/938 Loss D: 0.2187, Loss G: 2.7275\n",
      "Epoch [74/85] Batch 570/938 Loss D: 0.1877, Loss G: 2.8099\n",
      "Epoch [74/85] Batch 580/938 Loss D: 0.3089, Loss G: 2.9251\n",
      "Epoch [74/85] Batch 590/938 Loss D: 0.2113, Loss G: 2.6890\n",
      "Epoch [74/85] Batch 600/938 Loss D: 0.3024, Loss G: 1.8570\n",
      "Epoch [74/85] Batch 610/938 Loss D: 0.3567, Loss G: 1.8666\n",
      "Epoch [74/85] Batch 620/938 Loss D: 0.1445, Loss G: 2.9955\n",
      "Epoch [74/85] Batch 630/938 Loss D: 0.2148, Loss G: 2.7666\n",
      "Epoch [74/85] Batch 640/938 Loss D: 0.3804, Loss G: 1.8836\n",
      "Epoch [74/85] Batch 650/938 Loss D: 0.4229, Loss G: 2.4746\n",
      "Epoch [74/85] Batch 660/938 Loss D: 0.2521, Loss G: 2.4525\n",
      "Epoch [74/85] Batch 670/938 Loss D: 0.2183, Loss G: 2.1195\n",
      "Epoch [74/85] Batch 680/938 Loss D: 0.2487, Loss G: 3.2580\n",
      "Epoch [74/85] Batch 690/938 Loss D: 0.3285, Loss G: 3.3445\n",
      "Epoch [74/85] Batch 700/938 Loss D: 0.2124, Loss G: 2.6312\n",
      "Epoch [74/85] Batch 710/938 Loss D: 0.3650, Loss G: 2.1809\n",
      "Epoch [74/85] Batch 720/938 Loss D: 0.3426, Loss G: 1.6876\n",
      "Epoch [74/85] Batch 730/938 Loss D: 0.2380, Loss G: 2.8325\n",
      "Epoch [74/85] Batch 740/938 Loss D: 0.2556, Loss G: 2.4771\n",
      "Epoch [74/85] Batch 750/938 Loss D: 0.3134, Loss G: 2.1201\n",
      "Epoch [74/85] Batch 760/938 Loss D: 0.2858, Loss G: 2.2185\n",
      "Epoch [74/85] Batch 770/938 Loss D: 0.1993, Loss G: 2.9232\n",
      "Epoch [74/85] Batch 780/938 Loss D: 0.3317, Loss G: 2.4543\n",
      "Epoch [74/85] Batch 790/938 Loss D: 0.2040, Loss G: 4.0835\n",
      "Epoch [74/85] Batch 800/938 Loss D: 0.3432, Loss G: 2.0551\n",
      "Epoch [74/85] Batch 810/938 Loss D: 0.2426, Loss G: 2.9399\n",
      "Epoch [74/85] Batch 820/938 Loss D: 0.3165, Loss G: 2.9620\n",
      "Epoch [74/85] Batch 830/938 Loss D: 0.2654, Loss G: 2.7899\n",
      "Epoch [74/85] Batch 840/938 Loss D: 0.4086, Loss G: 2.5591\n",
      "Epoch [74/85] Batch 850/938 Loss D: 0.1952, Loss G: 2.6111\n",
      "Epoch [74/85] Batch 860/938 Loss D: 0.1915, Loss G: 2.9613\n",
      "Epoch [74/85] Batch 870/938 Loss D: 0.2060, Loss G: 3.9535\n",
      "Epoch [74/85] Batch 880/938 Loss D: 0.2721, Loss G: 2.3582\n",
      "Epoch [74/85] Batch 890/938 Loss D: 0.2812, Loss G: 2.0054\n",
      "Epoch [74/85] Batch 900/938 Loss D: 0.3495, Loss G: 2.0290\n",
      "Epoch [74/85] Batch 910/938 Loss D: 0.2881, Loss G: 2.4907\n",
      "Epoch [74/85] Batch 920/938 Loss D: 0.2937, Loss G: 2.6637\n",
      "Epoch [74/85] Batch 930/938 Loss D: 0.2638, Loss G: 2.5415\n",
      "Epoch [75/85] Batch 0/938 Loss D: 0.2949, Loss G: 1.6397\n",
      "Epoch [75/85] Batch 10/938 Loss D: 0.2716, Loss G: 2.5905\n",
      "Epoch [75/85] Batch 20/938 Loss D: 0.3442, Loss G: 2.6572\n",
      "Epoch [75/85] Batch 30/938 Loss D: 0.2336, Loss G: 2.3001\n",
      "Epoch [75/85] Batch 40/938 Loss D: 0.2492, Loss G: 2.1461\n",
      "Epoch [75/85] Batch 50/938 Loss D: 0.3060, Loss G: 2.3591\n",
      "Epoch [75/85] Batch 60/938 Loss D: 0.3476, Loss G: 2.5134\n",
      "Epoch [75/85] Batch 70/938 Loss D: 0.4257, Loss G: 1.9408\n",
      "Epoch [75/85] Batch 80/938 Loss D: 0.2432, Loss G: 3.5986\n",
      "Epoch [75/85] Batch 90/938 Loss D: 0.3412, Loss G: 2.4401\n",
      "Epoch [75/85] Batch 100/938 Loss D: 0.2026, Loss G: 2.8659\n",
      "Epoch [75/85] Batch 110/938 Loss D: 0.2719, Loss G: 2.8170\n",
      "Epoch [75/85] Batch 120/938 Loss D: 0.3119, Loss G: 2.5997\n",
      "Epoch [75/85] Batch 130/938 Loss D: 0.2068, Loss G: 3.8503\n",
      "Epoch [75/85] Batch 140/938 Loss D: 0.1720, Loss G: 3.9333\n",
      "Epoch [75/85] Batch 150/938 Loss D: 0.2007, Loss G: 3.4857\n",
      "Epoch [75/85] Batch 160/938 Loss D: 0.1638, Loss G: 3.9627\n",
      "Epoch [75/85] Batch 170/938 Loss D: 0.4551, Loss G: 2.0408\n",
      "Epoch [75/85] Batch 180/938 Loss D: 0.2691, Loss G: 2.0872\n",
      "Epoch [75/85] Batch 190/938 Loss D: 0.3067, Loss G: 2.1475\n",
      "Epoch [75/85] Batch 200/938 Loss D: 0.2037, Loss G: 2.1916\n",
      "Epoch [75/85] Batch 210/938 Loss D: 0.3092, Loss G: 2.4714\n",
      "Epoch [75/85] Batch 220/938 Loss D: 0.1399, Loss G: 3.7954\n",
      "Epoch [75/85] Batch 230/938 Loss D: 0.2076, Loss G: 2.7425\n",
      "Epoch [75/85] Batch 240/938 Loss D: 0.3052, Loss G: 2.4099\n",
      "Epoch [75/85] Batch 250/938 Loss D: 0.2821, Loss G: 1.9845\n",
      "Epoch [75/85] Batch 260/938 Loss D: 0.2900, Loss G: 1.9569\n",
      "Epoch [75/85] Batch 270/938 Loss D: 0.3373, Loss G: 2.4994\n",
      "Epoch [75/85] Batch 280/938 Loss D: 0.3775, Loss G: 2.6377\n",
      "Epoch [75/85] Batch 290/938 Loss D: 0.1534, Loss G: 3.4102\n",
      "Epoch [75/85] Batch 300/938 Loss D: 0.2771, Loss G: 2.3069\n",
      "Epoch [75/85] Batch 310/938 Loss D: 0.3228, Loss G: 2.3706\n",
      "Epoch [75/85] Batch 320/938 Loss D: 0.2998, Loss G: 3.2455\n",
      "Epoch [75/85] Batch 330/938 Loss D: 0.2262, Loss G: 2.6658\n",
      "Epoch [75/85] Batch 340/938 Loss D: 0.3519, Loss G: 1.9057\n",
      "Epoch [75/85] Batch 350/938 Loss D: 0.3927, Loss G: 2.4209\n",
      "Epoch [75/85] Batch 360/938 Loss D: 0.3281, Loss G: 2.6968\n",
      "Epoch [75/85] Batch 370/938 Loss D: 0.2524, Loss G: 2.5905\n",
      "Epoch [75/85] Batch 380/938 Loss D: 0.2646, Loss G: 2.5941\n",
      "Epoch [75/85] Batch 390/938 Loss D: 0.2881, Loss G: 1.9633\n",
      "Epoch [75/85] Batch 400/938 Loss D: 0.1572, Loss G: 3.6468\n",
      "Epoch [75/85] Batch 410/938 Loss D: 0.2662, Loss G: 2.6713\n",
      "Epoch [75/85] Batch 420/938 Loss D: 0.5061, Loss G: 2.0008\n",
      "Epoch [75/85] Batch 430/938 Loss D: 0.2086, Loss G: 2.9948\n",
      "Epoch [75/85] Batch 440/938 Loss D: 0.3993, Loss G: 1.9434\n",
      "Epoch [75/85] Batch 450/938 Loss D: 0.3661, Loss G: 2.5324\n",
      "Epoch [75/85] Batch 460/938 Loss D: 0.2890, Loss G: 2.6638\n",
      "Epoch [75/85] Batch 470/938 Loss D: 0.2960, Loss G: 2.6748\n",
      "Epoch [75/85] Batch 480/938 Loss D: 0.2202, Loss G: 4.1094\n",
      "Epoch [75/85] Batch 490/938 Loss D: 0.2078, Loss G: 3.5436\n",
      "Epoch [75/85] Batch 500/938 Loss D: 0.1656, Loss G: 3.8237\n",
      "Epoch [75/85] Batch 510/938 Loss D: 0.2680, Loss G: 3.0052\n",
      "Epoch [75/85] Batch 520/938 Loss D: 0.2166, Loss G: 3.2211\n",
      "Epoch [75/85] Batch 530/938 Loss D: 0.2072, Loss G: 2.9983\n",
      "Epoch [75/85] Batch 540/938 Loss D: 0.3008, Loss G: 2.6621\n",
      "Epoch [75/85] Batch 550/938 Loss D: 0.3045, Loss G: 3.3512\n",
      "Epoch [75/85] Batch 560/938 Loss D: 0.2935, Loss G: 2.2743\n",
      "Epoch [75/85] Batch 570/938 Loss D: 0.4243, Loss G: 2.2487\n",
      "Epoch [75/85] Batch 580/938 Loss D: 0.3437, Loss G: 1.8226\n",
      "Epoch [75/85] Batch 590/938 Loss D: 0.2865, Loss G: 2.4145\n",
      "Epoch [75/85] Batch 600/938 Loss D: 0.2657, Loss G: 1.9330\n",
      "Epoch [75/85] Batch 610/938 Loss D: 0.2626, Loss G: 2.9581\n",
      "Epoch [75/85] Batch 620/938 Loss D: 0.2798, Loss G: 2.8813\n",
      "Epoch [75/85] Batch 630/938 Loss D: 0.2472, Loss G: 3.2366\n",
      "Epoch [75/85] Batch 640/938 Loss D: 0.3511, Loss G: 2.0777\n",
      "Epoch [75/85] Batch 650/938 Loss D: 0.3530, Loss G: 2.1359\n",
      "Epoch [75/85] Batch 660/938 Loss D: 0.3025, Loss G: 2.6074\n",
      "Epoch [75/85] Batch 670/938 Loss D: 0.2401, Loss G: 1.9243\n",
      "Epoch [75/85] Batch 680/938 Loss D: 0.2095, Loss G: 2.6268\n",
      "Epoch [75/85] Batch 690/938 Loss D: 0.2111, Loss G: 3.4682\n",
      "Epoch [75/85] Batch 700/938 Loss D: 0.1025, Loss G: 4.5581\n",
      "Epoch [75/85] Batch 710/938 Loss D: 0.2128, Loss G: 3.3016\n",
      "Epoch [75/85] Batch 720/938 Loss D: 0.4155, Loss G: 3.0538\n",
      "Epoch [75/85] Batch 730/938 Loss D: 0.2334, Loss G: 2.9074\n",
      "Epoch [75/85] Batch 740/938 Loss D: 0.4096, Loss G: 2.8176\n",
      "Epoch [75/85] Batch 750/938 Loss D: 0.3404, Loss G: 2.0973\n",
      "Epoch [75/85] Batch 760/938 Loss D: 0.2799, Loss G: 2.8521\n",
      "Epoch [75/85] Batch 770/938 Loss D: 0.2338, Loss G: 2.3427\n",
      "Epoch [75/85] Batch 780/938 Loss D: 0.2989, Loss G: 2.3875\n",
      "Epoch [75/85] Batch 790/938 Loss D: 0.3113, Loss G: 2.0260\n",
      "Epoch [75/85] Batch 800/938 Loss D: 0.2272, Loss G: 2.5264\n",
      "Epoch [75/85] Batch 810/938 Loss D: 0.2833, Loss G: 3.1859\n",
      "Epoch [75/85] Batch 820/938 Loss D: 0.2948, Loss G: 2.4042\n",
      "Epoch [75/85] Batch 830/938 Loss D: 0.3114, Loss G: 2.1839\n",
      "Epoch [75/85] Batch 840/938 Loss D: 0.2815, Loss G: 2.3909\n",
      "Epoch [75/85] Batch 850/938 Loss D: 0.1862, Loss G: 2.8901\n",
      "Epoch [75/85] Batch 860/938 Loss D: 0.2801, Loss G: 2.0059\n",
      "Epoch [75/85] Batch 870/938 Loss D: 0.3367, Loss G: 2.0580\n",
      "Epoch [75/85] Batch 880/938 Loss D: 0.1772, Loss G: 3.1669\n",
      "Epoch [75/85] Batch 890/938 Loss D: 0.3828, Loss G: 2.6189\n",
      "Epoch [75/85] Batch 900/938 Loss D: 0.2819, Loss G: 2.6433\n",
      "Epoch [75/85] Batch 910/938 Loss D: 0.4106, Loss G: 2.2130\n",
      "Epoch [75/85] Batch 920/938 Loss D: 0.1812, Loss G: 3.4837\n",
      "Epoch [75/85] Batch 930/938 Loss D: 0.2681, Loss G: 2.5290\n",
      "Epoch [76/85] Batch 0/938 Loss D: 0.1724, Loss G: 2.5480\n",
      "Epoch [76/85] Batch 10/938 Loss D: 0.2792, Loss G: 2.6636\n",
      "Epoch [76/85] Batch 20/938 Loss D: 0.3981, Loss G: 1.9719\n",
      "Epoch [76/85] Batch 30/938 Loss D: 0.1843, Loss G: 3.2717\n",
      "Epoch [76/85] Batch 40/938 Loss D: 0.1823, Loss G: 3.5254\n",
      "Epoch [76/85] Batch 50/938 Loss D: 0.2272, Loss G: 3.3240\n",
      "Epoch [76/85] Batch 60/938 Loss D: 0.3204, Loss G: 2.0568\n",
      "Epoch [76/85] Batch 70/938 Loss D: 0.2829, Loss G: 2.6807\n",
      "Epoch [76/85] Batch 80/938 Loss D: 0.2902, Loss G: 2.7040\n",
      "Epoch [76/85] Batch 90/938 Loss D: 0.3258, Loss G: 2.8080\n",
      "Epoch [76/85] Batch 100/938 Loss D: 0.1332, Loss G: 3.6818\n",
      "Epoch [76/85] Batch 110/938 Loss D: 0.3880, Loss G: 2.2274\n",
      "Epoch [76/85] Batch 120/938 Loss D: 0.2562, Loss G: 2.4929\n",
      "Epoch [76/85] Batch 130/938 Loss D: 0.2880, Loss G: 2.9372\n",
      "Epoch [76/85] Batch 140/938 Loss D: 0.2595, Loss G: 2.5231\n",
      "Epoch [76/85] Batch 150/938 Loss D: 0.2762, Loss G: 2.3197\n",
      "Epoch [76/85] Batch 160/938 Loss D: 0.3321, Loss G: 2.4514\n",
      "Epoch [76/85] Batch 170/938 Loss D: 0.2259, Loss G: 2.8354\n",
      "Epoch [76/85] Batch 180/938 Loss D: 0.2423, Loss G: 2.6686\n",
      "Epoch [76/85] Batch 190/938 Loss D: 0.2632, Loss G: 2.3140\n",
      "Epoch [76/85] Batch 200/938 Loss D: 0.2411, Loss G: 2.4831\n",
      "Epoch [76/85] Batch 210/938 Loss D: 0.2968, Loss G: 2.2548\n",
      "Epoch [76/85] Batch 220/938 Loss D: 0.3829, Loss G: 1.9796\n",
      "Epoch [76/85] Batch 230/938 Loss D: 0.3226, Loss G: 2.4667\n",
      "Epoch [76/85] Batch 240/938 Loss D: 0.2242, Loss G: 2.5974\n",
      "Epoch [76/85] Batch 250/938 Loss D: 0.2869, Loss G: 2.9015\n",
      "Epoch [76/85] Batch 260/938 Loss D: 0.2558, Loss G: 2.8762\n",
      "Epoch [76/85] Batch 270/938 Loss D: 0.2643, Loss G: 2.6797\n",
      "Epoch [76/85] Batch 280/938 Loss D: 0.2219, Loss G: 2.4978\n",
      "Epoch [76/85] Batch 290/938 Loss D: 0.2955, Loss G: 2.3069\n",
      "Epoch [76/85] Batch 300/938 Loss D: 0.4581, Loss G: 2.3862\n",
      "Epoch [76/85] Batch 310/938 Loss D: 0.2747, Loss G: 2.0541\n",
      "Epoch [76/85] Batch 320/938 Loss D: 0.1973, Loss G: 2.7406\n",
      "Epoch [76/85] Batch 330/938 Loss D: 0.2777, Loss G: 2.4188\n",
      "Epoch [76/85] Batch 340/938 Loss D: 0.2258, Loss G: 2.5969\n",
      "Epoch [76/85] Batch 350/938 Loss D: 0.3741, Loss G: 1.8935\n",
      "Epoch [76/85] Batch 360/938 Loss D: 0.2349, Loss G: 3.1050\n",
      "Epoch [76/85] Batch 370/938 Loss D: 0.3491, Loss G: 2.3982\n",
      "Epoch [76/85] Batch 380/938 Loss D: 0.3985, Loss G: 2.1011\n",
      "Epoch [76/85] Batch 390/938 Loss D: 0.2649, Loss G: 2.9529\n",
      "Epoch [76/85] Batch 400/938 Loss D: 0.1914, Loss G: 2.3608\n",
      "Epoch [76/85] Batch 410/938 Loss D: 0.1636, Loss G: 3.7582\n",
      "Epoch [76/85] Batch 420/938 Loss D: 0.2840, Loss G: 2.4060\n",
      "Epoch [76/85] Batch 430/938 Loss D: 0.2850, Loss G: 2.7114\n",
      "Epoch [76/85] Batch 440/938 Loss D: 0.2103, Loss G: 3.1992\n",
      "Epoch [76/85] Batch 450/938 Loss D: 0.3183, Loss G: 2.4659\n",
      "Epoch [76/85] Batch 460/938 Loss D: 0.2601, Loss G: 2.4557\n",
      "Epoch [76/85] Batch 470/938 Loss D: 0.2464, Loss G: 3.3537\n",
      "Epoch [76/85] Batch 480/938 Loss D: 0.3303, Loss G: 2.9307\n",
      "Epoch [76/85] Batch 490/938 Loss D: 0.3038, Loss G: 2.2523\n",
      "Epoch [76/85] Batch 500/938 Loss D: 0.3940, Loss G: 1.9292\n",
      "Epoch [76/85] Batch 510/938 Loss D: 0.2734, Loss G: 2.7064\n",
      "Epoch [76/85] Batch 520/938 Loss D: 0.3416, Loss G: 2.0242\n",
      "Epoch [76/85] Batch 530/938 Loss D: 0.4042, Loss G: 1.6854\n",
      "Epoch [76/85] Batch 540/938 Loss D: 0.2278, Loss G: 2.5253\n",
      "Epoch [76/85] Batch 550/938 Loss D: 0.3565, Loss G: 2.1109\n",
      "Epoch [76/85] Batch 560/938 Loss D: 0.2196, Loss G: 3.0053\n",
      "Epoch [76/85] Batch 570/938 Loss D: 0.3212, Loss G: 2.2204\n",
      "Epoch [76/85] Batch 580/938 Loss D: 0.4213, Loss G: 2.8020\n",
      "Epoch [76/85] Batch 590/938 Loss D: 0.2791, Loss G: 2.6103\n",
      "Epoch [76/85] Batch 600/938 Loss D: 0.3495, Loss G: 1.9798\n",
      "Epoch [76/85] Batch 610/938 Loss D: 0.2774, Loss G: 2.4795\n",
      "Epoch [76/85] Batch 620/938 Loss D: 0.3620, Loss G: 2.3008\n",
      "Epoch [76/85] Batch 630/938 Loss D: 0.3179, Loss G: 2.5893\n",
      "Epoch [76/85] Batch 640/938 Loss D: 0.1961, Loss G: 3.1042\n",
      "Epoch [76/85] Batch 650/938 Loss D: 0.2110, Loss G: 2.5235\n",
      "Epoch [76/85] Batch 660/938 Loss D: 0.3879, Loss G: 1.9712\n",
      "Epoch [76/85] Batch 670/938 Loss D: 0.2241, Loss G: 2.5076\n",
      "Epoch [76/85] Batch 680/938 Loss D: 0.3618, Loss G: 1.9188\n",
      "Epoch [76/85] Batch 690/938 Loss D: 0.2955, Loss G: 2.2394\n",
      "Epoch [76/85] Batch 700/938 Loss D: 0.3441, Loss G: 2.6900\n",
      "Epoch [76/85] Batch 710/938 Loss D: 0.2894, Loss G: 2.6814\n",
      "Epoch [76/85] Batch 720/938 Loss D: 0.3776, Loss G: 2.8758\n",
      "Epoch [76/85] Batch 730/938 Loss D: 0.2913, Loss G: 2.9877\n",
      "Epoch [76/85] Batch 740/938 Loss D: 0.1322, Loss G: 3.5439\n",
      "Epoch [76/85] Batch 750/938 Loss D: 0.2755, Loss G: 2.7904\n",
      "Epoch [76/85] Batch 760/938 Loss D: 0.2793, Loss G: 2.2603\n",
      "Epoch [76/85] Batch 770/938 Loss D: 0.3795, Loss G: 1.9531\n",
      "Epoch [76/85] Batch 780/938 Loss D: 0.2621, Loss G: 2.4931\n",
      "Epoch [76/85] Batch 790/938 Loss D: 0.2939, Loss G: 2.1094\n",
      "Epoch [76/85] Batch 800/938 Loss D: 0.3060, Loss G: 2.0754\n",
      "Epoch [76/85] Batch 810/938 Loss D: 0.2192, Loss G: 2.7033\n",
      "Epoch [76/85] Batch 820/938 Loss D: 0.2091, Loss G: 3.0360\n",
      "Epoch [76/85] Batch 830/938 Loss D: 0.2309, Loss G: 2.7608\n",
      "Epoch [76/85] Batch 840/938 Loss D: 0.2172, Loss G: 3.2203\n",
      "Epoch [76/85] Batch 850/938 Loss D: 0.2571, Loss G: 2.5044\n",
      "Epoch [76/85] Batch 860/938 Loss D: 0.2392, Loss G: 2.9324\n",
      "Epoch [76/85] Batch 870/938 Loss D: 0.3292, Loss G: 2.5244\n",
      "Epoch [76/85] Batch 880/938 Loss D: 0.2667, Loss G: 2.5253\n",
      "Epoch [76/85] Batch 890/938 Loss D: 0.3358, Loss G: 2.3312\n",
      "Epoch [76/85] Batch 900/938 Loss D: 0.3749, Loss G: 1.9194\n",
      "Epoch [76/85] Batch 910/938 Loss D: 0.2083, Loss G: 3.6525\n",
      "Epoch [76/85] Batch 920/938 Loss D: 0.3133, Loss G: 3.7803\n",
      "Epoch [76/85] Batch 930/938 Loss D: 0.3541, Loss G: 2.3819\n",
      "Epoch [77/85] Batch 0/938 Loss D: 0.2787, Loss G: 2.0255\n",
      "Epoch [77/85] Batch 10/938 Loss D: 0.1435, Loss G: 2.7655\n",
      "Epoch [77/85] Batch 20/938 Loss D: 0.1836, Loss G: 3.8061\n",
      "Epoch [77/85] Batch 30/938 Loss D: 0.2063, Loss G: 3.0093\n",
      "Epoch [77/85] Batch 40/938 Loss D: 0.2808, Loss G: 2.4197\n",
      "Epoch [77/85] Batch 50/938 Loss D: 0.2450, Loss G: 2.8053\n",
      "Epoch [77/85] Batch 60/938 Loss D: 0.0718, Loss G: 3.9440\n",
      "Epoch [77/85] Batch 70/938 Loss D: 0.2353, Loss G: 3.2538\n",
      "Epoch [77/85] Batch 80/938 Loss D: 0.1885, Loss G: 2.6150\n",
      "Epoch [77/85] Batch 90/938 Loss D: 0.2409, Loss G: 2.8152\n",
      "Epoch [77/85] Batch 100/938 Loss D: 0.1587, Loss G: 3.6964\n",
      "Epoch [77/85] Batch 110/938 Loss D: 0.2482, Loss G: 2.2306\n",
      "Epoch [77/85] Batch 120/938 Loss D: 0.2773, Loss G: 2.5863\n",
      "Epoch [77/85] Batch 130/938 Loss D: 0.2383, Loss G: 2.5537\n",
      "Epoch [77/85] Batch 140/938 Loss D: 0.3164, Loss G: 2.0019\n",
      "Epoch [77/85] Batch 150/938 Loss D: 0.2666, Loss G: 2.6475\n",
      "Epoch [77/85] Batch 160/938 Loss D: 0.3117, Loss G: 2.6523\n",
      "Epoch [77/85] Batch 170/938 Loss D: 0.3251, Loss G: 2.4660\n",
      "Epoch [77/85] Batch 180/938 Loss D: 0.3063, Loss G: 2.5030\n",
      "Epoch [77/85] Batch 190/938 Loss D: 0.2220, Loss G: 2.5027\n",
      "Epoch [77/85] Batch 200/938 Loss D: 0.3580, Loss G: 2.0070\n",
      "Epoch [77/85] Batch 210/938 Loss D: 0.2877, Loss G: 2.1222\n",
      "Epoch [77/85] Batch 220/938 Loss D: 0.2888, Loss G: 2.2320\n",
      "Epoch [77/85] Batch 230/938 Loss D: 0.5025, Loss G: 2.3530\n",
      "Epoch [77/85] Batch 240/938 Loss D: 0.3202, Loss G: 2.1223\n",
      "Epoch [77/85] Batch 250/938 Loss D: 0.3094, Loss G: 2.9933\n",
      "Epoch [77/85] Batch 260/938 Loss D: 0.2123, Loss G: 2.8100\n",
      "Epoch [77/85] Batch 270/938 Loss D: 0.2705, Loss G: 2.5431\n",
      "Epoch [77/85] Batch 280/938 Loss D: 0.2623, Loss G: 2.7244\n",
      "Epoch [77/85] Batch 290/938 Loss D: 0.2157, Loss G: 2.8888\n",
      "Epoch [77/85] Batch 300/938 Loss D: 0.3647, Loss G: 2.5613\n",
      "Epoch [77/85] Batch 310/938 Loss D: 0.3351, Loss G: 2.4956\n",
      "Epoch [77/85] Batch 320/938 Loss D: 0.2752, Loss G: 2.3267\n",
      "Epoch [77/85] Batch 330/938 Loss D: 0.2806, Loss G: 3.1116\n",
      "Epoch [77/85] Batch 340/938 Loss D: 0.3905, Loss G: 2.1843\n",
      "Epoch [77/85] Batch 350/938 Loss D: 0.2492, Loss G: 3.0785\n",
      "Epoch [77/85] Batch 360/938 Loss D: 0.2157, Loss G: 2.6566\n",
      "Epoch [77/85] Batch 370/938 Loss D: 0.2947, Loss G: 2.4209\n",
      "Epoch [77/85] Batch 380/938 Loss D: 0.2694, Loss G: 3.1607\n",
      "Epoch [77/85] Batch 390/938 Loss D: 0.3099, Loss G: 2.3821\n",
      "Epoch [77/85] Batch 400/938 Loss D: 0.3838, Loss G: 2.6989\n",
      "Epoch [77/85] Batch 410/938 Loss D: 0.2463, Loss G: 2.5346\n",
      "Epoch [77/85] Batch 420/938 Loss D: 0.3168, Loss G: 2.0306\n",
      "Epoch [77/85] Batch 430/938 Loss D: 0.4072, Loss G: 2.0289\n",
      "Epoch [77/85] Batch 440/938 Loss D: 0.2553, Loss G: 2.3090\n",
      "Epoch [77/85] Batch 450/938 Loss D: 0.3057, Loss G: 2.8763\n",
      "Epoch [77/85] Batch 460/938 Loss D: 0.2225, Loss G: 2.9090\n",
      "Epoch [77/85] Batch 470/938 Loss D: 0.3175, Loss G: 2.0616\n",
      "Epoch [77/85] Batch 480/938 Loss D: 0.3430, Loss G: 1.9261\n",
      "Epoch [77/85] Batch 490/938 Loss D: 0.2777, Loss G: 2.3494\n",
      "Epoch [77/85] Batch 500/938 Loss D: 0.2960, Loss G: 2.7365\n",
      "Epoch [77/85] Batch 510/938 Loss D: 0.3770, Loss G: 2.5834\n",
      "Epoch [77/85] Batch 520/938 Loss D: 0.2384, Loss G: 3.1775\n",
      "Epoch [77/85] Batch 530/938 Loss D: 0.2037, Loss G: 3.1056\n",
      "Epoch [77/85] Batch 540/938 Loss D: 0.2385, Loss G: 2.8343\n",
      "Epoch [77/85] Batch 550/938 Loss D: 0.2005, Loss G: 3.1088\n",
      "Epoch [77/85] Batch 560/938 Loss D: 0.4140, Loss G: 1.7097\n",
      "Epoch [77/85] Batch 570/938 Loss D: 0.3117, Loss G: 2.5706\n",
      "Epoch [77/85] Batch 580/938 Loss D: 0.1836, Loss G: 3.7688\n",
      "Epoch [77/85] Batch 590/938 Loss D: 0.1425, Loss G: 4.1444\n",
      "Epoch [77/85] Batch 600/938 Loss D: 0.1630, Loss G: 3.3877\n",
      "Epoch [77/85] Batch 610/938 Loss D: 0.0746, Loss G: 3.8238\n",
      "Epoch [77/85] Batch 620/938 Loss D: 0.1564, Loss G: 3.9792\n",
      "Epoch [77/85] Batch 630/938 Loss D: 0.2731, Loss G: 2.7764\n",
      "Epoch [77/85] Batch 640/938 Loss D: 0.2819, Loss G: 2.9519\n",
      "Epoch [77/85] Batch 650/938 Loss D: 0.2711, Loss G: 2.5515\n",
      "Epoch [77/85] Batch 660/938 Loss D: 0.4072, Loss G: 2.1776\n",
      "Epoch [77/85] Batch 670/938 Loss D: 0.3886, Loss G: 2.1299\n",
      "Epoch [77/85] Batch 680/938 Loss D: 0.3112, Loss G: 2.1633\n",
      "Epoch [77/85] Batch 690/938 Loss D: 0.3039, Loss G: 2.0233\n",
      "Epoch [77/85] Batch 700/938 Loss D: 0.2846, Loss G: 2.4396\n",
      "Epoch [77/85] Batch 710/938 Loss D: 0.1971, Loss G: 3.1475\n",
      "Epoch [77/85] Batch 720/938 Loss D: 0.2684, Loss G: 2.7588\n",
      "Epoch [77/85] Batch 730/938 Loss D: 0.3557, Loss G: 2.5357\n",
      "Epoch [77/85] Batch 740/938 Loss D: 0.2509, Loss G: 2.3443\n",
      "Epoch [77/85] Batch 750/938 Loss D: 0.3837, Loss G: 2.0241\n",
      "Epoch [77/85] Batch 760/938 Loss D: 0.3602, Loss G: 3.2561\n",
      "Epoch [77/85] Batch 770/938 Loss D: 0.2657, Loss G: 2.7071\n",
      "Epoch [77/85] Batch 780/938 Loss D: 0.2718, Loss G: 2.7447\n",
      "Epoch [77/85] Batch 790/938 Loss D: 0.4721, Loss G: 2.0132\n",
      "Epoch [77/85] Batch 800/938 Loss D: 0.2312, Loss G: 2.4611\n",
      "Epoch [77/85] Batch 810/938 Loss D: 0.3830, Loss G: 1.9725\n",
      "Epoch [77/85] Batch 820/938 Loss D: 0.3385, Loss G: 2.1355\n",
      "Epoch [77/85] Batch 830/938 Loss D: 0.2449, Loss G: 2.6740\n",
      "Epoch [77/85] Batch 840/938 Loss D: 0.2316, Loss G: 3.0147\n",
      "Epoch [77/85] Batch 850/938 Loss D: 0.3656, Loss G: 1.7763\n",
      "Epoch [77/85] Batch 860/938 Loss D: 0.4192, Loss G: 1.8047\n",
      "Epoch [77/85] Batch 870/938 Loss D: 0.2071, Loss G: 2.5603\n",
      "Epoch [77/85] Batch 880/938 Loss D: 0.1889, Loss G: 2.5687\n",
      "Epoch [77/85] Batch 890/938 Loss D: 0.1355, Loss G: 3.3913\n",
      "Epoch [77/85] Batch 900/938 Loss D: 0.2124, Loss G: 3.9780\n",
      "Epoch [77/85] Batch 910/938 Loss D: 0.2033, Loss G: 3.1113\n",
      "Epoch [77/85] Batch 920/938 Loss D: 0.3736, Loss G: 1.6333\n",
      "Epoch [77/85] Batch 930/938 Loss D: 0.2325, Loss G: 3.5194\n",
      "Epoch [78/85] Batch 0/938 Loss D: 0.2377, Loss G: 3.7931\n",
      "Epoch [78/85] Batch 10/938 Loss D: 0.2625, Loss G: 2.1448\n",
      "Epoch [78/85] Batch 20/938 Loss D: 0.3186, Loss G: 1.9677\n",
      "Epoch [78/85] Batch 30/938 Loss D: 0.1963, Loss G: 2.8669\n",
      "Epoch [78/85] Batch 40/938 Loss D: 0.2527, Loss G: 2.3648\n",
      "Epoch [78/85] Batch 50/938 Loss D: 0.2313, Loss G: 2.1030\n",
      "Epoch [78/85] Batch 60/938 Loss D: 0.3289, Loss G: 2.2248\n",
      "Epoch [78/85] Batch 70/938 Loss D: 0.2378, Loss G: 3.3315\n",
      "Epoch [78/85] Batch 80/938 Loss D: 0.2994, Loss G: 2.4543\n",
      "Epoch [78/85] Batch 90/938 Loss D: 0.2371, Loss G: 2.4537\n",
      "Epoch [78/85] Batch 100/938 Loss D: 0.3332, Loss G: 2.3005\n",
      "Epoch [78/85] Batch 110/938 Loss D: 0.2618, Loss G: 2.7991\n",
      "Epoch [78/85] Batch 120/938 Loss D: 0.2331, Loss G: 3.2252\n",
      "Epoch [78/85] Batch 130/938 Loss D: 0.1052, Loss G: 3.7262\n",
      "Epoch [78/85] Batch 140/938 Loss D: 0.1837, Loss G: 3.2526\n",
      "Epoch [78/85] Batch 150/938 Loss D: 0.2606, Loss G: 3.7954\n",
      "Epoch [78/85] Batch 160/938 Loss D: 0.2323, Loss G: 2.9299\n",
      "Epoch [78/85] Batch 170/938 Loss D: 0.4985, Loss G: 1.6967\n",
      "Epoch [78/85] Batch 180/938 Loss D: 0.3304, Loss G: 1.8296\n",
      "Epoch [78/85] Batch 190/938 Loss D: 0.3875, Loss G: 1.9600\n",
      "Epoch [78/85] Batch 200/938 Loss D: 0.3327, Loss G: 2.1703\n",
      "Epoch [78/85] Batch 210/938 Loss D: 0.2203, Loss G: 2.4950\n",
      "Epoch [78/85] Batch 220/938 Loss D: 0.3013, Loss G: 2.5144\n",
      "Epoch [78/85] Batch 230/938 Loss D: 0.3465, Loss G: 2.2337\n",
      "Epoch [78/85] Batch 240/938 Loss D: 0.2158, Loss G: 3.3006\n",
      "Epoch [78/85] Batch 250/938 Loss D: 0.2049, Loss G: 3.3121\n",
      "Epoch [78/85] Batch 260/938 Loss D: 0.2639, Loss G: 2.0962\n",
      "Epoch [78/85] Batch 270/938 Loss D: 0.3696, Loss G: 1.8002\n",
      "Epoch [78/85] Batch 280/938 Loss D: 0.2576, Loss G: 2.2939\n",
      "Epoch [78/85] Batch 290/938 Loss D: 0.2233, Loss G: 3.5941\n",
      "Epoch [78/85] Batch 300/938 Loss D: 0.2471, Loss G: 2.6500\n",
      "Epoch [78/85] Batch 310/938 Loss D: 0.2686, Loss G: 2.0417\n",
      "Epoch [78/85] Batch 320/938 Loss D: 0.1823, Loss G: 2.8869\n",
      "Epoch [78/85] Batch 330/938 Loss D: 0.3479, Loss G: 2.2689\n",
      "Epoch [78/85] Batch 340/938 Loss D: 0.1115, Loss G: 3.7895\n",
      "Epoch [78/85] Batch 350/938 Loss D: 0.3056, Loss G: 1.8481\n",
      "Epoch [78/85] Batch 360/938 Loss D: 0.2291, Loss G: 3.1914\n",
      "Epoch [78/85] Batch 370/938 Loss D: 0.2121, Loss G: 3.0387\n",
      "Epoch [78/85] Batch 380/938 Loss D: 0.2622, Loss G: 2.3771\n",
      "Epoch [78/85] Batch 390/938 Loss D: 0.3030, Loss G: 2.5596\n",
      "Epoch [78/85] Batch 400/938 Loss D: 0.1998, Loss G: 2.7058\n",
      "Epoch [78/85] Batch 410/938 Loss D: 0.2825, Loss G: 3.3011\n",
      "Epoch [78/85] Batch 420/938 Loss D: 0.2164, Loss G: 3.0345\n",
      "Epoch [78/85] Batch 430/938 Loss D: 0.3613, Loss G: 1.7076\n",
      "Epoch [78/85] Batch 440/938 Loss D: 0.3821, Loss G: 1.7257\n",
      "Epoch [78/85] Batch 450/938 Loss D: 0.3161, Loss G: 2.2230\n",
      "Epoch [78/85] Batch 460/938 Loss D: 0.3213, Loss G: 2.4000\n",
      "Epoch [78/85] Batch 470/938 Loss D: 0.2059, Loss G: 3.4924\n",
      "Epoch [78/85] Batch 480/938 Loss D: 0.3366, Loss G: 2.2453\n",
      "Epoch [78/85] Batch 490/938 Loss D: 0.2321, Loss G: 2.1294\n",
      "Epoch [78/85] Batch 500/938 Loss D: 0.4731, Loss G: 2.7847\n",
      "Epoch [78/85] Batch 510/938 Loss D: 0.3103, Loss G: 1.9276\n",
      "Epoch [78/85] Batch 520/938 Loss D: 0.3751, Loss G: 2.4775\n",
      "Epoch [78/85] Batch 530/938 Loss D: 0.3939, Loss G: 2.3360\n",
      "Epoch [78/85] Batch 540/938 Loss D: 0.3411, Loss G: 2.6869\n",
      "Epoch [78/85] Batch 550/938 Loss D: 0.2827, Loss G: 2.5743\n",
      "Epoch [78/85] Batch 560/938 Loss D: 0.3615, Loss G: 2.2776\n",
      "Epoch [78/85] Batch 570/938 Loss D: 0.2856, Loss G: 2.2249\n",
      "Epoch [78/85] Batch 580/938 Loss D: 0.1310, Loss G: 3.4220\n",
      "Epoch [78/85] Batch 590/938 Loss D: 0.1934, Loss G: 2.9122\n",
      "Epoch [78/85] Batch 600/938 Loss D: 0.1933, Loss G: 3.4597\n",
      "Epoch [78/85] Batch 610/938 Loss D: 0.3453, Loss G: 2.3949\n",
      "Epoch [78/85] Batch 620/938 Loss D: 0.1745, Loss G: 2.9850\n",
      "Epoch [78/85] Batch 630/938 Loss D: 0.2293, Loss G: 2.8418\n",
      "Epoch [78/85] Batch 640/938 Loss D: 0.2974, Loss G: 2.6452\n",
      "Epoch [78/85] Batch 650/938 Loss D: 0.2854, Loss G: 2.0314\n",
      "Epoch [78/85] Batch 660/938 Loss D: 0.3515, Loss G: 2.6192\n",
      "Epoch [78/85] Batch 670/938 Loss D: 0.3272, Loss G: 2.8925\n",
      "Epoch [78/85] Batch 680/938 Loss D: 0.1956, Loss G: 3.7948\n",
      "Epoch [78/85] Batch 690/938 Loss D: 0.2808, Loss G: 2.5325\n",
      "Epoch [78/85] Batch 700/938 Loss D: 0.3221, Loss G: 2.8502\n",
      "Epoch [78/85] Batch 710/938 Loss D: 0.2397, Loss G: 2.6431\n",
      "Epoch [78/85] Batch 720/938 Loss D: 0.4620, Loss G: 1.5702\n",
      "Epoch [78/85] Batch 730/938 Loss D: 0.3012, Loss G: 2.4790\n",
      "Epoch [78/85] Batch 740/938 Loss D: 0.2850, Loss G: 2.1943\n",
      "Epoch [78/85] Batch 750/938 Loss D: 0.2423, Loss G: 2.3533\n",
      "Epoch [78/85] Batch 760/938 Loss D: 0.3338, Loss G: 2.3459\n",
      "Epoch [78/85] Batch 770/938 Loss D: 0.3279, Loss G: 2.0007\n",
      "Epoch [78/85] Batch 780/938 Loss D: 0.2802, Loss G: 2.4104\n",
      "Epoch [78/85] Batch 790/938 Loss D: 0.3336, Loss G: 2.5643\n",
      "Epoch [78/85] Batch 800/938 Loss D: 0.3254, Loss G: 2.1825\n",
      "Epoch [78/85] Batch 810/938 Loss D: 0.2730, Loss G: 2.5707\n",
      "Epoch [78/85] Batch 820/938 Loss D: 0.3179, Loss G: 2.4867\n",
      "Epoch [78/85] Batch 830/938 Loss D: 0.2870, Loss G: 2.4016\n",
      "Epoch [78/85] Batch 840/938 Loss D: 0.2117, Loss G: 2.9548\n",
      "Epoch [78/85] Batch 850/938 Loss D: 0.5007, Loss G: 1.6133\n",
      "Epoch [78/85] Batch 860/938 Loss D: 0.2446, Loss G: 2.3558\n",
      "Epoch [78/85] Batch 870/938 Loss D: 0.3030, Loss G: 2.4244\n",
      "Epoch [78/85] Batch 880/938 Loss D: 0.3499, Loss G: 2.7667\n",
      "Epoch [78/85] Batch 890/938 Loss D: 0.2690, Loss G: 3.3150\n",
      "Epoch [78/85] Batch 900/938 Loss D: 0.2154, Loss G: 2.8835\n",
      "Epoch [78/85] Batch 910/938 Loss D: 0.4887, Loss G: 2.3947\n",
      "Epoch [78/85] Batch 920/938 Loss D: 0.1525, Loss G: 2.8856\n",
      "Epoch [78/85] Batch 930/938 Loss D: 0.3194, Loss G: 2.1994\n",
      "Epoch [79/85] Batch 0/938 Loss D: 0.1803, Loss G: 3.4050\n",
      "Epoch [79/85] Batch 10/938 Loss D: 0.2357, Loss G: 2.4791\n",
      "Epoch [79/85] Batch 20/938 Loss D: 0.1791, Loss G: 3.2476\n",
      "Epoch [79/85] Batch 30/938 Loss D: 0.2729, Loss G: 3.1886\n",
      "Epoch [79/85] Batch 40/938 Loss D: 0.2092, Loss G: 2.4254\n",
      "Epoch [79/85] Batch 50/938 Loss D: 0.3151, Loss G: 2.5520\n",
      "Epoch [79/85] Batch 60/938 Loss D: 0.3601, Loss G: 1.8142\n",
      "Epoch [79/85] Batch 70/938 Loss D: 0.2129, Loss G: 3.0592\n",
      "Epoch [79/85] Batch 80/938 Loss D: 0.1816, Loss G: 3.5422\n",
      "Epoch [79/85] Batch 90/938 Loss D: 0.3644, Loss G: 1.9665\n",
      "Epoch [79/85] Batch 100/938 Loss D: 0.3718, Loss G: 2.0180\n",
      "Epoch [79/85] Batch 110/938 Loss D: 0.2503, Loss G: 2.1585\n",
      "Epoch [79/85] Batch 120/938 Loss D: 0.1327, Loss G: 3.0268\n",
      "Epoch [79/85] Batch 130/938 Loss D: 0.2489, Loss G: 2.5335\n",
      "Epoch [79/85] Batch 140/938 Loss D: 0.2952, Loss G: 2.0371\n",
      "Epoch [79/85] Batch 150/938 Loss D: 0.3396, Loss G: 2.6245\n",
      "Epoch [79/85] Batch 160/938 Loss D: 0.2445, Loss G: 3.0310\n",
      "Epoch [79/85] Batch 170/938 Loss D: 0.3108, Loss G: 2.9441\n",
      "Epoch [79/85] Batch 180/938 Loss D: 0.2686, Loss G: 2.5154\n",
      "Epoch [79/85] Batch 190/938 Loss D: 0.3804, Loss G: 1.7435\n",
      "Epoch [79/85] Batch 200/938 Loss D: 0.4527, Loss G: 1.8185\n",
      "Epoch [79/85] Batch 210/938 Loss D: 0.3004, Loss G: 2.8995\n",
      "Epoch [79/85] Batch 220/938 Loss D: 0.2531, Loss G: 2.7097\n",
      "Epoch [79/85] Batch 230/938 Loss D: 0.3291, Loss G: 2.1612\n",
      "Epoch [79/85] Batch 240/938 Loss D: 0.2290, Loss G: 2.4034\n",
      "Epoch [79/85] Batch 250/938 Loss D: 0.1521, Loss G: 3.5486\n",
      "Epoch [79/85] Batch 260/938 Loss D: 0.3176, Loss G: 2.2982\n",
      "Epoch [79/85] Batch 270/938 Loss D: 0.2979, Loss G: 2.1239\n",
      "Epoch [79/85] Batch 280/938 Loss D: 0.2624, Loss G: 2.5331\n",
      "Epoch [79/85] Batch 290/938 Loss D: 0.1870, Loss G: 3.6638\n",
      "Epoch [79/85] Batch 300/938 Loss D: 0.2394, Loss G: 3.6855\n",
      "Epoch [79/85] Batch 310/938 Loss D: 0.1454, Loss G: 2.8926\n",
      "Epoch [79/85] Batch 320/938 Loss D: 0.2195, Loss G: 3.0272\n",
      "Epoch [79/85] Batch 330/938 Loss D: 0.2679, Loss G: 3.3358\n",
      "Epoch [79/85] Batch 340/938 Loss D: 0.2087, Loss G: 2.8437\n",
      "Epoch [79/85] Batch 350/938 Loss D: 0.1773, Loss G: 3.2510\n",
      "Epoch [79/85] Batch 360/938 Loss D: 0.1708, Loss G: 4.1191\n",
      "Epoch [79/85] Batch 370/938 Loss D: 0.2521, Loss G: 2.9333\n",
      "Epoch [79/85] Batch 380/938 Loss D: 0.2073, Loss G: 2.7235\n",
      "Epoch [79/85] Batch 390/938 Loss D: 0.2237, Loss G: 2.2737\n",
      "Epoch [79/85] Batch 400/938 Loss D: 0.4078, Loss G: 2.2056\n",
      "Epoch [79/85] Batch 410/938 Loss D: 0.2624, Loss G: 2.8280\n",
      "Epoch [79/85] Batch 420/938 Loss D: 0.3311, Loss G: 2.8180\n",
      "Epoch [79/85] Batch 430/938 Loss D: 0.2619, Loss G: 2.3181\n",
      "Epoch [79/85] Batch 440/938 Loss D: 0.2646, Loss G: 2.2058\n",
      "Epoch [79/85] Batch 450/938 Loss D: 0.3057, Loss G: 2.4007\n",
      "Epoch [79/85] Batch 460/938 Loss D: 0.1920, Loss G: 4.2416\n",
      "Epoch [79/85] Batch 470/938 Loss D: 0.3268, Loss G: 2.5258\n",
      "Epoch [79/85] Batch 480/938 Loss D: 0.4196, Loss G: 1.8725\n",
      "Epoch [79/85] Batch 490/938 Loss D: 0.2466, Loss G: 2.5683\n",
      "Epoch [79/85] Batch 500/938 Loss D: 0.1677, Loss G: 3.7438\n",
      "Epoch [79/85] Batch 510/938 Loss D: 0.1885, Loss G: 3.4634\n",
      "Epoch [79/85] Batch 520/938 Loss D: 0.2890, Loss G: 2.3240\n",
      "Epoch [79/85] Batch 530/938 Loss D: 0.1928, Loss G: 3.4207\n",
      "Epoch [79/85] Batch 540/938 Loss D: 0.4240, Loss G: 1.6428\n",
      "Epoch [79/85] Batch 550/938 Loss D: 0.2573, Loss G: 3.1523\n",
      "Epoch [79/85] Batch 560/938 Loss D: 0.2922, Loss G: 3.7429\n",
      "Epoch [79/85] Batch 570/938 Loss D: 0.3461, Loss G: 2.6453\n",
      "Epoch [79/85] Batch 580/938 Loss D: 0.2561, Loss G: 2.1552\n",
      "Epoch [79/85] Batch 590/938 Loss D: 0.3381, Loss G: 1.7260\n",
      "Epoch [79/85] Batch 600/938 Loss D: 0.2225, Loss G: 2.8219\n",
      "Epoch [79/85] Batch 610/938 Loss D: 0.2351, Loss G: 2.9871\n",
      "Epoch [79/85] Batch 620/938 Loss D: 0.3022, Loss G: 2.0646\n",
      "Epoch [79/85] Batch 630/938 Loss D: 0.2342, Loss G: 2.3512\n",
      "Epoch [79/85] Batch 640/938 Loss D: 0.2499, Loss G: 2.8508\n",
      "Epoch [79/85] Batch 650/938 Loss D: 0.3103, Loss G: 2.4678\n",
      "Epoch [79/85] Batch 660/938 Loss D: 0.2569, Loss G: 2.3219\n",
      "Epoch [79/85] Batch 670/938 Loss D: 0.1553, Loss G: 3.5749\n",
      "Epoch [79/85] Batch 680/938 Loss D: 0.2316, Loss G: 3.4590\n",
      "Epoch [79/85] Batch 690/938 Loss D: 0.2971, Loss G: 2.6992\n",
      "Epoch [79/85] Batch 700/938 Loss D: 0.1868, Loss G: 2.5439\n",
      "Epoch [79/85] Batch 710/938 Loss D: 0.2370, Loss G: 2.6122\n",
      "Epoch [79/85] Batch 720/938 Loss D: 0.3055, Loss G: 2.4871\n",
      "Epoch [79/85] Batch 730/938 Loss D: 0.3760, Loss G: 1.8242\n",
      "Epoch [79/85] Batch 740/938 Loss D: 0.2151, Loss G: 2.6779\n",
      "Epoch [79/85] Batch 750/938 Loss D: 0.2952, Loss G: 2.8985\n",
      "Epoch [79/85] Batch 760/938 Loss D: 0.4308, Loss G: 2.4503\n",
      "Epoch [79/85] Batch 770/938 Loss D: 0.3104, Loss G: 2.4996\n",
      "Epoch [79/85] Batch 780/938 Loss D: 0.2883, Loss G: 2.5967\n",
      "Epoch [79/85] Batch 790/938 Loss D: 0.2091, Loss G: 2.6661\n",
      "Epoch [79/85] Batch 800/938 Loss D: 0.3316, Loss G: 2.3648\n",
      "Epoch [79/85] Batch 810/938 Loss D: 0.1144, Loss G: 4.8829\n",
      "Epoch [79/85] Batch 820/938 Loss D: 0.2667, Loss G: 3.3895\n",
      "Epoch [79/85] Batch 830/938 Loss D: 0.2305, Loss G: 3.2518\n",
      "Epoch [79/85] Batch 840/938 Loss D: 0.2351, Loss G: 2.4071\n",
      "Epoch [79/85] Batch 850/938 Loss D: 0.2981, Loss G: 2.7623\n",
      "Epoch [79/85] Batch 860/938 Loss D: 0.2841, Loss G: 2.1634\n",
      "Epoch [79/85] Batch 870/938 Loss D: 0.3137, Loss G: 2.5338\n",
      "Epoch [79/85] Batch 880/938 Loss D: 0.3011, Loss G: 3.0278\n",
      "Epoch [79/85] Batch 890/938 Loss D: 0.4108, Loss G: 2.3535\n",
      "Epoch [79/85] Batch 900/938 Loss D: 0.3040, Loss G: 2.5231\n",
      "Epoch [79/85] Batch 910/938 Loss D: 0.4170, Loss G: 2.1586\n",
      "Epoch [79/85] Batch 920/938 Loss D: 0.3366, Loss G: 1.9563\n",
      "Epoch [79/85] Batch 930/938 Loss D: 0.1045, Loss G: 3.4232\n",
      "Epoch [80/85] Batch 0/938 Loss D: 0.2708, Loss G: 3.1138\n",
      "Epoch [80/85] Batch 10/938 Loss D: 0.3341, Loss G: 2.6985\n",
      "Epoch [80/85] Batch 20/938 Loss D: 0.3289, Loss G: 2.4684\n",
      "Epoch [80/85] Batch 30/938 Loss D: 0.3235, Loss G: 2.1192\n",
      "Epoch [80/85] Batch 40/938 Loss D: 0.2365, Loss G: 3.8928\n",
      "Epoch [80/85] Batch 50/938 Loss D: 0.1238, Loss G: 3.1795\n",
      "Epoch [80/85] Batch 60/938 Loss D: 0.2468, Loss G: 2.4229\n",
      "Epoch [80/85] Batch 70/938 Loss D: 0.3461, Loss G: 2.1164\n",
      "Epoch [80/85] Batch 80/938 Loss D: 0.4318, Loss G: 1.7151\n",
      "Epoch [80/85] Batch 90/938 Loss D: 0.3318, Loss G: 3.7743\n",
      "Epoch [80/85] Batch 100/938 Loss D: 0.2979, Loss G: 3.6145\n",
      "Epoch [80/85] Batch 110/938 Loss D: 0.2600, Loss G: 2.8467\n",
      "Epoch [80/85] Batch 120/938 Loss D: 0.1829, Loss G: 3.0479\n",
      "Epoch [80/85] Batch 130/938 Loss D: 0.2125, Loss G: 2.3357\n",
      "Epoch [80/85] Batch 140/938 Loss D: 0.1656, Loss G: 3.1958\n",
      "Epoch [80/85] Batch 150/938 Loss D: 0.2371, Loss G: 2.4132\n",
      "Epoch [80/85] Batch 160/938 Loss D: 0.4078, Loss G: 1.9665\n",
      "Epoch [80/85] Batch 170/938 Loss D: 0.2918, Loss G: 2.4712\n",
      "Epoch [80/85] Batch 180/938 Loss D: 0.2563, Loss G: 2.5713\n",
      "Epoch [80/85] Batch 190/938 Loss D: 0.2847, Loss G: 2.5260\n",
      "Epoch [80/85] Batch 200/938 Loss D: 0.2155, Loss G: 2.7317\n",
      "Epoch [80/85] Batch 210/938 Loss D: 0.2830, Loss G: 2.6855\n",
      "Epoch [80/85] Batch 220/938 Loss D: 0.3756, Loss G: 2.4425\n",
      "Epoch [80/85] Batch 230/938 Loss D: 0.3055, Loss G: 2.4194\n",
      "Epoch [80/85] Batch 240/938 Loss D: 0.3908, Loss G: 2.6503\n",
      "Epoch [80/85] Batch 250/938 Loss D: 0.3524, Loss G: 2.3009\n",
      "Epoch [80/85] Batch 260/938 Loss D: 0.3889, Loss G: 1.8790\n",
      "Epoch [80/85] Batch 270/938 Loss D: 0.2507, Loss G: 2.9168\n",
      "Epoch [80/85] Batch 280/938 Loss D: 0.2929, Loss G: 2.4107\n",
      "Epoch [80/85] Batch 290/938 Loss D: 0.2488, Loss G: 2.5933\n",
      "Epoch [80/85] Batch 300/938 Loss D: 0.2700, Loss G: 3.1292\n",
      "Epoch [80/85] Batch 310/938 Loss D: 0.3271, Loss G: 3.1600\n",
      "Epoch [80/85] Batch 320/938 Loss D: 0.2392, Loss G: 2.2272\n",
      "Epoch [80/85] Batch 330/938 Loss D: 0.2435, Loss G: 2.0933\n",
      "Epoch [80/85] Batch 340/938 Loss D: 0.5316, Loss G: 1.7804\n",
      "Epoch [80/85] Batch 350/938 Loss D: 0.4114, Loss G: 2.7408\n",
      "Epoch [80/85] Batch 360/938 Loss D: 0.2934, Loss G: 3.0629\n",
      "Epoch [80/85] Batch 370/938 Loss D: 0.3135, Loss G: 2.8902\n",
      "Epoch [80/85] Batch 380/938 Loss D: 0.3139, Loss G: 3.4450\n",
      "Epoch [80/85] Batch 390/938 Loss D: 0.2869, Loss G: 2.4314\n",
      "Epoch [80/85] Batch 400/938 Loss D: 0.1636, Loss G: 3.5767\n",
      "Epoch [80/85] Batch 410/938 Loss D: 0.3248, Loss G: 2.3051\n",
      "Epoch [80/85] Batch 420/938 Loss D: 0.3171, Loss G: 2.0312\n",
      "Epoch [80/85] Batch 430/938 Loss D: 0.3952, Loss G: 2.3175\n",
      "Epoch [80/85] Batch 440/938 Loss D: 0.2000, Loss G: 3.0471\n",
      "Epoch [80/85] Batch 450/938 Loss D: 0.3919, Loss G: 2.1471\n",
      "Epoch [80/85] Batch 460/938 Loss D: 0.2725, Loss G: 2.7665\n",
      "Epoch [80/85] Batch 470/938 Loss D: 0.1826, Loss G: 3.0468\n",
      "Epoch [80/85] Batch 480/938 Loss D: 0.3341, Loss G: 3.2516\n",
      "Epoch [80/85] Batch 490/938 Loss D: 0.5736, Loss G: 1.8910\n",
      "Epoch [80/85] Batch 500/938 Loss D: 0.4330, Loss G: 1.6955\n",
      "Epoch [80/85] Batch 510/938 Loss D: 0.4246, Loss G: 2.5155\n",
      "Epoch [80/85] Batch 520/938 Loss D: 0.3285, Loss G: 3.2346\n",
      "Epoch [80/85] Batch 530/938 Loss D: 0.2495, Loss G: 2.6588\n",
      "Epoch [80/85] Batch 540/938 Loss D: 0.4182, Loss G: 2.5336\n",
      "Epoch [80/85] Batch 550/938 Loss D: 0.3782, Loss G: 1.8785\n",
      "Epoch [80/85] Batch 560/938 Loss D: 0.2311, Loss G: 3.0388\n",
      "Epoch [80/85] Batch 570/938 Loss D: 0.2634, Loss G: 3.0228\n",
      "Epoch [80/85] Batch 580/938 Loss D: 0.2240, Loss G: 2.4502\n",
      "Epoch [80/85] Batch 590/938 Loss D: 0.2149, Loss G: 2.3679\n",
      "Epoch [80/85] Batch 600/938 Loss D: 0.1769, Loss G: 3.9793\n",
      "Epoch [80/85] Batch 610/938 Loss D: 0.3939, Loss G: 2.2519\n",
      "Epoch [80/85] Batch 620/938 Loss D: 0.3805, Loss G: 2.0408\n",
      "Epoch [80/85] Batch 630/938 Loss D: 0.2640, Loss G: 2.6296\n",
      "Epoch [80/85] Batch 640/938 Loss D: 0.3115, Loss G: 2.7032\n",
      "Epoch [80/85] Batch 650/938 Loss D: 0.3150, Loss G: 2.8064\n",
      "Epoch [80/85] Batch 660/938 Loss D: 0.2849, Loss G: 2.7240\n",
      "Epoch [80/85] Batch 670/938 Loss D: 0.3336, Loss G: 2.2063\n",
      "Epoch [80/85] Batch 680/938 Loss D: 0.2946, Loss G: 2.2397\n",
      "Epoch [80/85] Batch 690/938 Loss D: 0.2984, Loss G: 2.8165\n",
      "Epoch [80/85] Batch 700/938 Loss D: 0.4049, Loss G: 2.3938\n",
      "Epoch [80/85] Batch 710/938 Loss D: 0.3939, Loss G: 2.0802\n",
      "Epoch [80/85] Batch 720/938 Loss D: 0.3467, Loss G: 2.0574\n",
      "Epoch [80/85] Batch 730/938 Loss D: 0.3172, Loss G: 2.2059\n",
      "Epoch [80/85] Batch 740/938 Loss D: 0.4574, Loss G: 2.1222\n",
      "Epoch [80/85] Batch 750/938 Loss D: 0.2043, Loss G: 3.1541\n",
      "Epoch [80/85] Batch 760/938 Loss D: 0.2790, Loss G: 2.6988\n",
      "Epoch [80/85] Batch 770/938 Loss D: 0.2716, Loss G: 2.1374\n",
      "Epoch [80/85] Batch 780/938 Loss D: 0.3412, Loss G: 2.3972\n",
      "Epoch [80/85] Batch 790/938 Loss D: 0.2328, Loss G: 2.8462\n",
      "Epoch [80/85] Batch 800/938 Loss D: 0.2361, Loss G: 3.3164\n",
      "Epoch [80/85] Batch 810/938 Loss D: 0.2617, Loss G: 3.0296\n",
      "Epoch [80/85] Batch 820/938 Loss D: 0.3239, Loss G: 2.5233\n",
      "Epoch [80/85] Batch 830/938 Loss D: 0.3679, Loss G: 2.5030\n",
      "Epoch [80/85] Batch 840/938 Loss D: 0.2878, Loss G: 2.4503\n",
      "Epoch [80/85] Batch 850/938 Loss D: 0.2090, Loss G: 2.9871\n",
      "Epoch [80/85] Batch 860/938 Loss D: 0.2208, Loss G: 2.5732\n",
      "Epoch [80/85] Batch 870/938 Loss D: 0.4004, Loss G: 2.0676\n",
      "Epoch [80/85] Batch 880/938 Loss D: 0.3521, Loss G: 2.3068\n",
      "Epoch [80/85] Batch 890/938 Loss D: 0.3676, Loss G: 2.1703\n",
      "Epoch [80/85] Batch 900/938 Loss D: 0.2132, Loss G: 3.0733\n",
      "Epoch [80/85] Batch 910/938 Loss D: 0.2938, Loss G: 2.3698\n",
      "Epoch [80/85] Batch 920/938 Loss D: 0.2951, Loss G: 2.1856\n",
      "Epoch [80/85] Batch 930/938 Loss D: 0.2775, Loss G: 2.5099\n",
      "Epoch [81/85] Batch 0/938 Loss D: 0.1632, Loss G: 3.2327\n",
      "Epoch [81/85] Batch 10/938 Loss D: 0.3205, Loss G: 2.9161\n",
      "Epoch [81/85] Batch 20/938 Loss D: 0.3273, Loss G: 2.7348\n",
      "Epoch [81/85] Batch 30/938 Loss D: 0.3494, Loss G: 1.7324\n",
      "Epoch [81/85] Batch 40/938 Loss D: 0.1400, Loss G: 2.8112\n",
      "Epoch [81/85] Batch 50/938 Loss D: 0.3155, Loss G: 2.1962\n",
      "Epoch [81/85] Batch 60/938 Loss D: 0.2652, Loss G: 2.6089\n",
      "Epoch [81/85] Batch 70/938 Loss D: 0.3642, Loss G: 2.0457\n",
      "Epoch [81/85] Batch 80/938 Loss D: 0.2326, Loss G: 2.5625\n",
      "Epoch [81/85] Batch 90/938 Loss D: 0.2417, Loss G: 2.6413\n",
      "Epoch [81/85] Batch 100/938 Loss D: 0.3205, Loss G: 2.3570\n",
      "Epoch [81/85] Batch 110/938 Loss D: 0.1999, Loss G: 2.3381\n",
      "Epoch [81/85] Batch 120/938 Loss D: 0.2604, Loss G: 2.1171\n",
      "Epoch [81/85] Batch 130/938 Loss D: 0.4647, Loss G: 2.2069\n",
      "Epoch [81/85] Batch 140/938 Loss D: 0.2541, Loss G: 2.0745\n",
      "Epoch [81/85] Batch 150/938 Loss D: 0.1469, Loss G: 4.5274\n",
      "Epoch [81/85] Batch 160/938 Loss D: 0.2823, Loss G: 2.5499\n",
      "Epoch [81/85] Batch 170/938 Loss D: 0.3115, Loss G: 2.7075\n",
      "Epoch [81/85] Batch 180/938 Loss D: 0.3780, Loss G: 2.2318\n",
      "Epoch [81/85] Batch 190/938 Loss D: 0.3438, Loss G: 2.1675\n",
      "Epoch [81/85] Batch 200/938 Loss D: 0.1762, Loss G: 3.0684\n",
      "Epoch [81/85] Batch 210/938 Loss D: 0.2520, Loss G: 2.1827\n",
      "Epoch [81/85] Batch 220/938 Loss D: 0.1651, Loss G: 2.9373\n",
      "Epoch [81/85] Batch 230/938 Loss D: 0.3669, Loss G: 2.2711\n",
      "Epoch [81/85] Batch 240/938 Loss D: 0.2238, Loss G: 3.5080\n",
      "Epoch [81/85] Batch 250/938 Loss D: 0.2679, Loss G: 2.8712\n",
      "Epoch [81/85] Batch 260/938 Loss D: 0.2156, Loss G: 3.3898\n",
      "Epoch [81/85] Batch 270/938 Loss D: 0.1956, Loss G: 2.8934\n",
      "Epoch [81/85] Batch 280/938 Loss D: 0.4304, Loss G: 1.9246\n",
      "Epoch [81/85] Batch 290/938 Loss D: 0.2859, Loss G: 2.8263\n",
      "Epoch [81/85] Batch 300/938 Loss D: 0.2733, Loss G: 2.2596\n",
      "Epoch [81/85] Batch 310/938 Loss D: 0.1552, Loss G: 3.2637\n",
      "Epoch [81/85] Batch 320/938 Loss D: 0.1481, Loss G: 3.6786\n",
      "Epoch [81/85] Batch 330/938 Loss D: 0.1239, Loss G: 3.5565\n",
      "Epoch [81/85] Batch 340/938 Loss D: 0.1818, Loss G: 3.0698\n",
      "Epoch [81/85] Batch 350/938 Loss D: 0.3694, Loss G: 2.9673\n",
      "Epoch [81/85] Batch 360/938 Loss D: 0.2697, Loss G: 3.8547\n",
      "Epoch [81/85] Batch 370/938 Loss D: 0.2644, Loss G: 2.7397\n",
      "Epoch [81/85] Batch 380/938 Loss D: 0.1140, Loss G: 4.0383\n",
      "Epoch [81/85] Batch 390/938 Loss D: 0.2880, Loss G: 2.2749\n",
      "Epoch [81/85] Batch 400/938 Loss D: 0.2167, Loss G: 2.6714\n",
      "Epoch [81/85] Batch 410/938 Loss D: 0.3123, Loss G: 2.8966\n",
      "Epoch [81/85] Batch 420/938 Loss D: 0.3108, Loss G: 2.9054\n",
      "Epoch [81/85] Batch 430/938 Loss D: 0.2690, Loss G: 2.7465\n",
      "Epoch [81/85] Batch 440/938 Loss D: 0.1790, Loss G: 2.7424\n",
      "Epoch [81/85] Batch 450/938 Loss D: 0.1864, Loss G: 3.0399\n",
      "Epoch [81/85] Batch 460/938 Loss D: 0.3520, Loss G: 3.0441\n",
      "Epoch [81/85] Batch 470/938 Loss D: 0.2057, Loss G: 2.8610\n",
      "Epoch [81/85] Batch 480/938 Loss D: 0.2165, Loss G: 2.4407\n",
      "Epoch [81/85] Batch 490/938 Loss D: 0.2603, Loss G: 2.5717\n",
      "Epoch [81/85] Batch 500/938 Loss D: 0.1459, Loss G: 4.1044\n",
      "Epoch [81/85] Batch 510/938 Loss D: 0.2716, Loss G: 2.4891\n",
      "Epoch [81/85] Batch 520/938 Loss D: 0.2781, Loss G: 3.3528\n",
      "Epoch [81/85] Batch 530/938 Loss D: 0.3608, Loss G: 2.2987\n",
      "Epoch [81/85] Batch 540/938 Loss D: 0.1744, Loss G: 3.0051\n",
      "Epoch [81/85] Batch 550/938 Loss D: 0.1917, Loss G: 3.0082\n",
      "Epoch [81/85] Batch 560/938 Loss D: 0.2314, Loss G: 2.4863\n",
      "Epoch [81/85] Batch 570/938 Loss D: 0.2150, Loss G: 3.3170\n",
      "Epoch [81/85] Batch 580/938 Loss D: 0.3180, Loss G: 2.7034\n",
      "Epoch [81/85] Batch 590/938 Loss D: 0.2876, Loss G: 2.2811\n",
      "Epoch [81/85] Batch 600/938 Loss D: 0.2239, Loss G: 2.3293\n",
      "Epoch [81/85] Batch 610/938 Loss D: 0.2209, Loss G: 2.8009\n",
      "Epoch [81/85] Batch 620/938 Loss D: 0.3326, Loss G: 2.1930\n",
      "Epoch [81/85] Batch 630/938 Loss D: 0.3130, Loss G: 2.4932\n",
      "Epoch [81/85] Batch 640/938 Loss D: 0.2921, Loss G: 2.8301\n",
      "Epoch [81/85] Batch 650/938 Loss D: 0.2976, Loss G: 2.6296\n",
      "Epoch [81/85] Batch 660/938 Loss D: 0.4695, Loss G: 1.8974\n",
      "Epoch [81/85] Batch 670/938 Loss D: 0.3083, Loss G: 2.3643\n",
      "Epoch [81/85] Batch 680/938 Loss D: 0.3108, Loss G: 2.1180\n",
      "Epoch [81/85] Batch 690/938 Loss D: 0.2033, Loss G: 3.2591\n",
      "Epoch [81/85] Batch 700/938 Loss D: 0.3135, Loss G: 2.0940\n",
      "Epoch [81/85] Batch 710/938 Loss D: 0.2532, Loss G: 1.9219\n",
      "Epoch [81/85] Batch 720/938 Loss D: 0.2158, Loss G: 2.4597\n",
      "Epoch [81/85] Batch 730/938 Loss D: 0.3121, Loss G: 2.3310\n",
      "Epoch [81/85] Batch 740/938 Loss D: 0.2825, Loss G: 2.4799\n",
      "Epoch [81/85] Batch 750/938 Loss D: 0.3909, Loss G: 1.6624\n",
      "Epoch [81/85] Batch 760/938 Loss D: 0.3191, Loss G: 2.1940\n",
      "Epoch [81/85] Batch 770/938 Loss D: 0.4258, Loss G: 1.9497\n",
      "Epoch [81/85] Batch 780/938 Loss D: 0.2669, Loss G: 2.1541\n",
      "Epoch [81/85] Batch 790/938 Loss D: 0.2504, Loss G: 3.3569\n",
      "Epoch [81/85] Batch 800/938 Loss D: 0.2700, Loss G: 3.2679\n",
      "Epoch [81/85] Batch 810/938 Loss D: 0.3348, Loss G: 2.0000\n",
      "Epoch [81/85] Batch 820/938 Loss D: 0.3413, Loss G: 2.5334\n",
      "Epoch [81/85] Batch 830/938 Loss D: 0.1692, Loss G: 3.4036\n",
      "Epoch [81/85] Batch 840/938 Loss D: 0.4501, Loss G: 2.7378\n",
      "Epoch [81/85] Batch 850/938 Loss D: 0.2586, Loss G: 2.4845\n",
      "Epoch [81/85] Batch 860/938 Loss D: 0.2094, Loss G: 2.1816\n",
      "Epoch [81/85] Batch 870/938 Loss D: 0.2790, Loss G: 2.8079\n",
      "Epoch [81/85] Batch 880/938 Loss D: 0.3325, Loss G: 2.4693\n",
      "Epoch [81/85] Batch 890/938 Loss D: 0.2238, Loss G: 2.8017\n",
      "Epoch [81/85] Batch 900/938 Loss D: 0.4257, Loss G: 1.8627\n",
      "Epoch [81/85] Batch 910/938 Loss D: 0.3535, Loss G: 2.8170\n",
      "Epoch [81/85] Batch 920/938 Loss D: 0.3430, Loss G: 2.8939\n",
      "Epoch [81/85] Batch 930/938 Loss D: 0.5051, Loss G: 1.1086\n",
      "Epoch [82/85] Batch 0/938 Loss D: 0.2073, Loss G: 4.7618\n",
      "Epoch [82/85] Batch 10/938 Loss D: 0.2436, Loss G: 2.9338\n",
      "Epoch [82/85] Batch 20/938 Loss D: 0.2800, Loss G: 2.3120\n",
      "Epoch [82/85] Batch 30/938 Loss D: 0.3186, Loss G: 2.8411\n",
      "Epoch [82/85] Batch 40/938 Loss D: 0.2818, Loss G: 2.4310\n",
      "Epoch [82/85] Batch 50/938 Loss D: 0.2260, Loss G: 2.6836\n",
      "Epoch [82/85] Batch 60/938 Loss D: 0.4447, Loss G: 2.1347\n",
      "Epoch [82/85] Batch 70/938 Loss D: 0.5399, Loss G: 2.4873\n",
      "Epoch [82/85] Batch 80/938 Loss D: 0.2989, Loss G: 2.1923\n",
      "Epoch [82/85] Batch 90/938 Loss D: 0.5309, Loss G: 1.4078\n",
      "Epoch [82/85] Batch 100/938 Loss D: 0.1920, Loss G: 2.6631\n",
      "Epoch [82/85] Batch 110/938 Loss D: 0.3033, Loss G: 4.0613\n",
      "Epoch [82/85] Batch 120/938 Loss D: 0.1939, Loss G: 3.5694\n",
      "Epoch [82/85] Batch 130/938 Loss D: 0.2359, Loss G: 2.3615\n",
      "Epoch [82/85] Batch 140/938 Loss D: 0.2083, Loss G: 2.6005\n",
      "Epoch [82/85] Batch 150/938 Loss D: 0.1802, Loss G: 3.0767\n",
      "Epoch [82/85] Batch 160/938 Loss D: 0.4224, Loss G: 2.1675\n",
      "Epoch [82/85] Batch 170/938 Loss D: 0.2606, Loss G: 2.6980\n",
      "Epoch [82/85] Batch 180/938 Loss D: 0.3897, Loss G: 1.8892\n",
      "Epoch [82/85] Batch 190/938 Loss D: 0.2036, Loss G: 2.2162\n",
      "Epoch [82/85] Batch 200/938 Loss D: 0.3492, Loss G: 2.6747\n",
      "Epoch [82/85] Batch 210/938 Loss D: 0.3186, Loss G: 2.2627\n",
      "Epoch [82/85] Batch 220/938 Loss D: 0.1715, Loss G: 2.4954\n",
      "Epoch [82/85] Batch 230/938 Loss D: 0.1950, Loss G: 2.7387\n",
      "Epoch [82/85] Batch 240/938 Loss D: 0.3532, Loss G: 2.6307\n",
      "Epoch [82/85] Batch 250/938 Loss D: 0.2155, Loss G: 2.8156\n",
      "Epoch [82/85] Batch 260/938 Loss D: 0.2476, Loss G: 2.9381\n",
      "Epoch [82/85] Batch 270/938 Loss D: 0.3061, Loss G: 2.5489\n",
      "Epoch [82/85] Batch 280/938 Loss D: 0.2788, Loss G: 2.1398\n",
      "Epoch [82/85] Batch 290/938 Loss D: 0.4369, Loss G: 1.6491\n",
      "Epoch [82/85] Batch 300/938 Loss D: 0.2287, Loss G: 3.0253\n",
      "Epoch [82/85] Batch 310/938 Loss D: 0.3287, Loss G: 4.4095\n",
      "Epoch [82/85] Batch 320/938 Loss D: 0.1991, Loss G: 3.6204\n",
      "Epoch [82/85] Batch 330/938 Loss D: 0.3668, Loss G: 2.3893\n",
      "Epoch [82/85] Batch 340/938 Loss D: 0.1813, Loss G: 2.6925\n",
      "Epoch [82/85] Batch 350/938 Loss D: 0.3327, Loss G: 2.6397\n",
      "Epoch [82/85] Batch 360/938 Loss D: 0.3992, Loss G: 3.1724\n",
      "Epoch [82/85] Batch 370/938 Loss D: 0.3163, Loss G: 2.7761\n",
      "Epoch [82/85] Batch 380/938 Loss D: 0.2986, Loss G: 2.1930\n",
      "Epoch [82/85] Batch 390/938 Loss D: 0.3041, Loss G: 2.1663\n",
      "Epoch [82/85] Batch 400/938 Loss D: 0.2493, Loss G: 3.1174\n",
      "Epoch [82/85] Batch 410/938 Loss D: 0.2200, Loss G: 3.5491\n",
      "Epoch [82/85] Batch 420/938 Loss D: 0.3047, Loss G: 2.3767\n",
      "Epoch [82/85] Batch 430/938 Loss D: 0.2262, Loss G: 2.2973\n",
      "Epoch [82/85] Batch 440/938 Loss D: 0.3445, Loss G: 1.7448\n",
      "Epoch [82/85] Batch 450/938 Loss D: 0.3058, Loss G: 2.9306\n",
      "Epoch [82/85] Batch 460/938 Loss D: 0.1800, Loss G: 3.2560\n",
      "Epoch [82/85] Batch 470/938 Loss D: 0.1742, Loss G: 3.1674\n",
      "Epoch [82/85] Batch 480/938 Loss D: 0.2020, Loss G: 2.7585\n",
      "Epoch [82/85] Batch 490/938 Loss D: 0.1799, Loss G: 2.7201\n",
      "Epoch [82/85] Batch 500/938 Loss D: 0.1786, Loss G: 3.0424\n",
      "Epoch [82/85] Batch 510/938 Loss D: 0.1524, Loss G: 3.5626\n",
      "Epoch [82/85] Batch 520/938 Loss D: 0.2838, Loss G: 1.8262\n",
      "Epoch [82/85] Batch 530/938 Loss D: 0.3362, Loss G: 2.4323\n",
      "Epoch [82/85] Batch 540/938 Loss D: 0.3252, Loss G: 1.8107\n",
      "Epoch [82/85] Batch 550/938 Loss D: 0.3738, Loss G: 1.7325\n",
      "Epoch [82/85] Batch 560/938 Loss D: 0.2145, Loss G: 2.8810\n",
      "Epoch [82/85] Batch 570/938 Loss D: 0.2356, Loss G: 3.5322\n",
      "Epoch [82/85] Batch 580/938 Loss D: 0.3712, Loss G: 2.5139\n",
      "Epoch [82/85] Batch 590/938 Loss D: 0.3619, Loss G: 2.1349\n",
      "Epoch [82/85] Batch 600/938 Loss D: 0.3708, Loss G: 2.1048\n",
      "Epoch [82/85] Batch 610/938 Loss D: 0.3548, Loss G: 2.0383\n",
      "Epoch [82/85] Batch 620/938 Loss D: 0.3742, Loss G: 2.0921\n",
      "Epoch [82/85] Batch 630/938 Loss D: 0.2543, Loss G: 2.4778\n",
      "Epoch [82/85] Batch 640/938 Loss D: 0.1916, Loss G: 3.5966\n",
      "Epoch [82/85] Batch 650/938 Loss D: 0.2156, Loss G: 3.3133\n",
      "Epoch [82/85] Batch 660/938 Loss D: 0.2008, Loss G: 2.8447\n",
      "Epoch [82/85] Batch 670/938 Loss D: 0.4444, Loss G: 2.3912\n",
      "Epoch [82/85] Batch 680/938 Loss D: 0.1686, Loss G: 3.6707\n",
      "Epoch [82/85] Batch 690/938 Loss D: 0.2316, Loss G: 2.9448\n",
      "Epoch [82/85] Batch 700/938 Loss D: 0.3713, Loss G: 2.1190\n",
      "Epoch [82/85] Batch 710/938 Loss D: 0.2424, Loss G: 2.7520\n",
      "Epoch [82/85] Batch 720/938 Loss D: 0.2674, Loss G: 2.3287\n",
      "Epoch [82/85] Batch 730/938 Loss D: 0.1952, Loss G: 2.8231\n",
      "Epoch [82/85] Batch 740/938 Loss D: 0.2861, Loss G: 3.6309\n",
      "Epoch [82/85] Batch 750/938 Loss D: 0.3316, Loss G: 2.0547\n",
      "Epoch [82/85] Batch 760/938 Loss D: 0.2961, Loss G: 1.9597\n",
      "Epoch [82/85] Batch 770/938 Loss D: 0.3370, Loss G: 2.2704\n",
      "Epoch [82/85] Batch 780/938 Loss D: 0.3717, Loss G: 2.5093\n",
      "Epoch [82/85] Batch 790/938 Loss D: 0.3567, Loss G: 2.4756\n",
      "Epoch [82/85] Batch 800/938 Loss D: 0.3046, Loss G: 2.4025\n",
      "Epoch [82/85] Batch 810/938 Loss D: 0.1847, Loss G: 3.1816\n",
      "Epoch [82/85] Batch 820/938 Loss D: 0.2791, Loss G: 2.2577\n",
      "Epoch [82/85] Batch 830/938 Loss D: 0.2770, Loss G: 2.4341\n",
      "Epoch [82/85] Batch 840/938 Loss D: 0.2812, Loss G: 2.8145\n",
      "Epoch [82/85] Batch 850/938 Loss D: 0.2158, Loss G: 3.1391\n",
      "Epoch [82/85] Batch 860/938 Loss D: 0.1509, Loss G: 3.2004\n",
      "Epoch [82/85] Batch 870/938 Loss D: 0.3693, Loss G: 2.3829\n",
      "Epoch [82/85] Batch 880/938 Loss D: 0.2209, Loss G: 3.0264\n",
      "Epoch [82/85] Batch 890/938 Loss D: 0.2687, Loss G: 2.4425\n",
      "Epoch [82/85] Batch 900/938 Loss D: 0.1869, Loss G: 2.5654\n",
      "Epoch [82/85] Batch 910/938 Loss D: 0.2028, Loss G: 2.9627\n",
      "Epoch [82/85] Batch 920/938 Loss D: 0.2134, Loss G: 2.6754\n",
      "Epoch [82/85] Batch 930/938 Loss D: 0.1877, Loss G: 3.8052\n",
      "Epoch [83/85] Batch 0/938 Loss D: 0.2195, Loss G: 2.7323\n",
      "Epoch [83/85] Batch 10/938 Loss D: 0.1957, Loss G: 3.3842\n",
      "Epoch [83/85] Batch 20/938 Loss D: 0.1131, Loss G: 4.9913\n",
      "Epoch [83/85] Batch 30/938 Loss D: 0.2718, Loss G: 4.4919\n",
      "Epoch [83/85] Batch 40/938 Loss D: 0.2031, Loss G: 3.4940\n",
      "Epoch [83/85] Batch 50/938 Loss D: 0.2487, Loss G: 2.4403\n",
      "Epoch [83/85] Batch 60/938 Loss D: 0.2243, Loss G: 2.6790\n",
      "Epoch [83/85] Batch 70/938 Loss D: 0.2425, Loss G: 2.8195\n",
      "Epoch [83/85] Batch 80/938 Loss D: 0.1193, Loss G: 4.3434\n",
      "Epoch [83/85] Batch 90/938 Loss D: 0.2157, Loss G: 4.4606\n",
      "Epoch [83/85] Batch 100/938 Loss D: 0.2117, Loss G: 3.7313\n",
      "Epoch [83/85] Batch 110/938 Loss D: 0.4252, Loss G: 2.0429\n",
      "Epoch [83/85] Batch 120/938 Loss D: 0.2428, Loss G: 2.5142\n",
      "Epoch [83/85] Batch 130/938 Loss D: 0.2801, Loss G: 2.8893\n",
      "Epoch [83/85] Batch 140/938 Loss D: 0.1170, Loss G: 3.4790\n",
      "Epoch [83/85] Batch 150/938 Loss D: 0.2342, Loss G: 4.4681\n",
      "Epoch [83/85] Batch 160/938 Loss D: 0.1383, Loss G: 3.1516\n",
      "Epoch [83/85] Batch 170/938 Loss D: 0.1739, Loss G: 2.8616\n",
      "Epoch [83/85] Batch 180/938 Loss D: 0.1849, Loss G: 4.1510\n",
      "Epoch [83/85] Batch 190/938 Loss D: 0.2491, Loss G: 3.8268\n",
      "Epoch [83/85] Batch 200/938 Loss D: 0.1181, Loss G: 3.2329\n",
      "Epoch [83/85] Batch 210/938 Loss D: 0.2357, Loss G: 3.6725\n",
      "Epoch [83/85] Batch 220/938 Loss D: 0.3973, Loss G: 2.0526\n",
      "Epoch [83/85] Batch 230/938 Loss D: 0.2376, Loss G: 2.4478\n",
      "Epoch [83/85] Batch 240/938 Loss D: 0.1683, Loss G: 3.1052\n",
      "Epoch [83/85] Batch 250/938 Loss D: 0.2760, Loss G: 2.6726\n",
      "Epoch [83/85] Batch 260/938 Loss D: 0.3255, Loss G: 3.1621\n",
      "Epoch [83/85] Batch 270/938 Loss D: 0.2727, Loss G: 2.2300\n",
      "Epoch [83/85] Batch 280/938 Loss D: 0.2981, Loss G: 2.3264\n",
      "Epoch [83/85] Batch 290/938 Loss D: 0.3357, Loss G: 2.6802\n",
      "Epoch [83/85] Batch 300/938 Loss D: 0.2579, Loss G: 2.4727\n",
      "Epoch [83/85] Batch 310/938 Loss D: 0.2171, Loss G: 2.9880\n",
      "Epoch [83/85] Batch 320/938 Loss D: 0.1894, Loss G: 2.9736\n",
      "Epoch [83/85] Batch 330/938 Loss D: 0.3001, Loss G: 2.1124\n",
      "Epoch [83/85] Batch 340/938 Loss D: 0.3635, Loss G: 2.8163\n",
      "Epoch [83/85] Batch 350/938 Loss D: 0.1693, Loss G: 2.7246\n",
      "Epoch [83/85] Batch 360/938 Loss D: 0.1039, Loss G: 3.9014\n",
      "Epoch [83/85] Batch 370/938 Loss D: 0.1796, Loss G: 3.5182\n",
      "Epoch [83/85] Batch 380/938 Loss D: 0.1968, Loss G: 3.0310\n",
      "Epoch [83/85] Batch 390/938 Loss D: 0.1948, Loss G: 2.7349\n",
      "Epoch [83/85] Batch 400/938 Loss D: 0.2162, Loss G: 3.3858\n",
      "Epoch [83/85] Batch 410/938 Loss D: 0.2519, Loss G: 3.0569\n",
      "Epoch [83/85] Batch 420/938 Loss D: 0.2965, Loss G: 2.1329\n",
      "Epoch [83/85] Batch 430/938 Loss D: 0.1164, Loss G: 3.6753\n",
      "Epoch [83/85] Batch 440/938 Loss D: 0.1467, Loss G: 3.3866\n",
      "Epoch [83/85] Batch 450/938 Loss D: 0.3479, Loss G: 2.6815\n",
      "Epoch [83/85] Batch 460/938 Loss D: 0.3115, Loss G: 2.2887\n",
      "Epoch [83/85] Batch 470/938 Loss D: 0.3105, Loss G: 2.0282\n",
      "Epoch [83/85] Batch 480/938 Loss D: 0.2545, Loss G: 3.2570\n",
      "Epoch [83/85] Batch 490/938 Loss D: 0.3246, Loss G: 1.9865\n",
      "Epoch [83/85] Batch 500/938 Loss D: 0.2836, Loss G: 2.7265\n",
      "Epoch [83/85] Batch 510/938 Loss D: 0.3903, Loss G: 2.7158\n",
      "Epoch [83/85] Batch 520/938 Loss D: 0.2462, Loss G: 2.5952\n",
      "Epoch [83/85] Batch 530/938 Loss D: 0.2153, Loss G: 2.5442\n",
      "Epoch [83/85] Batch 540/938 Loss D: 0.3433, Loss G: 1.9381\n",
      "Epoch [83/85] Batch 550/938 Loss D: 0.2702, Loss G: 3.5965\n",
      "Epoch [83/85] Batch 560/938 Loss D: 0.2155, Loss G: 3.0356\n",
      "Epoch [83/85] Batch 570/938 Loss D: 0.3052, Loss G: 2.2854\n",
      "Epoch [83/85] Batch 580/938 Loss D: 0.2386, Loss G: 2.4856\n",
      "Epoch [83/85] Batch 590/938 Loss D: 0.2746, Loss G: 2.1525\n",
      "Epoch [83/85] Batch 600/938 Loss D: 0.3470, Loss G: 1.9260\n",
      "Epoch [83/85] Batch 610/938 Loss D: 0.1927, Loss G: 3.0082\n",
      "Epoch [83/85] Batch 620/938 Loss D: 0.3705, Loss G: 1.9613\n",
      "Epoch [83/85] Batch 630/938 Loss D: 0.2286, Loss G: 2.5856\n",
      "Epoch [83/85] Batch 640/938 Loss D: 0.1639, Loss G: 3.4183\n",
      "Epoch [83/85] Batch 650/938 Loss D: 0.3123, Loss G: 4.4347\n",
      "Epoch [83/85] Batch 660/938 Loss D: 0.2643, Loss G: 2.9120\n",
      "Epoch [83/85] Batch 670/938 Loss D: 0.2716, Loss G: 2.6494\n",
      "Epoch [83/85] Batch 680/938 Loss D: 0.1903, Loss G: 2.5221\n",
      "Epoch [83/85] Batch 690/938 Loss D: 0.3036, Loss G: 3.0049\n",
      "Epoch [83/85] Batch 700/938 Loss D: 0.2321, Loss G: 4.1188\n",
      "Epoch [83/85] Batch 710/938 Loss D: 0.3270, Loss G: 2.8532\n",
      "Epoch [83/85] Batch 720/938 Loss D: 0.2936, Loss G: 2.6636\n",
      "Epoch [83/85] Batch 730/938 Loss D: 0.2435, Loss G: 2.4765\n",
      "Epoch [83/85] Batch 740/938 Loss D: 0.4928, Loss G: 3.0784\n",
      "Epoch [83/85] Batch 750/938 Loss D: 0.2505, Loss G: 2.9623\n",
      "Epoch [83/85] Batch 760/938 Loss D: 0.4330, Loss G: 2.1355\n",
      "Epoch [83/85] Batch 770/938 Loss D: 0.3967, Loss G: 2.4976\n",
      "Epoch [83/85] Batch 780/938 Loss D: 0.3408, Loss G: 2.4603\n",
      "Epoch [83/85] Batch 790/938 Loss D: 0.1589, Loss G: 3.8716\n",
      "Epoch [83/85] Batch 800/938 Loss D: 0.4365, Loss G: 2.2705\n",
      "Epoch [83/85] Batch 810/938 Loss D: 0.2705, Loss G: 2.6025\n",
      "Epoch [83/85] Batch 820/938 Loss D: 0.3848, Loss G: 1.9202\n",
      "Epoch [83/85] Batch 830/938 Loss D: 0.3482, Loss G: 2.0421\n",
      "Epoch [83/85] Batch 840/938 Loss D: 0.3498, Loss G: 2.3129\n",
      "Epoch [83/85] Batch 850/938 Loss D: 0.2520, Loss G: 3.0164\n",
      "Epoch [83/85] Batch 860/938 Loss D: 0.1669, Loss G: 2.7502\n",
      "Epoch [83/85] Batch 870/938 Loss D: 0.2557, Loss G: 3.0188\n",
      "Epoch [83/85] Batch 880/938 Loss D: 0.3440, Loss G: 3.1057\n",
      "Epoch [83/85] Batch 890/938 Loss D: 0.4201, Loss G: 2.7046\n",
      "Epoch [83/85] Batch 900/938 Loss D: 0.2823, Loss G: 3.2615\n",
      "Epoch [83/85] Batch 910/938 Loss D: 0.3736, Loss G: 2.4497\n",
      "Epoch [83/85] Batch 920/938 Loss D: 0.2031, Loss G: 3.5891\n",
      "Epoch [83/85] Batch 930/938 Loss D: 0.2280, Loss G: 3.1856\n",
      "Epoch [84/85] Batch 0/938 Loss D: 0.1993, Loss G: 3.3102\n",
      "Epoch [84/85] Batch 10/938 Loss D: 0.4322, Loss G: 1.7137\n",
      "Epoch [84/85] Batch 20/938 Loss D: 0.2666, Loss G: 3.6291\n",
      "Epoch [84/85] Batch 30/938 Loss D: 0.1669, Loss G: 3.6792\n",
      "Epoch [84/85] Batch 40/938 Loss D: 0.2082, Loss G: 2.8343\n",
      "Epoch [84/85] Batch 50/938 Loss D: 0.4980, Loss G: 2.1916\n",
      "Epoch [84/85] Batch 60/938 Loss D: 0.1666, Loss G: 3.2201\n",
      "Epoch [84/85] Batch 70/938 Loss D: 0.1661, Loss G: 3.2423\n",
      "Epoch [84/85] Batch 80/938 Loss D: 0.2342, Loss G: 3.0059\n",
      "Epoch [84/85] Batch 90/938 Loss D: 0.3056, Loss G: 3.0647\n",
      "Epoch [84/85] Batch 100/938 Loss D: 0.3514, Loss G: 2.2766\n",
      "Epoch [84/85] Batch 110/938 Loss D: 0.2873, Loss G: 3.4437\n",
      "Epoch [84/85] Batch 120/938 Loss D: 0.3342, Loss G: 2.5874\n",
      "Epoch [84/85] Batch 130/938 Loss D: 0.2358, Loss G: 2.8495\n",
      "Epoch [84/85] Batch 140/938 Loss D: 0.2276, Loss G: 2.8644\n",
      "Epoch [84/85] Batch 150/938 Loss D: 0.2460, Loss G: 2.4124\n",
      "Epoch [84/85] Batch 160/938 Loss D: 0.3654, Loss G: 1.9351\n",
      "Epoch [84/85] Batch 170/938 Loss D: 0.5073, Loss G: 1.7397\n",
      "Epoch [84/85] Batch 180/938 Loss D: 0.3008, Loss G: 2.2113\n",
      "Epoch [84/85] Batch 190/938 Loss D: 0.2744, Loss G: 2.0064\n",
      "Epoch [84/85] Batch 200/938 Loss D: 0.3490, Loss G: 1.8642\n",
      "Epoch [84/85] Batch 210/938 Loss D: 0.1502, Loss G: 3.3320\n",
      "Epoch [84/85] Batch 220/938 Loss D: 0.4009, Loss G: 2.5834\n",
      "Epoch [84/85] Batch 230/938 Loss D: 0.2981, Loss G: 2.4877\n",
      "Epoch [84/85] Batch 240/938 Loss D: 0.1247, Loss G: 3.9127\n",
      "Epoch [84/85] Batch 250/938 Loss D: 0.1764, Loss G: 3.2638\n",
      "Epoch [84/85] Batch 260/938 Loss D: 0.2272, Loss G: 2.6563\n",
      "Epoch [84/85] Batch 270/938 Loss D: 0.2045, Loss G: 3.2769\n",
      "Epoch [84/85] Batch 280/938 Loss D: 0.2131, Loss G: 2.6844\n",
      "Epoch [84/85] Batch 290/938 Loss D: 0.3188, Loss G: 2.4153\n",
      "Epoch [84/85] Batch 300/938 Loss D: 0.3140, Loss G: 2.3136\n",
      "Epoch [84/85] Batch 310/938 Loss D: 0.2906, Loss G: 2.7583\n",
      "Epoch [84/85] Batch 320/938 Loss D: 0.3046, Loss G: 2.5971\n",
      "Epoch [84/85] Batch 330/938 Loss D: 0.2646, Loss G: 3.1316\n",
      "Epoch [84/85] Batch 340/938 Loss D: 0.2905, Loss G: 3.3499\n",
      "Epoch [84/85] Batch 350/938 Loss D: 0.3610, Loss G: 2.8458\n",
      "Epoch [84/85] Batch 360/938 Loss D: 0.2920, Loss G: 2.8079\n",
      "Epoch [84/85] Batch 370/938 Loss D: 0.1754, Loss G: 3.4023\n",
      "Epoch [84/85] Batch 380/938 Loss D: 0.2622, Loss G: 3.6125\n",
      "Epoch [84/85] Batch 390/938 Loss D: 0.1822, Loss G: 3.3104\n",
      "Epoch [84/85] Batch 400/938 Loss D: 0.2646, Loss G: 2.0036\n",
      "Epoch [84/85] Batch 410/938 Loss D: 0.4105, Loss G: 1.8794\n",
      "Epoch [84/85] Batch 420/938 Loss D: 0.2284, Loss G: 2.6644\n",
      "Epoch [84/85] Batch 430/938 Loss D: 0.1842, Loss G: 2.9570\n",
      "Epoch [84/85] Batch 440/938 Loss D: 0.2753, Loss G: 2.1496\n",
      "Epoch [84/85] Batch 450/938 Loss D: 0.2247, Loss G: 2.8034\n",
      "Epoch [84/85] Batch 460/938 Loss D: 0.3414, Loss G: 2.5866\n",
      "Epoch [84/85] Batch 470/938 Loss D: 0.2799, Loss G: 2.2237\n",
      "Epoch [84/85] Batch 480/938 Loss D: 0.2495, Loss G: 2.4312\n",
      "Epoch [84/85] Batch 490/938 Loss D: 0.3202, Loss G: 2.2520\n",
      "Epoch [84/85] Batch 500/938 Loss D: 0.2619, Loss G: 2.8443\n",
      "Epoch [84/85] Batch 510/938 Loss D: 0.3965, Loss G: 2.4321\n",
      "Epoch [84/85] Batch 520/938 Loss D: 0.4012, Loss G: 2.4866\n",
      "Epoch [84/85] Batch 530/938 Loss D: 0.2847, Loss G: 2.8331\n",
      "Epoch [84/85] Batch 540/938 Loss D: 0.2997, Loss G: 2.1649\n",
      "Epoch [84/85] Batch 550/938 Loss D: 0.3732, Loss G: 2.6506\n",
      "Epoch [84/85] Batch 560/938 Loss D: 0.4202, Loss G: 2.5098\n",
      "Epoch [84/85] Batch 570/938 Loss D: 0.3481, Loss G: 2.3421\n",
      "Epoch [84/85] Batch 580/938 Loss D: 0.3104, Loss G: 2.3662\n",
      "Epoch [84/85] Batch 590/938 Loss D: 0.3395, Loss G: 3.0433\n",
      "Epoch [84/85] Batch 600/938 Loss D: 0.2450, Loss G: 3.1918\n",
      "Epoch [84/85] Batch 610/938 Loss D: 0.3218, Loss G: 2.2921\n",
      "Epoch [84/85] Batch 620/938 Loss D: 0.2764, Loss G: 2.3090\n",
      "Epoch [84/85] Batch 630/938 Loss D: 0.4227, Loss G: 1.8972\n",
      "Epoch [84/85] Batch 640/938 Loss D: 0.2392, Loss G: 2.9585\n",
      "Epoch [84/85] Batch 650/938 Loss D: 0.2630, Loss G: 2.6761\n",
      "Epoch [84/85] Batch 660/938 Loss D: 0.3843, Loss G: 2.2863\n",
      "Epoch [84/85] Batch 670/938 Loss D: 0.1918, Loss G: 3.4723\n",
      "Epoch [84/85] Batch 680/938 Loss D: 0.1365, Loss G: 3.5835\n",
      "Epoch [84/85] Batch 690/938 Loss D: 0.0941, Loss G: 4.4437\n",
      "Epoch [84/85] Batch 700/938 Loss D: 0.1000, Loss G: 4.4423\n",
      "Epoch [84/85] Batch 710/938 Loss D: 0.3301, Loss G: 3.1075\n",
      "Epoch [84/85] Batch 720/938 Loss D: 0.2480, Loss G: 2.4386\n",
      "Epoch [84/85] Batch 730/938 Loss D: 0.1981, Loss G: 3.1194\n",
      "Epoch [84/85] Batch 740/938 Loss D: 0.2962, Loss G: 2.6748\n",
      "Epoch [84/85] Batch 750/938 Loss D: 0.1835, Loss G: 3.1719\n",
      "Epoch [84/85] Batch 760/938 Loss D: 0.2245, Loss G: 2.5672\n",
      "Epoch [84/85] Batch 770/938 Loss D: 0.3075, Loss G: 2.0719\n",
      "Epoch [84/85] Batch 780/938 Loss D: 0.2953, Loss G: 1.9518\n",
      "Epoch [84/85] Batch 790/938 Loss D: 0.2020, Loss G: 2.4994\n",
      "Epoch [84/85] Batch 800/938 Loss D: 0.2928, Loss G: 1.7704\n",
      "Epoch [84/85] Batch 810/938 Loss D: 0.2552, Loss G: 2.1060\n",
      "Epoch [84/85] Batch 820/938 Loss D: 0.2465, Loss G: 3.0072\n",
      "Epoch [84/85] Batch 830/938 Loss D: 0.2012, Loss G: 4.4453\n",
      "Epoch [84/85] Batch 840/938 Loss D: 0.3422, Loss G: 2.3592\n",
      "Epoch [84/85] Batch 850/938 Loss D: 0.1569, Loss G: 2.8459\n",
      "Epoch [84/85] Batch 860/938 Loss D: 0.2627, Loss G: 2.5908\n",
      "Epoch [84/85] Batch 870/938 Loss D: 0.3379, Loss G: 2.1321\n",
      "Epoch [84/85] Batch 880/938 Loss D: 0.1800, Loss G: 3.2053\n",
      "Epoch [84/85] Batch 890/938 Loss D: 0.1960, Loss G: 4.0368\n",
      "Epoch [84/85] Batch 900/938 Loss D: 0.2564, Loss G: 2.8092\n",
      "Epoch [84/85] Batch 910/938 Loss D: 0.3902, Loss G: 1.4265\n",
      "Epoch [84/85] Batch 920/938 Loss D: 0.2205, Loss G: 2.3733\n",
      "Epoch [84/85] Batch 930/938 Loss D: 0.1789, Loss G: 3.5113\n",
      "Epoch [85/85] Batch 0/938 Loss D: 0.2553, Loss G: 2.3523\n",
      "Epoch [85/85] Batch 10/938 Loss D: 0.2972, Loss G: 1.9835\n",
      "Epoch [85/85] Batch 20/938 Loss D: 0.3099, Loss G: 2.5663\n",
      "Epoch [85/85] Batch 30/938 Loss D: 0.2757, Loss G: 3.5385\n",
      "Epoch [85/85] Batch 40/938 Loss D: 0.3055, Loss G: 2.8181\n",
      "Epoch [85/85] Batch 50/938 Loss D: 0.2742, Loss G: 2.5689\n",
      "Epoch [85/85] Batch 60/938 Loss D: 0.3205, Loss G: 2.7665\n",
      "Epoch [85/85] Batch 70/938 Loss D: 0.3008, Loss G: 2.8522\n",
      "Epoch [85/85] Batch 80/938 Loss D: 0.1912, Loss G: 2.7286\n",
      "Epoch [85/85] Batch 90/938 Loss D: 0.2231, Loss G: 2.7144\n",
      "Epoch [85/85] Batch 100/938 Loss D: 0.2990, Loss G: 2.4203\n",
      "Epoch [85/85] Batch 110/938 Loss D: 0.2440, Loss G: 2.9844\n",
      "Epoch [85/85] Batch 120/938 Loss D: 0.3093, Loss G: 2.6680\n",
      "Epoch [85/85] Batch 130/938 Loss D: 0.2273, Loss G: 2.8617\n",
      "Epoch [85/85] Batch 140/938 Loss D: 0.2261, Loss G: 2.7277\n",
      "Epoch [85/85] Batch 150/938 Loss D: 0.3018, Loss G: 2.5516\n",
      "Epoch [85/85] Batch 160/938 Loss D: 0.2806, Loss G: 2.5949\n",
      "Epoch [85/85] Batch 170/938 Loss D: 0.2595, Loss G: 2.4519\n",
      "Epoch [85/85] Batch 180/938 Loss D: 0.3884, Loss G: 1.8694\n",
      "Epoch [85/85] Batch 190/938 Loss D: 0.2919, Loss G: 3.0353\n",
      "Epoch [85/85] Batch 200/938 Loss D: 0.3845, Loss G: 2.9585\n",
      "Epoch [85/85] Batch 210/938 Loss D: 0.3427, Loss G: 2.0054\n",
      "Epoch [85/85] Batch 220/938 Loss D: 0.2052, Loss G: 2.7201\n",
      "Epoch [85/85] Batch 230/938 Loss D: 0.1387, Loss G: 2.6834\n",
      "Epoch [85/85] Batch 240/938 Loss D: 0.2095, Loss G: 3.5198\n",
      "Epoch [85/85] Batch 250/938 Loss D: 0.2998, Loss G: 3.0671\n",
      "Epoch [85/85] Batch 260/938 Loss D: 0.1279, Loss G: 3.4677\n",
      "Epoch [85/85] Batch 270/938 Loss D: 0.2550, Loss G: 2.4641\n",
      "Epoch [85/85] Batch 280/938 Loss D: 0.2268, Loss G: 3.0348\n",
      "Epoch [85/85] Batch 290/938 Loss D: 0.1176, Loss G: 4.4468\n",
      "Epoch [85/85] Batch 300/938 Loss D: 0.3633, Loss G: 1.9332\n",
      "Epoch [85/85] Batch 310/938 Loss D: 0.2348, Loss G: 2.7253\n",
      "Epoch [85/85] Batch 320/938 Loss D: 0.2940, Loss G: 2.0929\n",
      "Epoch [85/85] Batch 330/938 Loss D: 0.2156, Loss G: 2.7106\n",
      "Epoch [85/85] Batch 340/938 Loss D: 0.2193, Loss G: 2.2613\n",
      "Epoch [85/85] Batch 350/938 Loss D: 0.2368, Loss G: 2.6094\n",
      "Epoch [85/85] Batch 360/938 Loss D: 0.3864, Loss G: 2.8542\n",
      "Epoch [85/85] Batch 370/938 Loss D: 0.2747, Loss G: 2.8196\n",
      "Epoch [85/85] Batch 380/938 Loss D: 0.3568, Loss G: 2.1821\n",
      "Epoch [85/85] Batch 390/938 Loss D: 0.2061, Loss G: 2.6943\n",
      "Epoch [85/85] Batch 400/938 Loss D: 0.2450, Loss G: 2.6996\n",
      "Epoch [85/85] Batch 410/938 Loss D: 0.2321, Loss G: 3.0762\n",
      "Epoch [85/85] Batch 420/938 Loss D: 0.2894, Loss G: 3.1848\n",
      "Epoch [85/85] Batch 430/938 Loss D: 0.2707, Loss G: 2.5037\n",
      "Epoch [85/85] Batch 440/938 Loss D: 0.1558, Loss G: 3.3774\n",
      "Epoch [85/85] Batch 450/938 Loss D: 0.2105, Loss G: 2.6518\n",
      "Epoch [85/85] Batch 460/938 Loss D: 0.1185, Loss G: 3.4634\n",
      "Epoch [85/85] Batch 470/938 Loss D: 0.3352, Loss G: 2.5695\n",
      "Epoch [85/85] Batch 480/938 Loss D: 0.2260, Loss G: 2.7736\n",
      "Epoch [85/85] Batch 490/938 Loss D: 0.3011, Loss G: 2.7347\n",
      "Epoch [85/85] Batch 500/938 Loss D: 0.3891, Loss G: 2.2931\n",
      "Epoch [85/85] Batch 510/938 Loss D: 0.3093, Loss G: 2.1405\n",
      "Epoch [85/85] Batch 520/938 Loss D: 0.3255, Loss G: 2.2510\n",
      "Epoch [85/85] Batch 530/938 Loss D: 0.2133, Loss G: 2.5759\n",
      "Epoch [85/85] Batch 540/938 Loss D: 0.3316, Loss G: 2.3556\n",
      "Epoch [85/85] Batch 550/938 Loss D: 0.2518, Loss G: 2.4041\n",
      "Epoch [85/85] Batch 560/938 Loss D: 0.2221, Loss G: 2.9034\n",
      "Epoch [85/85] Batch 570/938 Loss D: 0.3945, Loss G: 2.9863\n",
      "Epoch [85/85] Batch 580/938 Loss D: 0.2704, Loss G: 2.4997\n",
      "Epoch [85/85] Batch 590/938 Loss D: 0.1902, Loss G: 3.4247\n",
      "Epoch [85/85] Batch 600/938 Loss D: 0.2317, Loss G: 4.0045\n",
      "Epoch [85/85] Batch 610/938 Loss D: 0.3236, Loss G: 2.5428\n",
      "Epoch [85/85] Batch 620/938 Loss D: 0.1317, Loss G: 3.6017\n",
      "Epoch [85/85] Batch 630/938 Loss D: 0.2352, Loss G: 2.4127\n",
      "Epoch [85/85] Batch 640/938 Loss D: 0.3229, Loss G: 2.8675\n",
      "Epoch [85/85] Batch 650/938 Loss D: 0.2987, Loss G: 2.8303\n",
      "Epoch [85/85] Batch 660/938 Loss D: 0.1487, Loss G: 3.4199\n",
      "Epoch [85/85] Batch 670/938 Loss D: 0.4158, Loss G: 2.4004\n",
      "Epoch [85/85] Batch 680/938 Loss D: 0.2534, Loss G: 2.7710\n",
      "Epoch [85/85] Batch 690/938 Loss D: 0.3024, Loss G: 2.8157\n",
      "Epoch [85/85] Batch 700/938 Loss D: 0.3565, Loss G: 2.5762\n",
      "Epoch [85/85] Batch 710/938 Loss D: 0.2990, Loss G: 2.3610\n",
      "Epoch [85/85] Batch 720/938 Loss D: 0.2474, Loss G: 2.7085\n",
      "Epoch [85/85] Batch 730/938 Loss D: 0.2073, Loss G: 3.2555\n",
      "Epoch [85/85] Batch 740/938 Loss D: 0.1414, Loss G: 2.9598\n",
      "Epoch [85/85] Batch 750/938 Loss D: 0.2626, Loss G: 2.5032\n",
      "Epoch [85/85] Batch 760/938 Loss D: 0.2978, Loss G: 2.5947\n",
      "Epoch [85/85] Batch 770/938 Loss D: 0.2032, Loss G: 2.8417\n",
      "Epoch [85/85] Batch 780/938 Loss D: 0.3717, Loss G: 2.4613\n",
      "Epoch [85/85] Batch 790/938 Loss D: 0.2547, Loss G: 3.0723\n",
      "Epoch [85/85] Batch 800/938 Loss D: 0.2454, Loss G: 3.3508\n",
      "Epoch [85/85] Batch 810/938 Loss D: 0.2818, Loss G: 2.8080\n",
      "Epoch [85/85] Batch 820/938 Loss D: 0.3284, Loss G: 3.5443\n",
      "Epoch [85/85] Batch 830/938 Loss D: 0.3661, Loss G: 2.0947\n",
      "Epoch [85/85] Batch 840/938 Loss D: 0.2552, Loss G: 2.6339\n",
      "Epoch [85/85] Batch 850/938 Loss D: 0.3503, Loss G: 2.5406\n",
      "Epoch [85/85] Batch 860/938 Loss D: 0.2244, Loss G: 2.9105\n",
      "Epoch [85/85] Batch 870/938 Loss D: 0.2814, Loss G: 1.8235\n",
      "Epoch [85/85] Batch 880/938 Loss D: 0.2411, Loss G: 2.5245\n",
      "Epoch [85/85] Batch 890/938 Loss D: 0.2829, Loss G: 2.4644\n",
      "Epoch [85/85] Batch 900/938 Loss D: 0.1893, Loss G: 3.9680\n",
      "Epoch [85/85] Batch 910/938 Loss D: 0.2368, Loss G: 3.0971\n",
      "Epoch [85/85] Batch 920/938 Loss D: 0.2389, Loss G: 2.3873\n",
      "Epoch [85/85] Batch 930/938 Loss D: 0.3332, Loss G: 2.3935\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir # data directory\n",
    "        self.transform = transform # 데이터 이미지 스케일 변환\n",
    "        self.image_paths = []\n",
    "\n",
    "        for i in range(10):\n",
    "            label_dir = os.path.join(root_dir, str(i))\n",
    "            for img_file in glob.glob(os.path.join(label_dir, '*.png')):\n",
    "                self.image_paths.append(img_file) # data 파일에 있는 이미지 파일 저장\n",
    "\n",
    "        print(f'Found {len(self.image_paths)} images')        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index): # 이미지 스케일 변환\n",
    "        img_path = self.image_paths[index]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=1, feature_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(z_dim, feature_g*4, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.InstanceNorm2d(feature_g*4)\n",
    "        self.r1 = nn.ReLU(True)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(feature_g*4, feature_g, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.InstanceNorm2d(feature_g)\n",
    "        self.r2 = nn.ReLU(True)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(feature_g, img_channels, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.t = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.r1(self.bn1(self.conv1(x)))\n",
    "        x = self.r2(self.bn2(self.conv2(x)))\n",
    "        x = self.t(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_d=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(img_channels, feature_d, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(feature_d)\n",
    "        self.r1 = nn.LeakyReLU(True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(feature_d, feature_d*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(feature_d*4)\n",
    "        self.r2 = nn.ReLU(True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(feature_d*4, 1, kernel_size=3, stride=2, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.r1(self.bn1(self.conv1(x)))\n",
    "        x = self.r2(self.bn2(self.conv2(x)))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "data_dir = './data/train/'\n",
    "result_dir = './result/'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 4. 하이퍼파라미터 정의\n",
    "batch_size = 64\n",
    "lr = 0.0005\n",
    "z_dim = 100\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 100  # 훈련 에포크 수\n",
    "\n",
    "print(f\"Using Device: {device}\")\n",
    "\n",
    "# 5. 데이터 변환 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((16, 16)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# 6. 데이터셋 및 데이터로더 생성\n",
    "\n",
    "train_dataset = CustomMNISTDataset(root_dir=data_dir, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# 7. 모델 초기화\n",
    "\n",
    "gen = Generator(z_dim=z_dim, img_channels=1, feature_g=32).to(device)\n",
    "disc = Discriminator(img_channels=1, feature_d=32).to(device)\n",
    "\n",
    "# 8. 최적화 함수 및 손실 함수 정의\n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr*0.75)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 9. 생성된 이미지 시각화 함수 정의\n",
    "\n",
    "def show_generated_images(generator, num_images=64, epoch=0):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_images, z_dim, 1, 1).to(device)  # CNN은 4D 텐서 입력을 기대\n",
    "        fake_images = generator(noise)\n",
    "        fake_images = fake_images.cpu()\n",
    "        grid = vutils.make_grid(fake_images, nrow=8, normalize=True)\n",
    "        plt.clf()\n",
    "        plt.imshow(grid.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Generated Images at Epoch {epoch}')\n",
    "        plt.savefig(f'{result_dir}image_lr_mod.png', pad_inches=0.1, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    generator.train()\n",
    "\n",
    "# 10. GAN 훈련 루프\n",
    "losses_g = []\n",
    "losses_d = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, real in enumerate(train_dataloader):\n",
    "        real = real.to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        ### (a) 판별자 훈련 (진짜 이미지)\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        \n",
    "        # 진짜 이미지(1) 판별\n",
    "        disc_real = disc(real).view(-1) # 이미지 판별 결과\n",
    "        loss_disc_real = bce_loss(disc_real, torch.ones_like(disc_real))\n",
    "\n",
    "        # 가짜 이미지(0) 판별\n",
    "        disc_fake = disc(fake.detach()).view(-1)\n",
    "        loss_disc_fake = bce_loss(disc_fake, torch.zeros_like(disc_fake))\n",
    "        \n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        opt_disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### (b) 생성자 훈련 (가짜 이미지)\n",
    "        output = disc(fake).view(-1)\n",
    "        loss_gen = bce_loss(output, torch.ones_like(output))\n",
    "        \n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        losses_g.append(loss_gen.item())\n",
    "        losses_d.append(loss_disc.item())\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Batch {batch_idx}/{len(train_dataloader)} \"\n",
    "                  f\"Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\")\n",
    "            show_generated_images(gen, num_images=16, epoch=epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실 그래프 그리기\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses_g, label=\"Generator Loss\", color='blue')\n",
    "plt.plot(losses_d, label=\"Discriminator Loss\", color='red')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"GAN Loss\")\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
