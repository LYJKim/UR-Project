{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n",
      "Found 60000 images\n",
      "Epoch [1/20] Batch 0/938 Loss D: 0.7414, Loss G: 0.6043\n",
      "Epoch [1/20] Batch 10/938 Loss D: 0.4739, Loss G: 0.7594\n",
      "Epoch [1/20] Batch 20/938 Loss D: 0.3420, Loss G: 1.0037\n",
      "Epoch [1/20] Batch 30/938 Loss D: 0.2948, Loss G: 1.0997\n",
      "Epoch [1/20] Batch 40/938 Loss D: 0.2482, Loss G: 1.2733\n",
      "Epoch [1/20] Batch 50/938 Loss D: 0.1630, Loss G: 1.7457\n",
      "Epoch [1/20] Batch 60/938 Loss D: 0.1667, Loss G: 1.7947\n",
      "Epoch [1/20] Batch 70/938 Loss D: 0.1200, Loss G: 2.1831\n",
      "Epoch [1/20] Batch 80/938 Loss D: 0.1160, Loss G: 2.1231\n",
      "Epoch [1/20] Batch 90/938 Loss D: 0.1043, Loss G: 2.3175\n",
      "Epoch [1/20] Batch 100/938 Loss D: 0.0600, Loss G: 2.9524\n",
      "Epoch [1/20] Batch 110/938 Loss D: 0.0581, Loss G: 2.9725\n",
      "Epoch [1/20] Batch 120/938 Loss D: 0.1040, Loss G: 2.1085\n",
      "Epoch [1/20] Batch 130/938 Loss D: 0.0882, Loss G: 2.3104\n",
      "Epoch [1/20] Batch 140/938 Loss D: 0.0768, Loss G: 2.7449\n",
      "Epoch [1/20] Batch 150/938 Loss D: 0.0617, Loss G: 2.8921\n",
      "Epoch [1/20] Batch 160/938 Loss D: 0.0566, Loss G: 2.9160\n",
      "Epoch [1/20] Batch 170/938 Loss D: 0.0600, Loss G: 2.7795\n",
      "Epoch [1/20] Batch 180/938 Loss D: 0.0931, Loss G: 2.1969\n",
      "Epoch [1/20] Batch 190/938 Loss D: 0.0592, Loss G: 2.7722\n",
      "Epoch [1/20] Batch 200/938 Loss D: 0.0333, Loss G: 3.5755\n",
      "Epoch [1/20] Batch 210/938 Loss D: 0.0263, Loss G: 3.7951\n",
      "Epoch [1/20] Batch 220/938 Loss D: 0.0337, Loss G: 3.2667\n",
      "Epoch [1/20] Batch 230/938 Loss D: 0.0315, Loss G: 3.3930\n",
      "Epoch [1/20] Batch 240/938 Loss D: 0.0271, Loss G: 3.6413\n",
      "Epoch [1/20] Batch 250/938 Loss D: 0.0289, Loss G: 3.4363\n",
      "Epoch [1/20] Batch 260/938 Loss D: 0.0271, Loss G: 3.5026\n",
      "Epoch [1/20] Batch 270/938 Loss D: 0.0236, Loss G: 3.8669\n",
      "Epoch [1/20] Batch 280/938 Loss D: 0.0229, Loss G: 3.8426\n",
      "Epoch [1/20] Batch 290/938 Loss D: 0.0251, Loss G: 3.7340\n",
      "Epoch [1/20] Batch 300/938 Loss D: 0.0190, Loss G: 3.9826\n",
      "Epoch [1/20] Batch 310/938 Loss D: 0.0156, Loss G: 4.3216\n",
      "Epoch [1/20] Batch 320/938 Loss D: 0.0193, Loss G: 4.0328\n",
      "Epoch [1/20] Batch 330/938 Loss D: 0.0390, Loss G: 3.0449\n",
      "Epoch [1/20] Batch 340/938 Loss D: 0.0286, Loss G: 3.6039\n",
      "Epoch [1/20] Batch 350/938 Loss D: 0.0170, Loss G: 4.5010\n",
      "Epoch [1/20] Batch 360/938 Loss D: 0.0117, Loss G: 4.7318\n",
      "Epoch [1/20] Batch 370/938 Loss D: 0.0184, Loss G: 4.5203\n",
      "Epoch [1/20] Batch 380/938 Loss D: 0.0150, Loss G: 4.1149\n",
      "Epoch [1/20] Batch 390/938 Loss D: 0.0155, Loss G: 4.0682\n",
      "Epoch [1/20] Batch 400/938 Loss D: 0.0131, Loss G: 4.2152\n",
      "Epoch [1/20] Batch 410/938 Loss D: 0.0211, Loss G: 3.6335\n",
      "Epoch [1/20] Batch 420/938 Loss D: 0.0128, Loss G: 4.3783\n",
      "Epoch [1/20] Batch 430/938 Loss D: 0.0144, Loss G: 4.4095\n",
      "Epoch [1/20] Batch 440/938 Loss D: 0.0604, Loss G: 2.7525\n",
      "Epoch [1/20] Batch 450/938 Loss D: 0.0728, Loss G: 2.9995\n",
      "Epoch [1/20] Batch 460/938 Loss D: 0.0308, Loss G: 4.5330\n",
      "Epoch [1/20] Batch 470/938 Loss D: 0.0215, Loss G: 3.9563\n",
      "Epoch [1/20] Batch 480/938 Loss D: 0.0290, Loss G: 3.5863\n",
      "Epoch [1/20] Batch 490/938 Loss D: 0.0133, Loss G: 4.5140\n",
      "Epoch [1/20] Batch 500/938 Loss D: 0.0144, Loss G: 4.5377\n",
      "Epoch [1/20] Batch 510/938 Loss D: 0.0233, Loss G: 3.7287\n",
      "Epoch [1/20] Batch 520/938 Loss D: 0.0108, Loss G: 4.7551\n",
      "Epoch [1/20] Batch 530/938 Loss D: 0.0082, Loss G: 5.1812\n",
      "Epoch [1/20] Batch 540/938 Loss D: 0.0129, Loss G: 4.4610\n",
      "Epoch [1/20] Batch 550/938 Loss D: 0.0108, Loss G: 4.6822\n",
      "Epoch [1/20] Batch 560/938 Loss D: 0.0076, Loss G: 5.1541\n",
      "Epoch [1/20] Batch 570/938 Loss D: 0.0080, Loss G: 5.1552\n",
      "Epoch [1/20] Batch 580/938 Loss D: 0.0087, Loss G: 4.8107\n",
      "Epoch [1/20] Batch 590/938 Loss D: 0.0099, Loss G: 4.3842\n",
      "Epoch [1/20] Batch 600/938 Loss D: 0.0133, Loss G: 4.1469\n",
      "Epoch [1/20] Batch 610/938 Loss D: 0.0163, Loss G: 3.9832\n",
      "Epoch [1/20] Batch 620/938 Loss D: 0.0307, Loss G: 3.6679\n",
      "Epoch [1/20] Batch 630/938 Loss D: 0.0332, Loss G: 3.8432\n",
      "Epoch [1/20] Batch 640/938 Loss D: 0.1062, Loss G: 2.6962\n",
      "Epoch [1/20] Batch 650/938 Loss D: 0.0534, Loss G: 4.3104\n",
      "Epoch [1/20] Batch 660/938 Loss D: 0.0330, Loss G: 4.2508\n",
      "Epoch [1/20] Batch 670/938 Loss D: 0.0581, Loss G: 3.0902\n",
      "Epoch [1/20] Batch 680/938 Loss D: 0.0398, Loss G: 3.6626\n",
      "Epoch [1/20] Batch 690/938 Loss D: 0.0548, Loss G: 3.3826\n",
      "Epoch [1/20] Batch 700/938 Loss D: 0.0378, Loss G: 4.0268\n",
      "Epoch [1/20] Batch 710/938 Loss D: 0.0552, Loss G: 3.2065\n",
      "Epoch [1/20] Batch 720/938 Loss D: 0.0337, Loss G: 4.2488\n",
      "Epoch [1/20] Batch 730/938 Loss D: 0.0259, Loss G: 4.5839\n",
      "Epoch [1/20] Batch 740/938 Loss D: 0.0149, Loss G: 4.3990\n",
      "Epoch [1/20] Batch 750/938 Loss D: 0.0162, Loss G: 4.4508\n",
      "Epoch [1/20] Batch 760/938 Loss D: 0.0148, Loss G: 4.3224\n",
      "Epoch [1/20] Batch 770/938 Loss D: 0.0199, Loss G: 4.0726\n",
      "Epoch [1/20] Batch 780/938 Loss D: 0.0199, Loss G: 4.0793\n",
      "Epoch [1/20] Batch 790/938 Loss D: 0.0198, Loss G: 4.0692\n",
      "Epoch [1/20] Batch 800/938 Loss D: 0.0210, Loss G: 4.4565\n",
      "Epoch [1/20] Batch 810/938 Loss D: 0.0223, Loss G: 4.1724\n",
      "Epoch [1/20] Batch 820/938 Loss D: 0.0355, Loss G: 3.6103\n",
      "Epoch [1/20] Batch 830/938 Loss D: 0.0513, Loss G: 3.6174\n",
      "Epoch [1/20] Batch 840/938 Loss D: 0.0605, Loss G: 3.4000\n",
      "Epoch [1/20] Batch 850/938 Loss D: 0.0424, Loss G: 4.0949\n",
      "Epoch [1/20] Batch 860/938 Loss D: 0.0240, Loss G: 4.2466\n",
      "Epoch [1/20] Batch 870/938 Loss D: 0.0183, Loss G: 4.1819\n",
      "Epoch [1/20] Batch 880/938 Loss D: 0.0158, Loss G: 4.4471\n",
      "Epoch [1/20] Batch 890/938 Loss D: 0.0149, Loss G: 4.6551\n",
      "Epoch [1/20] Batch 900/938 Loss D: 0.0119, Loss G: 4.6416\n",
      "Epoch [1/20] Batch 910/938 Loss D: 0.0117, Loss G: 4.5739\n",
      "Epoch [1/20] Batch 920/938 Loss D: 0.0180, Loss G: 4.2247\n",
      "Epoch [1/20] Batch 930/938 Loss D: 0.0159, Loss G: 4.5041\n",
      "Epoch [2/20] Batch 0/938 Loss D: 0.0129, Loss G: 4.5875\n",
      "Epoch [2/20] Batch 10/938 Loss D: 0.0121, Loss G: 4.5361\n",
      "Epoch [2/20] Batch 20/938 Loss D: 0.0171, Loss G: 4.4988\n",
      "Epoch [2/20] Batch 30/938 Loss D: 0.0113, Loss G: 4.8306\n",
      "Epoch [2/20] Batch 40/938 Loss D: 0.0110, Loss G: 5.0077\n",
      "Epoch [2/20] Batch 50/938 Loss D: 0.0178, Loss G: 4.2383\n",
      "Epoch [2/20] Batch 60/938 Loss D: 0.0342, Loss G: 3.5437\n",
      "Epoch [2/20] Batch 70/938 Loss D: 0.0344, Loss G: 4.0934\n",
      "Epoch [2/20] Batch 80/938 Loss D: 0.0228, Loss G: 4.7394\n",
      "Epoch [2/20] Batch 90/938 Loss D: 0.0156, Loss G: 4.6174\n",
      "Epoch [2/20] Batch 100/938 Loss D: 0.0193, Loss G: 4.5446\n",
      "Epoch [2/20] Batch 110/938 Loss D: 0.0110, Loss G: 4.7046\n",
      "Epoch [2/20] Batch 120/938 Loss D: 0.0109, Loss G: 4.9751\n",
      "Epoch [2/20] Batch 130/938 Loss D: 0.0088, Loss G: 5.0231\n",
      "Epoch [2/20] Batch 140/938 Loss D: 0.0096, Loss G: 4.8431\n",
      "Epoch [2/20] Batch 150/938 Loss D: 0.0103, Loss G: 4.8544\n",
      "Epoch [2/20] Batch 160/938 Loss D: 0.0088, Loss G: 4.9452\n",
      "Epoch [2/20] Batch 170/938 Loss D: 0.0116, Loss G: 4.5373\n",
      "Epoch [2/20] Batch 180/938 Loss D: 0.0157, Loss G: 4.5777\n",
      "Epoch [2/20] Batch 190/938 Loss D: 0.0191, Loss G: 4.5506\n",
      "Epoch [2/20] Batch 200/938 Loss D: 0.0124, Loss G: 4.8149\n",
      "Epoch [2/20] Batch 210/938 Loss D: 0.0104, Loss G: 4.8127\n",
      "Epoch [2/20] Batch 220/938 Loss D: 0.0090, Loss G: 5.0034\n",
      "Epoch [2/20] Batch 230/938 Loss D: 0.0086, Loss G: 4.8380\n",
      "Epoch [2/20] Batch 240/938 Loss D: 0.0117, Loss G: 4.8097\n",
      "Epoch [2/20] Batch 250/938 Loss D: 0.0109, Loss G: 4.6720\n",
      "Epoch [2/20] Batch 260/938 Loss D: 0.0135, Loss G: 4.8240\n",
      "Epoch [2/20] Batch 270/938 Loss D: 0.0103, Loss G: 5.0670\n",
      "Epoch [2/20] Batch 280/938 Loss D: 0.0101, Loss G: 4.9962\n",
      "Epoch [2/20] Batch 290/938 Loss D: 0.0097, Loss G: 4.8462\n",
      "Epoch [2/20] Batch 300/938 Loss D: 0.0147, Loss G: 4.5801\n",
      "Epoch [2/20] Batch 310/938 Loss D: 0.0224, Loss G: 4.2420\n",
      "Epoch [2/20] Batch 320/938 Loss D: 0.0265, Loss G: 4.1618\n",
      "Epoch [2/20] Batch 330/938 Loss D: 0.0281, Loss G: 4.1064\n",
      "Epoch [2/20] Batch 340/938 Loss D: 0.0330, Loss G: 3.9213\n",
      "Epoch [2/20] Batch 350/938 Loss D: 0.0515, Loss G: 3.8826\n",
      "Epoch [2/20] Batch 360/938 Loss D: 0.0442, Loss G: 4.1170\n",
      "Epoch [2/20] Batch 370/938 Loss D: 0.0994, Loss G: 3.1061\n",
      "Epoch [2/20] Batch 380/938 Loss D: 0.1513, Loss G: 2.9013\n",
      "Epoch [2/20] Batch 390/938 Loss D: 0.0677, Loss G: 3.4176\n",
      "Epoch [2/20] Batch 400/938 Loss D: 0.0425, Loss G: 3.8745\n",
      "Epoch [2/20] Batch 410/938 Loss D: 0.0275, Loss G: 4.1652\n",
      "Epoch [2/20] Batch 420/938 Loss D: 0.0295, Loss G: 3.9898\n",
      "Epoch [2/20] Batch 430/938 Loss D: 0.0524, Loss G: 3.7437\n",
      "Epoch [2/20] Batch 440/938 Loss D: 0.1761, Loss G: 2.5492\n",
      "Epoch [2/20] Batch 450/938 Loss D: 0.0969, Loss G: 2.7890\n",
      "Epoch [2/20] Batch 460/938 Loss D: 0.0743, Loss G: 3.0219\n",
      "Epoch [2/20] Batch 470/938 Loss D: 0.1945, Loss G: 2.3268\n",
      "Epoch [2/20] Batch 480/938 Loss D: 0.1922, Loss G: 2.2992\n",
      "Epoch [2/20] Batch 490/938 Loss D: 0.0815, Loss G: 3.2130\n",
      "Epoch [2/20] Batch 500/938 Loss D: 0.0945, Loss G: 2.7483\n",
      "Epoch [2/20] Batch 510/938 Loss D: 0.2222, Loss G: 2.0617\n",
      "Epoch [2/20] Batch 520/938 Loss D: 0.1539, Loss G: 2.4802\n",
      "Epoch [2/20] Batch 530/938 Loss D: 0.1555, Loss G: 2.5485\n",
      "Epoch [2/20] Batch 540/938 Loss D: 0.1102, Loss G: 2.6409\n",
      "Epoch [2/20] Batch 550/938 Loss D: 0.1251, Loss G: 2.4509\n",
      "Epoch [2/20] Batch 560/938 Loss D: 0.2609, Loss G: 2.0208\n",
      "Epoch [2/20] Batch 570/938 Loss D: 0.1992, Loss G: 2.2055\n",
      "Epoch [2/20] Batch 580/938 Loss D: 0.1610, Loss G: 2.4334\n",
      "Epoch [2/20] Batch 590/938 Loss D: 0.0881, Loss G: 2.9160\n",
      "Epoch [2/20] Batch 600/938 Loss D: 0.1199, Loss G: 2.5976\n",
      "Epoch [2/20] Batch 610/938 Loss D: 0.2061, Loss G: 1.9831\n",
      "Epoch [2/20] Batch 620/938 Loss D: 0.1638, Loss G: 2.2653\n",
      "Epoch [2/20] Batch 630/938 Loss D: 0.1497, Loss G: 2.4005\n",
      "Epoch [2/20] Batch 640/938 Loss D: 0.2877, Loss G: 2.0127\n",
      "Epoch [2/20] Batch 650/938 Loss D: 0.1766, Loss G: 2.2894\n",
      "Epoch [2/20] Batch 660/938 Loss D: 0.1458, Loss G: 2.7882\n",
      "Epoch [2/20] Batch 670/938 Loss D: 0.2063, Loss G: 2.2906\n",
      "Epoch [2/20] Batch 680/938 Loss D: 0.2252, Loss G: 2.4402\n",
      "Epoch [2/20] Batch 690/938 Loss D: 0.2282, Loss G: 2.3908\n",
      "Epoch [2/20] Batch 700/938 Loss D: 0.1574, Loss G: 2.4270\n",
      "Epoch [2/20] Batch 710/938 Loss D: 0.2446, Loss G: 2.0436\n",
      "Epoch [2/20] Batch 720/938 Loss D: 0.2000, Loss G: 2.1049\n",
      "Epoch [2/20] Batch 730/938 Loss D: 0.1521, Loss G: 2.6019\n",
      "Epoch [2/20] Batch 740/938 Loss D: 0.2162, Loss G: 2.0595\n",
      "Epoch [2/20] Batch 750/938 Loss D: 0.2240, Loss G: 2.0995\n",
      "Epoch [2/20] Batch 760/938 Loss D: 0.2199, Loss G: 2.0629\n",
      "Epoch [2/20] Batch 770/938 Loss D: 0.1399, Loss G: 2.3370\n",
      "Epoch [2/20] Batch 780/938 Loss D: 0.1691, Loss G: 2.3521\n",
      "Epoch [2/20] Batch 790/938 Loss D: 0.2269, Loss G: 2.0476\n",
      "Epoch [2/20] Batch 800/938 Loss D: 0.2507, Loss G: 2.1543\n",
      "Epoch [2/20] Batch 810/938 Loss D: 0.2744, Loss G: 2.0772\n",
      "Epoch [2/20] Batch 820/938 Loss D: 0.2420, Loss G: 2.1135\n",
      "Epoch [2/20] Batch 830/938 Loss D: 0.2101, Loss G: 2.4097\n",
      "Epoch [2/20] Batch 840/938 Loss D: 0.2255, Loss G: 2.0616\n",
      "Epoch [2/20] Batch 850/938 Loss D: 0.1860, Loss G: 2.2698\n",
      "Epoch [2/20] Batch 860/938 Loss D: 0.1570, Loss G: 2.2471\n",
      "Epoch [2/20] Batch 870/938 Loss D: 0.3016, Loss G: 1.8210\n",
      "Epoch [2/20] Batch 880/938 Loss D: 0.3176, Loss G: 1.6476\n",
      "Epoch [2/20] Batch 890/938 Loss D: 0.2656, Loss G: 2.0323\n",
      "Epoch [2/20] Batch 900/938 Loss D: 0.1723, Loss G: 2.2559\n",
      "Epoch [2/20] Batch 910/938 Loss D: 0.2880, Loss G: 1.5517\n",
      "Epoch [2/20] Batch 920/938 Loss D: 0.2774, Loss G: 1.5183\n",
      "Epoch [2/20] Batch 930/938 Loss D: 0.1940, Loss G: 2.0407\n",
      "Epoch [3/20] Batch 0/938 Loss D: 0.2035, Loss G: 1.7694\n",
      "Epoch [3/20] Batch 10/938 Loss D: 0.2097, Loss G: 1.9583\n",
      "Epoch [3/20] Batch 20/938 Loss D: 0.1889, Loss G: 2.1291\n",
      "Epoch [3/20] Batch 30/938 Loss D: 0.3117, Loss G: 1.7592\n",
      "Epoch [3/20] Batch 40/938 Loss D: 0.2678, Loss G: 1.6460\n",
      "Epoch [3/20] Batch 50/938 Loss D: 0.2005, Loss G: 1.9294\n",
      "Epoch [3/20] Batch 60/938 Loss D: 0.2505, Loss G: 1.7485\n",
      "Epoch [3/20] Batch 70/938 Loss D: 0.1901, Loss G: 2.0185\n",
      "Epoch [3/20] Batch 80/938 Loss D: 0.3134, Loss G: 1.4959\n",
      "Epoch [3/20] Batch 90/938 Loss D: 0.2249, Loss G: 1.9283\n",
      "Epoch [3/20] Batch 100/938 Loss D: 0.2820, Loss G: 1.5325\n",
      "Epoch [3/20] Batch 110/938 Loss D: 0.1836, Loss G: 2.0590\n",
      "Epoch [3/20] Batch 120/938 Loss D: 0.1945, Loss G: 2.1069\n",
      "Epoch [3/20] Batch 130/938 Loss D: 0.2396, Loss G: 2.1027\n",
      "Epoch [3/20] Batch 140/938 Loss D: 0.4054, Loss G: 1.5872\n",
      "Epoch [3/20] Batch 150/938 Loss D: 0.2631, Loss G: 1.7110\n",
      "Epoch [3/20] Batch 160/938 Loss D: 0.2977, Loss G: 1.6032\n",
      "Epoch [3/20] Batch 170/938 Loss D: 0.2447, Loss G: 1.8243\n",
      "Epoch [3/20] Batch 180/938 Loss D: 0.2555, Loss G: 1.7935\n",
      "Epoch [3/20] Batch 190/938 Loss D: 0.2827, Loss G: 1.9915\n",
      "Epoch [3/20] Batch 200/938 Loss D: 0.2625, Loss G: 2.1029\n",
      "Epoch [3/20] Batch 210/938 Loss D: 0.2515, Loss G: 1.8217\n",
      "Epoch [3/20] Batch 220/938 Loss D: 0.2395, Loss G: 1.7921\n",
      "Epoch [3/20] Batch 230/938 Loss D: 0.3003, Loss G: 1.6107\n",
      "Epoch [3/20] Batch 240/938 Loss D: 0.2100, Loss G: 2.0989\n",
      "Epoch [3/20] Batch 250/938 Loss D: 0.2555, Loss G: 1.5572\n",
      "Epoch [3/20] Batch 260/938 Loss D: 0.2468, Loss G: 1.5988\n",
      "Epoch [3/20] Batch 270/938 Loss D: 0.2507, Loss G: 1.7780\n",
      "Epoch [3/20] Batch 280/938 Loss D: 0.2959, Loss G: 1.7024\n",
      "Epoch [3/20] Batch 290/938 Loss D: 0.1813, Loss G: 2.4347\n",
      "Epoch [3/20] Batch 300/938 Loss D: 0.2539, Loss G: 1.7847\n",
      "Epoch [3/20] Batch 310/938 Loss D: 0.3469, Loss G: 1.5569\n",
      "Epoch [3/20] Batch 320/938 Loss D: 0.2438, Loss G: 2.0180\n",
      "Epoch [3/20] Batch 330/938 Loss D: 0.3378, Loss G: 1.7386\n",
      "Epoch [3/20] Batch 340/938 Loss D: 0.3091, Loss G: 1.6196\n",
      "Epoch [3/20] Batch 350/938 Loss D: 0.2849, Loss G: 1.7721\n",
      "Epoch [3/20] Batch 360/938 Loss D: 0.2456, Loss G: 1.8033\n",
      "Epoch [3/20] Batch 370/938 Loss D: 0.3901, Loss G: 1.8030\n",
      "Epoch [3/20] Batch 380/938 Loss D: 0.2206, Loss G: 2.0397\n",
      "Epoch [3/20] Batch 390/938 Loss D: 0.2816, Loss G: 1.3971\n",
      "Epoch [3/20] Batch 400/938 Loss D: 0.2525, Loss G: 1.5685\n",
      "Epoch [3/20] Batch 410/938 Loss D: 0.2954, Loss G: 1.5824\n",
      "Epoch [3/20] Batch 420/938 Loss D: 0.3076, Loss G: 1.6934\n",
      "Epoch [3/20] Batch 430/938 Loss D: 0.2898, Loss G: 1.5810\n",
      "Epoch [3/20] Batch 440/938 Loss D: 0.2674, Loss G: 1.6710\n",
      "Epoch [3/20] Batch 450/938 Loss D: 0.2840, Loss G: 1.8321\n",
      "Epoch [3/20] Batch 460/938 Loss D: 0.2731, Loss G: 1.6367\n",
      "Epoch [3/20] Batch 470/938 Loss D: 0.2736, Loss G: 1.9222\n",
      "Epoch [3/20] Batch 480/938 Loss D: 0.2102, Loss G: 2.0030\n",
      "Epoch [3/20] Batch 490/938 Loss D: 0.2571, Loss G: 1.6573\n",
      "Epoch [3/20] Batch 500/938 Loss D: 0.2750, Loss G: 1.6459\n",
      "Epoch [3/20] Batch 510/938 Loss D: 0.3195, Loss G: 1.4449\n",
      "Epoch [3/20] Batch 520/938 Loss D: 0.2854, Loss G: 1.5936\n",
      "Epoch [3/20] Batch 530/938 Loss D: 0.2961, Loss G: 1.5992\n",
      "Epoch [3/20] Batch 540/938 Loss D: 0.2686, Loss G: 1.9839\n",
      "Epoch [3/20] Batch 550/938 Loss D: 0.2236, Loss G: 1.8562\n",
      "Epoch [3/20] Batch 560/938 Loss D: 0.2809, Loss G: 1.5540\n",
      "Epoch [3/20] Batch 570/938 Loss D: 0.3011, Loss G: 1.8887\n",
      "Epoch [3/20] Batch 580/938 Loss D: 0.4377, Loss G: 1.4960\n",
      "Epoch [3/20] Batch 590/938 Loss D: 0.2849, Loss G: 2.1050\n",
      "Epoch [3/20] Batch 600/938 Loss D: 0.2100, Loss G: 1.9810\n",
      "Epoch [3/20] Batch 610/938 Loss D: 0.2867, Loss G: 1.8641\n",
      "Epoch [3/20] Batch 620/938 Loss D: 0.1842, Loss G: 2.0649\n",
      "Epoch [3/20] Batch 630/938 Loss D: 0.2570, Loss G: 1.5597\n",
      "Epoch [3/20] Batch 640/938 Loss D: 0.2404, Loss G: 1.6500\n",
      "Epoch [3/20] Batch 650/938 Loss D: 0.2741, Loss G: 1.5288\n",
      "Epoch [3/20] Batch 660/938 Loss D: 0.3076, Loss G: 1.4380\n",
      "Epoch [3/20] Batch 670/938 Loss D: 0.2231, Loss G: 1.6339\n",
      "Epoch [3/20] Batch 680/938 Loss D: 0.2710, Loss G: 1.8925\n",
      "Epoch [3/20] Batch 690/938 Loss D: 0.2665, Loss G: 1.9026\n",
      "Epoch [3/20] Batch 700/938 Loss D: 0.3249, Loss G: 1.4317\n",
      "Epoch [3/20] Batch 710/938 Loss D: 0.2673, Loss G: 1.5212\n",
      "Epoch [3/20] Batch 720/938 Loss D: 0.2770, Loss G: 1.7719\n",
      "Epoch [3/20] Batch 730/938 Loss D: 0.2716, Loss G: 1.9504\n",
      "Epoch [3/20] Batch 740/938 Loss D: 0.2211, Loss G: 1.8269\n",
      "Epoch [3/20] Batch 750/938 Loss D: 0.2749, Loss G: 1.5241\n",
      "Epoch [3/20] Batch 760/938 Loss D: 0.2707, Loss G: 1.7552\n",
      "Epoch [3/20] Batch 770/938 Loss D: 0.3707, Loss G: 1.4814\n",
      "Epoch [3/20] Batch 780/938 Loss D: 0.2217, Loss G: 1.8890\n",
      "Epoch [3/20] Batch 790/938 Loss D: 0.2862, Loss G: 1.4341\n",
      "Epoch [3/20] Batch 800/938 Loss D: 0.2963, Loss G: 1.3768\n",
      "Epoch [3/20] Batch 810/938 Loss D: 0.2272, Loss G: 1.7103\n",
      "Epoch [3/20] Batch 820/938 Loss D: 0.3337, Loss G: 1.3314\n",
      "Epoch [3/20] Batch 830/938 Loss D: 0.1940, Loss G: 1.8985\n",
      "Epoch [3/20] Batch 840/938 Loss D: 0.3004, Loss G: 1.4913\n",
      "Epoch [3/20] Batch 850/938 Loss D: 0.3120, Loss G: 1.5583\n",
      "Epoch [3/20] Batch 860/938 Loss D: 0.3423, Loss G: 1.3652\n",
      "Epoch [3/20] Batch 870/938 Loss D: 0.3200, Loss G: 1.2363\n",
      "Epoch [3/20] Batch 880/938 Loss D: 0.2941, Loss G: 1.6294\n",
      "Epoch [3/20] Batch 890/938 Loss D: 0.4240, Loss G: 1.2607\n",
      "Epoch [3/20] Batch 900/938 Loss D: 0.2542, Loss G: 2.0689\n",
      "Epoch [3/20] Batch 910/938 Loss D: 0.2479, Loss G: 1.8087\n",
      "Epoch [3/20] Batch 920/938 Loss D: 0.3358, Loss G: 1.2981\n",
      "Epoch [3/20] Batch 930/938 Loss D: 0.2571, Loss G: 1.7210\n",
      "Epoch [4/20] Batch 0/938 Loss D: 0.4245, Loss G: 1.3149\n",
      "Epoch [4/20] Batch 10/938 Loss D: 0.3341, Loss G: 1.4483\n",
      "Epoch [4/20] Batch 20/938 Loss D: 0.3117, Loss G: 1.4938\n",
      "Epoch [4/20] Batch 30/938 Loss D: 0.3537, Loss G: 1.4981\n",
      "Epoch [4/20] Batch 40/938 Loss D: 0.3098, Loss G: 1.8079\n",
      "Epoch [4/20] Batch 50/938 Loss D: 0.3009, Loss G: 1.5046\n",
      "Epoch [4/20] Batch 60/938 Loss D: 0.1952, Loss G: 2.0643\n",
      "Epoch [4/20] Batch 70/938 Loss D: 0.4058, Loss G: 1.1313\n",
      "Epoch [4/20] Batch 80/938 Loss D: 0.3168, Loss G: 1.4889\n",
      "Epoch [4/20] Batch 90/938 Loss D: 0.3448, Loss G: 1.5475\n",
      "Epoch [4/20] Batch 100/938 Loss D: 0.3313, Loss G: 1.7323\n",
      "Epoch [4/20] Batch 110/938 Loss D: 0.2409, Loss G: 1.9200\n",
      "Epoch [4/20] Batch 120/938 Loss D: 0.3603, Loss G: 1.3206\n",
      "Epoch [4/20] Batch 130/938 Loss D: 0.3573, Loss G: 1.7912\n",
      "Epoch [4/20] Batch 140/938 Loss D: 0.3039, Loss G: 1.7949\n",
      "Epoch [4/20] Batch 150/938 Loss D: 0.3163, Loss G: 1.6213\n",
      "Epoch [4/20] Batch 160/938 Loss D: 0.2740, Loss G: 1.6387\n",
      "Epoch [4/20] Batch 170/938 Loss D: 0.3914, Loss G: 1.2367\n",
      "Epoch [4/20] Batch 180/938 Loss D: 0.2598, Loss G: 1.9055\n",
      "Epoch [4/20] Batch 190/938 Loss D: 0.3887, Loss G: 1.3098\n",
      "Epoch [4/20] Batch 200/938 Loss D: 0.2599, Loss G: 1.9511\n",
      "Epoch [4/20] Batch 210/938 Loss D: 0.2783, Loss G: 1.7701\n",
      "Epoch [4/20] Batch 220/938 Loss D: 0.3661, Loss G: 1.3259\n",
      "Epoch [4/20] Batch 230/938 Loss D: 0.2188, Loss G: 1.5987\n",
      "Epoch [4/20] Batch 240/938 Loss D: 0.3834, Loss G: 1.1292\n",
      "Epoch [4/20] Batch 250/938 Loss D: 0.2503, Loss G: 1.7642\n",
      "Epoch [4/20] Batch 260/938 Loss D: 0.2791, Loss G: 1.5156\n",
      "Epoch [4/20] Batch 270/938 Loss D: 0.3244, Loss G: 1.5723\n",
      "Epoch [4/20] Batch 280/938 Loss D: 0.2524, Loss G: 1.8812\n",
      "Epoch [4/20] Batch 290/938 Loss D: 0.2759, Loss G: 1.6673\n",
      "Epoch [4/20] Batch 300/938 Loss D: 0.2965, Loss G: 1.7928\n",
      "Epoch [4/20] Batch 310/938 Loss D: 0.3898, Loss G: 1.3857\n",
      "Epoch [4/20] Batch 320/938 Loss D: 0.3151, Loss G: 1.5556\n",
      "Epoch [4/20] Batch 330/938 Loss D: 0.2907, Loss G: 1.5949\n",
      "Epoch [4/20] Batch 340/938 Loss D: 0.2975, Loss G: 1.3241\n",
      "Epoch [4/20] Batch 350/938 Loss D: 0.2834, Loss G: 1.4533\n",
      "Epoch [4/20] Batch 360/938 Loss D: 0.3183, Loss G: 1.6505\n",
      "Epoch [4/20] Batch 370/938 Loss D: 0.3027, Loss G: 1.7159\n",
      "Epoch [4/20] Batch 380/938 Loss D: 0.2812, Loss G: 1.4534\n",
      "Epoch [4/20] Batch 390/938 Loss D: 0.3036, Loss G: 1.5380\n",
      "Epoch [4/20] Batch 400/938 Loss D: 0.2718, Loss G: 1.8791\n",
      "Epoch [4/20] Batch 410/938 Loss D: 0.2771, Loss G: 1.7493\n",
      "Epoch [4/20] Batch 420/938 Loss D: 0.3065, Loss G: 1.4340\n",
      "Epoch [4/20] Batch 430/938 Loss D: 0.2526, Loss G: 1.5804\n",
      "Epoch [4/20] Batch 440/938 Loss D: 0.3788, Loss G: 1.3497\n",
      "Epoch [4/20] Batch 450/938 Loss D: 0.3171, Loss G: 1.6204\n",
      "Epoch [4/20] Batch 460/938 Loss D: 0.3152, Loss G: 1.4219\n",
      "Epoch [4/20] Batch 470/938 Loss D: 0.3997, Loss G: 1.1405\n",
      "Epoch [4/20] Batch 480/938 Loss D: 0.2341, Loss G: 1.7243\n",
      "Epoch [4/20] Batch 490/938 Loss D: 0.3119, Loss G: 1.4166\n",
      "Epoch [4/20] Batch 500/938 Loss D: 0.3321, Loss G: 1.5989\n",
      "Epoch [4/20] Batch 510/938 Loss D: 0.3009, Loss G: 1.3336\n",
      "Epoch [4/20] Batch 520/938 Loss D: 0.2506, Loss G: 1.3838\n",
      "Epoch [4/20] Batch 530/938 Loss D: 0.2507, Loss G: 1.6197\n",
      "Epoch [4/20] Batch 540/938 Loss D: 0.4469, Loss G: 1.0417\n",
      "Epoch [4/20] Batch 550/938 Loss D: 0.2184, Loss G: 1.9825\n",
      "Epoch [4/20] Batch 560/938 Loss D: 0.3797, Loss G: 1.1072\n",
      "Epoch [4/20] Batch 570/938 Loss D: 0.3509, Loss G: 1.3633\n",
      "Epoch [4/20] Batch 580/938 Loss D: 0.2751, Loss G: 1.6100\n",
      "Epoch [4/20] Batch 590/938 Loss D: 0.3070, Loss G: 1.3861\n",
      "Epoch [4/20] Batch 600/938 Loss D: 0.2817, Loss G: 1.4644\n",
      "Epoch [4/20] Batch 610/938 Loss D: 0.3297, Loss G: 1.3329\n",
      "Epoch [4/20] Batch 620/938 Loss D: 0.3153, Loss G: 1.5738\n",
      "Epoch [4/20] Batch 630/938 Loss D: 0.2969, Loss G: 2.0676\n",
      "Epoch [4/20] Batch 640/938 Loss D: 0.2871, Loss G: 1.4483\n",
      "Epoch [4/20] Batch 650/938 Loss D: 0.3440, Loss G: 1.3285\n",
      "Epoch [4/20] Batch 660/938 Loss D: 0.3603, Loss G: 1.4422\n",
      "Epoch [4/20] Batch 670/938 Loss D: 0.3254, Loss G: 1.4141\n",
      "Epoch [4/20] Batch 680/938 Loss D: 0.3396, Loss G: 1.4979\n",
      "Epoch [4/20] Batch 690/938 Loss D: 0.3736, Loss G: 1.0815\n",
      "Epoch [4/20] Batch 700/938 Loss D: 0.3397, Loss G: 1.3847\n",
      "Epoch [4/20] Batch 710/938 Loss D: 0.2508, Loss G: 1.8091\n",
      "Epoch [4/20] Batch 720/938 Loss D: 0.3128, Loss G: 1.4592\n",
      "Epoch [4/20] Batch 730/938 Loss D: 0.2918, Loss G: 1.4781\n",
      "Epoch [4/20] Batch 740/938 Loss D: 0.3274, Loss G: 1.4847\n",
      "Epoch [4/20] Batch 750/938 Loss D: 0.2944, Loss G: 1.4019\n",
      "Epoch [4/20] Batch 760/938 Loss D: 0.3236, Loss G: 1.6170\n",
      "Epoch [4/20] Batch 770/938 Loss D: 0.5220, Loss G: 1.2775\n",
      "Epoch [4/20] Batch 780/938 Loss D: 0.2734, Loss G: 1.5104\n",
      "Epoch [4/20] Batch 790/938 Loss D: 0.3424, Loss G: 1.7255\n",
      "Epoch [4/20] Batch 800/938 Loss D: 0.3792, Loss G: 1.3454\n",
      "Epoch [4/20] Batch 810/938 Loss D: 0.3591, Loss G: 1.3539\n",
      "Epoch [4/20] Batch 820/938 Loss D: 0.3490, Loss G: 1.4232\n",
      "Epoch [4/20] Batch 830/938 Loss D: 0.3490, Loss G: 1.4251\n",
      "Epoch [4/20] Batch 840/938 Loss D: 0.3296, Loss G: 1.5565\n",
      "Epoch [4/20] Batch 850/938 Loss D: 0.4241, Loss G: 1.2359\n",
      "Epoch [4/20] Batch 860/938 Loss D: 0.3846, Loss G: 1.4512\n",
      "Epoch [4/20] Batch 870/938 Loss D: 0.2508, Loss G: 1.6551\n",
      "Epoch [4/20] Batch 880/938 Loss D: 0.4060, Loss G: 1.2714\n",
      "Epoch [4/20] Batch 890/938 Loss D: 0.2953, Loss G: 1.6491\n",
      "Epoch [4/20] Batch 900/938 Loss D: 0.2453, Loss G: 1.7933\n",
      "Epoch [4/20] Batch 910/938 Loss D: 0.3586, Loss G: 1.2431\n",
      "Epoch [4/20] Batch 920/938 Loss D: 0.3146, Loss G: 1.4995\n",
      "Epoch [4/20] Batch 930/938 Loss D: 0.2956, Loss G: 1.6711\n",
      "Epoch [5/20] Batch 0/938 Loss D: 0.3880, Loss G: 1.2861\n",
      "Epoch [5/20] Batch 10/938 Loss D: 0.3183, Loss G: 1.3206\n",
      "Epoch [5/20] Batch 20/938 Loss D: 0.3412, Loss G: 1.1834\n",
      "Epoch [5/20] Batch 30/938 Loss D: 0.3375, Loss G: 1.6816\n",
      "Epoch [5/20] Batch 40/938 Loss D: 0.3326, Loss G: 1.5198\n",
      "Epoch [5/20] Batch 50/938 Loss D: 0.4713, Loss G: 1.1866\n",
      "Epoch [5/20] Batch 60/938 Loss D: 0.3562, Loss G: 1.6645\n",
      "Epoch [5/20] Batch 70/938 Loss D: 0.4075, Loss G: 1.1949\n",
      "Epoch [5/20] Batch 80/938 Loss D: 0.3069, Loss G: 1.5649\n",
      "Epoch [5/20] Batch 90/938 Loss D: 0.3908, Loss G: 1.3877\n",
      "Epoch [5/20] Batch 100/938 Loss D: 0.4126, Loss G: 1.3512\n",
      "Epoch [5/20] Batch 110/938 Loss D: 0.3635, Loss G: 1.5702\n",
      "Epoch [5/20] Batch 120/938 Loss D: 0.4267, Loss G: 1.3831\n",
      "Epoch [5/20] Batch 130/938 Loss D: 0.4039, Loss G: 1.3877\n",
      "Epoch [5/20] Batch 140/938 Loss D: 0.2991, Loss G: 1.6124\n",
      "Epoch [5/20] Batch 150/938 Loss D: 0.4329, Loss G: 1.2480\n",
      "Epoch [5/20] Batch 160/938 Loss D: 0.3372, Loss G: 1.3292\n",
      "Epoch [5/20] Batch 170/938 Loss D: 0.3648, Loss G: 1.4088\n",
      "Epoch [5/20] Batch 180/938 Loss D: 0.3876, Loss G: 1.2852\n",
      "Epoch [5/20] Batch 190/938 Loss D: 0.3641, Loss G: 1.4883\n",
      "Epoch [5/20] Batch 200/938 Loss D: 0.3204, Loss G: 1.4588\n",
      "Epoch [5/20] Batch 210/938 Loss D: 0.4262, Loss G: 1.1978\n",
      "Epoch [5/20] Batch 220/938 Loss D: 0.2874, Loss G: 1.3999\n",
      "Epoch [5/20] Batch 230/938 Loss D: 0.3557, Loss G: 1.3949\n",
      "Epoch [5/20] Batch 240/938 Loss D: 0.4120, Loss G: 1.4197\n",
      "Epoch [5/20] Batch 250/938 Loss D: 0.2749, Loss G: 1.6067\n",
      "Epoch [5/20] Batch 260/938 Loss D: 0.4240, Loss G: 1.0467\n",
      "Epoch [5/20] Batch 270/938 Loss D: 0.2999, Loss G: 1.4368\n",
      "Epoch [5/20] Batch 280/938 Loss D: 0.4675, Loss G: 1.1528\n",
      "Epoch [5/20] Batch 290/938 Loss D: 0.4311, Loss G: 1.5139\n",
      "Epoch [5/20] Batch 300/938 Loss D: 0.3243, Loss G: 1.7501\n",
      "Epoch [5/20] Batch 310/938 Loss D: 0.3083, Loss G: 1.5936\n",
      "Epoch [5/20] Batch 320/938 Loss D: 0.4049, Loss G: 1.3539\n",
      "Epoch [5/20] Batch 330/938 Loss D: 0.3659, Loss G: 1.6003\n",
      "Epoch [5/20] Batch 340/938 Loss D: 0.3778, Loss G: 1.5766\n",
      "Epoch [5/20] Batch 350/938 Loss D: 0.4615, Loss G: 1.4274\n",
      "Epoch [5/20] Batch 360/938 Loss D: 0.3113, Loss G: 1.6856\n",
      "Epoch [5/20] Batch 370/938 Loss D: 0.3304, Loss G: 1.6824\n",
      "Epoch [5/20] Batch 380/938 Loss D: 0.2981, Loss G: 1.7074\n",
      "Epoch [5/20] Batch 390/938 Loss D: 0.2987, Loss G: 1.4183\n",
      "Epoch [5/20] Batch 400/938 Loss D: 0.3808, Loss G: 1.3005\n",
      "Epoch [5/20] Batch 410/938 Loss D: 0.3492, Loss G: 1.5368\n",
      "Epoch [5/20] Batch 420/938 Loss D: 0.4003, Loss G: 1.4889\n",
      "Epoch [5/20] Batch 430/938 Loss D: 0.4356, Loss G: 1.4747\n",
      "Epoch [5/20] Batch 440/938 Loss D: 0.3058, Loss G: 1.7601\n",
      "Epoch [5/20] Batch 450/938 Loss D: 0.4793, Loss G: 1.2849\n",
      "Epoch [5/20] Batch 460/938 Loss D: 0.4499, Loss G: 1.4156\n",
      "Epoch [5/20] Batch 470/938 Loss D: 0.3053, Loss G: 1.4848\n",
      "Epoch [5/20] Batch 480/938 Loss D: 0.3395, Loss G: 1.5062\n",
      "Epoch [5/20] Batch 490/938 Loss D: 0.4201, Loss G: 1.3400\n",
      "Epoch [5/20] Batch 500/938 Loss D: 0.4141, Loss G: 1.2150\n",
      "Epoch [5/20] Batch 510/938 Loss D: 0.4639, Loss G: 1.0625\n",
      "Epoch [5/20] Batch 520/938 Loss D: 0.3536, Loss G: 1.6510\n",
      "Epoch [5/20] Batch 530/938 Loss D: 0.3348, Loss G: 1.7581\n",
      "Epoch [5/20] Batch 540/938 Loss D: 0.3786, Loss G: 1.4263\n",
      "Epoch [5/20] Batch 550/938 Loss D: 0.3787, Loss G: 1.8001\n",
      "Epoch [5/20] Batch 560/938 Loss D: 0.3617, Loss G: 1.5286\n",
      "Epoch [5/20] Batch 570/938 Loss D: 0.3850, Loss G: 1.3331\n",
      "Epoch [5/20] Batch 580/938 Loss D: 0.3601, Loss G: 1.4885\n",
      "Epoch [5/20] Batch 590/938 Loss D: 0.3958, Loss G: 1.3122\n",
      "Epoch [5/20] Batch 600/938 Loss D: 0.4647, Loss G: 1.3646\n",
      "Epoch [5/20] Batch 610/938 Loss D: 0.3845, Loss G: 1.6868\n",
      "Epoch [5/20] Batch 620/938 Loss D: 0.3627, Loss G: 1.5401\n",
      "Epoch [5/20] Batch 630/938 Loss D: 0.4626, Loss G: 1.2891\n",
      "Epoch [5/20] Batch 640/938 Loss D: 0.4864, Loss G: 1.6781\n",
      "Epoch [5/20] Batch 650/938 Loss D: 0.4562, Loss G: 1.3445\n",
      "Epoch [5/20] Batch 660/938 Loss D: 0.3691, Loss G: 1.5345\n",
      "Epoch [5/20] Batch 670/938 Loss D: 0.2894, Loss G: 1.6543\n",
      "Epoch [5/20] Batch 680/938 Loss D: 0.5027, Loss G: 1.1722\n",
      "Epoch [5/20] Batch 690/938 Loss D: 0.3579, Loss G: 1.8523\n",
      "Epoch [5/20] Batch 700/938 Loss D: 0.4182, Loss G: 1.4881\n",
      "Epoch [5/20] Batch 710/938 Loss D: 0.5136, Loss G: 1.1701\n",
      "Epoch [5/20] Batch 720/938 Loss D: 0.3760, Loss G: 1.3553\n",
      "Epoch [5/20] Batch 730/938 Loss D: 0.3260, Loss G: 1.6060\n",
      "Epoch [5/20] Batch 740/938 Loss D: 0.3975, Loss G: 1.2739\n",
      "Epoch [5/20] Batch 750/938 Loss D: 0.3201, Loss G: 1.5397\n",
      "Epoch [5/20] Batch 760/938 Loss D: 0.3505, Loss G: 1.5827\n",
      "Epoch [5/20] Batch 770/938 Loss D: 0.4650, Loss G: 1.4085\n",
      "Epoch [5/20] Batch 780/938 Loss D: 0.3776, Loss G: 1.3486\n",
      "Epoch [5/20] Batch 790/938 Loss D: 0.3149, Loss G: 1.5201\n",
      "Epoch [5/20] Batch 800/938 Loss D: 0.3604, Loss G: 1.4475\n",
      "Epoch [5/20] Batch 810/938 Loss D: 0.3520, Loss G: 1.6053\n",
      "Epoch [5/20] Batch 820/938 Loss D: 0.4175, Loss G: 1.7142\n",
      "Epoch [5/20] Batch 830/938 Loss D: 0.3983, Loss G: 1.4211\n",
      "Epoch [5/20] Batch 840/938 Loss D: 0.4272, Loss G: 1.4402\n",
      "Epoch [5/20] Batch 850/938 Loss D: 0.3045, Loss G: 1.6257\n",
      "Epoch [5/20] Batch 860/938 Loss D: 0.3293, Loss G: 1.5748\n",
      "Epoch [5/20] Batch 870/938 Loss D: 0.3690, Loss G: 1.5364\n",
      "Epoch [5/20] Batch 880/938 Loss D: 0.3311, Loss G: 1.6582\n",
      "Epoch [5/20] Batch 890/938 Loss D: 0.4398, Loss G: 1.3757\n",
      "Epoch [5/20] Batch 900/938 Loss D: 0.4513, Loss G: 1.2229\n",
      "Epoch [5/20] Batch 910/938 Loss D: 0.4097, Loss G: 1.3505\n",
      "Epoch [5/20] Batch 920/938 Loss D: 0.4269, Loss G: 1.2915\n",
      "Epoch [5/20] Batch 930/938 Loss D: 0.2880, Loss G: 1.7870\n",
      "Epoch [6/20] Batch 0/938 Loss D: 0.3749, Loss G: 1.3231\n",
      "Epoch [6/20] Batch 10/938 Loss D: 0.3428, Loss G: 1.5966\n",
      "Epoch [6/20] Batch 20/938 Loss D: 0.5467, Loss G: 1.3140\n",
      "Epoch [6/20] Batch 30/938 Loss D: 0.4135, Loss G: 1.2989\n",
      "Epoch [6/20] Batch 40/938 Loss D: 0.3054, Loss G: 1.6221\n",
      "Epoch [6/20] Batch 50/938 Loss D: 0.3068, Loss G: 1.4900\n",
      "Epoch [6/20] Batch 60/938 Loss D: 0.4721, Loss G: 1.2016\n",
      "Epoch [6/20] Batch 70/938 Loss D: 0.5012, Loss G: 1.1758\n",
      "Epoch [6/20] Batch 80/938 Loss D: 0.4813, Loss G: 1.3129\n",
      "Epoch [6/20] Batch 90/938 Loss D: 0.2923, Loss G: 1.6327\n",
      "Epoch [6/20] Batch 100/938 Loss D: 0.3030, Loss G: 1.9317\n",
      "Epoch [6/20] Batch 110/938 Loss D: 0.3206, Loss G: 1.6767\n",
      "Epoch [6/20] Batch 120/938 Loss D: 0.4607, Loss G: 1.2092\n",
      "Epoch [6/20] Batch 130/938 Loss D: 0.5234, Loss G: 1.3864\n",
      "Epoch [6/20] Batch 140/938 Loss D: 0.4166, Loss G: 1.3829\n",
      "Epoch [6/20] Batch 150/938 Loss D: 0.4011, Loss G: 1.4874\n",
      "Epoch [6/20] Batch 160/938 Loss D: 0.4323, Loss G: 1.3767\n",
      "Epoch [6/20] Batch 170/938 Loss D: 0.3630, Loss G: 1.4502\n",
      "Epoch [6/20] Batch 180/938 Loss D: 0.4494, Loss G: 1.1648\n",
      "Epoch [6/20] Batch 190/938 Loss D: 0.3324, Loss G: 1.4883\n",
      "Epoch [6/20] Batch 200/938 Loss D: 0.3136, Loss G: 1.4827\n",
      "Epoch [6/20] Batch 210/938 Loss D: 0.4582, Loss G: 1.2380\n",
      "Epoch [6/20] Batch 220/938 Loss D: 0.4630, Loss G: 1.3147\n",
      "Epoch [6/20] Batch 230/938 Loss D: 0.5116, Loss G: 1.2939\n",
      "Epoch [6/20] Batch 240/938 Loss D: 0.3692, Loss G: 1.4583\n",
      "Epoch [6/20] Batch 250/938 Loss D: 0.3964, Loss G: 1.3819\n",
      "Epoch [6/20] Batch 260/938 Loss D: 0.4505, Loss G: 1.3358\n",
      "Epoch [6/20] Batch 270/938 Loss D: 0.3712, Loss G: 1.5327\n",
      "Epoch [6/20] Batch 280/938 Loss D: 0.4608, Loss G: 1.2948\n",
      "Epoch [6/20] Batch 290/938 Loss D: 0.3596, Loss G: 1.3072\n",
      "Epoch [6/20] Batch 300/938 Loss D: 0.3846, Loss G: 1.3617\n",
      "Epoch [6/20] Batch 310/938 Loss D: 0.3874, Loss G: 1.3245\n",
      "Epoch [6/20] Batch 320/938 Loss D: 0.5700, Loss G: 1.1001\n",
      "Epoch [6/20] Batch 330/938 Loss D: 0.5130, Loss G: 1.4718\n",
      "Epoch [6/20] Batch 340/938 Loss D: 0.3852, Loss G: 1.4596\n",
      "Epoch [6/20] Batch 350/938 Loss D: 0.3480, Loss G: 1.4155\n",
      "Epoch [6/20] Batch 360/938 Loss D: 0.4666, Loss G: 1.3064\n",
      "Epoch [6/20] Batch 370/938 Loss D: 0.4115, Loss G: 1.2364\n",
      "Epoch [6/20] Batch 380/938 Loss D: 0.3603, Loss G: 1.4300\n",
      "Epoch [6/20] Batch 390/938 Loss D: 0.3699, Loss G: 1.4048\n",
      "Epoch [6/20] Batch 400/938 Loss D: 0.4501, Loss G: 1.2238\n",
      "Epoch [6/20] Batch 410/938 Loss D: 0.4596, Loss G: 1.0390\n",
      "Epoch [6/20] Batch 420/938 Loss D: 0.4167, Loss G: 1.2978\n",
      "Epoch [6/20] Batch 430/938 Loss D: 0.4668, Loss G: 1.4172\n",
      "Epoch [6/20] Batch 440/938 Loss D: 0.4002, Loss G: 1.4105\n",
      "Epoch [6/20] Batch 450/938 Loss D: 0.3485, Loss G: 1.4445\n",
      "Epoch [6/20] Batch 460/938 Loss D: 0.3148, Loss G: 1.5085\n",
      "Epoch [6/20] Batch 470/938 Loss D: 0.3987, Loss G: 1.3767\n",
      "Epoch [6/20] Batch 480/938 Loss D: 0.4523, Loss G: 1.2010\n",
      "Epoch [6/20] Batch 490/938 Loss D: 0.4039, Loss G: 1.4829\n",
      "Epoch [6/20] Batch 500/938 Loss D: 0.4720, Loss G: 1.5012\n",
      "Epoch [6/20] Batch 510/938 Loss D: 0.3860, Loss G: 1.4624\n",
      "Epoch [6/20] Batch 520/938 Loss D: 0.4462, Loss G: 1.2142\n",
      "Epoch [6/20] Batch 530/938 Loss D: 0.4484, Loss G: 1.3272\n",
      "Epoch [6/20] Batch 540/938 Loss D: 0.4516, Loss G: 1.2547\n",
      "Epoch [6/20] Batch 550/938 Loss D: 0.3490, Loss G: 1.3714\n",
      "Epoch [6/20] Batch 560/938 Loss D: 0.3713, Loss G: 1.4556\n",
      "Epoch [6/20] Batch 570/938 Loss D: 0.3778, Loss G: 1.3542\n",
      "Epoch [6/20] Batch 580/938 Loss D: 0.3470, Loss G: 1.4667\n",
      "Epoch [6/20] Batch 590/938 Loss D: 0.3462, Loss G: 1.5549\n",
      "Epoch [6/20] Batch 600/938 Loss D: 0.3880, Loss G: 1.2396\n",
      "Epoch [6/20] Batch 610/938 Loss D: 0.4582, Loss G: 1.3907\n",
      "Epoch [6/20] Batch 620/938 Loss D: 0.4806, Loss G: 1.2351\n",
      "Epoch [6/20] Batch 630/938 Loss D: 0.3773, Loss G: 1.1431\n",
      "Epoch [6/20] Batch 640/938 Loss D: 0.3412, Loss G: 1.5759\n",
      "Epoch [6/20] Batch 650/938 Loss D: 0.3362, Loss G: 1.5447\n",
      "Epoch [6/20] Batch 660/938 Loss D: 0.4708, Loss G: 1.1925\n",
      "Epoch [6/20] Batch 670/938 Loss D: 0.3816, Loss G: 1.5505\n",
      "Epoch [6/20] Batch 680/938 Loss D: 0.3946, Loss G: 1.6023\n",
      "Epoch [6/20] Batch 690/938 Loss D: 0.3923, Loss G: 1.2688\n",
      "Epoch [6/20] Batch 700/938 Loss D: 0.4219, Loss G: 1.2719\n",
      "Epoch [6/20] Batch 710/938 Loss D: 0.4483, Loss G: 1.3451\n",
      "Epoch [6/20] Batch 720/938 Loss D: 0.3419, Loss G: 1.6503\n",
      "Epoch [6/20] Batch 730/938 Loss D: 0.3416, Loss G: 1.4217\n",
      "Epoch [6/20] Batch 740/938 Loss D: 0.4031, Loss G: 1.2767\n",
      "Epoch [6/20] Batch 750/938 Loss D: 0.3829, Loss G: 1.3181\n",
      "Epoch [6/20] Batch 760/938 Loss D: 0.4311, Loss G: 1.2095\n",
      "Epoch [6/20] Batch 770/938 Loss D: 0.4001, Loss G: 1.4440\n",
      "Epoch [6/20] Batch 780/938 Loss D: 0.3350, Loss G: 1.4930\n",
      "Epoch [6/20] Batch 790/938 Loss D: 0.3478, Loss G: 1.4428\n",
      "Epoch [6/20] Batch 800/938 Loss D: 0.3805, Loss G: 1.2573\n",
      "Epoch [6/20] Batch 810/938 Loss D: 0.4186, Loss G: 1.4164\n",
      "Epoch [6/20] Batch 820/938 Loss D: 0.3718, Loss G: 1.4552\n",
      "Epoch [6/20] Batch 830/938 Loss D: 0.3712, Loss G: 1.2511\n",
      "Epoch [6/20] Batch 840/938 Loss D: 0.3702, Loss G: 1.2525\n",
      "Epoch [6/20] Batch 850/938 Loss D: 0.4600, Loss G: 1.2685\n",
      "Epoch [6/20] Batch 860/938 Loss D: 0.4485, Loss G: 1.2782\n",
      "Epoch [6/20] Batch 870/938 Loss D: 0.4322, Loss G: 1.2514\n",
      "Epoch [6/20] Batch 880/938 Loss D: 0.3895, Loss G: 1.4956\n",
      "Epoch [6/20] Batch 890/938 Loss D: 0.4215, Loss G: 1.5854\n",
      "Epoch [6/20] Batch 900/938 Loss D: 0.3742, Loss G: 1.3282\n",
      "Epoch [6/20] Batch 910/938 Loss D: 0.3999, Loss G: 1.2312\n",
      "Epoch [6/20] Batch 920/938 Loss D: 0.3380, Loss G: 1.5320\n",
      "Epoch [6/20] Batch 930/938 Loss D: 0.3594, Loss G: 1.4455\n",
      "Epoch [7/20] Batch 0/938 Loss D: 0.3617, Loss G: 1.4414\n",
      "Epoch [7/20] Batch 10/938 Loss D: 0.4360, Loss G: 1.3305\n",
      "Epoch [7/20] Batch 20/938 Loss D: 0.4143, Loss G: 1.2542\n",
      "Epoch [7/20] Batch 30/938 Loss D: 0.3744, Loss G: 1.2184\n",
      "Epoch [7/20] Batch 40/938 Loss D: 0.3665, Loss G: 1.6302\n",
      "Epoch [7/20] Batch 50/938 Loss D: 0.3407, Loss G: 1.4461\n",
      "Epoch [7/20] Batch 60/938 Loss D: 0.3516, Loss G: 1.4074\n",
      "Epoch [7/20] Batch 70/938 Loss D: 0.3504, Loss G: 1.3811\n",
      "Epoch [7/20] Batch 80/938 Loss D: 0.4290, Loss G: 1.2188\n",
      "Epoch [7/20] Batch 90/938 Loss D: 0.4109, Loss G: 1.4158\n",
      "Epoch [7/20] Batch 100/938 Loss D: 0.4013, Loss G: 1.3007\n",
      "Epoch [7/20] Batch 110/938 Loss D: 0.3931, Loss G: 1.2245\n",
      "Epoch [7/20] Batch 120/938 Loss D: 0.3276, Loss G: 1.6865\n",
      "Epoch [7/20] Batch 130/938 Loss D: 0.3677, Loss G: 1.4533\n",
      "Epoch [7/20] Batch 140/938 Loss D: 0.3730, Loss G: 1.3333\n",
      "Epoch [7/20] Batch 150/938 Loss D: 0.4131, Loss G: 1.3735\n",
      "Epoch [7/20] Batch 160/938 Loss D: 0.3756, Loss G: 1.3102\n",
      "Epoch [7/20] Batch 170/938 Loss D: 0.3649, Loss G: 1.3519\n",
      "Epoch [7/20] Batch 180/938 Loss D: 0.4106, Loss G: 1.4186\n",
      "Epoch [7/20] Batch 190/938 Loss D: 0.4290, Loss G: 1.3038\n",
      "Epoch [7/20] Batch 200/938 Loss D: 0.4092, Loss G: 1.4355\n",
      "Epoch [7/20] Batch 210/938 Loss D: 0.4469, Loss G: 1.2283\n",
      "Epoch [7/20] Batch 220/938 Loss D: 0.3417, Loss G: 1.3189\n",
      "Epoch [7/20] Batch 230/938 Loss D: 0.2963, Loss G: 1.5563\n",
      "Epoch [7/20] Batch 240/938 Loss D: 0.3673, Loss G: 1.4075\n",
      "Epoch [7/20] Batch 250/938 Loss D: 0.3641, Loss G: 1.2736\n",
      "Epoch [7/20] Batch 260/938 Loss D: 0.3993, Loss G: 1.2871\n",
      "Epoch [7/20] Batch 270/938 Loss D: 0.3912, Loss G: 1.5010\n",
      "Epoch [7/20] Batch 280/938 Loss D: 0.4487, Loss G: 1.1630\n",
      "Epoch [7/20] Batch 290/938 Loss D: 0.4055, Loss G: 1.3000\n",
      "Epoch [7/20] Batch 300/938 Loss D: 0.3771, Loss G: 1.3946\n",
      "Epoch [7/20] Batch 310/938 Loss D: 0.3921, Loss G: 1.4198\n",
      "Epoch [7/20] Batch 320/938 Loss D: 0.3500, Loss G: 1.3253\n",
      "Epoch [7/20] Batch 330/938 Loss D: 0.3442, Loss G: 1.3510\n",
      "Epoch [7/20] Batch 340/938 Loss D: 0.3606, Loss G: 1.5032\n",
      "Epoch [7/20] Batch 350/938 Loss D: 0.3880, Loss G: 1.2954\n",
      "Epoch [7/20] Batch 360/938 Loss D: 0.3734, Loss G: 1.5657\n",
      "Epoch [7/20] Batch 370/938 Loss D: 0.4069, Loss G: 1.3585\n",
      "Epoch [7/20] Batch 380/938 Loss D: 0.3265, Loss G: 1.5015\n",
      "Epoch [7/20] Batch 390/938 Loss D: 0.4202, Loss G: 1.2977\n",
      "Epoch [7/20] Batch 400/938 Loss D: 0.3581, Loss G: 1.3736\n",
      "Epoch [7/20] Batch 410/938 Loss D: 0.4755, Loss G: 1.2436\n",
      "Epoch [7/20] Batch 420/938 Loss D: 0.4199, Loss G: 1.5534\n",
      "Epoch [7/20] Batch 430/938 Loss D: 0.3312, Loss G: 1.4574\n",
      "Epoch [7/20] Batch 440/938 Loss D: 0.3786, Loss G: 1.2700\n",
      "Epoch [7/20] Batch 450/938 Loss D: 0.3730, Loss G: 1.4633\n",
      "Epoch [7/20] Batch 460/938 Loss D: 0.3782, Loss G: 1.3043\n",
      "Epoch [7/20] Batch 470/938 Loss D: 0.3483, Loss G: 1.3148\n",
      "Epoch [7/20] Batch 480/938 Loss D: 0.4179, Loss G: 1.4705\n",
      "Epoch [7/20] Batch 490/938 Loss D: 0.3389, Loss G: 1.5331\n",
      "Epoch [7/20] Batch 500/938 Loss D: 0.3704, Loss G: 1.5159\n",
      "Epoch [7/20] Batch 510/938 Loss D: 0.3600, Loss G: 1.3461\n",
      "Epoch [7/20] Batch 520/938 Loss D: 0.3526, Loss G: 1.3344\n",
      "Epoch [7/20] Batch 530/938 Loss D: 0.4507, Loss G: 1.2875\n",
      "Epoch [7/20] Batch 540/938 Loss D: 0.3973, Loss G: 1.4888\n",
      "Epoch [7/20] Batch 550/938 Loss D: 0.3493, Loss G: 1.4414\n",
      "Epoch [7/20] Batch 560/938 Loss D: 0.3279, Loss G: 1.5259\n",
      "Epoch [7/20] Batch 570/938 Loss D: 0.3780, Loss G: 1.3256\n",
      "Epoch [7/20] Batch 580/938 Loss D: 0.3712, Loss G: 1.4005\n",
      "Epoch [7/20] Batch 590/938 Loss D: 0.3599, Loss G: 1.3991\n",
      "Epoch [7/20] Batch 600/938 Loss D: 0.3579, Loss G: 1.4425\n",
      "Epoch [7/20] Batch 610/938 Loss D: 0.4000, Loss G: 1.2966\n",
      "Epoch [7/20] Batch 620/938 Loss D: 0.3865, Loss G: 1.3440\n",
      "Epoch [7/20] Batch 630/938 Loss D: 0.3675, Loss G: 1.3635\n",
      "Epoch [7/20] Batch 640/938 Loss D: 0.3627, Loss G: 1.4306\n",
      "Epoch [7/20] Batch 650/938 Loss D: 0.2898, Loss G: 1.7954\n",
      "Epoch [7/20] Batch 660/938 Loss D: 0.4034, Loss G: 1.3214\n",
      "Epoch [7/20] Batch 670/938 Loss D: 0.3284, Loss G: 1.5065\n",
      "Epoch [7/20] Batch 680/938 Loss D: 0.4138, Loss G: 1.3478\n",
      "Epoch [7/20] Batch 690/938 Loss D: 0.3393, Loss G: 1.4853\n",
      "Epoch [7/20] Batch 700/938 Loss D: 0.3945, Loss G: 1.4012\n",
      "Epoch [7/20] Batch 710/938 Loss D: 0.4309, Loss G: 1.3412\n",
      "Epoch [7/20] Batch 720/938 Loss D: 0.3515, Loss G: 1.5726\n",
      "Epoch [7/20] Batch 730/938 Loss D: 0.3521, Loss G: 1.6097\n",
      "Epoch [7/20] Batch 740/938 Loss D: 0.3779, Loss G: 1.4115\n",
      "Epoch [7/20] Batch 750/938 Loss D: 0.3900, Loss G: 1.4093\n",
      "Epoch [7/20] Batch 760/938 Loss D: 0.3775, Loss G: 1.4084\n",
      "Epoch [7/20] Batch 770/938 Loss D: 0.3326, Loss G: 1.3740\n",
      "Epoch [7/20] Batch 780/938 Loss D: 0.3949, Loss G: 1.4135\n",
      "Epoch [7/20] Batch 790/938 Loss D: 0.3742, Loss G: 1.3677\n",
      "Epoch [7/20] Batch 800/938 Loss D: 0.4004, Loss G: 1.3831\n",
      "Epoch [7/20] Batch 810/938 Loss D: 0.3639, Loss G: 1.3447\n",
      "Epoch [7/20] Batch 820/938 Loss D: 0.4275, Loss G: 1.3748\n",
      "Epoch [7/20] Batch 830/938 Loss D: 0.3591, Loss G: 1.5730\n",
      "Epoch [7/20] Batch 840/938 Loss D: 0.3310, Loss G: 1.6450\n",
      "Epoch [7/20] Batch 850/938 Loss D: 0.3802, Loss G: 1.4737\n",
      "Epoch [7/20] Batch 860/938 Loss D: 0.3231, Loss G: 1.4558\n",
      "Epoch [7/20] Batch 870/938 Loss D: 0.3638, Loss G: 1.3198\n",
      "Epoch [7/20] Batch 880/938 Loss D: 0.4542, Loss G: 1.2083\n",
      "Epoch [7/20] Batch 890/938 Loss D: 0.4154, Loss G: 1.4152\n",
      "Epoch [7/20] Batch 900/938 Loss D: 0.3758, Loss G: 1.4250\n",
      "Epoch [7/20] Batch 910/938 Loss D: 0.4391, Loss G: 1.2797\n",
      "Epoch [7/20] Batch 920/938 Loss D: 0.3459, Loss G: 1.3890\n",
      "Epoch [7/20] Batch 930/938 Loss D: 0.2723, Loss G: 1.6925\n",
      "Epoch [8/20] Batch 0/938 Loss D: 0.3357, Loss G: 1.5011\n",
      "Epoch [8/20] Batch 10/938 Loss D: 0.3311, Loss G: 1.5230\n",
      "Epoch [8/20] Batch 20/938 Loss D: 0.4135, Loss G: 1.3107\n",
      "Epoch [8/20] Batch 30/938 Loss D: 0.3685, Loss G: 1.3042\n",
      "Epoch [8/20] Batch 40/938 Loss D: 0.3284, Loss G: 1.4906\n",
      "Epoch [8/20] Batch 50/938 Loss D: 0.3088, Loss G: 1.4801\n",
      "Epoch [8/20] Batch 60/938 Loss D: 0.3885, Loss G: 1.4120\n",
      "Epoch [8/20] Batch 70/938 Loss D: 0.3368, Loss G: 1.5176\n",
      "Epoch [8/20] Batch 80/938 Loss D: 0.3151, Loss G: 1.5786\n",
      "Epoch [8/20] Batch 90/938 Loss D: 0.3910, Loss G: 1.3207\n",
      "Epoch [8/20] Batch 100/938 Loss D: 0.4265, Loss G: 1.4331\n",
      "Epoch [8/20] Batch 110/938 Loss D: 0.3827, Loss G: 1.4426\n",
      "Epoch [8/20] Batch 120/938 Loss D: 0.3763, Loss G: 1.1846\n",
      "Epoch [8/20] Batch 130/938 Loss D: 0.4050, Loss G: 1.2408\n",
      "Epoch [8/20] Batch 140/938 Loss D: 0.3947, Loss G: 1.4303\n",
      "Epoch [8/20] Batch 150/938 Loss D: 0.3455, Loss G: 1.5105\n",
      "Epoch [8/20] Batch 160/938 Loss D: 0.3437, Loss G: 1.5426\n",
      "Epoch [8/20] Batch 170/938 Loss D: 0.3274, Loss G: 1.4427\n",
      "Epoch [8/20] Batch 180/938 Loss D: 0.4182, Loss G: 1.2209\n",
      "Epoch [8/20] Batch 190/938 Loss D: 0.4627, Loss G: 1.2196\n",
      "Epoch [8/20] Batch 200/938 Loss D: 0.4006, Loss G: 1.5271\n",
      "Epoch [8/20] Batch 210/938 Loss D: 0.3698, Loss G: 1.3584\n",
      "Epoch [8/20] Batch 220/938 Loss D: 0.4038, Loss G: 1.4778\n",
      "Epoch [8/20] Batch 230/938 Loss D: 0.4227, Loss G: 1.4728\n",
      "Epoch [8/20] Batch 240/938 Loss D: 0.3200, Loss G: 1.5711\n",
      "Epoch [8/20] Batch 250/938 Loss D: 0.3124, Loss G: 1.5692\n",
      "Epoch [8/20] Batch 260/938 Loss D: 0.3416, Loss G: 1.2654\n",
      "Epoch [8/20] Batch 270/938 Loss D: 0.4248, Loss G: 1.3940\n",
      "Epoch [8/20] Batch 280/938 Loss D: 0.4166, Loss G: 1.4133\n",
      "Epoch [8/20] Batch 290/938 Loss D: 0.3339, Loss G: 1.3230\n",
      "Epoch [8/20] Batch 300/938 Loss D: 0.3850, Loss G: 1.3689\n",
      "Epoch [8/20] Batch 310/938 Loss D: 0.3846, Loss G: 1.4765\n",
      "Epoch [8/20] Batch 320/938 Loss D: 0.3567, Loss G: 1.6384\n",
      "Epoch [8/20] Batch 330/938 Loss D: 0.3218, Loss G: 1.4615\n",
      "Epoch [8/20] Batch 340/938 Loss D: 0.3875, Loss G: 1.4674\n",
      "Epoch [8/20] Batch 350/938 Loss D: 0.4199, Loss G: 1.3218\n",
      "Epoch [8/20] Batch 360/938 Loss D: 0.3552, Loss G: 1.3787\n",
      "Epoch [8/20] Batch 370/938 Loss D: 0.3182, Loss G: 1.5280\n",
      "Epoch [8/20] Batch 380/938 Loss D: 0.3312, Loss G: 1.3965\n",
      "Epoch [8/20] Batch 390/938 Loss D: 0.4021, Loss G: 1.4413\n",
      "Epoch [8/20] Batch 400/938 Loss D: 0.3861, Loss G: 1.4259\n",
      "Epoch [8/20] Batch 410/938 Loss D: 0.2889, Loss G: 1.5582\n",
      "Epoch [8/20] Batch 420/938 Loss D: 0.3271, Loss G: 1.5268\n",
      "Epoch [8/20] Batch 430/938 Loss D: 0.4677, Loss G: 1.3126\n",
      "Epoch [8/20] Batch 440/938 Loss D: 0.3411, Loss G: 1.3914\n",
      "Epoch [8/20] Batch 450/938 Loss D: 0.3663, Loss G: 1.3511\n",
      "Epoch [8/20] Batch 460/938 Loss D: 0.4169, Loss G: 1.4630\n",
      "Epoch [8/20] Batch 470/938 Loss D: 0.3710, Loss G: 1.2820\n",
      "Epoch [8/20] Batch 480/938 Loss D: 0.3326, Loss G: 1.7308\n",
      "Epoch [8/20] Batch 490/938 Loss D: 0.3710, Loss G: 1.6837\n",
      "Epoch [8/20] Batch 500/938 Loss D: 0.3109, Loss G: 1.5635\n",
      "Epoch [8/20] Batch 510/938 Loss D: 0.3363, Loss G: 1.4617\n",
      "Epoch [8/20] Batch 520/938 Loss D: 0.3762, Loss G: 1.2741\n",
      "Epoch [8/20] Batch 530/938 Loss D: 0.3017, Loss G: 1.4471\n",
      "Epoch [8/20] Batch 540/938 Loss D: 0.3817, Loss G: 1.4152\n",
      "Epoch [8/20] Batch 550/938 Loss D: 0.3511, Loss G: 1.5076\n",
      "Epoch [8/20] Batch 560/938 Loss D: 0.2699, Loss G: 1.6604\n",
      "Epoch [8/20] Batch 570/938 Loss D: 0.2902, Loss G: 1.5247\n",
      "Epoch [8/20] Batch 580/938 Loss D: 0.3813, Loss G: 1.3822\n",
      "Epoch [8/20] Batch 590/938 Loss D: 0.4158, Loss G: 1.2369\n",
      "Epoch [8/20] Batch 600/938 Loss D: 0.4516, Loss G: 1.3950\n",
      "Epoch [8/20] Batch 610/938 Loss D: 0.3776, Loss G: 1.4211\n",
      "Epoch [8/20] Batch 620/938 Loss D: 0.4412, Loss G: 1.3313\n",
      "Epoch [8/20] Batch 630/938 Loss D: 0.4681, Loss G: 1.1864\n",
      "Epoch [8/20] Batch 640/938 Loss D: 0.3221, Loss G: 1.5866\n",
      "Epoch [8/20] Batch 650/938 Loss D: 0.3387, Loss G: 1.4223\n",
      "Epoch [8/20] Batch 660/938 Loss D: 0.3806, Loss G: 1.3065\n",
      "Epoch [8/20] Batch 670/938 Loss D: 0.3288, Loss G: 1.4711\n",
      "Epoch [8/20] Batch 680/938 Loss D: 0.3726, Loss G: 1.1931\n",
      "Epoch [8/20] Batch 690/938 Loss D: 0.4368, Loss G: 1.0649\n",
      "Epoch [8/20] Batch 700/938 Loss D: 0.3925, Loss G: 1.3554\n",
      "Epoch [8/20] Batch 710/938 Loss D: 0.4026, Loss G: 1.4221\n",
      "Epoch [8/20] Batch 720/938 Loss D: 0.3129, Loss G: 1.6006\n",
      "Epoch [8/20] Batch 730/938 Loss D: 0.3750, Loss G: 1.3195\n",
      "Epoch [8/20] Batch 740/938 Loss D: 0.2937, Loss G: 1.5509\n",
      "Epoch [8/20] Batch 750/938 Loss D: 0.3203, Loss G: 1.5593\n",
      "Epoch [8/20] Batch 760/938 Loss D: 0.4197, Loss G: 1.2850\n",
      "Epoch [8/20] Batch 770/938 Loss D: 0.4349, Loss G: 1.3871\n",
      "Epoch [8/20] Batch 780/938 Loss D: 0.4043, Loss G: 1.4485\n",
      "Epoch [8/20] Batch 790/938 Loss D: 0.3193, Loss G: 1.6657\n",
      "Epoch [8/20] Batch 800/938 Loss D: 0.4080, Loss G: 1.4251\n",
      "Epoch [8/20] Batch 810/938 Loss D: 0.3717, Loss G: 1.3899\n",
      "Epoch [8/20] Batch 820/938 Loss D: 0.3372, Loss G: 1.5737\n",
      "Epoch [8/20] Batch 830/938 Loss D: 0.3297, Loss G: 1.4321\n",
      "Epoch [8/20] Batch 840/938 Loss D: 0.3579, Loss G: 1.3982\n",
      "Epoch [8/20] Batch 850/938 Loss D: 0.3920, Loss G: 1.6050\n",
      "Epoch [8/20] Batch 860/938 Loss D: 0.3859, Loss G: 1.4328\n",
      "Epoch [8/20] Batch 870/938 Loss D: 0.3579, Loss G: 1.4176\n",
      "Epoch [8/20] Batch 880/938 Loss D: 0.3889, Loss G: 1.2787\n",
      "Epoch [8/20] Batch 890/938 Loss D: 0.3444, Loss G: 1.5578\n",
      "Epoch [8/20] Batch 900/938 Loss D: 0.3359, Loss G: 1.4104\n",
      "Epoch [8/20] Batch 910/938 Loss D: 0.3744, Loss G: 1.5079\n",
      "Epoch [8/20] Batch 920/938 Loss D: 0.3905, Loss G: 1.4001\n",
      "Epoch [8/20] Batch 930/938 Loss D: 0.4040, Loss G: 1.2925\n",
      "Epoch [9/20] Batch 0/938 Loss D: 0.4317, Loss G: 1.3133\n",
      "Epoch [9/20] Batch 10/938 Loss D: 0.4362, Loss G: 1.4170\n",
      "Epoch [9/20] Batch 20/938 Loss D: 0.3774, Loss G: 1.3065\n",
      "Epoch [9/20] Batch 30/938 Loss D: 0.2995, Loss G: 1.6442\n",
      "Epoch [9/20] Batch 40/938 Loss D: 0.2958, Loss G: 1.5332\n",
      "Epoch [9/20] Batch 50/938 Loss D: 0.3674, Loss G: 1.4136\n",
      "Epoch [9/20] Batch 60/938 Loss D: 0.3584, Loss G: 1.4288\n",
      "Epoch [9/20] Batch 70/938 Loss D: 0.4007, Loss G: 1.3475\n",
      "Epoch [9/20] Batch 80/938 Loss D: 0.3997, Loss G: 1.2930\n",
      "Epoch [9/20] Batch 90/938 Loss D: 0.3637, Loss G: 1.3956\n",
      "Epoch [9/20] Batch 100/938 Loss D: 0.3372, Loss G: 1.4672\n",
      "Epoch [9/20] Batch 110/938 Loss D: 0.3273, Loss G: 1.5672\n",
      "Epoch [9/20] Batch 120/938 Loss D: 0.3275, Loss G: 1.5993\n",
      "Epoch [9/20] Batch 130/938 Loss D: 0.3637, Loss G: 1.3679\n",
      "Epoch [9/20] Batch 140/938 Loss D: 0.3310, Loss G: 1.5295\n",
      "Epoch [9/20] Batch 150/938 Loss D: 0.4034, Loss G: 1.4884\n",
      "Epoch [9/20] Batch 160/938 Loss D: 0.3404, Loss G: 1.4235\n",
      "Epoch [9/20] Batch 170/938 Loss D: 0.3755, Loss G: 1.3889\n",
      "Epoch [9/20] Batch 180/938 Loss D: 0.3454, Loss G: 1.4688\n",
      "Epoch [9/20] Batch 190/938 Loss D: 0.3233, Loss G: 1.5806\n",
      "Epoch [9/20] Batch 200/938 Loss D: 0.3802, Loss G: 1.4844\n",
      "Epoch [9/20] Batch 210/938 Loss D: 0.3520, Loss G: 1.3747\n",
      "Epoch [9/20] Batch 220/938 Loss D: 0.4207, Loss G: 1.2515\n",
      "Epoch [9/20] Batch 230/938 Loss D: 0.3182, Loss G: 1.6485\n",
      "Epoch [9/20] Batch 240/938 Loss D: 0.3742, Loss G: 1.2893\n",
      "Epoch [9/20] Batch 250/938 Loss D: 0.3786, Loss G: 1.2888\n",
      "Epoch [9/20] Batch 260/938 Loss D: 0.3486, Loss G: 1.5523\n",
      "Epoch [9/20] Batch 270/938 Loss D: 0.3894, Loss G: 1.2558\n",
      "Epoch [9/20] Batch 280/938 Loss D: 0.3776, Loss G: 1.2591\n",
      "Epoch [9/20] Batch 290/938 Loss D: 0.3274, Loss G: 1.4658\n",
      "Epoch [9/20] Batch 300/938 Loss D: 0.3563, Loss G: 1.5625\n",
      "Epoch [9/20] Batch 310/938 Loss D: 0.3842, Loss G: 1.3374\n",
      "Epoch [9/20] Batch 320/938 Loss D: 0.3742, Loss G: 1.2340\n",
      "Epoch [9/20] Batch 330/938 Loss D: 0.3876, Loss G: 1.5340\n",
      "Epoch [9/20] Batch 340/938 Loss D: 0.3432, Loss G: 1.4573\n",
      "Epoch [9/20] Batch 350/938 Loss D: 0.3497, Loss G: 1.3557\n",
      "Epoch [9/20] Batch 360/938 Loss D: 0.4592, Loss G: 1.2136\n",
      "Epoch [9/20] Batch 370/938 Loss D: 0.3693, Loss G: 1.4888\n",
      "Epoch [9/20] Batch 380/938 Loss D: 0.3378, Loss G: 1.3694\n",
      "Epoch [9/20] Batch 390/938 Loss D: 0.3366, Loss G: 1.4628\n",
      "Epoch [9/20] Batch 400/938 Loss D: 0.4075, Loss G: 1.4081\n",
      "Epoch [9/20] Batch 410/938 Loss D: 0.3180, Loss G: 1.6043\n",
      "Epoch [9/20] Batch 420/938 Loss D: 0.3533, Loss G: 1.3642\n",
      "Epoch [9/20] Batch 430/938 Loss D: 0.3442, Loss G: 1.4407\n",
      "Epoch [9/20] Batch 440/938 Loss D: 0.3970, Loss G: 1.4733\n",
      "Epoch [9/20] Batch 450/938 Loss D: 0.3040, Loss G: 1.5301\n",
      "Epoch [9/20] Batch 460/938 Loss D: 0.3659, Loss G: 1.4212\n",
      "Epoch [9/20] Batch 470/938 Loss D: 0.4106, Loss G: 1.3716\n",
      "Epoch [9/20] Batch 480/938 Loss D: 0.3917, Loss G: 1.2833\n",
      "Epoch [9/20] Batch 490/938 Loss D: 0.3554, Loss G: 1.4425\n",
      "Epoch [9/20] Batch 500/938 Loss D: 0.3530, Loss G: 1.4700\n",
      "Epoch [9/20] Batch 510/938 Loss D: 0.3299, Loss G: 1.6144\n",
      "Epoch [9/20] Batch 520/938 Loss D: 0.3507, Loss G: 1.4552\n",
      "Epoch [9/20] Batch 530/938 Loss D: 0.3333, Loss G: 1.6615\n",
      "Epoch [9/20] Batch 540/938 Loss D: 0.3573, Loss G: 1.4849\n",
      "Epoch [9/20] Batch 550/938 Loss D: 0.3684, Loss G: 1.3204\n",
      "Epoch [9/20] Batch 560/938 Loss D: 0.3912, Loss G: 1.2840\n",
      "Epoch [9/20] Batch 570/938 Loss D: 0.3967, Loss G: 1.4460\n",
      "Epoch [9/20] Batch 580/938 Loss D: 0.4427, Loss G: 1.4610\n",
      "Epoch [9/20] Batch 590/938 Loss D: 0.2995, Loss G: 1.5024\n",
      "Epoch [9/20] Batch 600/938 Loss D: 0.3357, Loss G: 1.4563\n",
      "Epoch [9/20] Batch 610/938 Loss D: 0.3364, Loss G: 1.5867\n",
      "Epoch [9/20] Batch 620/938 Loss D: 0.4033, Loss G: 1.1940\n",
      "Epoch [9/20] Batch 630/938 Loss D: 0.4391, Loss G: 1.3232\n",
      "Epoch [9/20] Batch 640/938 Loss D: 0.3406, Loss G: 1.4894\n",
      "Epoch [9/20] Batch 650/938 Loss D: 0.3749, Loss G: 1.3740\n",
      "Epoch [9/20] Batch 660/938 Loss D: 0.3437, Loss G: 1.3754\n",
      "Epoch [9/20] Batch 670/938 Loss D: 0.3446, Loss G: 1.4670\n",
      "Epoch [9/20] Batch 680/938 Loss D: 0.3985, Loss G: 1.4359\n",
      "Epoch [9/20] Batch 690/938 Loss D: 0.4098, Loss G: 1.3475\n",
      "Epoch [9/20] Batch 700/938 Loss D: 0.3892, Loss G: 1.4269\n",
      "Epoch [9/20] Batch 710/938 Loss D: 0.3528, Loss G: 1.4625\n",
      "Epoch [9/20] Batch 720/938 Loss D: 0.3053, Loss G: 1.4302\n",
      "Epoch [9/20] Batch 730/938 Loss D: 0.3464, Loss G: 1.3662\n",
      "Epoch [9/20] Batch 740/938 Loss D: 0.3603, Loss G: 1.4850\n",
      "Epoch [9/20] Batch 750/938 Loss D: 0.3408, Loss G: 1.6443\n",
      "Epoch [9/20] Batch 760/938 Loss D: 0.3616, Loss G: 1.2716\n",
      "Epoch [9/20] Batch 770/938 Loss D: 0.3193, Loss G: 1.4950\n",
      "Epoch [9/20] Batch 780/938 Loss D: 0.3064, Loss G: 1.7647\n",
      "Epoch [9/20] Batch 790/938 Loss D: 0.3944, Loss G: 1.3960\n",
      "Epoch [9/20] Batch 800/938 Loss D: 0.3566, Loss G: 1.4178\n",
      "Epoch [9/20] Batch 810/938 Loss D: 0.3675, Loss G: 1.4632\n",
      "Epoch [9/20] Batch 820/938 Loss D: 0.3918, Loss G: 1.4970\n",
      "Epoch [9/20] Batch 830/938 Loss D: 0.3927, Loss G: 1.3772\n",
      "Epoch [9/20] Batch 840/938 Loss D: 0.3821, Loss G: 1.4202\n",
      "Epoch [9/20] Batch 850/938 Loss D: 0.3756, Loss G: 1.4472\n",
      "Epoch [9/20] Batch 860/938 Loss D: 0.3150, Loss G: 1.4791\n",
      "Epoch [9/20] Batch 870/938 Loss D: 0.3491, Loss G: 1.5044\n",
      "Epoch [9/20] Batch 880/938 Loss D: 0.3465, Loss G: 1.5065\n",
      "Epoch [9/20] Batch 890/938 Loss D: 0.3676, Loss G: 1.3796\n",
      "Epoch [9/20] Batch 900/938 Loss D: 0.4076, Loss G: 1.1839\n",
      "Epoch [9/20] Batch 910/938 Loss D: 0.3708, Loss G: 1.4577\n",
      "Epoch [9/20] Batch 920/938 Loss D: 0.3704, Loss G: 1.4719\n",
      "Epoch [9/20] Batch 930/938 Loss D: 0.3512, Loss G: 1.4250\n",
      "Epoch [10/20] Batch 0/938 Loss D: 0.3277, Loss G: 1.6620\n",
      "Epoch [10/20] Batch 10/938 Loss D: 0.3597, Loss G: 1.5144\n",
      "Epoch [10/20] Batch 20/938 Loss D: 0.3237, Loss G: 1.5362\n",
      "Epoch [10/20] Batch 30/938 Loss D: 0.4612, Loss G: 1.3283\n",
      "Epoch [10/20] Batch 40/938 Loss D: 0.3408, Loss G: 1.5147\n",
      "Epoch [10/20] Batch 50/938 Loss D: 0.4084, Loss G: 1.2547\n",
      "Epoch [10/20] Batch 60/938 Loss D: 0.3672, Loss G: 1.2644\n",
      "Epoch [10/20] Batch 70/938 Loss D: 0.3460, Loss G: 1.3732\n",
      "Epoch [10/20] Batch 80/938 Loss D: 0.3792, Loss G: 1.3300\n",
      "Epoch [10/20] Batch 90/938 Loss D: 0.3523, Loss G: 1.4369\n",
      "Epoch [10/20] Batch 100/938 Loss D: 0.3592, Loss G: 1.2856\n",
      "Epoch [10/20] Batch 110/938 Loss D: 0.4598, Loss G: 1.6023\n",
      "Epoch [10/20] Batch 120/938 Loss D: 0.3486, Loss G: 1.7075\n",
      "Epoch [10/20] Batch 130/938 Loss D: 0.4431, Loss G: 1.5609\n",
      "Epoch [10/20] Batch 140/938 Loss D: 0.3754, Loss G: 1.4328\n",
      "Epoch [10/20] Batch 150/938 Loss D: 0.3752, Loss G: 1.4748\n",
      "Epoch [10/20] Batch 160/938 Loss D: 0.3561, Loss G: 1.4352\n",
      "Epoch [10/20] Batch 170/938 Loss D: 0.3467, Loss G: 1.3481\n",
      "Epoch [10/20] Batch 180/938 Loss D: 0.3615, Loss G: 1.4624\n",
      "Epoch [10/20] Batch 190/938 Loss D: 0.4479, Loss G: 1.3556\n",
      "Epoch [10/20] Batch 200/938 Loss D: 0.3478, Loss G: 1.3738\n",
      "Epoch [10/20] Batch 210/938 Loss D: 0.3647, Loss G: 1.1899\n",
      "Epoch [10/20] Batch 220/938 Loss D: 0.3563, Loss G: 1.5074\n",
      "Epoch [10/20] Batch 230/938 Loss D: 0.4201, Loss G: 1.3116\n",
      "Epoch [10/20] Batch 240/938 Loss D: 0.3832, Loss G: 1.5174\n",
      "Epoch [10/20] Batch 250/938 Loss D: 0.3607, Loss G: 1.4070\n",
      "Epoch [10/20] Batch 260/938 Loss D: 0.3291, Loss G: 1.3971\n",
      "Epoch [10/20] Batch 270/938 Loss D: 0.3147, Loss G: 1.5038\n",
      "Epoch [10/20] Batch 280/938 Loss D: 0.3920, Loss G: 1.1859\n",
      "Epoch [10/20] Batch 290/938 Loss D: 0.3002, Loss G: 1.5494\n",
      "Epoch [10/20] Batch 300/938 Loss D: 0.3485, Loss G: 1.3967\n",
      "Epoch [10/20] Batch 310/938 Loss D: 0.3467, Loss G: 1.6142\n",
      "Epoch [10/20] Batch 320/938 Loss D: 0.3913, Loss G: 1.5179\n",
      "Epoch [10/20] Batch 330/938 Loss D: 0.3578, Loss G: 1.3532\n",
      "Epoch [10/20] Batch 340/938 Loss D: 0.3204, Loss G: 1.6099\n",
      "Epoch [10/20] Batch 350/938 Loss D: 0.3144, Loss G: 1.5730\n",
      "Epoch [10/20] Batch 360/938 Loss D: 0.3955, Loss G: 1.3606\n",
      "Epoch [10/20] Batch 370/938 Loss D: 0.3656, Loss G: 1.4648\n",
      "Epoch [10/20] Batch 380/938 Loss D: 0.3103, Loss G: 1.5152\n",
      "Epoch [10/20] Batch 390/938 Loss D: 0.3634, Loss G: 1.6720\n",
      "Epoch [10/20] Batch 400/938 Loss D: 0.3016, Loss G: 1.7307\n",
      "Epoch [10/20] Batch 410/938 Loss D: 0.3217, Loss G: 1.3734\n",
      "Epoch [10/20] Batch 420/938 Loss D: 0.3028, Loss G: 1.3858\n",
      "Epoch [10/20] Batch 430/938 Loss D: 0.3234, Loss G: 1.4661\n",
      "Epoch [10/20] Batch 440/938 Loss D: 0.3675, Loss G: 1.3787\n",
      "Epoch [10/20] Batch 450/938 Loss D: 0.3896, Loss G: 1.4895\n",
      "Epoch [10/20] Batch 460/938 Loss D: 0.3915, Loss G: 1.5034\n",
      "Epoch [10/20] Batch 470/938 Loss D: 0.3103, Loss G: 1.4583\n",
      "Epoch [10/20] Batch 480/938 Loss D: 0.3909, Loss G: 1.4154\n",
      "Epoch [10/20] Batch 490/938 Loss D: 0.3193, Loss G: 1.5266\n",
      "Epoch [10/20] Batch 500/938 Loss D: 0.3366, Loss G: 1.3316\n",
      "Epoch [10/20] Batch 510/938 Loss D: 0.3282, Loss G: 1.7253\n",
      "Epoch [10/20] Batch 520/938 Loss D: 0.3638, Loss G: 1.5258\n",
      "Epoch [10/20] Batch 530/938 Loss D: 0.3576, Loss G: 1.5277\n",
      "Epoch [10/20] Batch 540/938 Loss D: 0.3305, Loss G: 1.5502\n",
      "Epoch [10/20] Batch 550/938 Loss D: 0.3943, Loss G: 1.3424\n",
      "Epoch [10/20] Batch 560/938 Loss D: 0.3478, Loss G: 1.5818\n",
      "Epoch [10/20] Batch 570/938 Loss D: 0.3986, Loss G: 1.4182\n",
      "Epoch [10/20] Batch 580/938 Loss D: 0.3536, Loss G: 1.4550\n",
      "Epoch [10/20] Batch 590/938 Loss D: 0.3196, Loss G: 1.4587\n",
      "Epoch [10/20] Batch 600/938 Loss D: 0.3486, Loss G: 1.3499\n",
      "Epoch [10/20] Batch 610/938 Loss D: 0.3881, Loss G: 1.3777\n",
      "Epoch [10/20] Batch 620/938 Loss D: 0.3794, Loss G: 1.5707\n",
      "Epoch [10/20] Batch 630/938 Loss D: 0.3260, Loss G: 1.5782\n",
      "Epoch [10/20] Batch 640/938 Loss D: 0.3346, Loss G: 1.3633\n",
      "Epoch [10/20] Batch 650/938 Loss D: 0.3981, Loss G: 1.2903\n",
      "Epoch [10/20] Batch 660/938 Loss D: 0.4168, Loss G: 1.3271\n",
      "Epoch [10/20] Batch 670/938 Loss D: 0.3240, Loss G: 1.5910\n",
      "Epoch [10/20] Batch 680/938 Loss D: 0.3508, Loss G: 1.4516\n",
      "Epoch [10/20] Batch 690/938 Loss D: 0.3076, Loss G: 1.6687\n",
      "Epoch [10/20] Batch 700/938 Loss D: 0.3184, Loss G: 1.5542\n",
      "Epoch [10/20] Batch 710/938 Loss D: 0.3228, Loss G: 1.5766\n",
      "Epoch [10/20] Batch 720/938 Loss D: 0.3460, Loss G: 1.4994\n",
      "Epoch [10/20] Batch 730/938 Loss D: 0.3763, Loss G: 1.2798\n",
      "Epoch [10/20] Batch 740/938 Loss D: 0.3709, Loss G: 1.4150\n",
      "Epoch [10/20] Batch 750/938 Loss D: 0.3072, Loss G: 1.6157\n",
      "Epoch [10/20] Batch 760/938 Loss D: 0.3506, Loss G: 1.2550\n",
      "Epoch [10/20] Batch 770/938 Loss D: 0.3510, Loss G: 1.5257\n",
      "Epoch [10/20] Batch 780/938 Loss D: 0.3992, Loss G: 1.4192\n",
      "Epoch [10/20] Batch 790/938 Loss D: 0.3365, Loss G: 1.4835\n",
      "Epoch [10/20] Batch 800/938 Loss D: 0.3305, Loss G: 1.7612\n",
      "Epoch [10/20] Batch 810/938 Loss D: 0.3735, Loss G: 1.3701\n",
      "Epoch [10/20] Batch 820/938 Loss D: 0.3342, Loss G: 1.3356\n",
      "Epoch [10/20] Batch 830/938 Loss D: 0.3940, Loss G: 1.3302\n",
      "Epoch [10/20] Batch 840/938 Loss D: 0.3529, Loss G: 1.6033\n",
      "Epoch [10/20] Batch 850/938 Loss D: 0.3688, Loss G: 1.3445\n",
      "Epoch [10/20] Batch 860/938 Loss D: 0.3792, Loss G: 1.5928\n",
      "Epoch [10/20] Batch 870/938 Loss D: 0.3003, Loss G: 1.7365\n",
      "Epoch [10/20] Batch 880/938 Loss D: 0.2919, Loss G: 1.6214\n",
      "Epoch [10/20] Batch 890/938 Loss D: 0.3973, Loss G: 1.4728\n",
      "Epoch [10/20] Batch 900/938 Loss D: 0.3454, Loss G: 1.6104\n",
      "Epoch [10/20] Batch 910/938 Loss D: 0.3289, Loss G: 1.4837\n",
      "Epoch [10/20] Batch 920/938 Loss D: 0.3682, Loss G: 1.2969\n",
      "Epoch [10/20] Batch 930/938 Loss D: 0.3490, Loss G: 1.3149\n",
      "Epoch [11/20] Batch 0/938 Loss D: 0.3867, Loss G: 1.6231\n",
      "Epoch [11/20] Batch 10/938 Loss D: 0.3384, Loss G: 1.4388\n",
      "Epoch [11/20] Batch 20/938 Loss D: 0.3373, Loss G: 1.2929\n",
      "Epoch [11/20] Batch 30/938 Loss D: 0.3532, Loss G: 1.3191\n",
      "Epoch [11/20] Batch 40/938 Loss D: 0.3021, Loss G: 1.5316\n",
      "Epoch [11/20] Batch 50/938 Loss D: 0.3077, Loss G: 1.5407\n",
      "Epoch [11/20] Batch 60/938 Loss D: 0.3364, Loss G: 1.3453\n",
      "Epoch [11/20] Batch 70/938 Loss D: 0.3475, Loss G: 1.2896\n",
      "Epoch [11/20] Batch 80/938 Loss D: 0.3546, Loss G: 1.3093\n",
      "Epoch [11/20] Batch 90/938 Loss D: 0.3272, Loss G: 1.3236\n",
      "Epoch [11/20] Batch 100/938 Loss D: 0.3130, Loss G: 1.6240\n",
      "Epoch [11/20] Batch 110/938 Loss D: 0.3917, Loss G: 1.1610\n",
      "Epoch [11/20] Batch 120/938 Loss D: 0.3743, Loss G: 1.6074\n",
      "Epoch [11/20] Batch 130/938 Loss D: 0.3179, Loss G: 1.6142\n",
      "Epoch [11/20] Batch 140/938 Loss D: 0.3061, Loss G: 1.3828\n",
      "Epoch [11/20] Batch 150/938 Loss D: 0.4250, Loss G: 1.3003\n",
      "Epoch [11/20] Batch 160/938 Loss D: 0.3001, Loss G: 1.4103\n",
      "Epoch [11/20] Batch 170/938 Loss D: 0.3319, Loss G: 1.6209\n",
      "Epoch [11/20] Batch 180/938 Loss D: 0.3763, Loss G: 1.3031\n",
      "Epoch [11/20] Batch 190/938 Loss D: 0.3245, Loss G: 1.3111\n",
      "Epoch [11/20] Batch 200/938 Loss D: 0.3316, Loss G: 1.4149\n",
      "Epoch [11/20] Batch 210/938 Loss D: 0.2965, Loss G: 1.6015\n",
      "Epoch [11/20] Batch 220/938 Loss D: 0.3764, Loss G: 1.3352\n",
      "Epoch [11/20] Batch 230/938 Loss D: 0.3600, Loss G: 1.2582\n",
      "Epoch [11/20] Batch 240/938 Loss D: 0.3960, Loss G: 1.4050\n",
      "Epoch [11/20] Batch 250/938 Loss D: 0.4258, Loss G: 1.3637\n",
      "Epoch [11/20] Batch 260/938 Loss D: 0.3298, Loss G: 1.4337\n",
      "Epoch [11/20] Batch 270/938 Loss D: 0.3512, Loss G: 1.4252\n",
      "Epoch [11/20] Batch 280/938 Loss D: 0.3144, Loss G: 1.4635\n",
      "Epoch [11/20] Batch 290/938 Loss D: 0.3416, Loss G: 1.5451\n",
      "Epoch [11/20] Batch 300/938 Loss D: 0.3583, Loss G: 1.3546\n",
      "Epoch [11/20] Batch 310/938 Loss D: 0.3871, Loss G: 1.2577\n",
      "Epoch [11/20] Batch 320/938 Loss D: 0.3475, Loss G: 1.5316\n",
      "Epoch [11/20] Batch 330/938 Loss D: 0.3724, Loss G: 1.4111\n",
      "Epoch [11/20] Batch 340/938 Loss D: 0.3506, Loss G: 1.4286\n",
      "Epoch [11/20] Batch 350/938 Loss D: 0.3457, Loss G: 1.3025\n",
      "Epoch [11/20] Batch 360/938 Loss D: 0.3034, Loss G: 1.4497\n",
      "Epoch [11/20] Batch 370/938 Loss D: 0.3364, Loss G: 1.6402\n",
      "Epoch [11/20] Batch 380/938 Loss D: 0.3430, Loss G: 1.3752\n",
      "Epoch [11/20] Batch 390/938 Loss D: 0.3636, Loss G: 1.2965\n",
      "Epoch [11/20] Batch 400/938 Loss D: 0.3348, Loss G: 1.5597\n",
      "Epoch [11/20] Batch 410/938 Loss D: 0.3259, Loss G: 1.5941\n",
      "Epoch [11/20] Batch 420/938 Loss D: 0.3461, Loss G: 1.4483\n",
      "Epoch [11/20] Batch 430/938 Loss D: 0.3433, Loss G: 1.5500\n",
      "Epoch [11/20] Batch 440/938 Loss D: 0.3301, Loss G: 1.4502\n",
      "Epoch [11/20] Batch 450/938 Loss D: 0.3302, Loss G: 1.5250\n",
      "Epoch [11/20] Batch 460/938 Loss D: 0.4058, Loss G: 1.1897\n",
      "Epoch [11/20] Batch 470/938 Loss D: 0.3295, Loss G: 1.4548\n",
      "Epoch [11/20] Batch 480/938 Loss D: 0.3586, Loss G: 1.4744\n",
      "Epoch [11/20] Batch 490/938 Loss D: 0.3116, Loss G: 1.5619\n",
      "Epoch [11/20] Batch 500/938 Loss D: 0.3346, Loss G: 1.4634\n",
      "Epoch [11/20] Batch 510/938 Loss D: 0.3809, Loss G: 1.3358\n",
      "Epoch [11/20] Batch 520/938 Loss D: 0.3362, Loss G: 1.3695\n",
      "Epoch [11/20] Batch 530/938 Loss D: 0.3420, Loss G: 1.2950\n",
      "Epoch [11/20] Batch 540/938 Loss D: 0.3851, Loss G: 1.3093\n",
      "Epoch [11/20] Batch 550/938 Loss D: 0.3723, Loss G: 1.4835\n",
      "Epoch [11/20] Batch 560/938 Loss D: 0.3843, Loss G: 1.4323\n",
      "Epoch [11/20] Batch 570/938 Loss D: 0.4006, Loss G: 1.3009\n",
      "Epoch [11/20] Batch 580/938 Loss D: 0.3961, Loss G: 1.3823\n",
      "Epoch [11/20] Batch 590/938 Loss D: 0.4321, Loss G: 1.4946\n",
      "Epoch [11/20] Batch 600/938 Loss D: 0.3381, Loss G: 1.4580\n",
      "Epoch [11/20] Batch 610/938 Loss D: 0.3979, Loss G: 1.2915\n",
      "Epoch [11/20] Batch 620/938 Loss D: 0.3894, Loss G: 1.5336\n",
      "Epoch [11/20] Batch 630/938 Loss D: 0.3243, Loss G: 1.4501\n",
      "Epoch [11/20] Batch 640/938 Loss D: 0.3652, Loss G: 1.5673\n",
      "Epoch [11/20] Batch 650/938 Loss D: 0.3425, Loss G: 1.3653\n",
      "Epoch [11/20] Batch 660/938 Loss D: 0.3825, Loss G: 1.1861\n",
      "Epoch [11/20] Batch 670/938 Loss D: 0.3177, Loss G: 1.7388\n",
      "Epoch [11/20] Batch 680/938 Loss D: 0.3251, Loss G: 1.5769\n",
      "Epoch [11/20] Batch 690/938 Loss D: 0.4204, Loss G: 1.1921\n",
      "Epoch [11/20] Batch 700/938 Loss D: 0.3438, Loss G: 1.3290\n",
      "Epoch [11/20] Batch 710/938 Loss D: 0.3729, Loss G: 1.6183\n",
      "Epoch [11/20] Batch 720/938 Loss D: 0.3470, Loss G: 1.5402\n",
      "Epoch [11/20] Batch 730/938 Loss D: 0.2810, Loss G: 1.7002\n",
      "Epoch [11/20] Batch 740/938 Loss D: 0.3777, Loss G: 1.3554\n",
      "Epoch [11/20] Batch 750/938 Loss D: 0.3810, Loss G: 1.3523\n",
      "Epoch [11/20] Batch 760/938 Loss D: 0.3046, Loss G: 1.5703\n",
      "Epoch [11/20] Batch 770/938 Loss D: 0.3607, Loss G: 1.2661\n",
      "Epoch [11/20] Batch 780/938 Loss D: 0.3281, Loss G: 1.4687\n",
      "Epoch [11/20] Batch 790/938 Loss D: 0.3316, Loss G: 1.5971\n",
      "Epoch [11/20] Batch 800/938 Loss D: 0.3491, Loss G: 1.4286\n",
      "Epoch [11/20] Batch 810/938 Loss D: 0.3170, Loss G: 1.5624\n",
      "Epoch [11/20] Batch 820/938 Loss D: 0.2903, Loss G: 1.7800\n",
      "Epoch [11/20] Batch 830/938 Loss D: 0.3387, Loss G: 1.5766\n",
      "Epoch [11/20] Batch 840/938 Loss D: 0.3324, Loss G: 1.4549\n",
      "Epoch [11/20] Batch 850/938 Loss D: 0.3270, Loss G: 1.4839\n",
      "Epoch [11/20] Batch 860/938 Loss D: 0.3868, Loss G: 1.4576\n",
      "Epoch [11/20] Batch 870/938 Loss D: 0.3198, Loss G: 1.5297\n",
      "Epoch [11/20] Batch 880/938 Loss D: 0.3687, Loss G: 1.4669\n",
      "Epoch [11/20] Batch 890/938 Loss D: 0.3525, Loss G: 1.4261\n",
      "Epoch [11/20] Batch 900/938 Loss D: 0.3168, Loss G: 1.4807\n",
      "Epoch [11/20] Batch 910/938 Loss D: 0.3777, Loss G: 1.3765\n",
      "Epoch [11/20] Batch 920/938 Loss D: 0.3614, Loss G: 1.4036\n",
      "Epoch [11/20] Batch 930/938 Loss D: 0.3670, Loss G: 1.3100\n",
      "Epoch [12/20] Batch 0/938 Loss D: 0.2791, Loss G: 1.5926\n",
      "Epoch [12/20] Batch 10/938 Loss D: 0.3013, Loss G: 1.5662\n",
      "Epoch [12/20] Batch 20/938 Loss D: 0.3752, Loss G: 1.3508\n",
      "Epoch [12/20] Batch 30/938 Loss D: 0.3457, Loss G: 1.5928\n",
      "Epoch [12/20] Batch 40/938 Loss D: 0.2937, Loss G: 1.6178\n",
      "Epoch [12/20] Batch 50/938 Loss D: 0.3453, Loss G: 1.4597\n",
      "Epoch [12/20] Batch 60/938 Loss D: 0.4120, Loss G: 1.4067\n",
      "Epoch [12/20] Batch 70/938 Loss D: 0.3254, Loss G: 1.6045\n",
      "Epoch [12/20] Batch 80/938 Loss D: 0.3544, Loss G: 1.2676\n",
      "Epoch [12/20] Batch 90/938 Loss D: 0.2895, Loss G: 1.5402\n",
      "Epoch [12/20] Batch 100/938 Loss D: 0.2835, Loss G: 1.5998\n",
      "Epoch [12/20] Batch 110/938 Loss D: 0.3516, Loss G: 1.2898\n",
      "Epoch [12/20] Batch 120/938 Loss D: 0.3372, Loss G: 1.2879\n",
      "Epoch [12/20] Batch 130/938 Loss D: 0.3744, Loss G: 1.3551\n",
      "Epoch [12/20] Batch 140/938 Loss D: 0.3659, Loss G: 1.7470\n",
      "Epoch [12/20] Batch 150/938 Loss D: 0.3653, Loss G: 1.6662\n",
      "Epoch [12/20] Batch 160/938 Loss D: 0.3098, Loss G: 1.4869\n",
      "Epoch [12/20] Batch 170/938 Loss D: 0.3526, Loss G: 1.4109\n",
      "Epoch [12/20] Batch 180/938 Loss D: 0.2932, Loss G: 1.4002\n",
      "Epoch [12/20] Batch 190/938 Loss D: 0.3276, Loss G: 1.4023\n",
      "Epoch [12/20] Batch 200/938 Loss D: 0.3415, Loss G: 1.5343\n",
      "Epoch [12/20] Batch 210/938 Loss D: 0.3193, Loss G: 1.6052\n",
      "Epoch [12/20] Batch 220/938 Loss D: 0.3410, Loss G: 1.2521\n",
      "Epoch [12/20] Batch 230/938 Loss D: 0.2881, Loss G: 1.5862\n",
      "Epoch [12/20] Batch 240/938 Loss D: 0.3543, Loss G: 1.5497\n",
      "Epoch [12/20] Batch 250/938 Loss D: 0.3276, Loss G: 1.4890\n",
      "Epoch [12/20] Batch 260/938 Loss D: 0.3459, Loss G: 1.3922\n",
      "Epoch [12/20] Batch 270/938 Loss D: 0.3341, Loss G: 1.4707\n",
      "Epoch [12/20] Batch 280/938 Loss D: 0.2865, Loss G: 1.6044\n",
      "Epoch [12/20] Batch 290/938 Loss D: 0.3149, Loss G: 1.5395\n",
      "Epoch [12/20] Batch 300/938 Loss D: 0.3536, Loss G: 1.4192\n",
      "Epoch [12/20] Batch 310/938 Loss D: 0.3210, Loss G: 1.6055\n",
      "Epoch [12/20] Batch 320/938 Loss D: 0.3862, Loss G: 1.5150\n",
      "Epoch [12/20] Batch 330/938 Loss D: 0.3649, Loss G: 1.5354\n",
      "Epoch [12/20] Batch 340/938 Loss D: 0.3207, Loss G: 1.6116\n",
      "Epoch [12/20] Batch 350/938 Loss D: 0.3641, Loss G: 1.5372\n",
      "Epoch [12/20] Batch 360/938 Loss D: 0.2725, Loss G: 1.5308\n",
      "Epoch [12/20] Batch 370/938 Loss D: 0.3424, Loss G: 1.4557\n",
      "Epoch [12/20] Batch 380/938 Loss D: 0.3693, Loss G: 1.6309\n",
      "Epoch [12/20] Batch 390/938 Loss D: 0.2797, Loss G: 1.6715\n",
      "Epoch [12/20] Batch 400/938 Loss D: 0.3217, Loss G: 1.5331\n",
      "Epoch [12/20] Batch 410/938 Loss D: 0.3105, Loss G: 1.5723\n",
      "Epoch [12/20] Batch 420/938 Loss D: 0.3789, Loss G: 1.4925\n",
      "Epoch [12/20] Batch 430/938 Loss D: 0.3840, Loss G: 1.4149\n",
      "Epoch [12/20] Batch 440/938 Loss D: 0.3103, Loss G: 1.4303\n",
      "Epoch [12/20] Batch 450/938 Loss D: 0.3103, Loss G: 1.3379\n",
      "Epoch [12/20] Batch 460/938 Loss D: 0.3683, Loss G: 1.2424\n",
      "Epoch [12/20] Batch 470/938 Loss D: 0.3284, Loss G: 1.5606\n",
      "Epoch [12/20] Batch 480/938 Loss D: 0.3476, Loss G: 1.2856\n",
      "Epoch [12/20] Batch 490/938 Loss D: 0.2986, Loss G: 1.5478\n",
      "Epoch [12/20] Batch 500/938 Loss D: 0.3239, Loss G: 1.3336\n",
      "Epoch [12/20] Batch 510/938 Loss D: 0.3285, Loss G: 1.3907\n",
      "Epoch [12/20] Batch 520/938 Loss D: 0.3893, Loss G: 1.3445\n",
      "Epoch [12/20] Batch 530/938 Loss D: 0.2901, Loss G: 1.6529\n",
      "Epoch [12/20] Batch 540/938 Loss D: 0.3258, Loss G: 1.5139\n",
      "Epoch [12/20] Batch 550/938 Loss D: 0.3716, Loss G: 1.3024\n",
      "Epoch [12/20] Batch 560/938 Loss D: 0.3725, Loss G: 1.3880\n",
      "Epoch [12/20] Batch 570/938 Loss D: 0.3331, Loss G: 1.4758\n",
      "Epoch [12/20] Batch 580/938 Loss D: 0.3728, Loss G: 1.4816\n",
      "Epoch [12/20] Batch 590/938 Loss D: 0.3259, Loss G: 1.5268\n",
      "Epoch [12/20] Batch 600/938 Loss D: 0.3201, Loss G: 1.4371\n",
      "Epoch [12/20] Batch 610/938 Loss D: 0.3663, Loss G: 1.3508\n",
      "Epoch [12/20] Batch 620/938 Loss D: 0.3517, Loss G: 1.3709\n",
      "Epoch [12/20] Batch 630/938 Loss D: 0.3078, Loss G: 1.4870\n",
      "Epoch [12/20] Batch 640/938 Loss D: 0.3279, Loss G: 1.6636\n",
      "Epoch [12/20] Batch 650/938 Loss D: 0.3444, Loss G: 1.5208\n",
      "Epoch [12/20] Batch 660/938 Loss D: 0.4082, Loss G: 1.2974\n",
      "Epoch [12/20] Batch 670/938 Loss D: 0.3322, Loss G: 1.5223\n",
      "Epoch [12/20] Batch 680/938 Loss D: 0.3129, Loss G: 1.6292\n",
      "Epoch [12/20] Batch 690/938 Loss D: 0.3752, Loss G: 1.4504\n",
      "Epoch [12/20] Batch 700/938 Loss D: 0.3584, Loss G: 1.4123\n",
      "Epoch [12/20] Batch 710/938 Loss D: 0.2909, Loss G: 1.3930\n",
      "Epoch [12/20] Batch 720/938 Loss D: 0.3719, Loss G: 1.4880\n",
      "Epoch [12/20] Batch 730/938 Loss D: 0.2890, Loss G: 1.6461\n",
      "Epoch [12/20] Batch 740/938 Loss D: 0.3263, Loss G: 1.5091\n",
      "Epoch [12/20] Batch 750/938 Loss D: 0.3469, Loss G: 1.5236\n",
      "Epoch [12/20] Batch 760/938 Loss D: 0.3315, Loss G: 1.6233\n",
      "Epoch [12/20] Batch 770/938 Loss D: 0.3212, Loss G: 1.4545\n",
      "Epoch [12/20] Batch 780/938 Loss D: 0.3489, Loss G: 1.2712\n",
      "Epoch [12/20] Batch 790/938 Loss D: 0.3389, Loss G: 1.5334\n",
      "Epoch [12/20] Batch 800/938 Loss D: 0.3384, Loss G: 1.4107\n",
      "Epoch [12/20] Batch 810/938 Loss D: 0.4011, Loss G: 1.7519\n",
      "Epoch [12/20] Batch 820/938 Loss D: 0.3271, Loss G: 1.4073\n",
      "Epoch [12/20] Batch 830/938 Loss D: 0.3060, Loss G: 1.5874\n",
      "Epoch [12/20] Batch 840/938 Loss D: 0.3081, Loss G: 1.5443\n",
      "Epoch [12/20] Batch 850/938 Loss D: 0.3437, Loss G: 1.4595\n",
      "Epoch [12/20] Batch 860/938 Loss D: 0.3574, Loss G: 1.7529\n",
      "Epoch [12/20] Batch 870/938 Loss D: 0.2802, Loss G: 1.5802\n",
      "Epoch [12/20] Batch 880/938 Loss D: 0.3215, Loss G: 1.5273\n",
      "Epoch [12/20] Batch 890/938 Loss D: 0.3572, Loss G: 1.7114\n",
      "Epoch [12/20] Batch 900/938 Loss D: 0.3328, Loss G: 1.4174\n",
      "Epoch [12/20] Batch 910/938 Loss D: 0.3507, Loss G: 1.4030\n",
      "Epoch [12/20] Batch 920/938 Loss D: 0.2897, Loss G: 1.6305\n",
      "Epoch [12/20] Batch 930/938 Loss D: 0.3783, Loss G: 1.3084\n",
      "Epoch [13/20] Batch 0/938 Loss D: 0.3203, Loss G: 1.5639\n",
      "Epoch [13/20] Batch 10/938 Loss D: 0.3147, Loss G: 1.5086\n",
      "Epoch [13/20] Batch 20/938 Loss D: 0.3687, Loss G: 1.3405\n",
      "Epoch [13/20] Batch 30/938 Loss D: 0.3022, Loss G: 1.4307\n",
      "Epoch [13/20] Batch 40/938 Loss D: 0.3073, Loss G: 1.4964\n",
      "Epoch [13/20] Batch 50/938 Loss D: 0.3592, Loss G: 1.5167\n",
      "Epoch [13/20] Batch 60/938 Loss D: 0.3496, Loss G: 1.3595\n",
      "Epoch [13/20] Batch 70/938 Loss D: 0.3700, Loss G: 1.2249\n",
      "Epoch [13/20] Batch 80/938 Loss D: 0.3028, Loss G: 1.6030\n",
      "Epoch [13/20] Batch 90/938 Loss D: 0.2952, Loss G: 1.6157\n",
      "Epoch [13/20] Batch 100/938 Loss D: 0.3204, Loss G: 1.5361\n",
      "Epoch [13/20] Batch 110/938 Loss D: 0.3068, Loss G: 1.5187\n",
      "Epoch [13/20] Batch 120/938 Loss D: 0.3507, Loss G: 1.5646\n",
      "Epoch [13/20] Batch 130/938 Loss D: 0.2993, Loss G: 1.5190\n",
      "Epoch [13/20] Batch 140/938 Loss D: 0.3694, Loss G: 1.4745\n",
      "Epoch [13/20] Batch 150/938 Loss D: 0.3064, Loss G: 1.5690\n",
      "Epoch [13/20] Batch 160/938 Loss D: 0.3548, Loss G: 1.4237\n",
      "Epoch [13/20] Batch 170/938 Loss D: 0.3762, Loss G: 1.2735\n",
      "Epoch [13/20] Batch 180/938 Loss D: 0.3234, Loss G: 1.4015\n",
      "Epoch [13/20] Batch 190/938 Loss D: 0.3161, Loss G: 1.6787\n",
      "Epoch [13/20] Batch 200/938 Loss D: 0.3077, Loss G: 1.4382\n",
      "Epoch [13/20] Batch 210/938 Loss D: 0.3458, Loss G: 1.4491\n",
      "Epoch [13/20] Batch 220/938 Loss D: 0.3805, Loss G: 1.6612\n",
      "Epoch [13/20] Batch 230/938 Loss D: 0.3222, Loss G: 1.4858\n",
      "Epoch [13/20] Batch 240/938 Loss D: 0.3601, Loss G: 1.2799\n",
      "Epoch [13/20] Batch 250/938 Loss D: 0.3473, Loss G: 1.4215\n",
      "Epoch [13/20] Batch 260/938 Loss D: 0.3839, Loss G: 1.4201\n",
      "Epoch [13/20] Batch 270/938 Loss D: 0.2925, Loss G: 1.5663\n",
      "Epoch [13/20] Batch 280/938 Loss D: 0.3454, Loss G: 1.3911\n",
      "Epoch [13/20] Batch 290/938 Loss D: 0.3590, Loss G: 1.5963\n",
      "Epoch [13/20] Batch 300/938 Loss D: 0.3854, Loss G: 1.4171\n",
      "Epoch [13/20] Batch 310/938 Loss D: 0.3426, Loss G: 1.4110\n",
      "Epoch [13/20] Batch 320/938 Loss D: 0.3362, Loss G: 1.5084\n",
      "Epoch [13/20] Batch 330/938 Loss D: 0.3368, Loss G: 1.5261\n",
      "Epoch [13/20] Batch 340/938 Loss D: 0.3317, Loss G: 1.5274\n",
      "Epoch [13/20] Batch 350/938 Loss D: 0.3450, Loss G: 1.4943\n",
      "Epoch [13/20] Batch 360/938 Loss D: 0.3909, Loss G: 1.4703\n",
      "Epoch [13/20] Batch 370/938 Loss D: 0.3405, Loss G: 1.3802\n",
      "Epoch [13/20] Batch 380/938 Loss D: 0.3572, Loss G: 1.3606\n",
      "Epoch [13/20] Batch 390/938 Loss D: 0.3426, Loss G: 1.6070\n",
      "Epoch [13/20] Batch 400/938 Loss D: 0.2780, Loss G: 1.7259\n",
      "Epoch [13/20] Batch 410/938 Loss D: 0.3651, Loss G: 1.3224\n",
      "Epoch [13/20] Batch 420/938 Loss D: 0.3673, Loss G: 1.4730\n",
      "Epoch [13/20] Batch 430/938 Loss D: 0.2907, Loss G: 1.7639\n",
      "Epoch [13/20] Batch 440/938 Loss D: 0.3797, Loss G: 1.5049\n",
      "Epoch [13/20] Batch 450/938 Loss D: 0.3129, Loss G: 1.3701\n",
      "Epoch [13/20] Batch 460/938 Loss D: 0.3941, Loss G: 1.4652\n",
      "Epoch [13/20] Batch 470/938 Loss D: 0.3295, Loss G: 1.8255\n",
      "Epoch [13/20] Batch 480/938 Loss D: 0.2548, Loss G: 1.8149\n",
      "Epoch [13/20] Batch 490/938 Loss D: 0.3138, Loss G: 1.4129\n",
      "Epoch [13/20] Batch 500/938 Loss D: 0.3223, Loss G: 1.4009\n",
      "Epoch [13/20] Batch 510/938 Loss D: 0.3170, Loss G: 1.4796\n",
      "Epoch [13/20] Batch 520/938 Loss D: 0.3349, Loss G: 1.6174\n",
      "Epoch [13/20] Batch 530/938 Loss D: 0.3133, Loss G: 1.6589\n",
      "Epoch [13/20] Batch 540/938 Loss D: 0.3726, Loss G: 1.2019\n",
      "Epoch [13/20] Batch 550/938 Loss D: 0.2944, Loss G: 1.6734\n",
      "Epoch [13/20] Batch 560/938 Loss D: 0.2765, Loss G: 1.6658\n",
      "Epoch [13/20] Batch 570/938 Loss D: 0.3290, Loss G: 1.4002\n",
      "Epoch [13/20] Batch 580/938 Loss D: 0.2852, Loss G: 1.5296\n",
      "Epoch [13/20] Batch 590/938 Loss D: 0.3993, Loss G: 1.5613\n",
      "Epoch [13/20] Batch 600/938 Loss D: 0.4058, Loss G: 1.2859\n",
      "Epoch [13/20] Batch 610/938 Loss D: 0.2780, Loss G: 1.6703\n",
      "Epoch [13/20] Batch 620/938 Loss D: 0.3271, Loss G: 1.6818\n",
      "Epoch [13/20] Batch 630/938 Loss D: 0.2960, Loss G: 1.6668\n",
      "Epoch [13/20] Batch 640/938 Loss D: 0.3125, Loss G: 1.6269\n",
      "Epoch [13/20] Batch 650/938 Loss D: 0.3354, Loss G: 1.3413\n",
      "Epoch [13/20] Batch 660/938 Loss D: 0.3216, Loss G: 1.4567\n",
      "Epoch [13/20] Batch 670/938 Loss D: 0.3182, Loss G: 1.7251\n",
      "Epoch [13/20] Batch 680/938 Loss D: 0.3014, Loss G: 1.7063\n",
      "Epoch [13/20] Batch 690/938 Loss D: 0.3046, Loss G: 1.7453\n",
      "Epoch [13/20] Batch 700/938 Loss D: 0.3589, Loss G: 1.4063\n",
      "Epoch [13/20] Batch 710/938 Loss D: 0.3506, Loss G: 1.5329\n",
      "Epoch [13/20] Batch 720/938 Loss D: 0.3276, Loss G: 1.7362\n",
      "Epoch [13/20] Batch 730/938 Loss D: 0.3444, Loss G: 1.3642\n",
      "Epoch [13/20] Batch 740/938 Loss D: 0.3851, Loss G: 1.3104\n",
      "Epoch [13/20] Batch 750/938 Loss D: 0.3463, Loss G: 1.5558\n",
      "Epoch [13/20] Batch 760/938 Loss D: 0.3174, Loss G: 1.6077\n",
      "Epoch [13/20] Batch 770/938 Loss D: 0.3122, Loss G: 1.7966\n",
      "Epoch [13/20] Batch 780/938 Loss D: 0.3391, Loss G: 1.4339\n",
      "Epoch [13/20] Batch 790/938 Loss D: 0.2840, Loss G: 1.4947\n",
      "Epoch [13/20] Batch 800/938 Loss D: 0.2639, Loss G: 1.7154\n",
      "Epoch [13/20] Batch 810/938 Loss D: 0.3503, Loss G: 1.4496\n",
      "Epoch [13/20] Batch 820/938 Loss D: 0.3090, Loss G: 1.5403\n",
      "Epoch [13/20] Batch 830/938 Loss D: 0.3467, Loss G: 1.5772\n",
      "Epoch [13/20] Batch 840/938 Loss D: 0.3146, Loss G: 1.4650\n",
      "Epoch [13/20] Batch 850/938 Loss D: 0.4011, Loss G: 1.2968\n",
      "Epoch [13/20] Batch 860/938 Loss D: 0.3289, Loss G: 1.6545\n",
      "Epoch [13/20] Batch 870/938 Loss D: 0.3613, Loss G: 1.4755\n",
      "Epoch [13/20] Batch 880/938 Loss D: 0.3557, Loss G: 1.3844\n",
      "Epoch [13/20] Batch 890/938 Loss D: 0.3167, Loss G: 1.4683\n",
      "Epoch [13/20] Batch 900/938 Loss D: 0.3706, Loss G: 1.5677\n",
      "Epoch [13/20] Batch 910/938 Loss D: 0.2958, Loss G: 1.5148\n",
      "Epoch [13/20] Batch 920/938 Loss D: 0.3339, Loss G: 1.5483\n",
      "Epoch [13/20] Batch 930/938 Loss D: 0.3702, Loss G: 1.4847\n",
      "Epoch [14/20] Batch 0/938 Loss D: 0.3100, Loss G: 1.6457\n",
      "Epoch [14/20] Batch 10/938 Loss D: 0.3546, Loss G: 1.6787\n",
      "Epoch [14/20] Batch 20/938 Loss D: 0.2977, Loss G: 1.7011\n",
      "Epoch [14/20] Batch 30/938 Loss D: 0.2597, Loss G: 1.8077\n",
      "Epoch [14/20] Batch 40/938 Loss D: 0.3033, Loss G: 1.6592\n",
      "Epoch [14/20] Batch 50/938 Loss D: 0.3068, Loss G: 1.4902\n",
      "Epoch [14/20] Batch 60/938 Loss D: 0.3412, Loss G: 1.6144\n",
      "Epoch [14/20] Batch 70/938 Loss D: 0.3246, Loss G: 1.4821\n",
      "Epoch [14/20] Batch 80/938 Loss D: 0.3197, Loss G: 1.4295\n",
      "Epoch [14/20] Batch 90/938 Loss D: 0.3165, Loss G: 1.5314\n",
      "Epoch [14/20] Batch 100/938 Loss D: 0.3103, Loss G: 1.4953\n",
      "Epoch [14/20] Batch 110/938 Loss D: 0.2983, Loss G: 1.6581\n",
      "Epoch [14/20] Batch 120/938 Loss D: 0.3554, Loss G: 1.5570\n",
      "Epoch [14/20] Batch 130/938 Loss D: 0.3309, Loss G: 1.6117\n",
      "Epoch [14/20] Batch 140/938 Loss D: 0.3277, Loss G: 1.5699\n",
      "Epoch [14/20] Batch 150/938 Loss D: 0.3171, Loss G: 1.5961\n",
      "Epoch [14/20] Batch 160/938 Loss D: 0.3235, Loss G: 1.5300\n",
      "Epoch [14/20] Batch 170/938 Loss D: 0.2370, Loss G: 1.8531\n",
      "Epoch [14/20] Batch 180/938 Loss D: 0.4347, Loss G: 1.4184\n",
      "Epoch [14/20] Batch 190/938 Loss D: 0.3110, Loss G: 1.4301\n",
      "Epoch [14/20] Batch 200/938 Loss D: 0.4021, Loss G: 1.3084\n",
      "Epoch [14/20] Batch 210/938 Loss D: 0.3631, Loss G: 1.5653\n",
      "Epoch [14/20] Batch 220/938 Loss D: 0.3060, Loss G: 1.3868\n",
      "Epoch [14/20] Batch 230/938 Loss D: 0.2874, Loss G: 1.6019\n",
      "Epoch [14/20] Batch 240/938 Loss D: 0.2812, Loss G: 1.7205\n",
      "Epoch [14/20] Batch 250/938 Loss D: 0.3228, Loss G: 1.4280\n",
      "Epoch [14/20] Batch 260/938 Loss D: 0.3585, Loss G: 1.3945\n",
      "Epoch [14/20] Batch 270/938 Loss D: 0.3298, Loss G: 1.4802\n",
      "Epoch [14/20] Batch 280/938 Loss D: 0.2778, Loss G: 1.8000\n",
      "Epoch [14/20] Batch 290/938 Loss D: 0.3479, Loss G: 1.4383\n",
      "Epoch [14/20] Batch 300/938 Loss D: 0.3000, Loss G: 1.4146\n",
      "Epoch [14/20] Batch 310/938 Loss D: 0.3431, Loss G: 1.4575\n",
      "Epoch [14/20] Batch 320/938 Loss D: 0.3068, Loss G: 1.3895\n",
      "Epoch [14/20] Batch 330/938 Loss D: 0.3338, Loss G: 1.6661\n",
      "Epoch [14/20] Batch 340/938 Loss D: 0.3473, Loss G: 1.5325\n",
      "Epoch [14/20] Batch 350/938 Loss D: 0.2743, Loss G: 1.4786\n",
      "Epoch [14/20] Batch 360/938 Loss D: 0.3140, Loss G: 1.3969\n",
      "Epoch [14/20] Batch 370/938 Loss D: 0.3384, Loss G: 1.6543\n",
      "Epoch [14/20] Batch 380/938 Loss D: 0.3507, Loss G: 1.5275\n",
      "Epoch [14/20] Batch 390/938 Loss D: 0.3659, Loss G: 1.5507\n",
      "Epoch [14/20] Batch 400/938 Loss D: 0.3233, Loss G: 1.6665\n",
      "Epoch [14/20] Batch 410/938 Loss D: 0.3167, Loss G: 1.4942\n",
      "Epoch [14/20] Batch 420/938 Loss D: 0.4067, Loss G: 1.3935\n",
      "Epoch [14/20] Batch 430/938 Loss D: 0.3312, Loss G: 1.5058\n",
      "Epoch [14/20] Batch 440/938 Loss D: 0.3274, Loss G: 1.6470\n",
      "Epoch [14/20] Batch 450/938 Loss D: 0.3304, Loss G: 1.6153\n",
      "Epoch [14/20] Batch 460/938 Loss D: 0.3245, Loss G: 1.5565\n",
      "Epoch [14/20] Batch 470/938 Loss D: 0.3075, Loss G: 1.3695\n",
      "Epoch [14/20] Batch 480/938 Loss D: 0.3408, Loss G: 1.4796\n",
      "Epoch [14/20] Batch 490/938 Loss D: 0.3115, Loss G: 1.6843\n",
      "Epoch [14/20] Batch 500/938 Loss D: 0.3012, Loss G: 1.6869\n",
      "Epoch [14/20] Batch 510/938 Loss D: 0.2667, Loss G: 1.9367\n",
      "Epoch [14/20] Batch 520/938 Loss D: 0.2900, Loss G: 1.6691\n",
      "Epoch [14/20] Batch 530/938 Loss D: 0.3725, Loss G: 1.3856\n",
      "Epoch [14/20] Batch 540/938 Loss D: 0.3249, Loss G: 1.7478\n",
      "Epoch [14/20] Batch 550/938 Loss D: 0.3037, Loss G: 1.6047\n",
      "Epoch [14/20] Batch 560/938 Loss D: 0.3249, Loss G: 1.7211\n",
      "Epoch [14/20] Batch 570/938 Loss D: 0.3162, Loss G: 1.5864\n",
      "Epoch [14/20] Batch 580/938 Loss D: 0.2891, Loss G: 1.7384\n",
      "Epoch [14/20] Batch 590/938 Loss D: 0.3530, Loss G: 1.4965\n",
      "Epoch [14/20] Batch 600/938 Loss D: 0.3013, Loss G: 1.5832\n",
      "Epoch [14/20] Batch 610/938 Loss D: 0.2702, Loss G: 1.7547\n",
      "Epoch [14/20] Batch 620/938 Loss D: 0.2985, Loss G: 1.4422\n",
      "Epoch [14/20] Batch 630/938 Loss D: 0.2703, Loss G: 1.8144\n",
      "Epoch [14/20] Batch 640/938 Loss D: 0.3214, Loss G: 1.6369\n",
      "Epoch [14/20] Batch 650/938 Loss D: 0.3348, Loss G: 1.6086\n",
      "Epoch [14/20] Batch 660/938 Loss D: 0.2830, Loss G: 1.6883\n",
      "Epoch [14/20] Batch 670/938 Loss D: 0.3183, Loss G: 1.6501\n",
      "Epoch [14/20] Batch 680/938 Loss D: 0.3289, Loss G: 1.5983\n",
      "Epoch [14/20] Batch 690/938 Loss D: 0.3351, Loss G: 1.5358\n",
      "Epoch [14/20] Batch 700/938 Loss D: 0.2771, Loss G: 1.7538\n",
      "Epoch [14/20] Batch 710/938 Loss D: 0.3601, Loss G: 1.5686\n",
      "Epoch [14/20] Batch 720/938 Loss D: 0.3282, Loss G: 1.7677\n",
      "Epoch [14/20] Batch 730/938 Loss D: 0.3348, Loss G: 1.6934\n",
      "Epoch [14/20] Batch 740/938 Loss D: 0.2806, Loss G: 1.7696\n",
      "Epoch [14/20] Batch 750/938 Loss D: 0.2920, Loss G: 1.6751\n",
      "Epoch [14/20] Batch 760/938 Loss D: 0.3466, Loss G: 1.2819\n",
      "Epoch [14/20] Batch 770/938 Loss D: 0.3805, Loss G: 1.3457\n",
      "Epoch [14/20] Batch 780/938 Loss D: 0.3021, Loss G: 1.7878\n",
      "Epoch [14/20] Batch 790/938 Loss D: 0.2670, Loss G: 1.8993\n",
      "Epoch [14/20] Batch 800/938 Loss D: 0.3141, Loss G: 1.4535\n",
      "Epoch [14/20] Batch 810/938 Loss D: 0.2771, Loss G: 1.7016\n",
      "Epoch [14/20] Batch 820/938 Loss D: 0.3500, Loss G: 1.5292\n",
      "Epoch [14/20] Batch 830/938 Loss D: 0.2872, Loss G: 1.7992\n",
      "Epoch [14/20] Batch 840/938 Loss D: 0.3365, Loss G: 1.4793\n",
      "Epoch [14/20] Batch 850/938 Loss D: 0.3187, Loss G: 1.5005\n",
      "Epoch [14/20] Batch 860/938 Loss D: 0.3236, Loss G: 1.5979\n",
      "Epoch [14/20] Batch 870/938 Loss D: 0.2939, Loss G: 1.9232\n",
      "Epoch [14/20] Batch 880/938 Loss D: 0.3182, Loss G: 1.6865\n",
      "Epoch [14/20] Batch 890/938 Loss D: 0.3130, Loss G: 1.5364\n",
      "Epoch [14/20] Batch 900/938 Loss D: 0.3048, Loss G: 1.4985\n",
      "Epoch [14/20] Batch 910/938 Loss D: 0.3080, Loss G: 1.7319\n",
      "Epoch [14/20] Batch 920/938 Loss D: 0.3253, Loss G: 1.6010\n",
      "Epoch [14/20] Batch 930/938 Loss D: 0.3044, Loss G: 1.5933\n",
      "Epoch [15/20] Batch 0/938 Loss D: 0.2981, Loss G: 1.5953\n",
      "Epoch [15/20] Batch 10/938 Loss D: 0.3198, Loss G: 1.7786\n",
      "Epoch [15/20] Batch 20/938 Loss D: 0.3014, Loss G: 1.7175\n",
      "Epoch [15/20] Batch 30/938 Loss D: 0.3503, Loss G: 1.5263\n",
      "Epoch [15/20] Batch 40/938 Loss D: 0.3143, Loss G: 1.6369\n",
      "Epoch [15/20] Batch 50/938 Loss D: 0.3654, Loss G: 1.5059\n",
      "Epoch [15/20] Batch 60/938 Loss D: 0.3028, Loss G: 1.5241\n",
      "Epoch [15/20] Batch 70/938 Loss D: 0.3360, Loss G: 1.4980\n",
      "Epoch [15/20] Batch 80/938 Loss D: 0.4146, Loss G: 1.6491\n",
      "Epoch [15/20] Batch 90/938 Loss D: 0.2943, Loss G: 1.8674\n",
      "Epoch [15/20] Batch 100/938 Loss D: 0.4273, Loss G: 1.4966\n",
      "Epoch [15/20] Batch 110/938 Loss D: 0.3137, Loss G: 1.6695\n",
      "Epoch [15/20] Batch 120/938 Loss D: 0.3124, Loss G: 1.4830\n",
      "Epoch [15/20] Batch 130/938 Loss D: 0.3627, Loss G: 1.4216\n",
      "Epoch [15/20] Batch 140/938 Loss D: 0.3639, Loss G: 1.6394\n",
      "Epoch [15/20] Batch 150/938 Loss D: 0.3628, Loss G: 1.5411\n",
      "Epoch [15/20] Batch 160/938 Loss D: 0.3153, Loss G: 1.5907\n",
      "Epoch [15/20] Batch 170/938 Loss D: 0.2811, Loss G: 1.6134\n",
      "Epoch [15/20] Batch 180/938 Loss D: 0.3374, Loss G: 1.5500\n",
      "Epoch [15/20] Batch 190/938 Loss D: 0.2790, Loss G: 1.8319\n",
      "Epoch [15/20] Batch 200/938 Loss D: 0.3189, Loss G: 1.6364\n",
      "Epoch [15/20] Batch 210/938 Loss D: 0.3123, Loss G: 1.6357\n",
      "Epoch [15/20] Batch 220/938 Loss D: 0.2911, Loss G: 1.6259\n",
      "Epoch [15/20] Batch 230/938 Loss D: 0.3133, Loss G: 1.6016\n",
      "Epoch [15/20] Batch 240/938 Loss D: 0.2972, Loss G: 1.6463\n",
      "Epoch [15/20] Batch 250/938 Loss D: 0.3186, Loss G: 1.7085\n",
      "Epoch [15/20] Batch 260/938 Loss D: 0.3066, Loss G: 1.6198\n",
      "Epoch [15/20] Batch 270/938 Loss D: 0.3717, Loss G: 1.5370\n",
      "Epoch [15/20] Batch 280/938 Loss D: 0.3152, Loss G: 1.6416\n",
      "Epoch [15/20] Batch 290/938 Loss D: 0.2940, Loss G: 1.9772\n",
      "Epoch [15/20] Batch 300/938 Loss D: 0.3337, Loss G: 1.6120\n",
      "Epoch [15/20] Batch 310/938 Loss D: 0.2999, Loss G: 1.6140\n",
      "Epoch [15/20] Batch 320/938 Loss D: 0.3213, Loss G: 1.4744\n",
      "Epoch [15/20] Batch 330/938 Loss D: 0.2722, Loss G: 1.7215\n",
      "Epoch [15/20] Batch 340/938 Loss D: 0.2908, Loss G: 1.4559\n",
      "Epoch [15/20] Batch 350/938 Loss D: 0.3388, Loss G: 1.5944\n",
      "Epoch [15/20] Batch 360/938 Loss D: 0.2986, Loss G: 1.6862\n",
      "Epoch [15/20] Batch 370/938 Loss D: 0.3064, Loss G: 1.4475\n",
      "Epoch [15/20] Batch 380/938 Loss D: 0.3702, Loss G: 1.1477\n",
      "Epoch [15/20] Batch 390/938 Loss D: 0.3018, Loss G: 1.7279\n",
      "Epoch [15/20] Batch 400/938 Loss D: 0.3186, Loss G: 1.6289\n",
      "Epoch [15/20] Batch 410/938 Loss D: 0.3707, Loss G: 1.4889\n",
      "Epoch [15/20] Batch 420/938 Loss D: 0.2650, Loss G: 1.9185\n",
      "Epoch [15/20] Batch 430/938 Loss D: 0.3005, Loss G: 1.8552\n",
      "Epoch [15/20] Batch 440/938 Loss D: 0.3579, Loss G: 1.5017\n",
      "Epoch [15/20] Batch 450/938 Loss D: 0.3291, Loss G: 1.3348\n",
      "Epoch [15/20] Batch 460/938 Loss D: 0.3121, Loss G: 1.4695\n",
      "Epoch [15/20] Batch 470/938 Loss D: 0.3004, Loss G: 1.6377\n",
      "Epoch [15/20] Batch 480/938 Loss D: 0.2852, Loss G: 1.6243\n",
      "Epoch [15/20] Batch 490/938 Loss D: 0.3658, Loss G: 1.3236\n",
      "Epoch [15/20] Batch 500/938 Loss D: 0.3215, Loss G: 1.4935\n",
      "Epoch [15/20] Batch 510/938 Loss D: 0.3488, Loss G: 1.7789\n",
      "Epoch [15/20] Batch 520/938 Loss D: 0.2975, Loss G: 1.6913\n",
      "Epoch [15/20] Batch 530/938 Loss D: 0.3904, Loss G: 1.3445\n",
      "Epoch [15/20] Batch 540/938 Loss D: 0.3728, Loss G: 1.5190\n",
      "Epoch [15/20] Batch 550/938 Loss D: 0.2759, Loss G: 1.8111\n",
      "Epoch [15/20] Batch 560/938 Loss D: 0.3128, Loss G: 1.5599\n",
      "Epoch [15/20] Batch 570/938 Loss D: 0.2876, Loss G: 1.5670\n",
      "Epoch [15/20] Batch 580/938 Loss D: 0.3010, Loss G: 1.5878\n",
      "Epoch [15/20] Batch 590/938 Loss D: 0.2938, Loss G: 1.4831\n",
      "Epoch [15/20] Batch 600/938 Loss D: 0.3513, Loss G: 1.6648\n",
      "Epoch [15/20] Batch 610/938 Loss D: 0.2825, Loss G: 1.8285\n",
      "Epoch [15/20] Batch 620/938 Loss D: 0.3647, Loss G: 1.3201\n",
      "Epoch [15/20] Batch 630/938 Loss D: 0.3536, Loss G: 1.5679\n",
      "Epoch [15/20] Batch 640/938 Loss D: 0.3307, Loss G: 1.7666\n",
      "Epoch [15/20] Batch 650/938 Loss D: 0.3626, Loss G: 1.6787\n",
      "Epoch [15/20] Batch 660/938 Loss D: 0.4036, Loss G: 1.2427\n",
      "Epoch [15/20] Batch 670/938 Loss D: 0.2760, Loss G: 1.5867\n",
      "Epoch [15/20] Batch 680/938 Loss D: 0.2967, Loss G: 1.5618\n",
      "Epoch [15/20] Batch 690/938 Loss D: 0.2643, Loss G: 1.8871\n",
      "Epoch [15/20] Batch 700/938 Loss D: 0.3528, Loss G: 1.6716\n",
      "Epoch [15/20] Batch 710/938 Loss D: 0.3311, Loss G: 1.5205\n",
      "Epoch [15/20] Batch 720/938 Loss D: 0.2649, Loss G: 1.9308\n",
      "Epoch [15/20] Batch 730/938 Loss D: 0.3253, Loss G: 1.6273\n",
      "Epoch [15/20] Batch 740/938 Loss D: 0.3349, Loss G: 1.4189\n",
      "Epoch [15/20] Batch 750/938 Loss D: 0.3335, Loss G: 1.5736\n",
      "Epoch [15/20] Batch 760/938 Loss D: 0.3600, Loss G: 1.3936\n",
      "Epoch [15/20] Batch 770/938 Loss D: 0.2823, Loss G: 1.5285\n",
      "Epoch [15/20] Batch 780/938 Loss D: 0.3658, Loss G: 1.6108\n",
      "Epoch [15/20] Batch 790/938 Loss D: 0.2994, Loss G: 1.8248\n",
      "Epoch [15/20] Batch 800/938 Loss D: 0.3303, Loss G: 1.7350\n",
      "Epoch [15/20] Batch 810/938 Loss D: 0.3197, Loss G: 1.7694\n",
      "Epoch [15/20] Batch 820/938 Loss D: 0.3435, Loss G: 1.5341\n",
      "Epoch [15/20] Batch 830/938 Loss D: 0.2729, Loss G: 1.7238\n",
      "Epoch [15/20] Batch 840/938 Loss D: 0.3245, Loss G: 1.6624\n",
      "Epoch [15/20] Batch 850/938 Loss D: 0.3230, Loss G: 1.7405\n",
      "Epoch [15/20] Batch 860/938 Loss D: 0.2980, Loss G: 1.8033\n",
      "Epoch [15/20] Batch 870/938 Loss D: 0.4008, Loss G: 1.2196\n",
      "Epoch [15/20] Batch 880/938 Loss D: 0.2598, Loss G: 1.4841\n",
      "Epoch [15/20] Batch 890/938 Loss D: 0.2921, Loss G: 1.6790\n",
      "Epoch [15/20] Batch 900/938 Loss D: 0.3066, Loss G: 1.8259\n",
      "Epoch [15/20] Batch 910/938 Loss D: 0.3098, Loss G: 1.5934\n",
      "Epoch [15/20] Batch 920/938 Loss D: 0.2905, Loss G: 1.7514\n",
      "Epoch [15/20] Batch 930/938 Loss D: 0.2878, Loss G: 1.6820\n",
      "Epoch [16/20] Batch 0/938 Loss D: 0.3536, Loss G: 1.4747\n",
      "Epoch [16/20] Batch 10/938 Loss D: 0.2889, Loss G: 1.4307\n",
      "Epoch [16/20] Batch 20/938 Loss D: 0.3353, Loss G: 1.4303\n",
      "Epoch [16/20] Batch 30/938 Loss D: 0.3867, Loss G: 1.3890\n",
      "Epoch [16/20] Batch 40/938 Loss D: 0.3267, Loss G: 1.5251\n",
      "Epoch [16/20] Batch 50/938 Loss D: 0.2707, Loss G: 1.8144\n",
      "Epoch [16/20] Batch 60/938 Loss D: 0.3151, Loss G: 1.5954\n",
      "Epoch [16/20] Batch 70/938 Loss D: 0.4669, Loss G: 1.4265\n",
      "Epoch [16/20] Batch 80/938 Loss D: 0.2903, Loss G: 1.6848\n",
      "Epoch [16/20] Batch 90/938 Loss D: 0.3265, Loss G: 1.4182\n",
      "Epoch [16/20] Batch 100/938 Loss D: 0.2786, Loss G: 1.5032\n",
      "Epoch [16/20] Batch 110/938 Loss D: 0.3024, Loss G: 1.7220\n",
      "Epoch [16/20] Batch 120/938 Loss D: 0.3261, Loss G: 1.5341\n",
      "Epoch [16/20] Batch 130/938 Loss D: 0.3743, Loss G: 1.3556\n",
      "Epoch [16/20] Batch 140/938 Loss D: 0.2943, Loss G: 1.5948\n",
      "Epoch [16/20] Batch 150/938 Loss D: 0.3310, Loss G: 1.5736\n",
      "Epoch [16/20] Batch 160/938 Loss D: 0.2615, Loss G: 1.7200\n",
      "Epoch [16/20] Batch 170/938 Loss D: 0.3071, Loss G: 1.6843\n",
      "Epoch [16/20] Batch 180/938 Loss D: 0.3437, Loss G: 1.5496\n",
      "Epoch [16/20] Batch 190/938 Loss D: 0.2834, Loss G: 1.5173\n",
      "Epoch [16/20] Batch 200/938 Loss D: 0.3337, Loss G: 1.5435\n",
      "Epoch [16/20] Batch 210/938 Loss D: 0.3527, Loss G: 1.4585\n",
      "Epoch [16/20] Batch 220/938 Loss D: 0.3179, Loss G: 1.7304\n",
      "Epoch [16/20] Batch 230/938 Loss D: 0.2764, Loss G: 1.7987\n",
      "Epoch [16/20] Batch 240/938 Loss D: 0.2709, Loss G: 1.5540\n",
      "Epoch [16/20] Batch 250/938 Loss D: 0.3576, Loss G: 1.6118\n",
      "Epoch [16/20] Batch 260/938 Loss D: 0.2976, Loss G: 1.6996\n",
      "Epoch [16/20] Batch 270/938 Loss D: 0.3381, Loss G: 1.5879\n",
      "Epoch [16/20] Batch 280/938 Loss D: 0.3319, Loss G: 1.5708\n",
      "Epoch [16/20] Batch 290/938 Loss D: 0.2603, Loss G: 1.6627\n",
      "Epoch [16/20] Batch 300/938 Loss D: 0.2855, Loss G: 1.6391\n",
      "Epoch [16/20] Batch 310/938 Loss D: 0.2796, Loss G: 1.6233\n",
      "Epoch [16/20] Batch 320/938 Loss D: 0.3655, Loss G: 1.4568\n",
      "Epoch [16/20] Batch 330/938 Loss D: 0.2922, Loss G: 1.7163\n",
      "Epoch [16/20] Batch 340/938 Loss D: 0.4018, Loss G: 1.5120\n",
      "Epoch [16/20] Batch 350/938 Loss D: 0.3130, Loss G: 1.7475\n",
      "Epoch [16/20] Batch 360/938 Loss D: 0.3393, Loss G: 1.7364\n",
      "Epoch [16/20] Batch 370/938 Loss D: 0.3404, Loss G: 1.3800\n",
      "Epoch [16/20] Batch 380/938 Loss D: 0.3690, Loss G: 1.4856\n",
      "Epoch [16/20] Batch 390/938 Loss D: 0.3579, Loss G: 1.6757\n",
      "Epoch [16/20] Batch 400/938 Loss D: 0.3486, Loss G: 1.4514\n",
      "Epoch [16/20] Batch 410/938 Loss D: 0.3544, Loss G: 1.6823\n",
      "Epoch [16/20] Batch 420/938 Loss D: 0.3207, Loss G: 1.5313\n",
      "Epoch [16/20] Batch 430/938 Loss D: 0.3081, Loss G: 1.6060\n",
      "Epoch [16/20] Batch 440/938 Loss D: 0.2504, Loss G: 2.0224\n",
      "Epoch [16/20] Batch 450/938 Loss D: 0.2591, Loss G: 1.7746\n",
      "Epoch [16/20] Batch 460/938 Loss D: 0.2856, Loss G: 1.4076\n",
      "Epoch [16/20] Batch 470/938 Loss D: 0.3353, Loss G: 1.3341\n",
      "Epoch [16/20] Batch 480/938 Loss D: 0.3386, Loss G: 1.7055\n",
      "Epoch [16/20] Batch 490/938 Loss D: 0.2929, Loss G: 1.7185\n",
      "Epoch [16/20] Batch 500/938 Loss D: 0.3442, Loss G: 1.4718\n",
      "Epoch [16/20] Batch 510/938 Loss D: 0.2343, Loss G: 1.7463\n",
      "Epoch [16/20] Batch 520/938 Loss D: 0.2965, Loss G: 1.5232\n",
      "Epoch [16/20] Batch 530/938 Loss D: 0.2904, Loss G: 1.7742\n",
      "Epoch [16/20] Batch 540/938 Loss D: 0.3223, Loss G: 1.5303\n",
      "Epoch [16/20] Batch 550/938 Loss D: 0.2834, Loss G: 1.7762\n",
      "Epoch [16/20] Batch 560/938 Loss D: 0.2901, Loss G: 1.5676\n",
      "Epoch [16/20] Batch 570/938 Loss D: 0.2738, Loss G: 1.6600\n",
      "Epoch [16/20] Batch 580/938 Loss D: 0.3563, Loss G: 1.3799\n",
      "Epoch [16/20] Batch 590/938 Loss D: 0.3482, Loss G: 1.4243\n",
      "Epoch [16/20] Batch 600/938 Loss D: 0.3147, Loss G: 1.4289\n",
      "Epoch [16/20] Batch 610/938 Loss D: 0.2646, Loss G: 1.8789\n",
      "Epoch [16/20] Batch 620/938 Loss D: 0.2949, Loss G: 1.7332\n",
      "Epoch [16/20] Batch 630/938 Loss D: 0.3197, Loss G: 1.5807\n",
      "Epoch [16/20] Batch 640/938 Loss D: 0.3618, Loss G: 1.5644\n",
      "Epoch [16/20] Batch 650/938 Loss D: 0.2818, Loss G: 1.7484\n",
      "Epoch [16/20] Batch 660/938 Loss D: 0.3133, Loss G: 1.6046\n",
      "Epoch [16/20] Batch 670/938 Loss D: 0.2922, Loss G: 1.4891\n",
      "Epoch [16/20] Batch 680/938 Loss D: 0.2879, Loss G: 1.7394\n",
      "Epoch [16/20] Batch 690/938 Loss D: 0.3412, Loss G: 1.5078\n",
      "Epoch [16/20] Batch 700/938 Loss D: 0.2727, Loss G: 1.4930\n",
      "Epoch [16/20] Batch 710/938 Loss D: 0.2771, Loss G: 1.4358\n",
      "Epoch [16/20] Batch 720/938 Loss D: 0.3013, Loss G: 1.7754\n",
      "Epoch [16/20] Batch 730/938 Loss D: 0.3276, Loss G: 1.3701\n",
      "Epoch [16/20] Batch 740/938 Loss D: 0.2768, Loss G: 1.6509\n",
      "Epoch [16/20] Batch 750/938 Loss D: 0.3372, Loss G: 1.6649\n",
      "Epoch [16/20] Batch 760/938 Loss D: 0.3554, Loss G: 1.4124\n",
      "Epoch [16/20] Batch 770/938 Loss D: 0.3468, Loss G: 1.6175\n",
      "Epoch [16/20] Batch 780/938 Loss D: 0.3389, Loss G: 1.6871\n",
      "Epoch [16/20] Batch 790/938 Loss D: 0.2533, Loss G: 1.9518\n",
      "Epoch [16/20] Batch 800/938 Loss D: 0.3057, Loss G: 1.5786\n",
      "Epoch [16/20] Batch 810/938 Loss D: 0.2960, Loss G: 1.5927\n",
      "Epoch [16/20] Batch 820/938 Loss D: 0.2840, Loss G: 1.8828\n",
      "Epoch [16/20] Batch 830/938 Loss D: 0.2370, Loss G: 1.7669\n",
      "Epoch [16/20] Batch 840/938 Loss D: 0.3437, Loss G: 1.5480\n",
      "Epoch [16/20] Batch 850/938 Loss D: 0.3115, Loss G: 1.5123\n",
      "Epoch [16/20] Batch 860/938 Loss D: 0.3417, Loss G: 1.6688\n",
      "Epoch [16/20] Batch 870/938 Loss D: 0.3168, Loss G: 1.5022\n",
      "Epoch [16/20] Batch 880/938 Loss D: 0.3021, Loss G: 1.6763\n",
      "Epoch [16/20] Batch 890/938 Loss D: 0.3472, Loss G: 1.4130\n",
      "Epoch [16/20] Batch 900/938 Loss D: 0.2400, Loss G: 1.7098\n",
      "Epoch [16/20] Batch 910/938 Loss D: 0.2895, Loss G: 1.7107\n",
      "Epoch [16/20] Batch 920/938 Loss D: 0.2515, Loss G: 1.7764\n",
      "Epoch [16/20] Batch 930/938 Loss D: 0.3460, Loss G: 1.6918\n",
      "Epoch [17/20] Batch 0/938 Loss D: 0.3008, Loss G: 1.5839\n",
      "Epoch [17/20] Batch 10/938 Loss D: 0.3288, Loss G: 1.5377\n",
      "Epoch [17/20] Batch 20/938 Loss D: 0.3106, Loss G: 1.6637\n",
      "Epoch [17/20] Batch 30/938 Loss D: 0.3139, Loss G: 1.7016\n",
      "Epoch [17/20] Batch 40/938 Loss D: 0.2665, Loss G: 1.6867\n",
      "Epoch [17/20] Batch 50/938 Loss D: 0.2961, Loss G: 1.6076\n",
      "Epoch [17/20] Batch 60/938 Loss D: 0.2693, Loss G: 1.6739\n",
      "Epoch [17/20] Batch 70/938 Loss D: 0.3045, Loss G: 1.5406\n",
      "Epoch [17/20] Batch 80/938 Loss D: 0.3468, Loss G: 1.6414\n",
      "Epoch [17/20] Batch 90/938 Loss D: 0.2850, Loss G: 1.4223\n",
      "Epoch [17/20] Batch 100/938 Loss D: 0.2998, Loss G: 1.3502\n",
      "Epoch [17/20] Batch 110/938 Loss D: 0.3054, Loss G: 1.6359\n",
      "Epoch [17/20] Batch 120/938 Loss D: 0.2633, Loss G: 1.7511\n",
      "Epoch [17/20] Batch 130/938 Loss D: 0.2764, Loss G: 1.6510\n",
      "Epoch [17/20] Batch 140/938 Loss D: 0.3007, Loss G: 1.6329\n",
      "Epoch [17/20] Batch 150/938 Loss D: 0.4197, Loss G: 1.5442\n",
      "Epoch [17/20] Batch 160/938 Loss D: 0.3522, Loss G: 1.6121\n",
      "Epoch [17/20] Batch 170/938 Loss D: 0.3453, Loss G: 1.5668\n",
      "Epoch [17/20] Batch 180/938 Loss D: 0.3344, Loss G: 1.6056\n",
      "Epoch [17/20] Batch 190/938 Loss D: 0.3021, Loss G: 1.6844\n",
      "Epoch [17/20] Batch 200/938 Loss D: 0.2856, Loss G: 1.6296\n",
      "Epoch [17/20] Batch 210/938 Loss D: 0.3153, Loss G: 1.8534\n",
      "Epoch [17/20] Batch 220/938 Loss D: 0.2970, Loss G: 1.7165\n",
      "Epoch [17/20] Batch 230/938 Loss D: 0.3428, Loss G: 1.4814\n",
      "Epoch [17/20] Batch 240/938 Loss D: 0.3178, Loss G: 1.6242\n",
      "Epoch [17/20] Batch 250/938 Loss D: 0.2579, Loss G: 1.6931\n",
      "Epoch [17/20] Batch 260/938 Loss D: 0.2804, Loss G: 1.8034\n",
      "Epoch [17/20] Batch 270/938 Loss D: 0.3415, Loss G: 1.5315\n",
      "Epoch [17/20] Batch 280/938 Loss D: 0.2757, Loss G: 1.5631\n",
      "Epoch [17/20] Batch 290/938 Loss D: 0.3607, Loss G: 1.5287\n",
      "Epoch [17/20] Batch 300/938 Loss D: 0.3202, Loss G: 1.6341\n",
      "Epoch [17/20] Batch 310/938 Loss D: 0.3493, Loss G: 1.4384\n",
      "Epoch [17/20] Batch 320/938 Loss D: 0.2985, Loss G: 1.4644\n",
      "Epoch [17/20] Batch 330/938 Loss D: 0.4236, Loss G: 1.4704\n",
      "Epoch [17/20] Batch 340/938 Loss D: 0.3473, Loss G: 1.5949\n",
      "Epoch [17/20] Batch 350/938 Loss D: 0.2920, Loss G: 1.6246\n",
      "Epoch [17/20] Batch 360/938 Loss D: 0.3017, Loss G: 1.5954\n",
      "Epoch [17/20] Batch 370/938 Loss D: 0.2526, Loss G: 1.7153\n",
      "Epoch [17/20] Batch 380/938 Loss D: 0.3087, Loss G: 1.6164\n",
      "Epoch [17/20] Batch 390/938 Loss D: 0.2414, Loss G: 1.8205\n",
      "Epoch [17/20] Batch 400/938 Loss D: 0.3527, Loss G: 1.5080\n",
      "Epoch [17/20] Batch 410/938 Loss D: 0.2936, Loss G: 1.7552\n",
      "Epoch [17/20] Batch 420/938 Loss D: 0.2680, Loss G: 1.6674\n",
      "Epoch [17/20] Batch 430/938 Loss D: 0.3309, Loss G: 1.6978\n",
      "Epoch [17/20] Batch 440/938 Loss D: 0.2683, Loss G: 1.6653\n",
      "Epoch [17/20] Batch 450/938 Loss D: 0.2446, Loss G: 1.8508\n",
      "Epoch [17/20] Batch 460/938 Loss D: 0.2891, Loss G: 1.6729\n",
      "Epoch [17/20] Batch 470/938 Loss D: 0.3235, Loss G: 1.7215\n",
      "Epoch [17/20] Batch 480/938 Loss D: 0.3103, Loss G: 1.5530\n",
      "Epoch [17/20] Batch 490/938 Loss D: 0.2779, Loss G: 1.6899\n",
      "Epoch [17/20] Batch 500/938 Loss D: 0.2921, Loss G: 1.5253\n",
      "Epoch [17/20] Batch 510/938 Loss D: 0.2926, Loss G: 1.6845\n",
      "Epoch [17/20] Batch 520/938 Loss D: 0.3255, Loss G: 1.8239\n",
      "Epoch [17/20] Batch 530/938 Loss D: 0.2835, Loss G: 1.7477\n",
      "Epoch [17/20] Batch 540/938 Loss D: 0.3295, Loss G: 1.4045\n",
      "Epoch [17/20] Batch 550/938 Loss D: 0.3504, Loss G: 1.6072\n",
      "Epoch [17/20] Batch 560/938 Loss D: 0.3092, Loss G: 1.6435\n",
      "Epoch [17/20] Batch 570/938 Loss D: 0.3282, Loss G: 1.4776\n",
      "Epoch [17/20] Batch 580/938 Loss D: 0.2559, Loss G: 1.6744\n",
      "Epoch [17/20] Batch 590/938 Loss D: 0.2947, Loss G: 1.6069\n",
      "Epoch [17/20] Batch 600/938 Loss D: 0.3605, Loss G: 1.3470\n",
      "Epoch [17/20] Batch 610/938 Loss D: 0.2840, Loss G: 1.5945\n",
      "Epoch [17/20] Batch 620/938 Loss D: 0.2659, Loss G: 1.8180\n",
      "Epoch [17/20] Batch 630/938 Loss D: 0.2642, Loss G: 2.0017\n",
      "Epoch [17/20] Batch 640/938 Loss D: 0.2598, Loss G: 1.9157\n",
      "Epoch [17/20] Batch 650/938 Loss D: 0.3370, Loss G: 1.7247\n",
      "Epoch [17/20] Batch 660/938 Loss D: 0.2892, Loss G: 1.5186\n",
      "Epoch [17/20] Batch 670/938 Loss D: 0.3244, Loss G: 1.7003\n",
      "Epoch [17/20] Batch 680/938 Loss D: 0.2330, Loss G: 1.7537\n",
      "Epoch [17/20] Batch 690/938 Loss D: 0.2644, Loss G: 1.9208\n",
      "Epoch [17/20] Batch 700/938 Loss D: 0.3051, Loss G: 1.6771\n",
      "Epoch [17/20] Batch 710/938 Loss D: 0.3883, Loss G: 1.7765\n",
      "Epoch [17/20] Batch 720/938 Loss D: 0.2711, Loss G: 1.8873\n",
      "Epoch [17/20] Batch 730/938 Loss D: 0.2999, Loss G: 1.5643\n",
      "Epoch [17/20] Batch 740/938 Loss D: 0.3642, Loss G: 1.4794\n",
      "Epoch [17/20] Batch 750/938 Loss D: 0.2495, Loss G: 1.9085\n",
      "Epoch [17/20] Batch 760/938 Loss D: 0.2906, Loss G: 1.6967\n",
      "Epoch [17/20] Batch 770/938 Loss D: 0.3262, Loss G: 1.5586\n",
      "Epoch [17/20] Batch 780/938 Loss D: 0.3005, Loss G: 1.6850\n",
      "Epoch [17/20] Batch 790/938 Loss D: 0.3064, Loss G: 1.5447\n",
      "Epoch [17/20] Batch 800/938 Loss D: 0.3363, Loss G: 1.5822\n",
      "Epoch [17/20] Batch 810/938 Loss D: 0.3436, Loss G: 1.3663\n",
      "Epoch [17/20] Batch 820/938 Loss D: 0.2309, Loss G: 1.7688\n",
      "Epoch [17/20] Batch 830/938 Loss D: 0.3316, Loss G: 1.4447\n",
      "Epoch [17/20] Batch 840/938 Loss D: 0.3080, Loss G: 1.7309\n",
      "Epoch [17/20] Batch 850/938 Loss D: 0.2575, Loss G: 1.7413\n",
      "Epoch [17/20] Batch 860/938 Loss D: 0.3333, Loss G: 1.4412\n",
      "Epoch [17/20] Batch 870/938 Loss D: 0.3066, Loss G: 1.7196\n",
      "Epoch [17/20] Batch 880/938 Loss D: 0.2802, Loss G: 1.5274\n",
      "Epoch [17/20] Batch 890/938 Loss D: 0.2135, Loss G: 2.1508\n",
      "Epoch [17/20] Batch 900/938 Loss D: 0.2860, Loss G: 1.7953\n",
      "Epoch [17/20] Batch 910/938 Loss D: 0.3088, Loss G: 1.3932\n",
      "Epoch [17/20] Batch 920/938 Loss D: 0.3602, Loss G: 1.3488\n",
      "Epoch [17/20] Batch 930/938 Loss D: 0.2840, Loss G: 1.6172\n",
      "Epoch [18/20] Batch 0/938 Loss D: 0.2961, Loss G: 1.7486\n",
      "Epoch [18/20] Batch 10/938 Loss D: 0.2970, Loss G: 1.4658\n",
      "Epoch [18/20] Batch 20/938 Loss D: 0.2825, Loss G: 1.7334\n",
      "Epoch [18/20] Batch 30/938 Loss D: 0.3126, Loss G: 1.7770\n",
      "Epoch [18/20] Batch 40/938 Loss D: 0.2933, Loss G: 1.6914\n",
      "Epoch [18/20] Batch 50/938 Loss D: 0.3036, Loss G: 1.5841\n",
      "Epoch [18/20] Batch 60/938 Loss D: 0.2747, Loss G: 1.7346\n",
      "Epoch [18/20] Batch 70/938 Loss D: 0.2879, Loss G: 1.7189\n",
      "Epoch [18/20] Batch 80/938 Loss D: 0.2880, Loss G: 1.5976\n",
      "Epoch [18/20] Batch 90/938 Loss D: 0.3188, Loss G: 1.5572\n",
      "Epoch [18/20] Batch 100/938 Loss D: 0.2960, Loss G: 1.7457\n",
      "Epoch [18/20] Batch 110/938 Loss D: 0.2966, Loss G: 1.6528\n",
      "Epoch [18/20] Batch 120/938 Loss D: 0.3131, Loss G: 1.4326\n",
      "Epoch [18/20] Batch 130/938 Loss D: 0.2651, Loss G: 1.8700\n",
      "Epoch [18/20] Batch 140/938 Loss D: 0.3263, Loss G: 1.6038\n",
      "Epoch [18/20] Batch 150/938 Loss D: 0.3097, Loss G: 1.6349\n",
      "Epoch [18/20] Batch 160/938 Loss D: 0.2928, Loss G: 1.4680\n",
      "Epoch [18/20] Batch 170/938 Loss D: 0.3886, Loss G: 1.6420\n",
      "Epoch [18/20] Batch 180/938 Loss D: 0.3388, Loss G: 1.5565\n",
      "Epoch [18/20] Batch 190/938 Loss D: 0.2757, Loss G: 1.7953\n",
      "Epoch [18/20] Batch 200/938 Loss D: 0.3443, Loss G: 1.4517\n",
      "Epoch [18/20] Batch 210/938 Loss D: 0.2795, Loss G: 1.5291\n",
      "Epoch [18/20] Batch 220/938 Loss D: 0.3906, Loss G: 1.4957\n",
      "Epoch [18/20] Batch 230/938 Loss D: 0.2991, Loss G: 1.7504\n",
      "Epoch [18/20] Batch 240/938 Loss D: 0.2531, Loss G: 2.0614\n",
      "Epoch [18/20] Batch 250/938 Loss D: 0.2791, Loss G: 1.8738\n",
      "Epoch [18/20] Batch 260/938 Loss D: 0.2852, Loss G: 1.7378\n",
      "Epoch [18/20] Batch 270/938 Loss D: 0.3341, Loss G: 1.4483\n",
      "Epoch [18/20] Batch 280/938 Loss D: 0.2864, Loss G: 1.6258\n",
      "Epoch [18/20] Batch 290/938 Loss D: 0.2917, Loss G: 1.4597\n",
      "Epoch [18/20] Batch 300/938 Loss D: 0.3277, Loss G: 1.6900\n",
      "Epoch [18/20] Batch 310/938 Loss D: 0.2962, Loss G: 1.8280\n",
      "Epoch [18/20] Batch 320/938 Loss D: 0.3073, Loss G: 1.5638\n",
      "Epoch [18/20] Batch 330/938 Loss D: 0.2927, Loss G: 1.6567\n",
      "Epoch [18/20] Batch 340/938 Loss D: 0.2999, Loss G: 1.5345\n",
      "Epoch [18/20] Batch 350/938 Loss D: 0.3005, Loss G: 1.5321\n",
      "Epoch [18/20] Batch 360/938 Loss D: 0.3244, Loss G: 1.3285\n",
      "Epoch [18/20] Batch 370/938 Loss D: 0.3415, Loss G: 1.8565\n",
      "Epoch [18/20] Batch 380/938 Loss D: 0.3635, Loss G: 1.6679\n",
      "Epoch [18/20] Batch 390/938 Loss D: 0.3186, Loss G: 1.4789\n",
      "Epoch [18/20] Batch 400/938 Loss D: 0.3100, Loss G: 1.6802\n",
      "Epoch [18/20] Batch 410/938 Loss D: 0.2715, Loss G: 1.8090\n",
      "Epoch [18/20] Batch 420/938 Loss D: 0.2884, Loss G: 1.4399\n",
      "Epoch [18/20] Batch 430/938 Loss D: 0.2960, Loss G: 1.5079\n",
      "Epoch [18/20] Batch 440/938 Loss D: 0.2768, Loss G: 1.8457\n",
      "Epoch [18/20] Batch 450/938 Loss D: 0.2728, Loss G: 1.6221\n",
      "Epoch [18/20] Batch 460/938 Loss D: 0.3216, Loss G: 1.6504\n",
      "Epoch [18/20] Batch 470/938 Loss D: 0.3486, Loss G: 1.5333\n",
      "Epoch [18/20] Batch 480/938 Loss D: 0.2656, Loss G: 1.6901\n",
      "Epoch [18/20] Batch 490/938 Loss D: 0.3309, Loss G: 1.4362\n",
      "Epoch [18/20] Batch 500/938 Loss D: 0.2789, Loss G: 1.4822\n",
      "Epoch [18/20] Batch 510/938 Loss D: 0.2901, Loss G: 1.6218\n",
      "Epoch [18/20] Batch 520/938 Loss D: 0.2981, Loss G: 1.8256\n",
      "Epoch [18/20] Batch 530/938 Loss D: 0.3765, Loss G: 1.4160\n",
      "Epoch [18/20] Batch 540/938 Loss D: 0.2591, Loss G: 1.6430\n",
      "Epoch [18/20] Batch 550/938 Loss D: 0.3255, Loss G: 1.5714\n",
      "Epoch [18/20] Batch 560/938 Loss D: 0.3519, Loss G: 1.5521\n",
      "Epoch [18/20] Batch 570/938 Loss D: 0.3547, Loss G: 1.4403\n",
      "Epoch [18/20] Batch 580/938 Loss D: 0.3406, Loss G: 1.6952\n",
      "Epoch [18/20] Batch 590/938 Loss D: 0.3211, Loss G: 1.4734\n",
      "Epoch [18/20] Batch 600/938 Loss D: 0.2714, Loss G: 1.8452\n",
      "Epoch [18/20] Batch 610/938 Loss D: 0.3207, Loss G: 1.6309\n",
      "Epoch [18/20] Batch 620/938 Loss D: 0.2927, Loss G: 1.8544\n",
      "Epoch [18/20] Batch 630/938 Loss D: 0.2763, Loss G: 1.5908\n",
      "Epoch [18/20] Batch 640/938 Loss D: 0.2982, Loss G: 1.5325\n",
      "Epoch [18/20] Batch 650/938 Loss D: 0.3111, Loss G: 1.5527\n",
      "Epoch [18/20] Batch 660/938 Loss D: 0.2976, Loss G: 1.5037\n",
      "Epoch [18/20] Batch 670/938 Loss D: 0.3087, Loss G: 1.5103\n",
      "Epoch [18/20] Batch 680/938 Loss D: 0.3148, Loss G: 1.3875\n",
      "Epoch [18/20] Batch 690/938 Loss D: 0.2672, Loss G: 1.7454\n",
      "Epoch [18/20] Batch 700/938 Loss D: 0.2965, Loss G: 1.9057\n",
      "Epoch [18/20] Batch 710/938 Loss D: 0.3147, Loss G: 1.5672\n",
      "Epoch [18/20] Batch 720/938 Loss D: 0.3151, Loss G: 1.5579\n",
      "Epoch [18/20] Batch 730/938 Loss D: 0.3025, Loss G: 1.6194\n",
      "Epoch [18/20] Batch 740/938 Loss D: 0.2914, Loss G: 1.7689\n",
      "Epoch [18/20] Batch 750/938 Loss D: 0.2476, Loss G: 1.8832\n",
      "Epoch [18/20] Batch 760/938 Loss D: 0.2858, Loss G: 1.7037\n",
      "Epoch [18/20] Batch 770/938 Loss D: 0.2199, Loss G: 1.8978\n",
      "Epoch [18/20] Batch 780/938 Loss D: 0.3353, Loss G: 1.7650\n",
      "Epoch [18/20] Batch 790/938 Loss D: 0.3756, Loss G: 1.9383\n",
      "Epoch [18/20] Batch 800/938 Loss D: 0.2964, Loss G: 1.7741\n",
      "Epoch [18/20] Batch 810/938 Loss D: 0.2833, Loss G: 1.9854\n",
      "Epoch [18/20] Batch 820/938 Loss D: 0.3046, Loss G: 1.4212\n",
      "Epoch [18/20] Batch 830/938 Loss D: 0.2382, Loss G: 1.7454\n",
      "Epoch [18/20] Batch 840/938 Loss D: 0.2969, Loss G: 1.6828\n",
      "Epoch [18/20] Batch 850/938 Loss D: 0.3041, Loss G: 1.5855\n",
      "Epoch [18/20] Batch 860/938 Loss D: 0.3891, Loss G: 1.6584\n",
      "Epoch [18/20] Batch 870/938 Loss D: 0.2961, Loss G: 1.8011\n",
      "Epoch [18/20] Batch 880/938 Loss D: 0.3531, Loss G: 1.4645\n",
      "Epoch [18/20] Batch 890/938 Loss D: 0.3514, Loss G: 1.3812\n",
      "Epoch [18/20] Batch 900/938 Loss D: 0.3100, Loss G: 1.5292\n",
      "Epoch [18/20] Batch 910/938 Loss D: 0.3017, Loss G: 1.5905\n",
      "Epoch [18/20] Batch 920/938 Loss D: 0.3303, Loss G: 1.5422\n",
      "Epoch [18/20] Batch 930/938 Loss D: 0.3270, Loss G: 1.5985\n",
      "Epoch [19/20] Batch 0/938 Loss D: 0.2529, Loss G: 1.7589\n",
      "Epoch [19/20] Batch 10/938 Loss D: 0.2736, Loss G: 1.5834\n",
      "Epoch [19/20] Batch 20/938 Loss D: 0.2923, Loss G: 1.6072\n",
      "Epoch [19/20] Batch 30/938 Loss D: 0.3798, Loss G: 1.5960\n",
      "Epoch [19/20] Batch 40/938 Loss D: 0.2961, Loss G: 1.7408\n",
      "Epoch [19/20] Batch 50/938 Loss D: 0.3257, Loss G: 1.7286\n",
      "Epoch [19/20] Batch 60/938 Loss D: 0.2253, Loss G: 1.9421\n",
      "Epoch [19/20] Batch 70/938 Loss D: 0.3319, Loss G: 1.4308\n",
      "Epoch [19/20] Batch 80/938 Loss D: 0.2935, Loss G: 1.8023\n",
      "Epoch [19/20] Batch 90/938 Loss D: 0.2761, Loss G: 1.8714\n",
      "Epoch [19/20] Batch 100/938 Loss D: 0.3031, Loss G: 1.9305\n",
      "Epoch [19/20] Batch 110/938 Loss D: 0.3212, Loss G: 1.5122\n",
      "Epoch [19/20] Batch 120/938 Loss D: 0.2208, Loss G: 2.2352\n",
      "Epoch [19/20] Batch 130/938 Loss D: 0.2156, Loss G: 1.8127\n",
      "Epoch [19/20] Batch 140/938 Loss D: 0.2615, Loss G: 1.5214\n",
      "Epoch [19/20] Batch 150/938 Loss D: 0.3550, Loss G: 1.4012\n",
      "Epoch [19/20] Batch 160/938 Loss D: 0.3017, Loss G: 1.5889\n",
      "Epoch [19/20] Batch 170/938 Loss D: 0.4040, Loss G: 1.6413\n",
      "Epoch [19/20] Batch 180/938 Loss D: 0.2546, Loss G: 2.2830\n",
      "Epoch [19/20] Batch 190/938 Loss D: 0.3471, Loss G: 1.4281\n",
      "Epoch [19/20] Batch 200/938 Loss D: 0.2994, Loss G: 1.6366\n",
      "Epoch [19/20] Batch 210/938 Loss D: 0.2963, Loss G: 1.6568\n",
      "Epoch [19/20] Batch 220/938 Loss D: 0.2843, Loss G: 1.7115\n",
      "Epoch [19/20] Batch 230/938 Loss D: 0.2727, Loss G: 1.8803\n",
      "Epoch [19/20] Batch 240/938 Loss D: 0.2905, Loss G: 1.6169\n",
      "Epoch [19/20] Batch 250/938 Loss D: 0.3130, Loss G: 1.6805\n",
      "Epoch [19/20] Batch 260/938 Loss D: 0.2914, Loss G: 1.6917\n",
      "Epoch [19/20] Batch 270/938 Loss D: 0.2935, Loss G: 2.0165\n",
      "Epoch [19/20] Batch 280/938 Loss D: 0.3351, Loss G: 1.5566\n",
      "Epoch [19/20] Batch 290/938 Loss D: 0.3449, Loss G: 1.5749\n",
      "Epoch [19/20] Batch 300/938 Loss D: 0.3007, Loss G: 1.3758\n",
      "Epoch [19/20] Batch 310/938 Loss D: 0.2990, Loss G: 1.4497\n",
      "Epoch [19/20] Batch 320/938 Loss D: 0.3151, Loss G: 1.4889\n",
      "Epoch [19/20] Batch 330/938 Loss D: 0.3459, Loss G: 1.4601\n",
      "Epoch [19/20] Batch 340/938 Loss D: 0.3589, Loss G: 1.4759\n",
      "Epoch [19/20] Batch 350/938 Loss D: 0.2916, Loss G: 1.6099\n",
      "Epoch [19/20] Batch 360/938 Loss D: 0.3394, Loss G: 1.4840\n",
      "Epoch [19/20] Batch 370/938 Loss D: 0.2793, Loss G: 1.7113\n",
      "Epoch [19/20] Batch 380/938 Loss D: 0.3518, Loss G: 1.5625\n",
      "Epoch [19/20] Batch 390/938 Loss D: 0.2929, Loss G: 1.9048\n",
      "Epoch [19/20] Batch 400/938 Loss D: 0.3330, Loss G: 1.6603\n",
      "Epoch [19/20] Batch 410/938 Loss D: 0.3182, Loss G: 1.7883\n",
      "Epoch [19/20] Batch 420/938 Loss D: 0.2831, Loss G: 1.7421\n",
      "Epoch [19/20] Batch 430/938 Loss D: 0.3054, Loss G: 1.8755\n",
      "Epoch [19/20] Batch 440/938 Loss D: 0.3412, Loss G: 1.6519\n",
      "Epoch [19/20] Batch 450/938 Loss D: 0.3786, Loss G: 1.7205\n",
      "Epoch [19/20] Batch 460/938 Loss D: 0.3651, Loss G: 1.6867\n",
      "Epoch [19/20] Batch 470/938 Loss D: 0.2867, Loss G: 1.7899\n",
      "Epoch [19/20] Batch 480/938 Loss D: 0.2678, Loss G: 1.7292\n",
      "Epoch [19/20] Batch 490/938 Loss D: 0.3850, Loss G: 1.4657\n",
      "Epoch [19/20] Batch 500/938 Loss D: 0.2324, Loss G: 1.8836\n",
      "Epoch [19/20] Batch 510/938 Loss D: 0.2902, Loss G: 1.7865\n",
      "Epoch [19/20] Batch 520/938 Loss D: 0.3033, Loss G: 1.5534\n",
      "Epoch [19/20] Batch 530/938 Loss D: 0.3629, Loss G: 1.5068\n",
      "Epoch [19/20] Batch 540/938 Loss D: 0.3728, Loss G: 1.4897\n",
      "Epoch [19/20] Batch 550/938 Loss D: 0.2901, Loss G: 1.6307\n",
      "Epoch [19/20] Batch 560/938 Loss D: 0.3103, Loss G: 1.7290\n",
      "Epoch [19/20] Batch 570/938 Loss D: 0.2659, Loss G: 1.8061\n",
      "Epoch [19/20] Batch 580/938 Loss D: 0.2821, Loss G: 1.7170\n",
      "Epoch [19/20] Batch 590/938 Loss D: 0.2646, Loss G: 1.7731\n",
      "Epoch [19/20] Batch 600/938 Loss D: 0.3474, Loss G: 1.8525\n",
      "Epoch [19/20] Batch 610/938 Loss D: 0.2769, Loss G: 1.9070\n",
      "Epoch [19/20] Batch 620/938 Loss D: 0.2378, Loss G: 1.7464\n",
      "Epoch [19/20] Batch 630/938 Loss D: 0.2977, Loss G: 1.7445\n",
      "Epoch [19/20] Batch 640/938 Loss D: 0.2655, Loss G: 1.7625\n",
      "Epoch [19/20] Batch 650/938 Loss D: 0.2769, Loss G: 1.6288\n",
      "Epoch [19/20] Batch 660/938 Loss D: 0.2655, Loss G: 1.5513\n",
      "Epoch [19/20] Batch 670/938 Loss D: 0.3835, Loss G: 1.3799\n",
      "Epoch [19/20] Batch 680/938 Loss D: 0.3811, Loss G: 1.4454\n",
      "Epoch [19/20] Batch 690/938 Loss D: 0.3041, Loss G: 1.7990\n",
      "Epoch [19/20] Batch 700/938 Loss D: 0.2839, Loss G: 1.5253\n",
      "Epoch [19/20] Batch 710/938 Loss D: 0.3143, Loss G: 1.6398\n",
      "Epoch [19/20] Batch 720/938 Loss D: 0.2743, Loss G: 1.4727\n",
      "Epoch [19/20] Batch 730/938 Loss D: 0.2715, Loss G: 1.5312\n",
      "Epoch [19/20] Batch 740/938 Loss D: 0.3391, Loss G: 1.4475\n",
      "Epoch [19/20] Batch 750/938 Loss D: 0.3034, Loss G: 1.5520\n",
      "Epoch [19/20] Batch 760/938 Loss D: 0.3721, Loss G: 1.6346\n",
      "Epoch [19/20] Batch 770/938 Loss D: 0.3061, Loss G: 2.0981\n",
      "Epoch [19/20] Batch 780/938 Loss D: 0.3479, Loss G: 1.5433\n",
      "Epoch [19/20] Batch 790/938 Loss D: 0.2359, Loss G: 1.7288\n",
      "Epoch [19/20] Batch 800/938 Loss D: 0.3364, Loss G: 1.5119\n",
      "Epoch [19/20] Batch 810/938 Loss D: 0.2710, Loss G: 1.8334\n",
      "Epoch [19/20] Batch 820/938 Loss D: 0.2727, Loss G: 1.8989\n",
      "Epoch [19/20] Batch 830/938 Loss D: 0.3342, Loss G: 1.4884\n",
      "Epoch [19/20] Batch 840/938 Loss D: 0.2850, Loss G: 1.6974\n",
      "Epoch [19/20] Batch 850/938 Loss D: 0.3110, Loss G: 1.6015\n",
      "Epoch [19/20] Batch 860/938 Loss D: 0.3453, Loss G: 1.8825\n",
      "Epoch [19/20] Batch 870/938 Loss D: 0.2854, Loss G: 1.7555\n",
      "Epoch [19/20] Batch 880/938 Loss D: 0.3219, Loss G: 1.4857\n",
      "Epoch [19/20] Batch 890/938 Loss D: 0.3749, Loss G: 1.4266\n",
      "Epoch [19/20] Batch 900/938 Loss D: 0.3440, Loss G: 1.6130\n",
      "Epoch [19/20] Batch 910/938 Loss D: 0.2556, Loss G: 1.6954\n",
      "Epoch [19/20] Batch 920/938 Loss D: 0.2757, Loss G: 1.9660\n",
      "Epoch [19/20] Batch 930/938 Loss D: 0.2835, Loss G: 1.5215\n",
      "Epoch [20/20] Batch 0/938 Loss D: 0.2888, Loss G: 1.8369\n",
      "Epoch [20/20] Batch 10/938 Loss D: 0.3138, Loss G: 1.8550\n",
      "Epoch [20/20] Batch 20/938 Loss D: 0.3218, Loss G: 1.7043\n",
      "Epoch [20/20] Batch 30/938 Loss D: 0.2723, Loss G: 1.8142\n",
      "Epoch [20/20] Batch 40/938 Loss D: 0.2702, Loss G: 1.7172\n",
      "Epoch [20/20] Batch 50/938 Loss D: 0.2880, Loss G: 1.8633\n",
      "Epoch [20/20] Batch 60/938 Loss D: 0.2893, Loss G: 1.8666\n",
      "Epoch [20/20] Batch 70/938 Loss D: 0.3657, Loss G: 1.8286\n",
      "Epoch [20/20] Batch 80/938 Loss D: 0.2979, Loss G: 1.5042\n",
      "Epoch [20/20] Batch 90/938 Loss D: 0.2749, Loss G: 1.9210\n",
      "Epoch [20/20] Batch 100/938 Loss D: 0.3250, Loss G: 1.5647\n",
      "Epoch [20/20] Batch 110/938 Loss D: 0.2474, Loss G: 1.9100\n",
      "Epoch [20/20] Batch 120/938 Loss D: 0.2631, Loss G: 1.7253\n",
      "Epoch [20/20] Batch 130/938 Loss D: 0.3034, Loss G: 1.5347\n",
      "Epoch [20/20] Batch 140/938 Loss D: 0.2666, Loss G: 1.9437\n",
      "Epoch [20/20] Batch 150/938 Loss D: 0.3703, Loss G: 1.8606\n",
      "Epoch [20/20] Batch 160/938 Loss D: 0.2775, Loss G: 1.5775\n",
      "Epoch [20/20] Batch 170/938 Loss D: 0.2578, Loss G: 1.5878\n",
      "Epoch [20/20] Batch 180/938 Loss D: 0.2625, Loss G: 1.5609\n",
      "Epoch [20/20] Batch 190/938 Loss D: 0.2693, Loss G: 1.8833\n",
      "Epoch [20/20] Batch 200/938 Loss D: 0.3365, Loss G: 1.7016\n",
      "Epoch [20/20] Batch 210/938 Loss D: 0.2940, Loss G: 1.6982\n",
      "Epoch [20/20] Batch 220/938 Loss D: 0.2843, Loss G: 1.5499\n",
      "Epoch [20/20] Batch 230/938 Loss D: 0.2754, Loss G: 1.6933\n",
      "Epoch [20/20] Batch 240/938 Loss D: 0.2668, Loss G: 1.7806\n",
      "Epoch [20/20] Batch 250/938 Loss D: 0.3236, Loss G: 1.8074\n",
      "Epoch [20/20] Batch 260/938 Loss D: 0.3547, Loss G: 1.5777\n",
      "Epoch [20/20] Batch 270/938 Loss D: 0.3669, Loss G: 1.3879\n",
      "Epoch [20/20] Batch 280/938 Loss D: 0.2849, Loss G: 1.7587\n",
      "Epoch [20/20] Batch 290/938 Loss D: 0.3509, Loss G: 1.7609\n",
      "Epoch [20/20] Batch 300/938 Loss D: 0.2604, Loss G: 2.0721\n",
      "Epoch [20/20] Batch 310/938 Loss D: 0.3318, Loss G: 1.3911\n",
      "Epoch [20/20] Batch 320/938 Loss D: 0.2986, Loss G: 1.5380\n",
      "Epoch [20/20] Batch 330/938 Loss D: 0.3578, Loss G: 1.5160\n",
      "Epoch [20/20] Batch 340/938 Loss D: 0.3560, Loss G: 1.9122\n",
      "Epoch [20/20] Batch 350/938 Loss D: 0.3332, Loss G: 1.7652\n",
      "Epoch [20/20] Batch 360/938 Loss D: 0.2651, Loss G: 1.7210\n",
      "Epoch [20/20] Batch 370/938 Loss D: 0.2928, Loss G: 1.6558\n",
      "Epoch [20/20] Batch 380/938 Loss D: 0.2808, Loss G: 1.8904\n",
      "Epoch [20/20] Batch 390/938 Loss D: 0.2929, Loss G: 2.2540\n",
      "Epoch [20/20] Batch 400/938 Loss D: 0.2663, Loss G: 1.7301\n",
      "Epoch [20/20] Batch 410/938 Loss D: 0.3039, Loss G: 1.8507\n",
      "Epoch [20/20] Batch 420/938 Loss D: 0.3317, Loss G: 1.7275\n",
      "Epoch [20/20] Batch 430/938 Loss D: 0.2934, Loss G: 1.7963\n",
      "Epoch [20/20] Batch 440/938 Loss D: 0.3221, Loss G: 1.5092\n",
      "Epoch [20/20] Batch 450/938 Loss D: 0.3164, Loss G: 1.5517\n",
      "Epoch [20/20] Batch 460/938 Loss D: 0.3354, Loss G: 1.6360\n",
      "Epoch [20/20] Batch 470/938 Loss D: 0.2611, Loss G: 1.7009\n",
      "Epoch [20/20] Batch 480/938 Loss D: 0.2660, Loss G: 1.7396\n",
      "Epoch [20/20] Batch 490/938 Loss D: 0.2433, Loss G: 1.8442\n",
      "Epoch [20/20] Batch 500/938 Loss D: 0.3533, Loss G: 1.6915\n",
      "Epoch [20/20] Batch 510/938 Loss D: 0.3224, Loss G: 2.1114\n",
      "Epoch [20/20] Batch 520/938 Loss D: 0.3214, Loss G: 1.7262\n",
      "Epoch [20/20] Batch 530/938 Loss D: 0.2824, Loss G: 1.6826\n",
      "Epoch [20/20] Batch 540/938 Loss D: 0.2750, Loss G: 1.7905\n",
      "Epoch [20/20] Batch 550/938 Loss D: 0.2993, Loss G: 1.8352\n",
      "Epoch [20/20] Batch 560/938 Loss D: 0.2883, Loss G: 1.8546\n",
      "Epoch [20/20] Batch 570/938 Loss D: 0.3196, Loss G: 1.7499\n",
      "Epoch [20/20] Batch 580/938 Loss D: 0.2987, Loss G: 1.7319\n",
      "Epoch [20/20] Batch 590/938 Loss D: 0.2801, Loss G: 1.7197\n",
      "Epoch [20/20] Batch 600/938 Loss D: 0.2916, Loss G: 1.9455\n",
      "Epoch [20/20] Batch 610/938 Loss D: 0.3237, Loss G: 1.6229\n",
      "Epoch [20/20] Batch 620/938 Loss D: 0.2457, Loss G: 2.0746\n",
      "Epoch [20/20] Batch 630/938 Loss D: 0.2871, Loss G: 1.5100\n",
      "Epoch [20/20] Batch 640/938 Loss D: 0.3080, Loss G: 1.6246\n",
      "Epoch [20/20] Batch 650/938 Loss D: 0.2794, Loss G: 1.8663\n",
      "Epoch [20/20] Batch 660/938 Loss D: 0.3152, Loss G: 1.5566\n",
      "Epoch [20/20] Batch 670/938 Loss D: 0.2784, Loss G: 1.6822\n",
      "Epoch [20/20] Batch 680/938 Loss D: 0.2618, Loss G: 1.9962\n",
      "Epoch [20/20] Batch 690/938 Loss D: 0.2828, Loss G: 2.0615\n",
      "Epoch [20/20] Batch 700/938 Loss D: 0.2824, Loss G: 1.9064\n",
      "Epoch [20/20] Batch 710/938 Loss D: 0.3292, Loss G: 1.5294\n",
      "Epoch [20/20] Batch 720/938 Loss D: 0.2763, Loss G: 1.6143\n",
      "Epoch [20/20] Batch 730/938 Loss D: 0.2973, Loss G: 1.5568\n",
      "Epoch [20/20] Batch 740/938 Loss D: 0.3321, Loss G: 1.7346\n",
      "Epoch [20/20] Batch 750/938 Loss D: 0.3431, Loss G: 1.6103\n",
      "Epoch [20/20] Batch 760/938 Loss D: 0.2904, Loss G: 1.8613\n",
      "Epoch [20/20] Batch 770/938 Loss D: 0.3322, Loss G: 1.5426\n",
      "Epoch [20/20] Batch 780/938 Loss D: 0.2702, Loss G: 1.7889\n",
      "Epoch [20/20] Batch 790/938 Loss D: 0.3448, Loss G: 1.7554\n",
      "Epoch [20/20] Batch 800/938 Loss D: 0.3562, Loss G: 1.7791\n",
      "Epoch [20/20] Batch 810/938 Loss D: 0.3169, Loss G: 1.7414\n",
      "Epoch [20/20] Batch 820/938 Loss D: 0.3258, Loss G: 1.9392\n",
      "Epoch [20/20] Batch 830/938 Loss D: 0.3142, Loss G: 1.6843\n",
      "Epoch [20/20] Batch 840/938 Loss D: 0.2495, Loss G: 1.9023\n",
      "Epoch [20/20] Batch 850/938 Loss D: 0.2997, Loss G: 1.9370\n",
      "Epoch [20/20] Batch 860/938 Loss D: 0.2363, Loss G: 1.8780\n",
      "Epoch [20/20] Batch 870/938 Loss D: 0.3578, Loss G: 1.6891\n",
      "Epoch [20/20] Batch 880/938 Loss D: 0.3313, Loss G: 1.8793\n",
      "Epoch [20/20] Batch 890/938 Loss D: 0.2794, Loss G: 1.6767\n",
      "Epoch [20/20] Batch 900/938 Loss D: 0.2778, Loss G: 1.7302\n",
      "Epoch [20/20] Batch 910/938 Loss D: 0.2784, Loss G: 1.6811\n",
      "Epoch [20/20] Batch 920/938 Loss D: 0.2901, Loss G: 1.6904\n",
      "Epoch [20/20] Batch 930/938 Loss D: 0.2531, Loss G: 1.8121\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir # data directory\n",
    "        self.transform = transform #    \n",
    "        self.image_paths = []\n",
    "\n",
    "        for i in range(10):\n",
    "            label_dir = os.path.join(root_dir, str(i))\n",
    "            for img_file in glob.glob(os.path.join(label_dir, '*.png')):\n",
    "                self.image_paths.append(img_file) # data     \n",
    "\n",
    "        print(f'Found {len(self.image_paths)} images')        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index): #   \n",
    "        img_path = self.image_paths[index]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=1, feature_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(z_dim, feature_g*4, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.InstanceNorm2d(feature_g*4)\n",
    "        self.r1 = nn.ReLU(True)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(feature_g*4, feature_g, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.InstanceNorm2d(feature_g)\n",
    "        self.r2 = nn.ReLU(True)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(feature_g, img_channels, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.t = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.r1(self.bn1(self.conv1(x)))\n",
    "        conv1_out = x  #    \n",
    "        x = self.r2(self.bn2(self.conv2(x)))\n",
    "        conv2_out = x  #    \n",
    "        x = self.t(self.conv3(x))\n",
    "        conv3_out = x  #    \n",
    "        return x, conv1_out, conv2_out, conv3_out\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_d=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(img_channels, feature_d, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(feature_d)\n",
    "        self.r1 = nn.LeakyReLU(True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(feature_d, feature_d*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(feature_d*4)\n",
    "        self.r2 = nn.ReLU(True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(feature_d*4, 1, kernel_size=3, stride=2, padding=0, bias=False)\n",
    "        self.t = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.r1(self.bn1(self.conv1(x)))\n",
    "        conv1_out = x  #    \n",
    "        x = self.r2(self.bn2(self.conv2(x)))\n",
    "        conv2_out = x  #    \n",
    "        x = self.t(self.conv3(x))\n",
    "        conv3_out = x  #    \n",
    "        return x, conv1_out, conv2_out, conv3_out\n",
    "\n",
    "\n",
    "data_dir = './data/train/'\n",
    "result_dir = './result/'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 4.  \n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "z_dim = 100\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 20  #   \n",
    "\n",
    "print(f\"Using Device: {device}\")\n",
    "\n",
    "# 5.   \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((16, 16)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# 6.    \n",
    "\n",
    "train_dataset = CustomMNISTDataset(root_dir=data_dir, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# 7.  \n",
    "\n",
    "gen = Generator(z_dim=z_dim, img_channels=1, feature_g=32).to(device)\n",
    "disc = Discriminator(img_channels=1, feature_d=32).to(device)\n",
    "\n",
    "# 8.      \n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "# 9.     \n",
    "\n",
    "def show_generated_images(generator, num_images=64, epoch=0):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_images, z_dim, 1, 1).to(device)  # CNN 4D   \n",
    "        fake_images, conv1_out, conv2_out, conv3_out = generator(noise)\n",
    "        \n",
    "        fake_images = fake_images.cpu()\n",
    "        grid = vutils.make_grid(fake_images, nrow=8, normalize=True)\n",
    "        plt.clf()\n",
    "        plt.imshow(grid.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Generated Images at Epoch {epoch}')\n",
    "        plt.savefig(f'{result_dir}image_normalnormal.png', pad_inches=0.1, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        plt.show\n",
    "    generator.train()\n",
    "\n",
    "# 10. GAN  \n",
    "losses_g = []\n",
    "losses_d = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, real in enumerate(train_dataloader):\n",
    "        real = real.to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        ### (a)   ( )\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
    "        fake, conv1_out_gen, conv2_out_gen, conv3_out_gen = gen(noise)\n",
    "        \n",
    "        #  (1) \n",
    "        disc_real, conv1_out_disc_real, conv2_out_disc_real, conv3_out_disc_real = disc(real)\n",
    "        loss_disc_real = bce_loss(disc_real.view(-1), torch.ones_like(disc_real.view(-1)))\n",
    "\n",
    "        #  (0) \n",
    "        disc_fake, conv1_out_disc_fake, conv2_out_disc_fake, conv3_out_disc_fake = disc(fake.detach())\n",
    "        loss_disc_fake = bce_loss(disc_fake.view(-1), torch.zeros_like(disc_fake.view(-1)))\n",
    "        \n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        opt_disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### (b)   ( )\n",
    "        output, conv1_out_gen, conv2_out_gen, conv3_out_gen = disc(fake)\n",
    "        loss_gen = bce_loss(output.view(-1), torch.ones_like(output.view(-1)))\n",
    "        \n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        losses_g.append(loss_gen.item())\n",
    "        losses_d.append(loss_disc.item())\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Batch {batch_idx}/{len(train_dataloader)} \"\n",
    "                  f\"Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\")\n",
    "            show_generated_images(gen, num_images=16, epoch=epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cpu\n",
      "Found 60000 images\n",
      "Epoch [1/85] Batch 0/938 Loss D: 0.6839, Loss G: 0.7823\n",
      "Epoch [1/85] Batch 10/938 Loss D: 0.4286, Loss G: 1.0740\n",
      "Epoch [1/85] Batch 20/938 Loss D: 0.3256, Loss G: 1.8696\n",
      "Epoch [1/85] Batch 30/938 Loss D: 0.2234, Loss G: 2.2573\n",
      "Epoch [1/85] Batch 40/938 Loss D: 0.1040, Loss G: 2.9401\n",
      "Epoch [1/85] Batch 50/938 Loss D: 0.1247, Loss G: 2.3908\n",
      "Epoch [1/85] Batch 60/938 Loss D: 0.0557, Loss G: 3.3700\n",
      "Epoch [1/85] Batch 70/938 Loss D: 0.0665, Loss G: 3.2769\n",
      "Epoch [1/85] Batch 80/938 Loss D: 0.0705, Loss G: 4.1119\n",
      "Epoch [1/85] Batch 90/938 Loss D: 0.0565, Loss G: 3.1707\n",
      "Epoch [1/85] Batch 100/938 Loss D: 0.0540, Loss G: 3.5522\n",
      "Epoch [1/85] Batch 110/938 Loss D: 0.0924, Loss G: 2.9719\n",
      "Epoch [1/85] Batch 120/938 Loss D: 0.0371, Loss G: 4.5118\n",
      "Epoch [1/85] Batch 130/938 Loss D: 0.0288, Loss G: 4.0343\n",
      "Epoch [1/85] Batch 140/938 Loss D: 0.0212, Loss G: 4.1827\n",
      "Epoch [1/85] Batch 150/938 Loss D: 0.0189, Loss G: 4.1441\n",
      "Epoch [1/85] Batch 160/938 Loss D: 0.0346, Loss G: 3.5810\n",
      "Epoch [1/85] Batch 170/938 Loss D: 0.0220, Loss G: 4.0889\n",
      "Epoch [1/85] Batch 180/938 Loss D: 0.0483, Loss G: 3.2399\n",
      "Epoch [1/85] Batch 190/938 Loss D: 0.0500, Loss G: 4.0087\n",
      "Epoch [1/85] Batch 200/938 Loss D: 0.0547, Loss G: 3.5220\n",
      "Epoch [1/85] Batch 210/938 Loss D: 0.0750, Loss G: 3.5440\n",
      "Epoch [1/85] Batch 220/938 Loss D: 0.0288, Loss G: 4.1771\n",
      "Epoch [1/85] Batch 230/938 Loss D: 0.0190, Loss G: 4.6150\n",
      "Epoch [1/85] Batch 240/938 Loss D: 0.0088, Loss G: 5.3308\n",
      "Epoch [1/85] Batch 250/938 Loss D: 0.0098, Loss G: 4.9468\n",
      "Epoch [1/85] Batch 260/938 Loss D: 0.0161, Loss G: 4.4096\n",
      "Epoch [1/85] Batch 270/938 Loss D: 0.0163, Loss G: 4.4869\n",
      "Epoch [1/85] Batch 280/938 Loss D: 0.0164, Loss G: 4.8215\n",
      "Epoch [1/85] Batch 290/938 Loss D: 0.0212, Loss G: 4.1947\n",
      "Epoch [1/85] Batch 300/938 Loss D: 0.0216, Loss G: 4.4965\n",
      "Epoch [1/85] Batch 310/938 Loss D: 0.0215, Loss G: 4.4247\n",
      "Epoch [1/85] Batch 320/938 Loss D: 0.0168, Loss G: 4.6732\n",
      "Epoch [1/85] Batch 330/938 Loss D: 0.0131, Loss G: 4.9269\n",
      "Epoch [1/85] Batch 340/938 Loss D: 0.0114, Loss G: 4.6797\n",
      "Epoch [1/85] Batch 350/938 Loss D: 0.0173, Loss G: 4.6787\n",
      "Epoch [1/85] Batch 360/938 Loss D: 0.0160, Loss G: 4.6359\n",
      "Epoch [1/85] Batch 370/938 Loss D: 0.0126, Loss G: 5.0630\n",
      "Epoch [1/85] Batch 380/938 Loss D: 0.0169, Loss G: 4.8088\n",
      "Epoch [1/85] Batch 390/938 Loss D: 0.0243, Loss G: 4.7015\n",
      "Epoch [1/85] Batch 400/938 Loss D: 0.0493, Loss G: 4.0107\n",
      "Epoch [1/85] Batch 410/938 Loss D: 0.0401, Loss G: 4.3492\n",
      "Epoch [1/85] Batch 420/938 Loss D: 0.0392, Loss G: 3.9832\n",
      "Epoch [1/85] Batch 430/938 Loss D: 0.0340, Loss G: 4.3282\n",
      "Epoch [1/85] Batch 440/938 Loss D: 0.0233, Loss G: 4.1388\n",
      "Epoch [1/85] Batch 450/938 Loss D: 0.0430, Loss G: 4.6898\n",
      "Epoch [1/85] Batch 460/938 Loss D: 0.1258, Loss G: 3.7503\n",
      "Epoch [1/85] Batch 470/938 Loss D: 0.0438, Loss G: 4.0432\n",
      "Epoch [1/85] Batch 480/938 Loss D: 0.0680, Loss G: 3.4658\n",
      "Epoch [1/85] Batch 490/938 Loss D: 0.0821, Loss G: 3.3535\n",
      "Epoch [1/85] Batch 500/938 Loss D: 0.0925, Loss G: 3.4919\n",
      "Epoch [1/85] Batch 510/938 Loss D: 0.0630, Loss G: 3.7831\n",
      "Epoch [1/85] Batch 520/938 Loss D: 0.0547, Loss G: 4.0226\n",
      "Epoch [1/85] Batch 530/938 Loss D: 0.0474, Loss G: 4.1095\n",
      "Epoch [1/85] Batch 540/938 Loss D: 0.0442, Loss G: 4.5841\n",
      "Epoch [1/85] Batch 550/938 Loss D: 0.0579, Loss G: 4.2846\n",
      "Epoch [1/85] Batch 560/938 Loss D: 0.0505, Loss G: 4.1107\n",
      "Epoch [1/85] Batch 570/938 Loss D: 0.0383, Loss G: 4.2447\n",
      "Epoch [1/85] Batch 580/938 Loss D: 0.0208, Loss G: 4.2504\n",
      "Epoch [1/85] Batch 590/938 Loss D: 0.0400, Loss G: 3.9214\n",
      "Epoch [1/85] Batch 600/938 Loss D: 0.0919, Loss G: 3.4322\n",
      "Epoch [1/85] Batch 610/938 Loss D: 0.0503, Loss G: 4.1738\n",
      "Epoch [1/85] Batch 620/938 Loss D: 0.0450, Loss G: 4.2009\n",
      "Epoch [1/85] Batch 630/938 Loss D: 0.0483, Loss G: 3.8407\n",
      "Epoch [1/85] Batch 640/938 Loss D: 0.0497, Loss G: 3.5694\n",
      "Epoch [1/85] Batch 650/938 Loss D: 0.1565, Loss G: 3.1461\n",
      "Epoch [1/85] Batch 660/938 Loss D: 0.1391, Loss G: 2.8368\n",
      "Epoch [1/85] Batch 670/938 Loss D: 0.0700, Loss G: 3.3565\n",
      "Epoch [1/85] Batch 680/938 Loss D: 0.0816, Loss G: 3.1706\n",
      "Epoch [1/85] Batch 690/938 Loss D: 0.0934, Loss G: 3.4611\n",
      "Epoch [1/85] Batch 700/938 Loss D: 0.1055, Loss G: 3.6103\n",
      "Epoch [1/85] Batch 710/938 Loss D: 0.1242, Loss G: 3.0734\n",
      "Epoch [1/85] Batch 720/938 Loss D: 0.1583, Loss G: 2.3341\n",
      "Epoch [1/85] Batch 730/938 Loss D: 0.0667, Loss G: 3.5692\n",
      "Epoch [1/85] Batch 740/938 Loss D: 0.0663, Loss G: 3.4493\n",
      "Epoch [1/85] Batch 750/938 Loss D: 0.1826, Loss G: 2.7728\n",
      "Epoch [1/85] Batch 760/938 Loss D: 0.1405, Loss G: 2.6493\n",
      "Epoch [1/85] Batch 770/938 Loss D: 0.1760, Loss G: 2.1764\n",
      "Epoch [1/85] Batch 780/938 Loss D: 0.1550, Loss G: 2.7277\n",
      "Epoch [1/85] Batch 790/938 Loss D: 0.1350, Loss G: 3.1184\n",
      "Epoch [1/85] Batch 800/938 Loss D: 0.1447, Loss G: 3.2782\n",
      "Epoch [1/85] Batch 810/938 Loss D: 0.2284, Loss G: 2.7273\n",
      "Epoch [1/85] Batch 820/938 Loss D: 0.2985, Loss G: 1.9282\n",
      "Epoch [1/85] Batch 830/938 Loss D: 0.0635, Loss G: 3.1267\n",
      "Epoch [1/85] Batch 840/938 Loss D: 0.1217, Loss G: 3.6265\n",
      "Epoch [1/85] Batch 850/938 Loss D: 0.1547, Loss G: 3.1365\n",
      "Epoch [1/85] Batch 860/938 Loss D: 0.2287, Loss G: 2.8870\n",
      "Epoch [1/85] Batch 870/938 Loss D: 0.3774, Loss G: 1.5185\n",
      "Epoch [1/85] Batch 880/938 Loss D: 0.1522, Loss G: 2.8606\n",
      "Epoch [1/85] Batch 890/938 Loss D: 0.1942, Loss G: 2.9562\n",
      "Epoch [1/85] Batch 900/938 Loss D: 0.1407, Loss G: 3.0511\n",
      "Epoch [1/85] Batch 910/938 Loss D: 0.0866, Loss G: 3.2738\n",
      "Epoch [1/85] Batch 920/938 Loss D: 0.1014, Loss G: 3.3842\n",
      "Epoch [1/85] Batch 930/938 Loss D: 0.2770, Loss G: 2.0743\n",
      "Epoch [2/85] Batch 0/938 Loss D: 0.4589, Loss G: 1.5677\n",
      "Epoch [2/85] Batch 10/938 Loss D: 0.1445, Loss G: 2.7995\n",
      "Epoch [2/85] Batch 20/938 Loss D: 0.1798, Loss G: 2.4031\n",
      "Epoch [2/85] Batch 30/938 Loss D: 0.1974, Loss G: 2.2212\n",
      "Epoch [2/85] Batch 40/938 Loss D: 0.1994, Loss G: 2.2972\n",
      "Epoch [2/85] Batch 50/938 Loss D: 0.2055, Loss G: 2.3552\n",
      "Epoch [2/85] Batch 60/938 Loss D: 0.2131, Loss G: 2.4203\n",
      "Epoch [2/85] Batch 70/938 Loss D: 0.2308, Loss G: 2.6182\n",
      "Epoch [2/85] Batch 80/938 Loss D: 0.1791, Loss G: 3.0550\n",
      "Epoch [2/85] Batch 90/938 Loss D: 0.3255, Loss G: 2.4559\n",
      "Epoch [2/85] Batch 100/938 Loss D: 0.2314, Loss G: 2.3893\n",
      "Epoch [2/85] Batch 110/938 Loss D: 0.3075, Loss G: 2.4555\n",
      "Epoch [2/85] Batch 120/938 Loss D: 0.1340, Loss G: 3.1465\n",
      "Epoch [2/85] Batch 130/938 Loss D: 0.1423, Loss G: 2.6544\n",
      "Epoch [2/85] Batch 140/938 Loss D: 0.2090, Loss G: 2.6380\n",
      "Epoch [2/85] Batch 150/938 Loss D: 0.2299, Loss G: 2.5296\n",
      "Epoch [2/85] Batch 160/938 Loss D: 0.2505, Loss G: 1.9703\n",
      "Epoch [2/85] Batch 170/938 Loss D: 0.1089, Loss G: 2.4422\n",
      "Epoch [2/85] Batch 180/938 Loss D: 0.0919, Loss G: 2.7255\n",
      "Epoch [2/85] Batch 190/938 Loss D: 0.1645, Loss G: 2.4473\n",
      "Epoch [2/85] Batch 200/938 Loss D: 0.2430, Loss G: 2.3033\n",
      "Epoch [2/85] Batch 210/938 Loss D: 0.2227, Loss G: 2.1917\n",
      "Epoch [2/85] Batch 220/938 Loss D: 0.2533, Loss G: 2.1144\n",
      "Epoch [2/85] Batch 230/938 Loss D: 0.1701, Loss G: 2.3021\n",
      "Epoch [2/85] Batch 240/938 Loss D: 0.2490, Loss G: 2.4065\n",
      "Epoch [2/85] Batch 250/938 Loss D: 0.2693, Loss G: 2.0465\n",
      "Epoch [2/85] Batch 260/938 Loss D: 0.1588, Loss G: 2.5438\n",
      "Epoch [2/85] Batch 270/938 Loss D: 0.2200, Loss G: 1.9850\n",
      "Epoch [2/85] Batch 280/938 Loss D: 0.3716, Loss G: 1.9626\n",
      "Epoch [2/85] Batch 290/938 Loss D: 0.1892, Loss G: 2.4801\n",
      "Epoch [2/85] Batch 300/938 Loss D: 0.1359, Loss G: 2.5046\n",
      "Epoch [2/85] Batch 310/938 Loss D: 0.1272, Loss G: 3.7999\n",
      "Epoch [2/85] Batch 320/938 Loss D: 0.1722, Loss G: 3.1775\n",
      "Epoch [2/85] Batch 330/938 Loss D: 0.2654, Loss G: 2.2832\n",
      "Epoch [2/85] Batch 340/938 Loss D: 0.3440, Loss G: 2.3787\n",
      "Epoch [2/85] Batch 350/938 Loss D: 0.3592, Loss G: 1.9173\n",
      "Epoch [2/85] Batch 360/938 Loss D: 0.2470, Loss G: 1.9871\n",
      "Epoch [2/85] Batch 370/938 Loss D: 0.2259, Loss G: 1.9817\n",
      "Epoch [2/85] Batch 380/938 Loss D: 0.1314, Loss G: 2.5442\n",
      "Epoch [2/85] Batch 390/938 Loss D: 0.1816, Loss G: 2.9744\n",
      "Epoch [2/85] Batch 400/938 Loss D: 0.2396, Loss G: 2.8276\n",
      "Epoch [2/85] Batch 410/938 Loss D: 0.4347, Loss G: 2.6832\n",
      "Epoch [2/85] Batch 420/938 Loss D: 0.1922, Loss G: 3.2031\n",
      "Epoch [2/85] Batch 430/938 Loss D: 0.1987, Loss G: 2.4917\n",
      "Epoch [2/85] Batch 440/938 Loss D: 0.1388, Loss G: 2.3494\n",
      "Epoch [2/85] Batch 450/938 Loss D: 0.2629, Loss G: 2.4511\n",
      "Epoch [2/85] Batch 460/938 Loss D: 0.2205, Loss G: 2.6674\n",
      "Epoch [2/85] Batch 470/938 Loss D: 0.2077, Loss G: 2.1647\n",
      "Epoch [2/85] Batch 480/938 Loss D: 0.1386, Loss G: 2.4977\n",
      "Epoch [2/85] Batch 490/938 Loss D: 0.2420, Loss G: 2.2337\n",
      "Epoch [2/85] Batch 500/938 Loss D: 0.2907, Loss G: 1.7134\n",
      "Epoch [2/85] Batch 510/938 Loss D: 0.3296, Loss G: 1.7362\n",
      "Epoch [2/85] Batch 520/938 Loss D: 0.1449, Loss G: 2.4800\n",
      "Epoch [2/85] Batch 530/938 Loss D: 0.1230, Loss G: 3.1746\n",
      "Epoch [2/85] Batch 540/938 Loss D: 0.2268, Loss G: 2.4742\n",
      "Epoch [2/85] Batch 550/938 Loss D: 0.2966, Loss G: 2.0470\n",
      "Epoch [2/85] Batch 560/938 Loss D: 0.2947, Loss G: 2.7111\n",
      "Epoch [2/85] Batch 570/938 Loss D: 0.4414, Loss G: 1.9678\n",
      "Epoch [2/85] Batch 580/938 Loss D: 0.1722, Loss G: 2.6375\n",
      "Epoch [2/85] Batch 590/938 Loss D: 0.1979, Loss G: 2.8500\n",
      "Epoch [2/85] Batch 600/938 Loss D: 0.1898, Loss G: 2.5037\n",
      "Epoch [2/85] Batch 610/938 Loss D: 0.2330, Loss G: 2.1692\n",
      "Epoch [2/85] Batch 620/938 Loss D: 0.2623, Loss G: 1.7041\n",
      "Epoch [2/85] Batch 630/938 Loss D: 0.1691, Loss G: 2.1291\n",
      "Epoch [2/85] Batch 640/938 Loss D: 0.3186, Loss G: 2.1349\n",
      "Epoch [2/85] Batch 650/938 Loss D: 0.3184, Loss G: 1.8654\n",
      "Epoch [2/85] Batch 660/938 Loss D: 0.1120, Loss G: 3.3577\n",
      "Epoch [2/85] Batch 670/938 Loss D: 0.0605, Loss G: 3.7427\n",
      "Epoch [2/85] Batch 680/938 Loss D: 0.1266, Loss G: 3.0805\n",
      "Epoch [2/85] Batch 690/938 Loss D: 0.2317, Loss G: 2.6947\n",
      "Epoch [2/85] Batch 700/938 Loss D: 0.1828, Loss G: 2.7796\n",
      "Epoch [2/85] Batch 710/938 Loss D: 0.1699, Loss G: 2.4172\n",
      "Epoch [2/85] Batch 720/938 Loss D: 0.1642, Loss G: 2.2171\n",
      "Epoch [2/85] Batch 730/938 Loss D: 0.1889, Loss G: 2.0371\n",
      "Epoch [2/85] Batch 740/938 Loss D: 0.2248, Loss G: 2.0109\n",
      "Epoch [2/85] Batch 750/938 Loss D: 0.1560, Loss G: 2.7738\n",
      "Epoch [2/85] Batch 760/938 Loss D: 0.1984, Loss G: 2.1908\n",
      "Epoch [2/85] Batch 770/938 Loss D: 0.2042, Loss G: 2.2053\n",
      "Epoch [2/85] Batch 780/938 Loss D: 0.1873, Loss G: 2.2983\n",
      "Epoch [2/85] Batch 790/938 Loss D: 0.2690, Loss G: 2.1543\n",
      "Epoch [2/85] Batch 800/938 Loss D: 0.2044, Loss G: 2.9667\n",
      "Epoch [2/85] Batch 810/938 Loss D: 0.2011, Loss G: 2.4760\n",
      "Epoch [2/85] Batch 820/938 Loss D: 0.3222, Loss G: 1.7497\n",
      "Epoch [2/85] Batch 830/938 Loss D: 0.2937, Loss G: 1.7098\n",
      "Epoch [2/85] Batch 840/938 Loss D: 0.2879, Loss G: 1.4361\n",
      "Epoch [2/85] Batch 850/938 Loss D: 0.1747, Loss G: 2.4184\n",
      "Epoch [2/85] Batch 860/938 Loss D: 0.2197, Loss G: 2.8154\n",
      "Epoch [2/85] Batch 870/938 Loss D: 0.2046, Loss G: 2.3662\n",
      "Epoch [2/85] Batch 880/938 Loss D: 0.2376, Loss G: 2.1174\n",
      "Epoch [2/85] Batch 890/938 Loss D: 0.2507, Loss G: 2.0953\n",
      "Epoch [2/85] Batch 900/938 Loss D: 0.2088, Loss G: 2.1896\n",
      "Epoch [2/85] Batch 910/938 Loss D: 0.1908, Loss G: 2.0673\n",
      "Epoch [2/85] Batch 920/938 Loss D: 0.1952, Loss G: 2.3111\n",
      "Epoch [2/85] Batch 930/938 Loss D: 0.2090, Loss G: 1.8794\n",
      "Epoch [3/85] Batch 0/938 Loss D: 0.2000, Loss G: 2.2205\n",
      "Epoch [3/85] Batch 10/938 Loss D: 0.2454, Loss G: 2.3496\n",
      "Epoch [3/85] Batch 20/938 Loss D: 0.2123, Loss G: 2.3953\n",
      "Epoch [3/85] Batch 30/938 Loss D: 0.1623, Loss G: 2.7077\n",
      "Epoch [3/85] Batch 40/938 Loss D: 0.2095, Loss G: 2.5273\n",
      "Epoch [3/85] Batch 50/938 Loss D: 0.1923, Loss G: 2.1723\n",
      "Epoch [3/85] Batch 60/938 Loss D: 0.2018, Loss G: 2.3601\n",
      "Epoch [3/85] Batch 70/938 Loss D: 0.1281, Loss G: 2.8780\n",
      "Epoch [3/85] Batch 80/938 Loss D: 0.2141, Loss G: 2.1435\n",
      "Epoch [3/85] Batch 90/938 Loss D: 0.2480, Loss G: 2.1069\n",
      "Epoch [3/85] Batch 100/938 Loss D: 0.1732, Loss G: 2.3137\n",
      "Epoch [3/85] Batch 110/938 Loss D: 0.2079, Loss G: 2.7720\n",
      "Epoch [3/85] Batch 120/938 Loss D: 0.2502, Loss G: 2.3906\n",
      "Epoch [3/85] Batch 130/938 Loss D: 0.2511, Loss G: 2.6326\n",
      "Epoch [3/85] Batch 140/938 Loss D: 0.1583, Loss G: 2.7937\n",
      "Epoch [3/85] Batch 150/938 Loss D: 0.1225, Loss G: 2.7948\n",
      "Epoch [3/85] Batch 160/938 Loss D: 0.1381, Loss G: 2.8437\n",
      "Epoch [3/85] Batch 170/938 Loss D: 0.2093, Loss G: 2.5851\n",
      "Epoch [3/85] Batch 180/938 Loss D: 0.1270, Loss G: 3.0540\n",
      "Epoch [3/85] Batch 190/938 Loss D: 0.1637, Loss G: 2.8921\n",
      "Epoch [3/85] Batch 200/938 Loss D: 0.1947, Loss G: 2.5501\n",
      "Epoch [3/85] Batch 210/938 Loss D: 0.2378, Loss G: 2.1694\n",
      "Epoch [3/85] Batch 220/938 Loss D: 0.2594, Loss G: 1.9268\n",
      "Epoch [3/85] Batch 230/938 Loss D: 0.1123, Loss G: 3.1478\n",
      "Epoch [3/85] Batch 240/938 Loss D: 0.1765, Loss G: 2.6021\n",
      "Epoch [3/85] Batch 250/938 Loss D: 0.1932, Loss G: 2.4319\n",
      "Epoch [3/85] Batch 260/938 Loss D: 0.1833, Loss G: 2.6851\n",
      "Epoch [3/85] Batch 270/938 Loss D: 0.2556, Loss G: 1.9906\n",
      "Epoch [3/85] Batch 280/938 Loss D: 0.2070, Loss G: 2.3602\n",
      "Epoch [3/85] Batch 290/938 Loss D: 0.3050, Loss G: 2.0570\n",
      "Epoch [3/85] Batch 300/938 Loss D: 0.2654, Loss G: 2.3800\n",
      "Epoch [3/85] Batch 310/938 Loss D: 0.2103, Loss G: 2.2354\n",
      "Epoch [3/85] Batch 320/938 Loss D: 0.2687, Loss G: 1.9445\n",
      "Epoch [3/85] Batch 330/938 Loss D: 0.1964, Loss G: 2.8090\n",
      "Epoch [3/85] Batch 340/938 Loss D: 0.1125, Loss G: 3.3771\n",
      "Epoch [3/85] Batch 350/938 Loss D: 0.2031, Loss G: 2.8623\n",
      "Epoch [3/85] Batch 360/938 Loss D: 0.3204, Loss G: 1.8541\n",
      "Epoch [3/85] Batch 370/938 Loss D: 0.2209, Loss G: 2.5989\n",
      "Epoch [3/85] Batch 380/938 Loss D: 0.1347, Loss G: 2.4545\n",
      "Epoch [3/85] Batch 390/938 Loss D: 0.2008, Loss G: 2.7537\n",
      "Epoch [3/85] Batch 400/938 Loss D: 0.3444, Loss G: 1.6103\n",
      "Epoch [3/85] Batch 410/938 Loss D: 0.3148, Loss G: 1.7119\n",
      "Epoch [3/85] Batch 420/938 Loss D: 0.1666, Loss G: 2.5279\n",
      "Epoch [3/85] Batch 430/938 Loss D: 0.1928, Loss G: 2.3792\n",
      "Epoch [3/85] Batch 440/938 Loss D: 0.1564, Loss G: 2.3012\n",
      "Epoch [3/85] Batch 450/938 Loss D: 0.1384, Loss G: 2.1220\n",
      "Epoch [3/85] Batch 460/938 Loss D: 0.2009, Loss G: 2.0246\n",
      "Epoch [3/85] Batch 470/938 Loss D: 0.3990, Loss G: 1.7072\n",
      "Epoch [3/85] Batch 480/938 Loss D: 0.2053, Loss G: 2.1004\n",
      "Epoch [3/85] Batch 490/938 Loss D: 0.1420, Loss G: 2.8881\n",
      "Epoch [3/85] Batch 500/938 Loss D: 0.1828, Loss G: 2.5138\n",
      "Epoch [3/85] Batch 510/938 Loss D: 0.2287, Loss G: 2.0180\n",
      "Epoch [3/85] Batch 520/938 Loss D: 0.1412, Loss G: 2.7249\n",
      "Epoch [3/85] Batch 530/938 Loss D: 0.1370, Loss G: 2.7534\n",
      "Epoch [3/85] Batch 540/938 Loss D: 0.2473, Loss G: 2.4632\n",
      "Epoch [3/85] Batch 550/938 Loss D: 0.3042, Loss G: 2.1654\n",
      "Epoch [3/85] Batch 560/938 Loss D: 0.2460, Loss G: 1.9846\n",
      "Epoch [3/85] Batch 570/938 Loss D: 0.1841, Loss G: 2.4135\n",
      "Epoch [3/85] Batch 580/938 Loss D: 0.1043, Loss G: 2.8225\n",
      "Epoch [3/85] Batch 590/938 Loss D: 0.1739, Loss G: 2.9006\n",
      "Epoch [3/85] Batch 600/938 Loss D: 0.2557, Loss G: 2.7846\n",
      "Epoch [3/85] Batch 610/938 Loss D: 0.2295, Loss G: 2.5814\n",
      "Epoch [3/85] Batch 620/938 Loss D: 0.2514, Loss G: 2.3775\n",
      "Epoch [3/85] Batch 630/938 Loss D: 0.1978, Loss G: 2.6952\n",
      "Epoch [3/85] Batch 640/938 Loss D: 0.2119, Loss G: 2.5841\n",
      "Epoch [3/85] Batch 650/938 Loss D: 0.1989, Loss G: 2.3953\n",
      "Epoch [3/85] Batch 660/938 Loss D: 0.2710, Loss G: 2.3514\n",
      "Epoch [3/85] Batch 670/938 Loss D: 0.3255, Loss G: 1.9464\n",
      "Epoch [3/85] Batch 680/938 Loss D: 0.2823, Loss G: 1.9801\n",
      "Epoch [3/85] Batch 690/938 Loss D: 0.2585, Loss G: 2.0164\n",
      "Epoch [3/85] Batch 700/938 Loss D: 0.3510, Loss G: 1.6098\n",
      "Epoch [3/85] Batch 710/938 Loss D: 0.2252, Loss G: 2.1773\n",
      "Epoch [3/85] Batch 720/938 Loss D: 0.2231, Loss G: 2.3965\n",
      "Epoch [3/85] Batch 730/938 Loss D: 0.3618, Loss G: 2.5215\n",
      "Epoch [3/85] Batch 740/938 Loss D: 0.2319, Loss G: 2.7189\n",
      "Epoch [3/85] Batch 750/938 Loss D: 0.3029, Loss G: 2.4299\n",
      "Epoch [3/85] Batch 760/938 Loss D: 0.3389, Loss G: 2.5348\n",
      "Epoch [3/85] Batch 770/938 Loss D: 0.1676, Loss G: 3.0181\n",
      "Epoch [3/85] Batch 780/938 Loss D: 0.2481, Loss G: 2.1944\n",
      "Epoch [3/85] Batch 790/938 Loss D: 0.2466, Loss G: 2.3102\n",
      "Epoch [3/85] Batch 800/938 Loss D: 0.2936, Loss G: 1.8477\n",
      "Epoch [3/85] Batch 810/938 Loss D: 0.2681, Loss G: 1.8393\n",
      "Epoch [3/85] Batch 820/938 Loss D: 0.3247, Loss G: 2.0513\n",
      "Epoch [3/85] Batch 830/938 Loss D: 0.2059, Loss G: 2.3644\n",
      "Epoch [3/85] Batch 840/938 Loss D: 0.2815, Loss G: 2.5959\n",
      "Epoch [3/85] Batch 850/938 Loss D: 0.1822, Loss G: 2.5581\n",
      "Epoch [3/85] Batch 860/938 Loss D: 0.2615, Loss G: 2.0976\n",
      "Epoch [3/85] Batch 870/938 Loss D: 0.2276, Loss G: 2.3048\n",
      "Epoch [3/85] Batch 880/938 Loss D: 0.2122, Loss G: 2.3369\n",
      "Epoch [3/85] Batch 890/938 Loss D: 0.1984, Loss G: 2.0392\n",
      "Epoch [3/85] Batch 900/938 Loss D: 0.2264, Loss G: 2.2095\n",
      "Epoch [3/85] Batch 910/938 Loss D: 0.1694, Loss G: 2.7622\n",
      "Epoch [3/85] Batch 920/938 Loss D: 0.2142, Loss G: 2.2763\n",
      "Epoch [3/85] Batch 930/938 Loss D: 0.2503, Loss G: 2.0157\n",
      "Epoch [4/85] Batch 0/938 Loss D: 0.1785, Loss G: 2.2564\n",
      "Epoch [4/85] Batch 10/938 Loss D: 0.2441, Loss G: 1.8484\n",
      "Epoch [4/85] Batch 20/938 Loss D: 0.3438, Loss G: 1.9809\n",
      "Epoch [4/85] Batch 30/938 Loss D: 0.2006, Loss G: 2.4896\n",
      "Epoch [4/85] Batch 40/938 Loss D: 0.2281, Loss G: 2.0760\n",
      "Epoch [4/85] Batch 50/938 Loss D: 0.2523, Loss G: 2.0541\n",
      "Epoch [4/85] Batch 60/938 Loss D: 0.2736, Loss G: 1.7287\n",
      "Epoch [4/85] Batch 70/938 Loss D: 0.2309, Loss G: 2.0840\n",
      "Epoch [4/85] Batch 80/938 Loss D: 0.2816, Loss G: 2.0812\n",
      "Epoch [4/85] Batch 90/938 Loss D: 0.2859, Loss G: 1.8037\n",
      "Epoch [4/85] Batch 100/938 Loss D: 0.2921, Loss G: 1.7512\n",
      "Epoch [4/85] Batch 110/938 Loss D: 0.1867, Loss G: 2.3142\n",
      "Epoch [4/85] Batch 120/938 Loss D: 0.2099, Loss G: 2.3756\n",
      "Epoch [4/85] Batch 130/938 Loss D: 0.2843, Loss G: 2.2451\n",
      "Epoch [4/85] Batch 140/938 Loss D: 0.2708, Loss G: 1.9834\n",
      "Epoch [4/85] Batch 150/938 Loss D: 0.2996, Loss G: 2.1010\n",
      "Epoch [4/85] Batch 160/938 Loss D: 0.2290, Loss G: 2.6604\n",
      "Epoch [4/85] Batch 170/938 Loss D: 0.1859, Loss G: 2.5349\n",
      "Epoch [4/85] Batch 180/938 Loss D: 0.2710, Loss G: 2.5488\n",
      "Epoch [4/85] Batch 190/938 Loss D: 0.3371, Loss G: 1.8435\n",
      "Epoch [4/85] Batch 200/938 Loss D: 0.1302, Loss G: 3.1104\n",
      "Epoch [4/85] Batch 210/938 Loss D: 0.2340, Loss G: 2.6271\n",
      "Epoch [4/85] Batch 220/938 Loss D: 0.3621, Loss G: 1.7875\n",
      "Epoch [4/85] Batch 230/938 Loss D: 0.2963, Loss G: 2.0919\n",
      "Epoch [4/85] Batch 240/938 Loss D: 0.1756, Loss G: 2.4211\n",
      "Epoch [4/85] Batch 250/938 Loss D: 0.2811, Loss G: 2.0170\n",
      "Epoch [4/85] Batch 260/938 Loss D: 0.2932, Loss G: 1.7606\n",
      "Epoch [4/85] Batch 270/938 Loss D: 0.4645, Loss G: 1.8371\n",
      "Epoch [4/85] Batch 280/938 Loss D: 0.2564, Loss G: 2.4824\n",
      "Epoch [4/85] Batch 290/938 Loss D: 0.1801, Loss G: 3.1386\n",
      "Epoch [4/85] Batch 300/938 Loss D: 0.4505, Loss G: 1.6336\n",
      "Epoch [4/85] Batch 310/938 Loss D: 0.4851, Loss G: 2.1652\n",
      "Epoch [4/85] Batch 320/938 Loss D: 0.1812, Loss G: 2.9403\n",
      "Epoch [4/85] Batch 330/938 Loss D: 0.2761, Loss G: 2.7960\n",
      "Epoch [4/85] Batch 340/938 Loss D: 0.5341, Loss G: 2.0256\n",
      "Epoch [4/85] Batch 350/938 Loss D: 0.3078, Loss G: 2.6341\n",
      "Epoch [4/85] Batch 360/938 Loss D: 0.2537, Loss G: 2.3981\n",
      "Epoch [4/85] Batch 370/938 Loss D: 0.2410, Loss G: 2.8888\n",
      "Epoch [4/85] Batch 380/938 Loss D: 0.3610, Loss G: 2.1447\n",
      "Epoch [4/85] Batch 390/938 Loss D: 0.3165, Loss G: 2.8484\n",
      "Epoch [4/85] Batch 400/938 Loss D: 0.2215, Loss G: 3.0307\n",
      "Epoch [4/85] Batch 410/938 Loss D: 0.2155, Loss G: 2.9856\n",
      "Epoch [4/85] Batch 420/938 Loss D: 0.2540, Loss G: 2.4995\n",
      "Epoch [4/85] Batch 430/938 Loss D: 0.1220, Loss G: 2.8374\n",
      "Epoch [4/85] Batch 440/938 Loss D: 0.2154, Loss G: 2.3966\n",
      "Epoch [4/85] Batch 450/938 Loss D: 0.3894, Loss G: 1.6561\n",
      "Epoch [4/85] Batch 460/938 Loss D: 0.2710, Loss G: 2.0913\n",
      "Epoch [4/85] Batch 470/938 Loss D: 0.2446, Loss G: 2.0705\n",
      "Epoch [4/85] Batch 480/938 Loss D: 0.4256, Loss G: 2.1496\n",
      "Epoch [4/85] Batch 490/938 Loss D: 0.3099, Loss G: 2.2657\n",
      "Epoch [4/85] Batch 500/938 Loss D: 0.2017, Loss G: 2.6750\n",
      "Epoch [4/85] Batch 510/938 Loss D: 0.4170, Loss G: 1.6947\n",
      "Epoch [4/85] Batch 520/938 Loss D: 0.3745, Loss G: 1.9532\n",
      "Epoch [4/85] Batch 530/938 Loss D: 0.3706, Loss G: 2.5694\n",
      "Epoch [4/85] Batch 540/938 Loss D: 0.3080, Loss G: 2.3544\n",
      "Epoch [4/85] Batch 550/938 Loss D: 0.4018, Loss G: 2.3410\n",
      "Epoch [4/85] Batch 560/938 Loss D: 0.5113, Loss G: 1.8762\n",
      "Epoch [4/85] Batch 570/938 Loss D: 0.4124, Loss G: 1.9340\n",
      "Epoch [4/85] Batch 580/938 Loss D: 0.2955, Loss G: 2.5851\n",
      "Epoch [4/85] Batch 590/938 Loss D: 0.3000, Loss G: 2.8274\n",
      "Epoch [4/85] Batch 600/938 Loss D: 0.2520, Loss G: 2.1895\n",
      "Epoch [4/85] Batch 610/938 Loss D: 0.3577, Loss G: 2.0475\n",
      "Epoch [4/85] Batch 620/938 Loss D: 0.3139, Loss G: 2.1945\n",
      "Epoch [4/85] Batch 630/938 Loss D: 0.3448, Loss G: 2.3381\n",
      "Epoch [4/85] Batch 640/938 Loss D: 0.3132, Loss G: 2.2433\n",
      "Epoch [4/85] Batch 650/938 Loss D: 0.2778, Loss G: 2.2844\n",
      "Epoch [4/85] Batch 660/938 Loss D: 0.2351, Loss G: 2.3536\n",
      "Epoch [4/85] Batch 670/938 Loss D: 0.3597, Loss G: 2.1601\n",
      "Epoch [4/85] Batch 680/938 Loss D: 0.3473, Loss G: 2.2961\n",
      "Epoch [4/85] Batch 690/938 Loss D: 0.1691, Loss G: 2.4340\n",
      "Epoch [4/85] Batch 700/938 Loss D: 0.2248, Loss G: 2.6121\n",
      "Epoch [4/85] Batch 710/938 Loss D: 0.2495, Loss G: 1.9893\n",
      "Epoch [4/85] Batch 720/938 Loss D: 0.3643, Loss G: 2.2001\n",
      "Epoch [4/85] Batch 730/938 Loss D: 0.2635, Loss G: 2.1537\n",
      "Epoch [4/85] Batch 740/938 Loss D: 0.2847, Loss G: 2.2900\n",
      "Epoch [4/85] Batch 750/938 Loss D: 0.2323, Loss G: 2.3301\n",
      "Epoch [4/85] Batch 760/938 Loss D: 0.3051, Loss G: 2.0037\n",
      "Epoch [4/85] Batch 770/938 Loss D: 0.2628, Loss G: 2.4765\n",
      "Epoch [4/85] Batch 780/938 Loss D: 0.2867, Loss G: 1.9051\n",
      "Epoch [4/85] Batch 790/938 Loss D: 0.2558, Loss G: 2.4153\n",
      "Epoch [4/85] Batch 800/938 Loss D: 0.2595, Loss G: 2.2401\n",
      "Epoch [4/85] Batch 810/938 Loss D: 0.4294, Loss G: 2.0599\n",
      "Epoch [4/85] Batch 820/938 Loss D: 0.4206, Loss G: 2.2081\n",
      "Epoch [4/85] Batch 830/938 Loss D: 0.3388, Loss G: 2.0751\n",
      "Epoch [4/85] Batch 840/938 Loss D: 0.3107, Loss G: 2.0337\n",
      "Epoch [4/85] Batch 850/938 Loss D: 0.4803, Loss G: 1.7645\n",
      "Epoch [4/85] Batch 860/938 Loss D: 0.3674, Loss G: 2.3786\n",
      "Epoch [4/85] Batch 870/938 Loss D: 0.2135, Loss G: 2.4951\n",
      "Epoch [4/85] Batch 880/938 Loss D: 0.3673, Loss G: 1.7840\n",
      "Epoch [4/85] Batch 890/938 Loss D: 0.2987, Loss G: 2.1292\n",
      "Epoch [4/85] Batch 900/938 Loss D: 0.3528, Loss G: 1.8188\n",
      "Epoch [4/85] Batch 910/938 Loss D: 0.3590, Loss G: 1.7712\n",
      "Epoch [4/85] Batch 920/938 Loss D: 0.2608, Loss G: 1.9136\n",
      "Epoch [4/85] Batch 930/938 Loss D: 0.2833, Loss G: 1.7916\n",
      "Epoch [5/85] Batch 0/938 Loss D: 0.5047, Loss G: 2.0526\n",
      "Epoch [5/85] Batch 10/938 Loss D: 0.4065, Loss G: 1.5720\n",
      "Epoch [5/85] Batch 20/938 Loss D: 0.5262, Loss G: 1.6676\n",
      "Epoch [5/85] Batch 30/938 Loss D: 0.4151, Loss G: 2.0307\n",
      "Epoch [5/85] Batch 40/938 Loss D: 0.4577, Loss G: 1.6597\n",
      "Epoch [5/85] Batch 50/938 Loss D: 0.2588, Loss G: 2.3670\n",
      "Epoch [5/85] Batch 60/938 Loss D: 0.4137, Loss G: 1.8088\n",
      "Epoch [5/85] Batch 70/938 Loss D: 0.2881, Loss G: 2.0541\n",
      "Epoch [5/85] Batch 80/938 Loss D: 0.4806, Loss G: 1.2659\n",
      "Epoch [5/85] Batch 90/938 Loss D: 0.4042, Loss G: 1.3707\n",
      "Epoch [5/85] Batch 100/938 Loss D: 0.5079, Loss G: 1.7557\n",
      "Epoch [5/85] Batch 110/938 Loss D: 0.3610, Loss G: 2.4860\n",
      "Epoch [5/85] Batch 120/938 Loss D: 0.2588, Loss G: 2.8660\n",
      "Epoch [5/85] Batch 130/938 Loss D: 0.3042, Loss G: 2.6330\n",
      "Epoch [5/85] Batch 140/938 Loss D: 0.4246, Loss G: 2.1245\n",
      "Epoch [5/85] Batch 150/938 Loss D: 0.3011, Loss G: 2.5439\n",
      "Epoch [5/85] Batch 160/938 Loss D: 0.3379, Loss G: 1.7873\n",
      "Epoch [5/85] Batch 170/938 Loss D: 0.5642, Loss G: 1.4379\n",
      "Epoch [5/85] Batch 180/938 Loss D: 0.3730, Loss G: 2.0190\n",
      "Epoch [5/85] Batch 190/938 Loss D: 0.3242, Loss G: 2.2219\n",
      "Epoch [5/85] Batch 200/938 Loss D: 0.4431, Loss G: 2.0277\n",
      "Epoch [5/85] Batch 210/938 Loss D: 0.3180, Loss G: 2.2010\n",
      "Epoch [5/85] Batch 220/938 Loss D: 0.2560, Loss G: 2.4727\n",
      "Epoch [5/85] Batch 230/938 Loss D: 0.2332, Loss G: 2.1261\n",
      "Epoch [5/85] Batch 240/938 Loss D: 0.3769, Loss G: 1.6792\n",
      "Epoch [5/85] Batch 250/938 Loss D: 0.6040, Loss G: 1.2626\n",
      "Epoch [5/85] Batch 260/938 Loss D: 0.2826, Loss G: 2.4668\n",
      "Epoch [5/85] Batch 270/938 Loss D: 0.2881, Loss G: 2.2744\n",
      "Epoch [5/85] Batch 280/938 Loss D: 0.3044, Loss G: 1.8111\n",
      "Epoch [5/85] Batch 290/938 Loss D: 0.3769, Loss G: 1.9669\n",
      "Epoch [5/85] Batch 300/938 Loss D: 0.5473, Loss G: 1.7087\n",
      "Epoch [5/85] Batch 310/938 Loss D: 0.2271, Loss G: 2.3761\n",
      "Epoch [5/85] Batch 320/938 Loss D: 0.2078, Loss G: 2.3579\n",
      "Epoch [5/85] Batch 330/938 Loss D: 0.2857, Loss G: 2.2923\n",
      "Epoch [5/85] Batch 340/938 Loss D: 0.4435, Loss G: 1.9291\n",
      "Epoch [5/85] Batch 350/938 Loss D: 0.3790, Loss G: 1.8491\n",
      "Epoch [5/85] Batch 360/938 Loss D: 0.3298, Loss G: 1.7152\n",
      "Epoch [5/85] Batch 370/938 Loss D: 0.3299, Loss G: 2.2368\n",
      "Epoch [5/85] Batch 380/938 Loss D: 0.3234, Loss G: 2.2104\n",
      "Epoch [5/85] Batch 390/938 Loss D: 0.3145, Loss G: 2.0944\n",
      "Epoch [5/85] Batch 400/938 Loss D: 0.3173, Loss G: 1.9460\n",
      "Epoch [5/85] Batch 410/938 Loss D: 0.3035, Loss G: 1.7849\n",
      "Epoch [5/85] Batch 420/938 Loss D: 0.3697, Loss G: 1.9383\n",
      "Epoch [5/85] Batch 430/938 Loss D: 0.5340, Loss G: 1.7918\n",
      "Epoch [5/85] Batch 440/938 Loss D: 0.4191, Loss G: 1.6784\n",
      "Epoch [5/85] Batch 450/938 Loss D: 0.3189, Loss G: 2.3460\n",
      "Epoch [5/85] Batch 460/938 Loss D: 0.3513, Loss G: 1.9002\n",
      "Epoch [5/85] Batch 470/938 Loss D: 0.3592, Loss G: 1.6650\n",
      "Epoch [5/85] Batch 480/938 Loss D: 0.5835, Loss G: 1.6573\n",
      "Epoch [5/85] Batch 490/938 Loss D: 0.3930, Loss G: 1.8016\n",
      "Epoch [5/85] Batch 500/938 Loss D: 0.4163, Loss G: 1.8917\n",
      "Epoch [5/85] Batch 510/938 Loss D: 0.4286, Loss G: 1.8013\n",
      "Epoch [5/85] Batch 520/938 Loss D: 0.2144, Loss G: 2.2798\n",
      "Epoch [5/85] Batch 530/938 Loss D: 0.4865, Loss G: 1.4350\n",
      "Epoch [5/85] Batch 540/938 Loss D: 0.4787, Loss G: 1.6343\n",
      "Epoch [5/85] Batch 550/938 Loss D: 0.4607, Loss G: 1.5554\n",
      "Epoch [5/85] Batch 560/938 Loss D: 0.4892, Loss G: 1.7949\n",
      "Epoch [5/85] Batch 570/938 Loss D: 0.3414, Loss G: 1.9510\n",
      "Epoch [5/85] Batch 580/938 Loss D: 0.3418, Loss G: 1.7879\n",
      "Epoch [5/85] Batch 590/938 Loss D: 0.2888, Loss G: 1.9256\n",
      "Epoch [5/85] Batch 600/938 Loss D: 0.3187, Loss G: 1.7197\n",
      "Epoch [5/85] Batch 610/938 Loss D: 0.3814, Loss G: 2.1048\n",
      "Epoch [5/85] Batch 620/938 Loss D: 0.3463, Loss G: 2.1857\n",
      "Epoch [5/85] Batch 630/938 Loss D: 0.2943, Loss G: 2.1168\n",
      "Epoch [5/85] Batch 640/938 Loss D: 0.4133, Loss G: 2.0340\n",
      "Epoch [5/85] Batch 650/938 Loss D: 0.4773, Loss G: 1.7895\n",
      "Epoch [5/85] Batch 660/938 Loss D: 0.2774, Loss G: 2.2423\n",
      "Epoch [5/85] Batch 670/938 Loss D: 0.3616, Loss G: 1.6933\n",
      "Epoch [5/85] Batch 680/938 Loss D: 0.3685, Loss G: 1.6128\n",
      "Epoch [5/85] Batch 690/938 Loss D: 0.4711, Loss G: 1.5957\n",
      "Epoch [5/85] Batch 700/938 Loss D: 0.4747, Loss G: 1.4185\n",
      "Epoch [5/85] Batch 710/938 Loss D: 0.4085, Loss G: 1.7455\n",
      "Epoch [5/85] Batch 720/938 Loss D: 0.3284, Loss G: 2.2660\n",
      "Epoch [5/85] Batch 730/938 Loss D: 0.1943, Loss G: 2.2498\n",
      "Epoch [5/85] Batch 740/938 Loss D: 0.4097, Loss G: 1.7909\n",
      "Epoch [5/85] Batch 750/938 Loss D: 0.3521, Loss G: 1.9787\n",
      "Epoch [5/85] Batch 760/938 Loss D: 0.3514, Loss G: 1.6456\n",
      "Epoch [5/85] Batch 770/938 Loss D: 0.4340, Loss G: 1.6439\n",
      "Epoch [5/85] Batch 780/938 Loss D: 0.4170, Loss G: 1.9566\n",
      "Epoch [5/85] Batch 790/938 Loss D: 0.3070, Loss G: 2.0874\n",
      "Epoch [5/85] Batch 800/938 Loss D: 0.3391, Loss G: 2.0918\n",
      "Epoch [5/85] Batch 810/938 Loss D: 0.2623, Loss G: 2.2609\n",
      "Epoch [5/85] Batch 820/938 Loss D: 0.3255, Loss G: 2.0613\n",
      "Epoch [5/85] Batch 830/938 Loss D: 0.5068, Loss G: 1.5683\n",
      "Epoch [5/85] Batch 840/938 Loss D: 0.3725, Loss G: 1.5211\n",
      "Epoch [5/85] Batch 850/938 Loss D: 0.3465, Loss G: 1.8836\n",
      "Epoch [5/85] Batch 860/938 Loss D: 0.4160, Loss G: 2.5698\n",
      "Epoch [5/85] Batch 870/938 Loss D: 0.3959, Loss G: 2.2669\n",
      "Epoch [5/85] Batch 880/938 Loss D: 0.3679, Loss G: 1.8632\n",
      "Epoch [5/85] Batch 890/938 Loss D: 0.3552, Loss G: 2.2908\n",
      "Epoch [5/85] Batch 900/938 Loss D: 0.2929, Loss G: 2.1215\n",
      "Epoch [5/85] Batch 910/938 Loss D: 0.3744, Loss G: 1.4946\n",
      "Epoch [5/85] Batch 920/938 Loss D: 0.2862, Loss G: 1.8906\n",
      "Epoch [5/85] Batch 930/938 Loss D: 0.3059, Loss G: 2.0419\n",
      "Epoch [6/85] Batch 0/938 Loss D: 0.3456, Loss G: 1.8768\n",
      "Epoch [6/85] Batch 10/938 Loss D: 0.4376, Loss G: 1.4235\n",
      "Epoch [6/85] Batch 20/938 Loss D: 0.4063, Loss G: 1.4636\n",
      "Epoch [6/85] Batch 30/938 Loss D: 0.3341, Loss G: 1.9545\n",
      "Epoch [6/85] Batch 40/938 Loss D: 0.3088, Loss G: 2.1044\n",
      "Epoch [6/85] Batch 50/938 Loss D: 0.4391, Loss G: 1.8046\n",
      "Epoch [6/85] Batch 60/938 Loss D: 0.3747, Loss G: 1.7409\n",
      "Epoch [6/85] Batch 70/938 Loss D: 0.3880, Loss G: 2.0022\n",
      "Epoch [6/85] Batch 80/938 Loss D: 0.3466, Loss G: 1.9198\n",
      "Epoch [6/85] Batch 90/938 Loss D: 0.4585, Loss G: 1.6151\n",
      "Epoch [6/85] Batch 100/938 Loss D: 0.2897, Loss G: 2.0393\n",
      "Epoch [6/85] Batch 110/938 Loss D: 0.3802, Loss G: 1.6864\n",
      "Epoch [6/85] Batch 120/938 Loss D: 0.3334, Loss G: 1.6747\n",
      "Epoch [6/85] Batch 130/938 Loss D: 0.3586, Loss G: 1.8203\n",
      "Epoch [6/85] Batch 140/938 Loss D: 0.3571, Loss G: 1.9526\n",
      "Epoch [6/85] Batch 150/938 Loss D: 0.3439, Loss G: 1.8640\n",
      "Epoch [6/85] Batch 160/938 Loss D: 0.3443, Loss G: 1.7797\n",
      "Epoch [6/85] Batch 170/938 Loss D: 0.3463, Loss G: 1.5248\n",
      "Epoch [6/85] Batch 180/938 Loss D: 0.2345, Loss G: 1.8786\n",
      "Epoch [6/85] Batch 190/938 Loss D: 0.4577, Loss G: 1.6575\n",
      "Epoch [6/85] Batch 200/938 Loss D: 0.2319, Loss G: 2.3650\n",
      "Epoch [6/85] Batch 210/938 Loss D: 0.3546, Loss G: 1.7495\n",
      "Epoch [6/85] Batch 220/938 Loss D: 0.4667, Loss G: 1.5981\n",
      "Epoch [6/85] Batch 230/938 Loss D: 0.3952, Loss G: 2.4009\n",
      "Epoch [6/85] Batch 240/938 Loss D: 0.4283, Loss G: 1.7625\n",
      "Epoch [6/85] Batch 250/938 Loss D: 0.4485, Loss G: 1.5404\n",
      "Epoch [6/85] Batch 260/938 Loss D: 0.2693, Loss G: 1.7457\n",
      "Epoch [6/85] Batch 270/938 Loss D: 0.3706, Loss G: 1.7686\n",
      "Epoch [6/85] Batch 280/938 Loss D: 0.3354, Loss G: 1.9841\n",
      "Epoch [6/85] Batch 290/938 Loss D: 0.2413, Loss G: 2.1067\n",
      "Epoch [6/85] Batch 300/938 Loss D: 0.3012, Loss G: 2.0877\n",
      "Epoch [6/85] Batch 310/938 Loss D: 0.2832, Loss G: 1.7233\n",
      "Epoch [6/85] Batch 320/938 Loss D: 0.3420, Loss G: 1.8161\n",
      "Epoch [6/85] Batch 330/938 Loss D: 0.3248, Loss G: 1.7502\n",
      "Epoch [6/85] Batch 340/938 Loss D: 0.3231, Loss G: 1.8657\n",
      "Epoch [6/85] Batch 350/938 Loss D: 0.4481, Loss G: 1.5781\n",
      "Epoch [6/85] Batch 360/938 Loss D: 0.4164, Loss G: 1.8884\n",
      "Epoch [6/85] Batch 370/938 Loss D: 0.3095, Loss G: 1.9325\n",
      "Epoch [6/85] Batch 380/938 Loss D: 0.3885, Loss G: 1.6061\n",
      "Epoch [6/85] Batch 390/938 Loss D: 0.2287, Loss G: 2.5491\n",
      "Epoch [6/85] Batch 400/938 Loss D: 0.3274, Loss G: 1.6733\n",
      "Epoch [6/85] Batch 410/938 Loss D: 0.3284, Loss G: 1.8954\n",
      "Epoch [6/85] Batch 420/938 Loss D: 0.2308, Loss G: 2.0132\n",
      "Epoch [6/85] Batch 430/938 Loss D: 0.3379, Loss G: 1.4775\n",
      "Epoch [6/85] Batch 440/938 Loss D: 0.2445, Loss G: 1.9618\n",
      "Epoch [6/85] Batch 450/938 Loss D: 0.3007, Loss G: 2.2480\n",
      "Epoch [6/85] Batch 460/938 Loss D: 0.3780, Loss G: 2.0675\n",
      "Epoch [6/85] Batch 470/938 Loss D: 0.3488, Loss G: 1.7652\n",
      "Epoch [6/85] Batch 480/938 Loss D: 0.2921, Loss G: 1.8629\n",
      "Epoch [6/85] Batch 490/938 Loss D: 0.4272, Loss G: 1.5520\n",
      "Epoch [6/85] Batch 500/938 Loss D: 0.3266, Loss G: 1.9435\n",
      "Epoch [6/85] Batch 510/938 Loss D: 0.3618, Loss G: 2.0618\n",
      "Epoch [6/85] Batch 520/938 Loss D: 0.2933, Loss G: 2.0196\n",
      "Epoch [6/85] Batch 530/938 Loss D: 0.2799, Loss G: 1.8772\n",
      "Epoch [6/85] Batch 540/938 Loss D: 0.3578, Loss G: 1.9632\n",
      "Epoch [6/85] Batch 550/938 Loss D: 0.3276, Loss G: 1.5647\n",
      "Epoch [6/85] Batch 560/938 Loss D: 0.3629, Loss G: 1.4916\n",
      "Epoch [6/85] Batch 570/938 Loss D: 0.3271, Loss G: 1.8658\n",
      "Epoch [6/85] Batch 580/938 Loss D: 0.3180, Loss G: 1.5867\n",
      "Epoch [6/85] Batch 590/938 Loss D: 0.4954, Loss G: 1.2163\n",
      "Epoch [6/85] Batch 600/938 Loss D: 0.3679, Loss G: 1.4144\n",
      "Epoch [6/85] Batch 610/938 Loss D: 0.3620, Loss G: 1.4776\n",
      "Epoch [6/85] Batch 620/938 Loss D: 0.3248, Loss G: 1.6584\n",
      "Epoch [6/85] Batch 630/938 Loss D: 0.2980, Loss G: 1.8777\n",
      "Epoch [6/85] Batch 640/938 Loss D: 0.3018, Loss G: 2.0658\n",
      "Epoch [6/85] Batch 650/938 Loss D: 0.3214, Loss G: 1.9981\n",
      "Epoch [6/85] Batch 660/938 Loss D: 0.3033, Loss G: 1.7249\n",
      "Epoch [6/85] Batch 670/938 Loss D: 0.4008, Loss G: 1.4667\n",
      "Epoch [6/85] Batch 680/938 Loss D: 0.3069, Loss G: 1.8055\n",
      "Epoch [6/85] Batch 690/938 Loss D: 0.2966, Loss G: 1.7888\n",
      "Epoch [6/85] Batch 700/938 Loss D: 0.3197, Loss G: 1.6662\n",
      "Epoch [6/85] Batch 710/938 Loss D: 0.2624, Loss G: 2.0090\n",
      "Epoch [6/85] Batch 720/938 Loss D: 0.3080, Loss G: 1.9069\n",
      "Epoch [6/85] Batch 730/938 Loss D: 0.4352, Loss G: 1.5484\n",
      "Epoch [6/85] Batch 740/938 Loss D: 0.3413, Loss G: 1.6257\n",
      "Epoch [6/85] Batch 750/938 Loss D: 0.4094, Loss G: 1.5151\n",
      "Epoch [6/85] Batch 760/938 Loss D: 0.3475, Loss G: 1.9843\n",
      "Epoch [6/85] Batch 770/938 Loss D: 0.3603, Loss G: 1.8006\n",
      "Epoch [6/85] Batch 780/938 Loss D: 0.3620, Loss G: 1.8213\n",
      "Epoch [6/85] Batch 790/938 Loss D: 0.3281, Loss G: 1.6282\n",
      "Epoch [6/85] Batch 800/938 Loss D: 0.2721, Loss G: 1.6125\n",
      "Epoch [6/85] Batch 810/938 Loss D: 0.2886, Loss G: 1.9933\n",
      "Epoch [6/85] Batch 820/938 Loss D: 0.3630, Loss G: 1.9947\n",
      "Epoch [6/85] Batch 830/938 Loss D: 0.3348, Loss G: 1.7369\n",
      "Epoch [6/85] Batch 840/938 Loss D: 0.4283, Loss G: 1.5245\n",
      "Epoch [6/85] Batch 850/938 Loss D: 0.3163, Loss G: 1.9609\n",
      "Epoch [6/85] Batch 860/938 Loss D: 0.3380, Loss G: 1.5572\n",
      "Epoch [6/85] Batch 870/938 Loss D: 0.3838, Loss G: 1.5688\n",
      "Epoch [6/85] Batch 880/938 Loss D: 0.3680, Loss G: 1.8315\n",
      "Epoch [6/85] Batch 890/938 Loss D: 0.3711, Loss G: 1.7128\n",
      "Epoch [6/85] Batch 900/938 Loss D: 0.3348, Loss G: 1.6920\n",
      "Epoch [6/85] Batch 910/938 Loss D: 0.3315, Loss G: 1.6892\n",
      "Epoch [6/85] Batch 920/938 Loss D: 0.2680, Loss G: 1.9581\n",
      "Epoch [6/85] Batch 930/938 Loss D: 0.2693, Loss G: 2.0112\n",
      "Epoch [7/85] Batch 0/938 Loss D: 0.2694, Loss G: 2.0295\n",
      "Epoch [7/85] Batch 10/938 Loss D: 0.3116, Loss G: 1.7473\n",
      "Epoch [7/85] Batch 20/938 Loss D: 0.3665, Loss G: 1.7249\n",
      "Epoch [7/85] Batch 30/938 Loss D: 0.3216, Loss G: 2.0384\n",
      "Epoch [7/85] Batch 40/938 Loss D: 0.3703, Loss G: 1.9699\n",
      "Epoch [7/85] Batch 50/938 Loss D: 0.3210, Loss G: 1.7999\n",
      "Epoch [7/85] Batch 60/938 Loss D: 0.2531, Loss G: 2.1324\n",
      "Epoch [7/85] Batch 70/938 Loss D: 0.4010, Loss G: 1.6113\n",
      "Epoch [7/85] Batch 80/938 Loss D: 0.3124, Loss G: 1.7657\n",
      "Epoch [7/85] Batch 90/938 Loss D: 0.3862, Loss G: 1.8574\n",
      "Epoch [7/85] Batch 100/938 Loss D: 0.3229, Loss G: 1.8648\n",
      "Epoch [7/85] Batch 110/938 Loss D: 0.3467, Loss G: 1.7203\n",
      "Epoch [7/85] Batch 120/938 Loss D: 0.2951, Loss G: 2.0777\n",
      "Epoch [7/85] Batch 130/938 Loss D: 0.2876, Loss G: 1.8893\n",
      "Epoch [7/85] Batch 140/938 Loss D: 0.3760, Loss G: 1.6421\n",
      "Epoch [7/85] Batch 150/938 Loss D: 0.4080, Loss G: 1.7273\n",
      "Epoch [7/85] Batch 160/938 Loss D: 0.3374, Loss G: 1.9802\n",
      "Epoch [7/85] Batch 170/938 Loss D: 0.3054, Loss G: 1.8289\n",
      "Epoch [7/85] Batch 180/938 Loss D: 0.3114, Loss G: 1.8728\n",
      "Epoch [7/85] Batch 190/938 Loss D: 0.4057, Loss G: 1.4707\n",
      "Epoch [7/85] Batch 200/938 Loss D: 0.2666, Loss G: 1.7962\n",
      "Epoch [7/85] Batch 210/938 Loss D: 0.3399, Loss G: 1.8504\n",
      "Epoch [7/85] Batch 220/938 Loss D: 0.2842, Loss G: 2.0674\n",
      "Epoch [7/85] Batch 230/938 Loss D: 0.3634, Loss G: 2.0805\n",
      "Epoch [7/85] Batch 240/938 Loss D: 0.3708, Loss G: 2.1340\n",
      "Epoch [7/85] Batch 250/938 Loss D: 0.3076, Loss G: 1.8244\n",
      "Epoch [7/85] Batch 260/938 Loss D: 0.3139, Loss G: 1.7521\n",
      "Epoch [7/85] Batch 270/938 Loss D: 0.3178, Loss G: 1.9096\n",
      "Epoch [7/85] Batch 280/938 Loss D: 0.3639, Loss G: 1.7275\n",
      "Epoch [7/85] Batch 290/938 Loss D: 0.3707, Loss G: 1.5368\n",
      "Epoch [7/85] Batch 300/938 Loss D: 0.3137, Loss G: 1.8785\n",
      "Epoch [7/85] Batch 310/938 Loss D: 0.2852, Loss G: 2.0415\n",
      "Epoch [7/85] Batch 320/938 Loss D: 0.3078, Loss G: 1.7915\n",
      "Epoch [7/85] Batch 330/938 Loss D: 0.2381, Loss G: 2.0362\n",
      "Epoch [7/85] Batch 340/938 Loss D: 0.3106, Loss G: 2.1087\n",
      "Epoch [7/85] Batch 350/938 Loss D: 0.4271, Loss G: 1.4446\n",
      "Epoch [7/85] Batch 360/938 Loss D: 0.2723, Loss G: 2.0329\n",
      "Epoch [7/85] Batch 370/938 Loss D: 0.3783, Loss G: 1.7944\n",
      "Epoch [7/85] Batch 380/938 Loss D: 0.4179, Loss G: 1.6649\n",
      "Epoch [7/85] Batch 390/938 Loss D: 0.3270, Loss G: 1.9595\n",
      "Epoch [7/85] Batch 400/938 Loss D: 0.3158, Loss G: 2.2274\n",
      "Epoch [7/85] Batch 410/938 Loss D: 0.4006, Loss G: 1.5483\n",
      "Epoch [7/85] Batch 420/938 Loss D: 0.2886, Loss G: 1.9240\n",
      "Epoch [7/85] Batch 430/938 Loss D: 0.2727, Loss G: 1.8944\n",
      "Epoch [7/85] Batch 440/938 Loss D: 0.3490, Loss G: 1.4649\n",
      "Epoch [7/85] Batch 450/938 Loss D: 0.4381, Loss G: 1.3385\n",
      "Epoch [7/85] Batch 460/938 Loss D: 0.2582, Loss G: 1.6516\n",
      "Epoch [7/85] Batch 470/938 Loss D: 0.2225, Loss G: 1.8024\n",
      "Epoch [7/85] Batch 480/938 Loss D: 0.3666, Loss G: 1.5514\n",
      "Epoch [7/85] Batch 490/938 Loss D: 0.2732, Loss G: 2.0397\n",
      "Epoch [7/85] Batch 500/938 Loss D: 0.2765, Loss G: 1.8350\n",
      "Epoch [7/85] Batch 510/938 Loss D: 0.3665, Loss G: 1.7736\n",
      "Epoch [7/85] Batch 520/938 Loss D: 0.2511, Loss G: 2.1815\n",
      "Epoch [7/85] Batch 530/938 Loss D: 0.2997, Loss G: 1.7360\n",
      "Epoch [7/85] Batch 540/938 Loss D: 0.4170, Loss G: 1.5811\n",
      "Epoch [7/85] Batch 550/938 Loss D: 0.3195, Loss G: 2.0112\n",
      "Epoch [7/85] Batch 560/938 Loss D: 0.2275, Loss G: 2.0267\n",
      "Epoch [7/85] Batch 570/938 Loss D: 0.2989, Loss G: 1.8946\n",
      "Epoch [7/85] Batch 580/938 Loss D: 0.3022, Loss G: 1.9512\n",
      "Epoch [7/85] Batch 590/938 Loss D: 0.2342, Loss G: 2.2622\n",
      "Epoch [7/85] Batch 600/938 Loss D: 0.2993, Loss G: 2.0617\n",
      "Epoch [7/85] Batch 610/938 Loss D: 0.3241, Loss G: 1.7192\n",
      "Epoch [7/85] Batch 620/938 Loss D: 0.2608, Loss G: 2.2935\n",
      "Epoch [7/85] Batch 630/938 Loss D: 0.2825, Loss G: 2.1062\n",
      "Epoch [7/85] Batch 640/938 Loss D: 0.3585, Loss G: 1.6813\n",
      "Epoch [7/85] Batch 650/938 Loss D: 0.2376, Loss G: 2.1030\n",
      "Epoch [7/85] Batch 660/938 Loss D: 0.2484, Loss G: 1.9878\n",
      "Epoch [7/85] Batch 670/938 Loss D: 0.3545, Loss G: 1.4799\n",
      "Epoch [7/85] Batch 680/938 Loss D: 0.3597, Loss G: 1.5837\n",
      "Epoch [7/85] Batch 690/938 Loss D: 0.3955, Loss G: 1.3201\n",
      "Epoch [7/85] Batch 700/938 Loss D: 0.3352, Loss G: 1.6018\n",
      "Epoch [7/85] Batch 710/938 Loss D: 0.2693, Loss G: 1.9096\n",
      "Epoch [7/85] Batch 720/938 Loss D: 0.4031, Loss G: 1.8429\n",
      "Epoch [7/85] Batch 730/938 Loss D: 0.3577, Loss G: 1.5212\n",
      "Epoch [7/85] Batch 740/938 Loss D: 0.2709, Loss G: 1.7950\n",
      "Epoch [7/85] Batch 750/938 Loss D: 0.2842, Loss G: 1.9360\n",
      "Epoch [7/85] Batch 760/938 Loss D: 0.3096, Loss G: 1.6625\n",
      "Epoch [7/85] Batch 770/938 Loss D: 0.3022, Loss G: 1.9608\n",
      "Epoch [7/85] Batch 780/938 Loss D: 0.2315, Loss G: 2.0496\n",
      "Epoch [7/85] Batch 790/938 Loss D: 0.2960, Loss G: 1.8759\n",
      "Epoch [7/85] Batch 800/938 Loss D: 0.3048, Loss G: 1.5827\n",
      "Epoch [7/85] Batch 810/938 Loss D: 0.2432, Loss G: 1.9449\n",
      "Epoch [7/85] Batch 820/938 Loss D: 0.3794, Loss G: 1.8816\n",
      "Epoch [7/85] Batch 830/938 Loss D: 0.3359, Loss G: 1.9591\n",
      "Epoch [7/85] Batch 840/938 Loss D: 0.2144, Loss G: 2.4420\n",
      "Epoch [7/85] Batch 850/938 Loss D: 0.2785, Loss G: 2.0326\n",
      "Epoch [7/85] Batch 860/938 Loss D: 0.2969, Loss G: 1.7476\n",
      "Epoch [7/85] Batch 870/938 Loss D: 0.2905, Loss G: 1.9041\n",
      "Epoch [7/85] Batch 880/938 Loss D: 0.3763, Loss G: 1.7207\n",
      "Epoch [7/85] Batch 890/938 Loss D: 0.3247, Loss G: 1.7891\n",
      "Epoch [7/85] Batch 900/938 Loss D: 0.2885, Loss G: 1.9107\n",
      "Epoch [7/85] Batch 910/938 Loss D: 0.2919, Loss G: 2.3160\n",
      "Epoch [7/85] Batch 920/938 Loss D: 0.4027, Loss G: 1.6884\n",
      "Epoch [7/85] Batch 930/938 Loss D: 0.2496, Loss G: 1.9683\n",
      "Epoch [8/85] Batch 0/938 Loss D: 0.2570, Loss G: 1.9089\n",
      "Epoch [8/85] Batch 10/938 Loss D: 0.3336, Loss G: 1.4664\n",
      "Epoch [8/85] Batch 20/938 Loss D: 0.3606, Loss G: 1.9949\n",
      "Epoch [8/85] Batch 30/938 Loss D: 0.1937, Loss G: 2.4284\n",
      "Epoch [8/85] Batch 40/938 Loss D: 0.2991, Loss G: 1.8789\n",
      "Epoch [8/85] Batch 50/938 Loss D: 0.4099, Loss G: 1.6728\n",
      "Epoch [8/85] Batch 60/938 Loss D: 0.2946, Loss G: 2.1944\n",
      "Epoch [8/85] Batch 70/938 Loss D: 0.3514, Loss G: 1.9550\n",
      "Epoch [8/85] Batch 80/938 Loss D: 0.3899, Loss G: 1.7848\n",
      "Epoch [8/85] Batch 90/938 Loss D: 0.2461, Loss G: 2.4673\n",
      "Epoch [8/85] Batch 100/938 Loss D: 0.2702, Loss G: 2.1738\n",
      "Epoch [8/85] Batch 110/938 Loss D: 0.3001, Loss G: 1.9194\n",
      "Epoch [8/85] Batch 120/938 Loss D: 0.3201, Loss G: 1.8641\n",
      "Epoch [8/85] Batch 130/938 Loss D: 0.3101, Loss G: 2.0917\n",
      "Epoch [8/85] Batch 140/938 Loss D: 0.3395, Loss G: 1.6906\n",
      "Epoch [8/85] Batch 150/938 Loss D: 0.2654, Loss G: 2.2474\n",
      "Epoch [8/85] Batch 160/938 Loss D: 0.2586, Loss G: 2.2082\n",
      "Epoch [8/85] Batch 170/938 Loss D: 0.3646, Loss G: 2.0005\n",
      "Epoch [8/85] Batch 180/938 Loss D: 0.2704, Loss G: 1.9967\n",
      "Epoch [8/85] Batch 190/938 Loss D: 0.3182, Loss G: 1.5614\n",
      "Epoch [8/85] Batch 200/938 Loss D: 0.2844, Loss G: 1.9751\n",
      "Epoch [8/85] Batch 210/938 Loss D: 0.3235, Loss G: 2.0224\n",
      "Epoch [8/85] Batch 220/938 Loss D: 0.2467, Loss G: 2.2795\n",
      "Epoch [8/85] Batch 230/938 Loss D: 0.2782, Loss G: 2.3319\n",
      "Epoch [8/85] Batch 240/938 Loss D: 0.2749, Loss G: 1.9024\n",
      "Epoch [8/85] Batch 250/938 Loss D: 0.2764, Loss G: 1.8639\n",
      "Epoch [8/85] Batch 260/938 Loss D: 0.2017, Loss G: 2.1243\n",
      "Epoch [8/85] Batch 270/938 Loss D: 0.3606, Loss G: 1.4327\n",
      "Epoch [8/85] Batch 280/938 Loss D: 0.2750, Loss G: 2.0818\n",
      "Epoch [8/85] Batch 290/938 Loss D: 0.2626, Loss G: 2.0213\n",
      "Epoch [8/85] Batch 300/938 Loss D: 0.3124, Loss G: 1.7218\n",
      "Epoch [8/85] Batch 310/938 Loss D: 0.2682, Loss G: 1.7570\n",
      "Epoch [8/85] Batch 320/938 Loss D: 0.2873, Loss G: 1.8024\n",
      "Epoch [8/85] Batch 330/938 Loss D: 0.3149, Loss G: 1.6390\n",
      "Epoch [8/85] Batch 340/938 Loss D: 0.2457, Loss G: 1.9773\n",
      "Epoch [8/85] Batch 350/938 Loss D: 0.2654, Loss G: 2.0868\n",
      "Epoch [8/85] Batch 360/938 Loss D: 0.4393, Loss G: 1.7268\n",
      "Epoch [8/85] Batch 370/938 Loss D: 0.2891, Loss G: 1.8241\n",
      "Epoch [8/85] Batch 380/938 Loss D: 0.2592, Loss G: 2.4582\n",
      "Epoch [8/85] Batch 390/938 Loss D: 0.3712, Loss G: 1.8665\n",
      "Epoch [8/85] Batch 400/938 Loss D: 0.2727, Loss G: 2.2358\n",
      "Epoch [8/85] Batch 410/938 Loss D: 0.2733, Loss G: 2.0022\n",
      "Epoch [8/85] Batch 420/938 Loss D: 0.4053, Loss G: 1.6057\n",
      "Epoch [8/85] Batch 430/938 Loss D: 0.3448, Loss G: 1.8107\n",
      "Epoch [8/85] Batch 440/938 Loss D: 0.1464, Loss G: 2.4786\n",
      "Epoch [8/85] Batch 450/938 Loss D: 0.3181, Loss G: 1.5680\n",
      "Epoch [8/85] Batch 460/938 Loss D: 0.2788, Loss G: 1.8164\n",
      "Epoch [8/85] Batch 470/938 Loss D: 0.3365, Loss G: 1.7400\n",
      "Epoch [8/85] Batch 480/938 Loss D: 0.3650, Loss G: 1.7148\n",
      "Epoch [8/85] Batch 490/938 Loss D: 0.2248, Loss G: 1.8415\n",
      "Epoch [8/85] Batch 500/938 Loss D: 0.2246, Loss G: 1.8821\n",
      "Epoch [8/85] Batch 510/938 Loss D: 0.4006, Loss G: 1.6024\n",
      "Epoch [8/85] Batch 520/938 Loss D: 0.2451, Loss G: 2.3796\n",
      "Epoch [8/85] Batch 530/938 Loss D: 0.1998, Loss G: 2.1767\n",
      "Epoch [8/85] Batch 540/938 Loss D: 0.4062, Loss G: 1.6822\n",
      "Epoch [8/85] Batch 550/938 Loss D: 0.3111, Loss G: 1.9721\n",
      "Epoch [8/85] Batch 560/938 Loss D: 0.2950, Loss G: 1.9082\n",
      "Epoch [8/85] Batch 570/938 Loss D: 0.3059, Loss G: 1.8620\n",
      "Epoch [8/85] Batch 580/938 Loss D: 0.2769, Loss G: 1.8673\n",
      "Epoch [8/85] Batch 590/938 Loss D: 0.2186, Loss G: 2.2051\n",
      "Epoch [8/85] Batch 600/938 Loss D: 0.2974, Loss G: 1.7514\n",
      "Epoch [8/85] Batch 610/938 Loss D: 0.3755, Loss G: 1.4210\n",
      "Epoch [8/85] Batch 620/938 Loss D: 0.3712, Loss G: 1.9698\n",
      "Epoch [8/85] Batch 630/938 Loss D: 0.3200, Loss G: 2.1595\n",
      "Epoch [8/85] Batch 640/938 Loss D: 0.2906, Loss G: 2.0992\n",
      "Epoch [8/85] Batch 650/938 Loss D: 0.2127, Loss G: 2.2443\n",
      "Epoch [8/85] Batch 660/938 Loss D: 0.2736, Loss G: 1.8687\n",
      "Epoch [8/85] Batch 670/938 Loss D: 0.3462, Loss G: 1.5627\n",
      "Epoch [8/85] Batch 680/938 Loss D: 0.3695, Loss G: 2.0269\n",
      "Epoch [8/85] Batch 690/938 Loss D: 0.3140, Loss G: 1.8539\n",
      "Epoch [8/85] Batch 700/938 Loss D: 0.2923, Loss G: 1.8184\n",
      "Epoch [8/85] Batch 710/938 Loss D: 0.2009, Loss G: 2.0778\n",
      "Epoch [8/85] Batch 720/938 Loss D: 0.1726, Loss G: 2.2290\n",
      "Epoch [8/85] Batch 730/938 Loss D: 0.3439, Loss G: 1.7532\n",
      "Epoch [8/85] Batch 740/938 Loss D: 0.3813, Loss G: 1.8255\n",
      "Epoch [8/85] Batch 750/938 Loss D: 0.1808, Loss G: 2.5416\n",
      "Epoch [8/85] Batch 760/938 Loss D: 0.3602, Loss G: 2.0663\n",
      "Epoch [8/85] Batch 770/938 Loss D: 0.3550, Loss G: 2.0009\n",
      "Epoch [8/85] Batch 780/938 Loss D: 0.1770, Loss G: 2.9058\n",
      "Epoch [8/85] Batch 790/938 Loss D: 0.3116, Loss G: 1.7189\n",
      "Epoch [8/85] Batch 800/938 Loss D: 0.3908, Loss G: 1.5295\n",
      "Epoch [8/85] Batch 810/938 Loss D: 0.2431, Loss G: 1.8787\n",
      "Epoch [8/85] Batch 820/938 Loss D: 0.2680, Loss G: 1.6683\n",
      "Epoch [8/85] Batch 830/938 Loss D: 0.3776, Loss G: 1.7341\n",
      "Epoch [8/85] Batch 840/938 Loss D: 0.2665, Loss G: 1.9321\n",
      "Epoch [8/85] Batch 850/938 Loss D: 0.3352, Loss G: 1.4944\n",
      "Epoch [8/85] Batch 860/938 Loss D: 0.3099, Loss G: 1.8350\n",
      "Epoch [8/85] Batch 870/938 Loss D: 0.2153, Loss G: 2.3921\n",
      "Epoch [8/85] Batch 880/938 Loss D: 0.3378, Loss G: 1.7993\n",
      "Epoch [8/85] Batch 890/938 Loss D: 0.2587, Loss G: 2.2102\n",
      "Epoch [8/85] Batch 900/938 Loss D: 0.2410, Loss G: 2.2987\n",
      "Epoch [8/85] Batch 910/938 Loss D: 0.3163, Loss G: 2.2508\n",
      "Epoch [8/85] Batch 920/938 Loss D: 0.3464, Loss G: 1.9137\n",
      "Epoch [8/85] Batch 930/938 Loss D: 0.1832, Loss G: 2.5428\n",
      "Epoch [9/85] Batch 0/938 Loss D: 0.2075, Loss G: 1.9996\n",
      "Epoch [9/85] Batch 10/938 Loss D: 0.3328, Loss G: 1.5479\n",
      "Epoch [9/85] Batch 20/938 Loss D: 0.3273, Loss G: 1.6514\n",
      "Epoch [9/85] Batch 30/938 Loss D: 0.2503, Loss G: 2.2967\n",
      "Epoch [9/85] Batch 40/938 Loss D: 0.2623, Loss G: 2.0775\n",
      "Epoch [9/85] Batch 50/938 Loss D: 0.3130, Loss G: 2.0197\n",
      "Epoch [9/85] Batch 60/938 Loss D: 0.2558, Loss G: 2.3120\n",
      "Epoch [9/85] Batch 70/938 Loss D: 0.2092, Loss G: 1.8345\n",
      "Epoch [9/85] Batch 80/938 Loss D: 0.2419, Loss G: 1.7851\n",
      "Epoch [9/85] Batch 90/938 Loss D: 0.2623, Loss G: 1.5073\n",
      "Epoch [9/85] Batch 100/938 Loss D: 0.3114, Loss G: 1.5869\n",
      "Epoch [9/85] Batch 110/938 Loss D: 0.2256, Loss G: 2.4251\n",
      "Epoch [9/85] Batch 120/938 Loss D: 0.3111, Loss G: 1.9932\n",
      "Epoch [9/85] Batch 130/938 Loss D: 0.3164, Loss G: 1.7240\n",
      "Epoch [9/85] Batch 140/938 Loss D: 0.2137, Loss G: 2.1198\n",
      "Epoch [9/85] Batch 150/938 Loss D: 0.2682, Loss G: 2.2299\n",
      "Epoch [9/85] Batch 160/938 Loss D: 0.3064, Loss G: 1.5939\n",
      "Epoch [9/85] Batch 170/938 Loss D: 0.2801, Loss G: 1.8828\n",
      "Epoch [9/85] Batch 180/938 Loss D: 0.2226, Loss G: 2.1094\n",
      "Epoch [9/85] Batch 190/938 Loss D: 0.2253, Loss G: 2.0816\n",
      "Epoch [9/85] Batch 200/938 Loss D: 0.3383, Loss G: 1.4771\n",
      "Epoch [9/85] Batch 210/938 Loss D: 0.2892, Loss G: 1.7655\n",
      "Epoch [9/85] Batch 220/938 Loss D: 0.3435, Loss G: 1.4680\n",
      "Epoch [9/85] Batch 230/938 Loss D: 0.3748, Loss G: 1.2122\n",
      "Epoch [9/85] Batch 240/938 Loss D: 0.2256, Loss G: 1.6173\n",
      "Epoch [9/85] Batch 250/938 Loss D: 0.1948, Loss G: 2.1845\n",
      "Epoch [9/85] Batch 260/938 Loss D: 0.3038, Loss G: 2.0268\n",
      "Epoch [9/85] Batch 270/938 Loss D: 0.2702, Loss G: 2.1325\n",
      "Epoch [9/85] Batch 280/938 Loss D: 0.3025, Loss G: 1.7171\n",
      "Epoch [9/85] Batch 290/938 Loss D: 0.3526, Loss G: 1.6985\n",
      "Epoch [9/85] Batch 300/938 Loss D: 0.2769, Loss G: 1.8384\n",
      "Epoch [9/85] Batch 310/938 Loss D: 0.2998, Loss G: 1.6950\n",
      "Epoch [9/85] Batch 320/938 Loss D: 0.3341, Loss G: 1.7423\n",
      "Epoch [9/85] Batch 330/938 Loss D: 0.2875, Loss G: 2.1697\n",
      "Epoch [9/85] Batch 340/938 Loss D: 0.2211, Loss G: 2.0358\n",
      "Epoch [9/85] Batch 350/938 Loss D: 0.2399, Loss G: 2.0701\n",
      "Epoch [9/85] Batch 360/938 Loss D: 0.2768, Loss G: 1.8689\n",
      "Epoch [9/85] Batch 370/938 Loss D: 0.4061, Loss G: 1.6154\n",
      "Epoch [9/85] Batch 380/938 Loss D: 0.2334, Loss G: 2.1471\n",
      "Epoch [9/85] Batch 390/938 Loss D: 0.2910, Loss G: 1.9396\n",
      "Epoch [9/85] Batch 400/938 Loss D: 0.2929, Loss G: 1.7737\n",
      "Epoch [9/85] Batch 410/938 Loss D: 0.3427, Loss G: 1.8800\n",
      "Epoch [9/85] Batch 420/938 Loss D: 0.2581, Loss G: 2.1390\n",
      "Epoch [9/85] Batch 430/938 Loss D: 0.2804, Loss G: 1.9733\n",
      "Epoch [9/85] Batch 440/938 Loss D: 0.3656, Loss G: 1.5293\n",
      "Epoch [9/85] Batch 450/938 Loss D: 0.2890, Loss G: 1.8145\n",
      "Epoch [9/85] Batch 460/938 Loss D: 0.1999, Loss G: 2.2061\n",
      "Epoch [9/85] Batch 470/938 Loss D: 0.2361, Loss G: 1.8266\n",
      "Epoch [9/85] Batch 480/938 Loss D: 0.2528, Loss G: 2.2258\n",
      "Epoch [9/85] Batch 490/938 Loss D: 0.3184, Loss G: 2.0271\n",
      "Epoch [9/85] Batch 500/938 Loss D: 0.3650, Loss G: 1.6979\n",
      "Epoch [9/85] Batch 510/938 Loss D: 0.2835, Loss G: 1.8060\n",
      "Epoch [9/85] Batch 520/938 Loss D: 0.3215, Loss G: 1.6332\n",
      "Epoch [9/85] Batch 530/938 Loss D: 0.2833, Loss G: 1.7833\n",
      "Epoch [9/85] Batch 540/938 Loss D: 0.2642, Loss G: 1.9487\n",
      "Epoch [9/85] Batch 550/938 Loss D: 0.2525, Loss G: 2.2482\n",
      "Epoch [9/85] Batch 560/938 Loss D: 0.2975, Loss G: 1.9337\n",
      "Epoch [9/85] Batch 570/938 Loss D: 0.3584, Loss G: 2.2483\n",
      "Epoch [9/85] Batch 580/938 Loss D: 0.3815, Loss G: 2.4874\n",
      "Epoch [9/85] Batch 590/938 Loss D: 0.2412, Loss G: 2.1973\n",
      "Epoch [9/85] Batch 600/938 Loss D: 0.2833, Loss G: 2.3852\n",
      "Epoch [9/85] Batch 610/938 Loss D: 0.2709, Loss G: 2.3378\n",
      "Epoch [9/85] Batch 620/938 Loss D: 0.2390, Loss G: 2.3188\n",
      "Epoch [9/85] Batch 630/938 Loss D: 0.2888, Loss G: 1.7288\n",
      "Epoch [9/85] Batch 640/938 Loss D: 0.3114, Loss G: 1.7512\n",
      "Epoch [9/85] Batch 650/938 Loss D: 0.2147, Loss G: 2.1560\n",
      "Epoch [9/85] Batch 660/938 Loss D: 0.3078, Loss G: 2.0032\n",
      "Epoch [9/85] Batch 670/938 Loss D: 0.3132, Loss G: 1.9155\n",
      "Epoch [9/85] Batch 680/938 Loss D: 0.3053, Loss G: 2.0877\n",
      "Epoch [9/85] Batch 690/938 Loss D: 0.1905, Loss G: 2.4573\n",
      "Epoch [9/85] Batch 700/938 Loss D: 0.3681, Loss G: 1.7172\n",
      "Epoch [9/85] Batch 710/938 Loss D: 0.2423, Loss G: 1.7639\n",
      "Epoch [9/85] Batch 720/938 Loss D: 0.3138, Loss G: 2.0303\n",
      "Epoch [9/85] Batch 730/938 Loss D: 0.2571, Loss G: 1.6737\n",
      "Epoch [9/85] Batch 740/938 Loss D: 0.2119, Loss G: 2.2747\n",
      "Epoch [9/85] Batch 750/938 Loss D: 0.2585, Loss G: 2.2501\n",
      "Epoch [9/85] Batch 760/938 Loss D: 0.2300, Loss G: 2.0674\n",
      "Epoch [9/85] Batch 770/938 Loss D: 0.3394, Loss G: 2.5346\n",
      "Epoch [9/85] Batch 780/938 Loss D: 0.2642, Loss G: 2.0775\n",
      "Epoch [9/85] Batch 790/938 Loss D: 0.3008, Loss G: 2.1323\n",
      "Epoch [9/85] Batch 800/938 Loss D: 0.3919, Loss G: 1.6079\n",
      "Epoch [9/85] Batch 810/938 Loss D: 0.1859, Loss G: 2.1825\n",
      "Epoch [9/85] Batch 820/938 Loss D: 0.2166, Loss G: 2.1224\n",
      "Epoch [9/85] Batch 830/938 Loss D: 0.3309, Loss G: 1.4122\n",
      "Epoch [9/85] Batch 840/938 Loss D: 0.2757, Loss G: 2.0046\n",
      "Epoch [9/85] Batch 850/938 Loss D: 0.2595, Loss G: 2.4063\n",
      "Epoch [9/85] Batch 860/938 Loss D: 0.2927, Loss G: 1.9363\n",
      "Epoch [9/85] Batch 870/938 Loss D: 0.3424, Loss G: 1.7617\n",
      "Epoch [9/85] Batch 880/938 Loss D: 0.2021, Loss G: 2.1918\n",
      "Epoch [9/85] Batch 890/938 Loss D: 0.2125, Loss G: 2.0899\n",
      "Epoch [9/85] Batch 900/938 Loss D: 0.2744, Loss G: 1.8552\n",
      "Epoch [9/85] Batch 910/938 Loss D: 0.3177, Loss G: 1.9606\n",
      "Epoch [9/85] Batch 920/938 Loss D: 0.2624, Loss G: 2.0167\n",
      "Epoch [9/85] Batch 930/938 Loss D: 0.2489, Loss G: 2.1262\n",
      "Epoch [10/85] Batch 0/938 Loss D: 0.3050, Loss G: 1.7972\n",
      "Epoch [10/85] Batch 10/938 Loss D: 0.2815, Loss G: 1.6921\n",
      "Epoch [10/85] Batch 20/938 Loss D: 0.2146, Loss G: 2.0998\n",
      "Epoch [10/85] Batch 30/938 Loss D: 0.3762, Loss G: 1.5967\n",
      "Epoch [10/85] Batch 40/938 Loss D: 0.2754, Loss G: 1.9754\n",
      "Epoch [10/85] Batch 50/938 Loss D: 0.2292, Loss G: 2.1237\n",
      "Epoch [10/85] Batch 60/938 Loss D: 0.2105, Loss G: 2.2072\n",
      "Epoch [10/85] Batch 70/938 Loss D: 0.2781, Loss G: 1.8866\n",
      "Epoch [10/85] Batch 80/938 Loss D: 0.2721, Loss G: 1.8755\n",
      "Epoch [10/85] Batch 90/938 Loss D: 0.2244, Loss G: 2.3305\n",
      "Epoch [10/85] Batch 100/938 Loss D: 0.2590, Loss G: 2.2563\n",
      "Epoch [10/85] Batch 110/938 Loss D: 0.2948, Loss G: 2.0933\n",
      "Epoch [10/85] Batch 120/938 Loss D: 0.2581, Loss G: 1.9171\n",
      "Epoch [10/85] Batch 130/938 Loss D: 0.2462, Loss G: 2.0661\n",
      "Epoch [10/85] Batch 140/938 Loss D: 0.2384, Loss G: 2.1562\n",
      "Epoch [10/85] Batch 150/938 Loss D: 0.2789, Loss G: 2.0604\n",
      "Epoch [10/85] Batch 160/938 Loss D: 0.2981, Loss G: 2.0647\n",
      "Epoch [10/85] Batch 170/938 Loss D: 0.2707, Loss G: 1.7463\n",
      "Epoch [10/85] Batch 180/938 Loss D: 0.2302, Loss G: 2.1219\n",
      "Epoch [10/85] Batch 190/938 Loss D: 0.2193, Loss G: 2.4801\n",
      "Epoch [10/85] Batch 200/938 Loss D: 0.3703, Loss G: 1.6615\n",
      "Epoch [10/85] Batch 210/938 Loss D: 0.2780, Loss G: 1.9281\n",
      "Epoch [10/85] Batch 220/938 Loss D: 0.2580, Loss G: 2.4735\n",
      "Epoch [10/85] Batch 230/938 Loss D: 0.3312, Loss G: 2.7032\n",
      "Epoch [10/85] Batch 240/938 Loss D: 0.1916, Loss G: 2.4392\n",
      "Epoch [10/85] Batch 250/938 Loss D: 0.2492, Loss G: 2.1926\n",
      "Epoch [10/85] Batch 260/938 Loss D: 0.2135, Loss G: 1.9453\n",
      "Epoch [10/85] Batch 270/938 Loss D: 0.3080, Loss G: 1.8195\n",
      "Epoch [10/85] Batch 280/938 Loss D: 0.3004, Loss G: 1.7017\n",
      "Epoch [10/85] Batch 290/938 Loss D: 0.2110, Loss G: 1.9963\n",
      "Epoch [10/85] Batch 300/938 Loss D: 0.2852, Loss G: 1.5817\n",
      "Epoch [10/85] Batch 310/938 Loss D: 0.2186, Loss G: 2.3413\n",
      "Epoch [10/85] Batch 320/938 Loss D: 0.2361, Loss G: 2.2607\n",
      "Epoch [10/85] Batch 330/938 Loss D: 0.2903, Loss G: 2.0532\n",
      "Epoch [10/85] Batch 340/938 Loss D: 0.2756, Loss G: 2.2647\n",
      "Epoch [10/85] Batch 350/938 Loss D: 0.2362, Loss G: 2.5571\n",
      "Epoch [10/85] Batch 360/938 Loss D: 0.2620, Loss G: 2.6255\n",
      "Epoch [10/85] Batch 370/938 Loss D: 0.3292, Loss G: 2.3365\n",
      "Epoch [10/85] Batch 380/938 Loss D: 0.4489, Loss G: 1.7436\n",
      "Epoch [10/85] Batch 390/938 Loss D: 0.2049, Loss G: 2.1750\n",
      "Epoch [10/85] Batch 400/938 Loss D: 0.3124, Loss G: 1.9174\n",
      "Epoch [10/85] Batch 410/938 Loss D: 0.3089, Loss G: 2.3669\n",
      "Epoch [10/85] Batch 420/938 Loss D: 0.1906, Loss G: 2.7677\n",
      "Epoch [10/85] Batch 430/938 Loss D: 0.2160, Loss G: 2.2922\n",
      "Epoch [10/85] Batch 440/938 Loss D: 0.3051, Loss G: 2.2545\n",
      "Epoch [10/85] Batch 450/938 Loss D: 0.2680, Loss G: 2.0189\n",
      "Epoch [10/85] Batch 460/938 Loss D: 0.2561, Loss G: 1.9846\n",
      "Epoch [10/85] Batch 470/938 Loss D: 0.2176, Loss G: 2.1354\n",
      "Epoch [10/85] Batch 480/938 Loss D: 0.2893, Loss G: 2.0178\n",
      "Epoch [10/85] Batch 490/938 Loss D: 0.1758, Loss G: 2.1658\n",
      "Epoch [10/85] Batch 500/938 Loss D: 0.3032, Loss G: 2.2816\n",
      "Epoch [10/85] Batch 510/938 Loss D: 0.3174, Loss G: 2.3092\n",
      "Epoch [10/85] Batch 520/938 Loss D: 0.2069, Loss G: 2.3413\n",
      "Epoch [10/85] Batch 530/938 Loss D: 0.2699, Loss G: 1.9238\n",
      "Epoch [10/85] Batch 540/938 Loss D: 0.2683, Loss G: 2.1170\n",
      "Epoch [10/85] Batch 550/938 Loss D: 0.2065, Loss G: 2.3137\n",
      "Epoch [10/85] Batch 560/938 Loss D: 0.2626, Loss G: 2.1876\n",
      "Epoch [10/85] Batch 570/938 Loss D: 0.2794, Loss G: 1.9104\n",
      "Epoch [10/85] Batch 580/938 Loss D: 0.2159, Loss G: 1.9902\n",
      "Epoch [10/85] Batch 590/938 Loss D: 0.2123, Loss G: 2.5383\n",
      "Epoch [10/85] Batch 600/938 Loss D: 0.2823, Loss G: 1.9385\n",
      "Epoch [10/85] Batch 610/938 Loss D: 0.3331, Loss G: 1.5248\n",
      "Epoch [10/85] Batch 620/938 Loss D: 0.2153, Loss G: 2.0870\n",
      "Epoch [10/85] Batch 630/938 Loss D: 0.2463, Loss G: 1.8002\n",
      "Epoch [10/85] Batch 640/938 Loss D: 0.1600, Loss G: 2.5005\n",
      "Epoch [10/85] Batch 650/938 Loss D: 0.2504, Loss G: 2.8056\n",
      "Epoch [10/85] Batch 660/938 Loss D: 0.2596, Loss G: 2.1547\n",
      "Epoch [10/85] Batch 670/938 Loss D: 0.2447, Loss G: 2.2789\n",
      "Epoch [10/85] Batch 680/938 Loss D: 0.1795, Loss G: 2.0968\n",
      "Epoch [10/85] Batch 690/938 Loss D: 0.2354, Loss G: 2.0307\n",
      "Epoch [10/85] Batch 700/938 Loss D: 0.2605, Loss G: 1.6723\n",
      "Epoch [10/85] Batch 710/938 Loss D: 0.2185, Loss G: 2.2910\n",
      "Epoch [10/85] Batch 720/938 Loss D: 0.2745, Loss G: 1.8714\n",
      "Epoch [10/85] Batch 730/938 Loss D: 0.2677, Loss G: 1.5690\n",
      "Epoch [10/85] Batch 740/938 Loss D: 0.2876, Loss G: 1.9693\n",
      "Epoch [10/85] Batch 750/938 Loss D: 0.1885, Loss G: 2.2393\n",
      "Epoch [10/85] Batch 760/938 Loss D: 0.3163, Loss G: 2.0339\n",
      "Epoch [10/85] Batch 770/938 Loss D: 0.2659, Loss G: 1.8465\n",
      "Epoch [10/85] Batch 780/938 Loss D: 0.1871, Loss G: 2.6755\n",
      "Epoch [10/85] Batch 790/938 Loss D: 0.2446, Loss G: 2.4274\n",
      "Epoch [10/85] Batch 800/938 Loss D: 0.2431, Loss G: 2.3006\n",
      "Epoch [10/85] Batch 810/938 Loss D: 0.1717, Loss G: 2.5871\n",
      "Epoch [10/85] Batch 820/938 Loss D: 0.2181, Loss G: 2.0853\n",
      "Epoch [10/85] Batch 830/938 Loss D: 0.3661, Loss G: 1.8944\n",
      "Epoch [10/85] Batch 840/938 Loss D: 0.2344, Loss G: 2.1968\n",
      "Epoch [10/85] Batch 850/938 Loss D: 0.1638, Loss G: 2.4210\n",
      "Epoch [10/85] Batch 860/938 Loss D: 0.2661, Loss G: 2.0888\n",
      "Epoch [10/85] Batch 870/938 Loss D: 0.2354, Loss G: 2.0874\n",
      "Epoch [10/85] Batch 880/938 Loss D: 0.1466, Loss G: 2.5546\n",
      "Epoch [10/85] Batch 890/938 Loss D: 0.2138, Loss G: 2.2500\n",
      "Epoch [10/85] Batch 900/938 Loss D: 0.3118, Loss G: 1.9319\n",
      "Epoch [10/85] Batch 910/938 Loss D: 0.2719, Loss G: 2.2555\n",
      "Epoch [10/85] Batch 920/938 Loss D: 0.2463, Loss G: 2.1850\n",
      "Epoch [10/85] Batch 930/938 Loss D: 0.3491, Loss G: 2.0918\n",
      "Epoch [11/85] Batch 0/938 Loss D: 0.2434, Loss G: 2.5668\n",
      "Epoch [11/85] Batch 10/938 Loss D: 0.2364, Loss G: 2.2340\n",
      "Epoch [11/85] Batch 20/938 Loss D: 0.2999, Loss G: 2.0874\n",
      "Epoch [11/85] Batch 30/938 Loss D: 0.3156, Loss G: 1.9414\n",
      "Epoch [11/85] Batch 40/938 Loss D: 0.2035, Loss G: 2.1811\n",
      "Epoch [11/85] Batch 50/938 Loss D: 0.2283, Loss G: 2.0713\n",
      "Epoch [11/85] Batch 60/938 Loss D: 0.2464, Loss G: 2.1217\n",
      "Epoch [11/85] Batch 70/938 Loss D: 0.1686, Loss G: 2.7086\n",
      "Epoch [11/85] Batch 80/938 Loss D: 0.2338, Loss G: 2.4435\n",
      "Epoch [11/85] Batch 90/938 Loss D: 0.3862, Loss G: 2.2564\n",
      "Epoch [11/85] Batch 100/938 Loss D: 0.2423, Loss G: 2.5517\n",
      "Epoch [11/85] Batch 110/938 Loss D: 0.1888, Loss G: 2.9222\n",
      "Epoch [11/85] Batch 120/938 Loss D: 0.2691, Loss G: 2.2999\n",
      "Epoch [11/85] Batch 130/938 Loss D: 0.2693, Loss G: 2.0525\n",
      "Epoch [11/85] Batch 140/938 Loss D: 0.2595, Loss G: 1.9688\n",
      "Epoch [11/85] Batch 150/938 Loss D: 0.1423, Loss G: 2.7957\n",
      "Epoch [11/85] Batch 160/938 Loss D: 0.2211, Loss G: 2.3190\n",
      "Epoch [11/85] Batch 170/938 Loss D: 0.2890, Loss G: 1.8903\n",
      "Epoch [11/85] Batch 180/938 Loss D: 0.1474, Loss G: 2.6979\n",
      "Epoch [11/85] Batch 190/938 Loss D: 0.2251, Loss G: 2.4469\n",
      "Epoch [11/85] Batch 200/938 Loss D: 0.2713, Loss G: 1.7964\n",
      "Epoch [11/85] Batch 210/938 Loss D: 0.2668, Loss G: 1.7010\n",
      "Epoch [11/85] Batch 220/938 Loss D: 0.1520, Loss G: 2.4914\n",
      "Epoch [11/85] Batch 230/938 Loss D: 0.1894, Loss G: 3.0469\n",
      "Epoch [11/85] Batch 240/938 Loss D: 0.2922, Loss G: 2.4741\n",
      "Epoch [11/85] Batch 250/938 Loss D: 0.2504, Loss G: 2.3635\n",
      "Epoch [11/85] Batch 260/938 Loss D: 0.2316, Loss G: 2.2524\n",
      "Epoch [11/85] Batch 270/938 Loss D: 0.2400, Loss G: 2.1089\n",
      "Epoch [11/85] Batch 280/938 Loss D: 0.2775, Loss G: 1.8599\n",
      "Epoch [11/85] Batch 290/938 Loss D: 0.1863, Loss G: 2.4569\n",
      "Epoch [11/85] Batch 300/938 Loss D: 0.2065, Loss G: 2.7399\n",
      "Epoch [11/85] Batch 310/938 Loss D: 0.2361, Loss G: 2.1194\n",
      "Epoch [11/85] Batch 320/938 Loss D: 0.2649, Loss G: 1.5780\n",
      "Epoch [11/85] Batch 330/938 Loss D: 0.2182, Loss G: 2.0807\n",
      "Epoch [11/85] Batch 340/938 Loss D: 0.2904, Loss G: 2.3851\n",
      "Epoch [11/85] Batch 350/938 Loss D: 0.4293, Loss G: 1.5690\n",
      "Epoch [11/85] Batch 360/938 Loss D: 0.1935, Loss G: 2.0757\n",
      "Epoch [11/85] Batch 370/938 Loss D: 0.1904, Loss G: 2.3724\n",
      "Epoch [11/85] Batch 380/938 Loss D: 0.3789, Loss G: 1.9322\n",
      "Epoch [11/85] Batch 390/938 Loss D: 0.2283, Loss G: 2.1925\n",
      "Epoch [11/85] Batch 400/938 Loss D: 0.1478, Loss G: 3.0953\n",
      "Epoch [11/85] Batch 410/938 Loss D: 0.2371, Loss G: 3.0019\n",
      "Epoch [11/85] Batch 420/938 Loss D: 0.2756, Loss G: 2.2772\n",
      "Epoch [11/85] Batch 430/938 Loss D: 0.1744, Loss G: 2.2263\n",
      "Epoch [11/85] Batch 440/938 Loss D: 0.2821, Loss G: 2.0846\n",
      "Epoch [11/85] Batch 450/938 Loss D: 0.2938, Loss G: 2.2760\n",
      "Epoch [11/85] Batch 460/938 Loss D: 0.2642, Loss G: 2.3626\n",
      "Epoch [11/85] Batch 470/938 Loss D: 0.1713, Loss G: 2.6403\n",
      "Epoch [11/85] Batch 480/938 Loss D: 0.3176, Loss G: 1.7212\n",
      "Epoch [11/85] Batch 490/938 Loss D: 0.2985, Loss G: 1.7538\n",
      "Epoch [11/85] Batch 500/938 Loss D: 0.2657, Loss G: 2.3193\n",
      "Epoch [11/85] Batch 510/938 Loss D: 0.1815, Loss G: 2.3172\n",
      "Epoch [11/85] Batch 520/938 Loss D: 0.3356, Loss G: 1.7702\n",
      "Epoch [11/85] Batch 530/938 Loss D: 0.2515, Loss G: 2.1887\n",
      "Epoch [11/85] Batch 540/938 Loss D: 0.2114, Loss G: 2.3602\n",
      "Epoch [11/85] Batch 550/938 Loss D: 0.2986, Loss G: 2.6031\n",
      "Epoch [11/85] Batch 560/938 Loss D: 0.2437, Loss G: 2.2633\n",
      "Epoch [11/85] Batch 570/938 Loss D: 0.3238, Loss G: 2.2653\n",
      "Epoch [11/85] Batch 580/938 Loss D: 0.2142, Loss G: 2.3349\n",
      "Epoch [11/85] Batch 590/938 Loss D: 0.1883, Loss G: 2.5820\n",
      "Epoch [11/85] Batch 600/938 Loss D: 0.2592, Loss G: 1.8910\n",
      "Epoch [11/85] Batch 610/938 Loss D: 0.1600, Loss G: 2.6653\n",
      "Epoch [11/85] Batch 620/938 Loss D: 0.2578, Loss G: 1.8809\n",
      "Epoch [11/85] Batch 630/938 Loss D: 0.3042, Loss G: 1.8305\n",
      "Epoch [11/85] Batch 640/938 Loss D: 0.2805, Loss G: 2.1615\n",
      "Epoch [11/85] Batch 650/938 Loss D: 0.3375, Loss G: 2.8115\n",
      "Epoch [11/85] Batch 660/938 Loss D: 0.2759, Loss G: 2.4804\n",
      "Epoch [11/85] Batch 670/938 Loss D: 0.3450, Loss G: 1.9059\n",
      "Epoch [11/85] Batch 680/938 Loss D: 0.3816, Loss G: 2.2747\n",
      "Epoch [11/85] Batch 690/938 Loss D: 0.2182, Loss G: 2.3468\n",
      "Epoch [11/85] Batch 700/938 Loss D: 0.3431, Loss G: 2.0945\n",
      "Epoch [11/85] Batch 710/938 Loss D: 0.1812, Loss G: 2.5730\n",
      "Epoch [11/85] Batch 720/938 Loss D: 0.1997, Loss G: 2.4267\n",
      "Epoch [11/85] Batch 730/938 Loss D: 0.2331, Loss G: 2.3117\n",
      "Epoch [11/85] Batch 740/938 Loss D: 0.3162, Loss G: 2.0314\n",
      "Epoch [11/85] Batch 750/938 Loss D: 0.1970, Loss G: 2.3013\n",
      "Epoch [11/85] Batch 760/938 Loss D: 0.2927, Loss G: 2.0703\n",
      "Epoch [11/85] Batch 770/938 Loss D: 0.2524, Loss G: 2.1571\n",
      "Epoch [11/85] Batch 780/938 Loss D: 0.2911, Loss G: 2.1580\n",
      "Epoch [11/85] Batch 790/938 Loss D: 0.2329, Loss G: 2.0719\n",
      "Epoch [11/85] Batch 800/938 Loss D: 0.2654, Loss G: 1.9976\n",
      "Epoch [11/85] Batch 810/938 Loss D: 0.2773, Loss G: 1.9033\n",
      "Epoch [11/85] Batch 820/938 Loss D: 0.2572, Loss G: 2.2003\n",
      "Epoch [11/85] Batch 830/938 Loss D: 0.1947, Loss G: 2.1118\n",
      "Epoch [11/85] Batch 840/938 Loss D: 0.2806, Loss G: 1.8759\n",
      "Epoch [11/85] Batch 850/938 Loss D: 0.3089, Loss G: 1.6440\n",
      "Epoch [11/85] Batch 860/938 Loss D: 0.2539, Loss G: 1.9954\n",
      "Epoch [11/85] Batch 870/938 Loss D: 0.1544, Loss G: 2.3270\n",
      "Epoch [11/85] Batch 880/938 Loss D: 0.2982, Loss G: 1.8874\n",
      "Epoch [11/85] Batch 890/938 Loss D: 0.2793, Loss G: 1.8521\n",
      "Epoch [11/85] Batch 900/938 Loss D: 0.2458, Loss G: 2.2178\n",
      "Epoch [11/85] Batch 910/938 Loss D: 0.1847, Loss G: 2.6746\n",
      "Epoch [11/85] Batch 920/938 Loss D: 0.2945, Loss G: 1.7249\n",
      "Epoch [11/85] Batch 930/938 Loss D: 0.2333, Loss G: 2.3322\n",
      "Epoch [12/85] Batch 0/938 Loss D: 0.2629, Loss G: 2.1612\n",
      "Epoch [12/85] Batch 10/938 Loss D: 0.2204, Loss G: 2.0020\n",
      "Epoch [12/85] Batch 20/938 Loss D: 0.3580, Loss G: 1.7028\n",
      "Epoch [12/85] Batch 30/938 Loss D: 0.1821, Loss G: 1.9894\n",
      "Epoch [12/85] Batch 40/938 Loss D: 0.1835, Loss G: 2.0317\n",
      "Epoch [12/85] Batch 50/938 Loss D: 0.3176, Loss G: 2.2649\n",
      "Epoch [12/85] Batch 60/938 Loss D: 0.1975, Loss G: 2.5881\n",
      "Epoch [12/85] Batch 70/938 Loss D: 0.1956, Loss G: 2.8450\n",
      "Epoch [12/85] Batch 80/938 Loss D: 0.2911, Loss G: 2.0171\n",
      "Epoch [12/85] Batch 90/938 Loss D: 0.3354, Loss G: 2.4549\n",
      "Epoch [12/85] Batch 100/938 Loss D: 0.1725, Loss G: 2.6536\n",
      "Epoch [12/85] Batch 110/938 Loss D: 0.2315, Loss G: 2.3537\n",
      "Epoch [12/85] Batch 120/938 Loss D: 0.3646, Loss G: 1.9124\n",
      "Epoch [12/85] Batch 130/938 Loss D: 0.1632, Loss G: 2.3214\n",
      "Epoch [12/85] Batch 140/938 Loss D: 0.2846, Loss G: 2.0317\n",
      "Epoch [12/85] Batch 150/938 Loss D: 0.2123, Loss G: 2.1246\n",
      "Epoch [12/85] Batch 160/938 Loss D: 0.2386, Loss G: 1.9182\n",
      "Epoch [12/85] Batch 170/938 Loss D: 0.2272, Loss G: 1.8912\n",
      "Epoch [12/85] Batch 180/938 Loss D: 0.1923, Loss G: 2.6818\n",
      "Epoch [12/85] Batch 190/938 Loss D: 0.2468, Loss G: 2.2361\n",
      "Epoch [12/85] Batch 200/938 Loss D: 0.2179, Loss G: 2.1883\n",
      "Epoch [12/85] Batch 210/938 Loss D: 0.2461, Loss G: 2.1781\n",
      "Epoch [12/85] Batch 220/938 Loss D: 0.2226, Loss G: 2.0298\n",
      "Epoch [12/85] Batch 230/938 Loss D: 0.2002, Loss G: 2.1481\n",
      "Epoch [12/85] Batch 240/938 Loss D: 0.2403, Loss G: 2.1755\n",
      "Epoch [12/85] Batch 250/938 Loss D: 0.2645, Loss G: 2.0185\n",
      "Epoch [12/85] Batch 260/938 Loss D: 0.1641, Loss G: 2.3436\n",
      "Epoch [12/85] Batch 270/938 Loss D: 0.2951, Loss G: 2.0113\n",
      "Epoch [12/85] Batch 280/938 Loss D: 0.2094, Loss G: 2.3894\n",
      "Epoch [12/85] Batch 290/938 Loss D: 0.1920, Loss G: 2.4220\n",
      "Epoch [12/85] Batch 300/938 Loss D: 0.2040, Loss G: 2.3855\n",
      "Epoch [12/85] Batch 310/938 Loss D: 0.3526, Loss G: 2.1101\n",
      "Epoch [12/85] Batch 320/938 Loss D: 0.3084, Loss G: 1.9267\n",
      "Epoch [12/85] Batch 330/938 Loss D: 0.2256, Loss G: 2.5265\n",
      "Epoch [12/85] Batch 340/938 Loss D: 0.2923, Loss G: 2.0033\n",
      "Epoch [12/85] Batch 350/938 Loss D: 0.2384, Loss G: 1.8643\n",
      "Epoch [12/85] Batch 360/938 Loss D: 0.1815, Loss G: 2.3098\n",
      "Epoch [12/85] Batch 370/938 Loss D: 0.2792, Loss G: 2.0460\n",
      "Epoch [12/85] Batch 380/938 Loss D: 0.2509, Loss G: 2.1378\n",
      "Epoch [12/85] Batch 390/938 Loss D: 0.2679, Loss G: 2.3012\n",
      "Epoch [12/85] Batch 400/938 Loss D: 0.2020, Loss G: 2.0131\n",
      "Epoch [12/85] Batch 410/938 Loss D: 0.2011, Loss G: 2.2798\n",
      "Epoch [12/85] Batch 420/938 Loss D: 0.2216, Loss G: 2.3472\n",
      "Epoch [12/85] Batch 430/938 Loss D: 0.1841, Loss G: 2.5403\n",
      "Epoch [12/85] Batch 440/938 Loss D: 0.1940, Loss G: 1.8973\n",
      "Epoch [12/85] Batch 450/938 Loss D: 0.2318, Loss G: 1.9744\n",
      "Epoch [12/85] Batch 460/938 Loss D: 0.2451, Loss G: 1.8397\n",
      "Epoch [12/85] Batch 470/938 Loss D: 0.1794, Loss G: 2.2133\n",
      "Epoch [12/85] Batch 480/938 Loss D: 0.1909, Loss G: 1.9512\n",
      "Epoch [12/85] Batch 490/938 Loss D: 0.3257, Loss G: 1.5661\n",
      "Epoch [12/85] Batch 500/938 Loss D: 0.2750, Loss G: 2.1483\n",
      "Epoch [12/85] Batch 510/938 Loss D: 0.2333, Loss G: 2.3540\n",
      "Epoch [12/85] Batch 520/938 Loss D: 0.2234, Loss G: 2.3462\n",
      "Epoch [12/85] Batch 530/938 Loss D: 0.3212, Loss G: 1.7676\n",
      "Epoch [12/85] Batch 540/938 Loss D: 0.1979, Loss G: 2.5076\n",
      "Epoch [12/85] Batch 550/938 Loss D: 0.1584, Loss G: 2.5540\n",
      "Epoch [12/85] Batch 560/938 Loss D: 0.2958, Loss G: 2.3410\n",
      "Epoch [12/85] Batch 570/938 Loss D: 0.2605, Loss G: 1.9853\n",
      "Epoch [12/85] Batch 580/938 Loss D: 0.2064, Loss G: 1.9890\n",
      "Epoch [12/85] Batch 590/938 Loss D: 0.1668, Loss G: 2.3934\n",
      "Epoch [12/85] Batch 600/938 Loss D: 0.2182, Loss G: 2.1717\n",
      "Epoch [12/85] Batch 610/938 Loss D: 0.3187, Loss G: 2.1729\n",
      "Epoch [12/85] Batch 620/938 Loss D: 0.1753, Loss G: 2.4883\n",
      "Epoch [12/85] Batch 630/938 Loss D: 0.4118, Loss G: 1.4174\n",
      "Epoch [12/85] Batch 640/938 Loss D: 0.2699, Loss G: 1.8759\n",
      "Epoch [12/85] Batch 650/938 Loss D: 0.2803, Loss G: 2.1076\n",
      "Epoch [12/85] Batch 660/938 Loss D: 0.2979, Loss G: 1.9711\n",
      "Epoch [12/85] Batch 670/938 Loss D: 0.1870, Loss G: 2.3417\n",
      "Epoch [12/85] Batch 680/938 Loss D: 0.2541, Loss G: 2.3936\n",
      "Epoch [12/85] Batch 690/938 Loss D: 0.3078, Loss G: 2.2300\n",
      "Epoch [12/85] Batch 700/938 Loss D: 0.3320, Loss G: 2.1672\n",
      "Epoch [12/85] Batch 710/938 Loss D: 0.2348, Loss G: 2.2696\n",
      "Epoch [12/85] Batch 720/938 Loss D: 0.2384, Loss G: 2.1498\n",
      "Epoch [12/85] Batch 730/938 Loss D: 0.2774, Loss G: 2.1534\n",
      "Epoch [12/85] Batch 740/938 Loss D: 0.2846, Loss G: 2.0506\n",
      "Epoch [12/85] Batch 750/938 Loss D: 0.2369, Loss G: 2.6423\n",
      "Epoch [12/85] Batch 760/938 Loss D: 0.2461, Loss G: 2.2394\n",
      "Epoch [12/85] Batch 770/938 Loss D: 0.3253, Loss G: 2.0057\n",
      "Epoch [12/85] Batch 780/938 Loss D: 0.1993, Loss G: 2.6276\n",
      "Epoch [12/85] Batch 790/938 Loss D: 0.1724, Loss G: 2.6375\n",
      "Epoch [12/85] Batch 800/938 Loss D: 0.3592, Loss G: 2.0022\n",
      "Epoch [12/85] Batch 810/938 Loss D: 0.2212, Loss G: 2.4962\n",
      "Epoch [12/85] Batch 820/938 Loss D: 0.1526, Loss G: 2.5649\n",
      "Epoch [12/85] Batch 830/938 Loss D: 0.2112, Loss G: 2.5210\n",
      "Epoch [12/85] Batch 840/938 Loss D: 0.2828, Loss G: 2.2402\n",
      "Epoch [12/85] Batch 850/938 Loss D: 0.1383, Loss G: 2.6870\n",
      "Epoch [12/85] Batch 860/938 Loss D: 0.3100, Loss G: 1.9234\n",
      "Epoch [12/85] Batch 870/938 Loss D: 0.3621, Loss G: 1.9473\n",
      "Epoch [12/85] Batch 880/938 Loss D: 0.2075, Loss G: 2.3398\n",
      "Epoch [12/85] Batch 890/938 Loss D: 0.1504, Loss G: 2.8119\n",
      "Epoch [12/85] Batch 900/938 Loss D: 0.3084, Loss G: 1.6895\n",
      "Epoch [12/85] Batch 910/938 Loss D: 0.2053, Loss G: 2.4046\n",
      "Epoch [12/85] Batch 920/938 Loss D: 0.1448, Loss G: 2.7339\n",
      "Epoch [12/85] Batch 930/938 Loss D: 0.3638, Loss G: 1.5871\n",
      "Epoch [13/85] Batch 0/938 Loss D: 0.3515, Loss G: 1.5364\n",
      "Epoch [13/85] Batch 10/938 Loss D: 0.1921, Loss G: 2.0286\n",
      "Epoch [13/85] Batch 20/938 Loss D: 0.1833, Loss G: 2.1274\n",
      "Epoch [13/85] Batch 30/938 Loss D: 0.3212, Loss G: 1.9958\n",
      "Epoch [13/85] Batch 40/938 Loss D: 0.2941, Loss G: 1.7617\n",
      "Epoch [13/85] Batch 50/938 Loss D: 0.1378, Loss G: 2.3149\n",
      "Epoch [13/85] Batch 60/938 Loss D: 0.2244, Loss G: 2.0014\n",
      "Epoch [13/85] Batch 70/938 Loss D: 0.2432, Loss G: 1.9024\n",
      "Epoch [13/85] Batch 80/938 Loss D: 0.3121, Loss G: 1.8199\n",
      "Epoch [13/85] Batch 90/938 Loss D: 0.3564, Loss G: 2.0389\n",
      "Epoch [13/85] Batch 100/938 Loss D: 0.1817, Loss G: 2.3924\n",
      "Epoch [13/85] Batch 110/938 Loss D: 0.2362, Loss G: 2.0209\n",
      "Epoch [13/85] Batch 120/938 Loss D: 0.2176, Loss G: 2.2624\n",
      "Epoch [13/85] Batch 130/938 Loss D: 0.2173, Loss G: 2.4039\n",
      "Epoch [13/85] Batch 140/938 Loss D: 0.2436, Loss G: 2.1513\n",
      "Epoch [13/85] Batch 150/938 Loss D: 0.2676, Loss G: 2.0319\n",
      "Epoch [13/85] Batch 160/938 Loss D: 0.1929, Loss G: 2.3399\n",
      "Epoch [13/85] Batch 170/938 Loss D: 0.2416, Loss G: 1.8668\n",
      "Epoch [13/85] Batch 180/938 Loss D: 0.2558, Loss G: 2.0939\n",
      "Epoch [13/85] Batch 190/938 Loss D: 0.3022, Loss G: 1.7803\n",
      "Epoch [13/85] Batch 200/938 Loss D: 0.1670, Loss G: 2.2804\n",
      "Epoch [13/85] Batch 210/938 Loss D: 0.2315, Loss G: 2.4439\n",
      "Epoch [13/85] Batch 220/938 Loss D: 0.2936, Loss G: 2.3781\n",
      "Epoch [13/85] Batch 230/938 Loss D: 0.2769, Loss G: 2.0946\n",
      "Epoch [13/85] Batch 240/938 Loss D: 0.1991, Loss G: 2.4521\n",
      "Epoch [13/85] Batch 250/938 Loss D: 0.2465, Loss G: 2.6039\n",
      "Epoch [13/85] Batch 260/938 Loss D: 0.2753, Loss G: 2.1801\n",
      "Epoch [13/85] Batch 270/938 Loss D: 0.1874, Loss G: 2.3933\n",
      "Epoch [13/85] Batch 280/938 Loss D: 0.2041, Loss G: 2.4870\n",
      "Epoch [13/85] Batch 290/938 Loss D: 0.1478, Loss G: 2.2181\n",
      "Epoch [13/85] Batch 300/938 Loss D: 0.2408, Loss G: 1.7702\n",
      "Epoch [13/85] Batch 310/938 Loss D: 0.2360, Loss G: 1.9880\n",
      "Epoch [13/85] Batch 320/938 Loss D: 0.2550, Loss G: 2.1350\n",
      "Epoch [13/85] Batch 330/938 Loss D: 0.2254, Loss G: 2.2378\n",
      "Epoch [13/85] Batch 340/938 Loss D: 0.2794, Loss G: 2.1515\n",
      "Epoch [13/85] Batch 350/938 Loss D: 0.2617, Loss G: 2.4138\n",
      "Epoch [13/85] Batch 360/938 Loss D: 0.2205, Loss G: 2.5157\n",
      "Epoch [13/85] Batch 370/938 Loss D: 0.3350, Loss G: 1.9393\n",
      "Epoch [13/85] Batch 380/938 Loss D: 0.2022, Loss G: 2.9096\n",
      "Epoch [13/85] Batch 390/938 Loss D: 0.2172, Loss G: 2.8510\n",
      "Epoch [13/85] Batch 400/938 Loss D: 0.2919, Loss G: 2.2581\n",
      "Epoch [13/85] Batch 410/938 Loss D: 0.1888, Loss G: 2.4805\n",
      "Epoch [13/85] Batch 420/938 Loss D: 0.2869, Loss G: 2.3483\n",
      "Epoch [13/85] Batch 430/938 Loss D: 0.1731, Loss G: 2.3043\n",
      "Epoch [13/85] Batch 440/938 Loss D: 0.3513, Loss G: 1.4115\n",
      "Epoch [13/85] Batch 450/938 Loss D: 0.3045, Loss G: 1.8739\n",
      "Epoch [13/85] Batch 460/938 Loss D: 0.1538, Loss G: 2.6881\n",
      "Epoch [13/85] Batch 470/938 Loss D: 0.1531, Loss G: 2.8371\n",
      "Epoch [13/85] Batch 480/938 Loss D: 0.1763, Loss G: 2.8287\n",
      "Epoch [13/85] Batch 490/938 Loss D: 0.2708, Loss G: 2.3342\n",
      "Epoch [13/85] Batch 500/938 Loss D: 0.1747, Loss G: 2.5718\n",
      "Epoch [13/85] Batch 510/938 Loss D: 0.2356, Loss G: 2.8999\n",
      "Epoch [13/85] Batch 520/938 Loss D: 0.2677, Loss G: 2.5682\n",
      "Epoch [13/85] Batch 530/938 Loss D: 0.2227, Loss G: 2.4083\n",
      "Epoch [13/85] Batch 540/938 Loss D: 0.1987, Loss G: 1.9965\n",
      "Epoch [13/85] Batch 550/938 Loss D: 0.2097, Loss G: 2.0416\n",
      "Epoch [13/85] Batch 560/938 Loss D: 0.2719, Loss G: 2.1633\n",
      "Epoch [13/85] Batch 570/938 Loss D: 0.2369, Loss G: 2.2009\n",
      "Epoch [13/85] Batch 580/938 Loss D: 0.3003, Loss G: 2.2150\n",
      "Epoch [13/85] Batch 590/938 Loss D: 0.2475, Loss G: 2.0173\n",
      "Epoch [13/85] Batch 600/938 Loss D: 0.2201, Loss G: 2.6751\n",
      "Epoch [13/85] Batch 610/938 Loss D: 0.2319, Loss G: 2.3212\n",
      "Epoch [13/85] Batch 620/938 Loss D: 0.2281, Loss G: 2.2926\n",
      "Epoch [13/85] Batch 630/938 Loss D: 0.3919, Loss G: 2.0366\n",
      "Epoch [13/85] Batch 640/938 Loss D: 0.2686, Loss G: 2.5887\n",
      "Epoch [13/85] Batch 650/938 Loss D: 0.1671, Loss G: 2.2464\n",
      "Epoch [13/85] Batch 660/938 Loss D: 0.2360, Loss G: 2.2963\n",
      "Epoch [13/85] Batch 670/938 Loss D: 0.2590, Loss G: 1.9804\n",
      "Epoch [13/85] Batch 680/938 Loss D: 0.3066, Loss G: 1.5674\n",
      "Epoch [13/85] Batch 690/938 Loss D: 0.2780, Loss G: 2.2142\n",
      "Epoch [13/85] Batch 700/938 Loss D: 0.2884, Loss G: 2.0105\n",
      "Epoch [13/85] Batch 710/938 Loss D: 0.1558, Loss G: 2.7676\n",
      "Epoch [13/85] Batch 720/938 Loss D: 0.2987, Loss G: 2.3036\n",
      "Epoch [13/85] Batch 730/938 Loss D: 0.1792, Loss G: 2.8445\n",
      "Epoch [13/85] Batch 740/938 Loss D: 0.2661, Loss G: 2.2035\n",
      "Epoch [13/85] Batch 750/938 Loss D: 0.3249, Loss G: 1.9014\n",
      "Epoch [13/85] Batch 760/938 Loss D: 0.1902, Loss G: 2.3207\n",
      "Epoch [13/85] Batch 770/938 Loss D: 0.3259, Loss G: 1.8418\n",
      "Epoch [13/85] Batch 780/938 Loss D: 0.2283, Loss G: 2.0302\n",
      "Epoch [13/85] Batch 790/938 Loss D: 0.3096, Loss G: 1.8278\n",
      "Epoch [13/85] Batch 800/938 Loss D: 0.2378, Loss G: 2.7214\n",
      "Epoch [13/85] Batch 810/938 Loss D: 0.2743, Loss G: 2.4090\n",
      "Epoch [13/85] Batch 820/938 Loss D: 0.1645, Loss G: 2.6554\n",
      "Epoch [13/85] Batch 830/938 Loss D: 0.2263, Loss G: 2.1261\n",
      "Epoch [13/85] Batch 840/938 Loss D: 0.3125, Loss G: 2.1088\n",
      "Epoch [13/85] Batch 850/938 Loss D: 0.2560, Loss G: 2.2643\n",
      "Epoch [13/85] Batch 860/938 Loss D: 0.1737, Loss G: 2.1816\n",
      "Epoch [13/85] Batch 870/938 Loss D: 0.2068, Loss G: 2.1786\n",
      "Epoch [13/85] Batch 880/938 Loss D: 0.2958, Loss G: 1.6496\n",
      "Epoch [13/85] Batch 890/938 Loss D: 0.2809, Loss G: 2.1134\n",
      "Epoch [13/85] Batch 900/938 Loss D: 0.1656, Loss G: 2.3355\n",
      "Epoch [13/85] Batch 910/938 Loss D: 0.2131, Loss G: 2.4861\n",
      "Epoch [13/85] Batch 920/938 Loss D: 0.3331, Loss G: 1.4369\n",
      "Epoch [13/85] Batch 930/938 Loss D: 0.3270, Loss G: 1.6406\n",
      "Epoch [14/85] Batch 0/938 Loss D: 0.2074, Loss G: 2.0689\n",
      "Epoch [14/85] Batch 10/938 Loss D: 0.2358, Loss G: 1.9871\n",
      "Epoch [14/85] Batch 20/938 Loss D: 0.2716, Loss G: 2.0334\n",
      "Epoch [14/85] Batch 30/938 Loss D: 0.2373, Loss G: 2.0458\n",
      "Epoch [14/85] Batch 40/938 Loss D: 0.2375, Loss G: 2.3961\n",
      "Epoch [14/85] Batch 50/938 Loss D: 0.2577, Loss G: 2.5847\n",
      "Epoch [14/85] Batch 60/938 Loss D: 0.2807, Loss G: 2.2650\n",
      "Epoch [14/85] Batch 70/938 Loss D: 0.1908, Loss G: 2.8429\n",
      "Epoch [14/85] Batch 80/938 Loss D: 0.2380, Loss G: 2.7743\n",
      "Epoch [14/85] Batch 90/938 Loss D: 0.3287, Loss G: 2.5600\n",
      "Epoch [14/85] Batch 100/938 Loss D: 0.3948, Loss G: 2.0498\n",
      "Epoch [14/85] Batch 110/938 Loss D: 0.2030, Loss G: 2.2556\n",
      "Epoch [14/85] Batch 120/938 Loss D: 0.1712, Loss G: 2.3891\n",
      "Epoch [14/85] Batch 130/938 Loss D: 0.2679, Loss G: 1.9208\n",
      "Epoch [14/85] Batch 140/938 Loss D: 0.3528, Loss G: 2.1218\n",
      "Epoch [14/85] Batch 150/938 Loss D: 0.1845, Loss G: 2.6581\n",
      "Epoch [14/85] Batch 160/938 Loss D: 0.2325, Loss G: 2.4949\n",
      "Epoch [14/85] Batch 170/938 Loss D: 0.3886, Loss G: 2.7114\n",
      "Epoch [14/85] Batch 180/938 Loss D: 0.2707, Loss G: 2.8773\n",
      "Epoch [14/85] Batch 190/938 Loss D: 0.2457, Loss G: 2.4917\n",
      "Epoch [14/85] Batch 200/938 Loss D: 0.2262, Loss G: 2.2104\n",
      "Epoch [14/85] Batch 210/938 Loss D: 0.1579, Loss G: 2.7385\n",
      "Epoch [14/85] Batch 220/938 Loss D: 0.2981, Loss G: 2.4797\n",
      "Epoch [14/85] Batch 230/938 Loss D: 0.2869, Loss G: 2.0603\n",
      "Epoch [14/85] Batch 240/938 Loss D: 0.2578, Loss G: 2.4247\n",
      "Epoch [14/85] Batch 250/938 Loss D: 0.1782, Loss G: 2.3900\n",
      "Epoch [14/85] Batch 260/938 Loss D: 0.2464, Loss G: 2.6473\n",
      "Epoch [14/85] Batch 270/938 Loss D: 0.2475, Loss G: 3.0946\n",
      "Epoch [14/85] Batch 280/938 Loss D: 0.2649, Loss G: 2.6351\n",
      "Epoch [14/85] Batch 290/938 Loss D: 0.2880, Loss G: 2.1273\n",
      "Epoch [14/85] Batch 300/938 Loss D: 0.2907, Loss G: 1.8733\n",
      "Epoch [14/85] Batch 310/938 Loss D: 0.1916, Loss G: 2.6403\n",
      "Epoch [14/85] Batch 320/938 Loss D: 0.1800, Loss G: 2.2288\n",
      "Epoch [14/85] Batch 330/938 Loss D: 0.2289, Loss G: 2.0598\n",
      "Epoch [14/85] Batch 340/938 Loss D: 0.1926, Loss G: 2.3955\n",
      "Epoch [14/85] Batch 350/938 Loss D: 0.2008, Loss G: 2.6812\n",
      "Epoch [14/85] Batch 360/938 Loss D: 0.2447, Loss G: 2.0154\n",
      "Epoch [14/85] Batch 370/938 Loss D: 0.1801, Loss G: 2.5876\n",
      "Epoch [14/85] Batch 380/938 Loss D: 0.2616, Loss G: 2.1589\n",
      "Epoch [14/85] Batch 390/938 Loss D: 0.2059, Loss G: 1.9567\n",
      "Epoch [14/85] Batch 400/938 Loss D: 0.1919, Loss G: 2.2382\n",
      "Epoch [14/85] Batch 410/938 Loss D: 0.2366, Loss G: 2.4255\n",
      "Epoch [14/85] Batch 420/938 Loss D: 0.2118, Loss G: 1.9544\n",
      "Epoch [14/85] Batch 430/938 Loss D: 0.2642, Loss G: 2.0412\n",
      "Epoch [14/85] Batch 440/938 Loss D: 0.2532, Loss G: 2.0246\n",
      "Epoch [14/85] Batch 450/938 Loss D: 0.2267, Loss G: 2.5133\n",
      "Epoch [14/85] Batch 460/938 Loss D: 0.2057, Loss G: 2.6380\n",
      "Epoch [14/85] Batch 470/938 Loss D: 0.2819, Loss G: 2.0692\n",
      "Epoch [14/85] Batch 480/938 Loss D: 0.2103, Loss G: 2.2061\n",
      "Epoch [14/85] Batch 490/938 Loss D: 0.2263, Loss G: 2.4578\n",
      "Epoch [14/85] Batch 500/938 Loss D: 0.2105, Loss G: 2.2968\n",
      "Epoch [14/85] Batch 510/938 Loss D: 0.1946, Loss G: 2.1382\n",
      "Epoch [14/85] Batch 520/938 Loss D: 0.2368, Loss G: 2.1191\n",
      "Epoch [14/85] Batch 530/938 Loss D: 0.2455, Loss G: 2.7018\n",
      "Epoch [14/85] Batch 540/938 Loss D: 0.2331, Loss G: 1.9234\n",
      "Epoch [14/85] Batch 550/938 Loss D: 0.2772, Loss G: 1.8543\n",
      "Epoch [14/85] Batch 560/938 Loss D: 0.2999, Loss G: 1.9553\n",
      "Epoch [14/85] Batch 570/938 Loss D: 0.2667, Loss G: 2.3041\n",
      "Epoch [14/85] Batch 580/938 Loss D: 0.3092, Loss G: 1.9298\n",
      "Epoch [14/85] Batch 590/938 Loss D: 0.4183, Loss G: 2.4670\n",
      "Epoch [14/85] Batch 600/938 Loss D: 0.2390, Loss G: 2.6609\n",
      "Epoch [14/85] Batch 610/938 Loss D: 0.2436, Loss G: 2.2090\n",
      "Epoch [14/85] Batch 620/938 Loss D: 0.2487, Loss G: 2.3667\n",
      "Epoch [14/85] Batch 630/938 Loss D: 0.2363, Loss G: 2.6627\n",
      "Epoch [14/85] Batch 640/938 Loss D: 0.2190, Loss G: 2.1011\n",
      "Epoch [14/85] Batch 650/938 Loss D: 0.2561, Loss G: 1.9428\n",
      "Epoch [14/85] Batch 660/938 Loss D: 0.1826, Loss G: 2.2096\n",
      "Epoch [14/85] Batch 670/938 Loss D: 0.2657, Loss G: 1.6768\n",
      "Epoch [14/85] Batch 680/938 Loss D: 0.2809, Loss G: 1.8561\n",
      "Epoch [14/85] Batch 690/938 Loss D: 0.2286, Loss G: 1.9960\n",
      "Epoch [14/85] Batch 700/938 Loss D: 0.3147, Loss G: 1.7405\n",
      "Epoch [14/85] Batch 710/938 Loss D: 0.2891, Loss G: 1.9124\n",
      "Epoch [14/85] Batch 720/938 Loss D: 0.2699, Loss G: 2.4150\n",
      "Epoch [14/85] Batch 730/938 Loss D: 0.2596, Loss G: 1.8409\n",
      "Epoch [14/85] Batch 740/938 Loss D: 0.2037, Loss G: 2.0656\n",
      "Epoch [14/85] Batch 750/938 Loss D: 0.2183, Loss G: 2.2836\n",
      "Epoch [14/85] Batch 760/938 Loss D: 0.2758, Loss G: 2.0295\n",
      "Epoch [14/85] Batch 770/938 Loss D: 0.2113, Loss G: 2.4334\n",
      "Epoch [14/85] Batch 780/938 Loss D: 0.1897, Loss G: 2.4442\n",
      "Epoch [14/85] Batch 790/938 Loss D: 0.2208, Loss G: 2.4729\n",
      "Epoch [14/85] Batch 800/938 Loss D: 0.2453, Loss G: 2.0219\n",
      "Epoch [14/85] Batch 810/938 Loss D: 0.1989, Loss G: 2.2820\n",
      "Epoch [14/85] Batch 820/938 Loss D: 0.2532, Loss G: 2.3684\n",
      "Epoch [14/85] Batch 830/938 Loss D: 0.3433, Loss G: 2.4561\n",
      "Epoch [14/85] Batch 840/938 Loss D: 0.2144, Loss G: 2.1518\n",
      "Epoch [14/85] Batch 850/938 Loss D: 0.2857, Loss G: 2.2706\n",
      "Epoch [14/85] Batch 860/938 Loss D: 0.2328, Loss G: 2.6041\n",
      "Epoch [14/85] Batch 870/938 Loss D: 0.1722, Loss G: 2.7446\n",
      "Epoch [14/85] Batch 880/938 Loss D: 0.2217, Loss G: 2.2103\n",
      "Epoch [14/85] Batch 890/938 Loss D: 0.2445, Loss G: 2.0027\n",
      "Epoch [14/85] Batch 900/938 Loss D: 0.1836, Loss G: 2.0030\n",
      "Epoch [14/85] Batch 910/938 Loss D: 0.2278, Loss G: 1.7376\n",
      "Epoch [14/85] Batch 920/938 Loss D: 0.2095, Loss G: 2.1627\n",
      "Epoch [14/85] Batch 930/938 Loss D: 0.2651, Loss G: 2.0001\n",
      "Epoch [15/85] Batch 0/938 Loss D: 0.2330, Loss G: 1.7657\n",
      "Epoch [15/85] Batch 10/938 Loss D: 0.1492, Loss G: 2.9266\n",
      "Epoch [15/85] Batch 20/938 Loss D: 0.2399, Loss G: 2.1243\n",
      "Epoch [15/85] Batch 30/938 Loss D: 0.2507, Loss G: 2.0643\n",
      "Epoch [15/85] Batch 40/938 Loss D: 0.2724, Loss G: 2.1777\n",
      "Epoch [15/85] Batch 50/938 Loss D: 0.2489, Loss G: 2.8573\n",
      "Epoch [15/85] Batch 60/938 Loss D: 0.2620, Loss G: 2.1896\n",
      "Epoch [15/85] Batch 70/938 Loss D: 0.2077, Loss G: 2.2089\n",
      "Epoch [15/85] Batch 80/938 Loss D: 0.1592, Loss G: 2.2776\n",
      "Epoch [15/85] Batch 90/938 Loss D: 0.2407, Loss G: 2.2593\n",
      "Epoch [15/85] Batch 100/938 Loss D: 0.2667, Loss G: 1.9552\n",
      "Epoch [15/85] Batch 110/938 Loss D: 0.2445, Loss G: 2.1469\n",
      "Epoch [15/85] Batch 120/938 Loss D: 0.1842, Loss G: 2.0651\n",
      "Epoch [15/85] Batch 130/938 Loss D: 0.2203, Loss G: 2.2901\n",
      "Epoch [15/85] Batch 140/938 Loss D: 0.2370, Loss G: 2.2379\n",
      "Epoch [15/85] Batch 150/938 Loss D: 0.4589, Loss G: 2.1452\n",
      "Epoch [15/85] Batch 160/938 Loss D: 0.3325, Loss G: 2.4096\n",
      "Epoch [15/85] Batch 170/938 Loss D: 0.3719, Loss G: 2.2983\n",
      "Epoch [15/85] Batch 180/938 Loss D: 0.2384, Loss G: 2.7415\n",
      "Epoch [15/85] Batch 190/938 Loss D: 0.2667, Loss G: 2.2880\n",
      "Epoch [15/85] Batch 200/938 Loss D: 0.2022, Loss G: 2.6054\n",
      "Epoch [15/85] Batch 210/938 Loss D: 0.2041, Loss G: 2.9107\n",
      "Epoch [15/85] Batch 220/938 Loss D: 0.2190, Loss G: 3.1065\n",
      "Epoch [15/85] Batch 230/938 Loss D: 0.2931, Loss G: 2.5030\n",
      "Epoch [15/85] Batch 240/938 Loss D: 0.2041, Loss G: 2.5061\n",
      "Epoch [15/85] Batch 250/938 Loss D: 0.2104, Loss G: 2.1845\n",
      "Epoch [15/85] Batch 260/938 Loss D: 0.2245, Loss G: 2.1769\n",
      "Epoch [15/85] Batch 270/938 Loss D: 0.1842, Loss G: 2.3604\n",
      "Epoch [15/85] Batch 280/938 Loss D: 0.2725, Loss G: 2.2305\n",
      "Epoch [15/85] Batch 290/938 Loss D: 0.2828, Loss G: 2.2864\n",
      "Epoch [15/85] Batch 300/938 Loss D: 0.2629, Loss G: 2.3488\n",
      "Epoch [15/85] Batch 310/938 Loss D: 0.2091, Loss G: 2.4170\n",
      "Epoch [15/85] Batch 320/938 Loss D: 0.2233, Loss G: 2.1477\n",
      "Epoch [15/85] Batch 330/938 Loss D: 0.3231, Loss G: 2.7569\n",
      "Epoch [15/85] Batch 340/938 Loss D: 0.1840, Loss G: 2.9030\n",
      "Epoch [15/85] Batch 350/938 Loss D: 0.3213, Loss G: 2.2024\n",
      "Epoch [15/85] Batch 360/938 Loss D: 0.3458, Loss G: 2.0013\n",
      "Epoch [15/85] Batch 370/938 Loss D: 0.2555, Loss G: 2.1558\n",
      "Epoch [15/85] Batch 380/938 Loss D: 0.2080, Loss G: 2.4245\n",
      "Epoch [15/85] Batch 390/938 Loss D: 0.2332, Loss G: 2.1334\n",
      "Epoch [15/85] Batch 400/938 Loss D: 0.3757, Loss G: 2.0009\n",
      "Epoch [15/85] Batch 410/938 Loss D: 0.2550, Loss G: 2.4928\n",
      "Epoch [15/85] Batch 420/938 Loss D: 0.2032, Loss G: 2.4790\n",
      "Epoch [15/85] Batch 430/938 Loss D: 0.2910, Loss G: 2.1950\n",
      "Epoch [15/85] Batch 440/938 Loss D: 0.2699, Loss G: 1.8917\n",
      "Epoch [15/85] Batch 450/938 Loss D: 0.1567, Loss G: 2.6216\n",
      "Epoch [15/85] Batch 460/938 Loss D: 0.1804, Loss G: 2.6667\n",
      "Epoch [15/85] Batch 470/938 Loss D: 0.2174, Loss G: 2.1111\n",
      "Epoch [15/85] Batch 480/938 Loss D: 0.1671, Loss G: 2.7247\n",
      "Epoch [15/85] Batch 490/938 Loss D: 0.1657, Loss G: 2.6452\n",
      "Epoch [15/85] Batch 500/938 Loss D: 0.2233, Loss G: 2.1760\n",
      "Epoch [15/85] Batch 510/938 Loss D: 0.1671, Loss G: 2.1743\n",
      "Epoch [15/85] Batch 520/938 Loss D: 0.3173, Loss G: 2.1050\n",
      "Epoch [15/85] Batch 530/938 Loss D: 0.2181, Loss G: 2.1736\n",
      "Epoch [15/85] Batch 540/938 Loss D: 0.2381, Loss G: 2.1291\n",
      "Epoch [15/85] Batch 550/938 Loss D: 0.3745, Loss G: 1.7661\n",
      "Epoch [15/85] Batch 560/938 Loss D: 0.2462, Loss G: 2.2056\n",
      "Epoch [15/85] Batch 570/938 Loss D: 0.1647, Loss G: 2.3747\n",
      "Epoch [15/85] Batch 580/938 Loss D: 0.3716, Loss G: 1.6720\n",
      "Epoch [15/85] Batch 590/938 Loss D: 0.2742, Loss G: 2.6512\n",
      "Epoch [15/85] Batch 600/938 Loss D: 0.2054, Loss G: 2.4403\n",
      "Epoch [15/85] Batch 610/938 Loss D: 0.1761, Loss G: 2.3048\n",
      "Epoch [15/85] Batch 620/938 Loss D: 0.3145, Loss G: 2.5924\n",
      "Epoch [15/85] Batch 630/938 Loss D: 0.2525, Loss G: 2.0999\n",
      "Epoch [15/85] Batch 640/938 Loss D: 0.1861, Loss G: 2.3275\n",
      "Epoch [15/85] Batch 650/938 Loss D: 0.2220, Loss G: 2.4234\n",
      "Epoch [15/85] Batch 660/938 Loss D: 0.2733, Loss G: 2.1598\n",
      "Epoch [15/85] Batch 670/938 Loss D: 0.2321, Loss G: 2.5266\n",
      "Epoch [15/85] Batch 680/938 Loss D: 0.2288, Loss G: 2.0209\n",
      "Epoch [15/85] Batch 690/938 Loss D: 0.2214, Loss G: 2.5433\n",
      "Epoch [15/85] Batch 700/938 Loss D: 0.3099, Loss G: 2.6162\n",
      "Epoch [15/85] Batch 710/938 Loss D: 0.1919, Loss G: 2.8111\n",
      "Epoch [15/85] Batch 720/938 Loss D: 0.2288, Loss G: 1.7817\n",
      "Epoch [15/85] Batch 730/938 Loss D: 0.4200, Loss G: 1.9360\n",
      "Epoch [15/85] Batch 740/938 Loss D: 0.2670, Loss G: 1.8818\n",
      "Epoch [15/85] Batch 750/938 Loss D: 0.1988, Loss G: 2.3553\n",
      "Epoch [15/85] Batch 760/938 Loss D: 0.2068, Loss G: 2.1757\n",
      "Epoch [15/85] Batch 770/938 Loss D: 0.2649, Loss G: 1.9299\n",
      "Epoch [15/85] Batch 780/938 Loss D: 0.2433, Loss G: 2.2359\n",
      "Epoch [15/85] Batch 790/938 Loss D: 0.3154, Loss G: 2.8444\n",
      "Epoch [15/85] Batch 800/938 Loss D: 0.3409, Loss G: 2.3330\n",
      "Epoch [15/85] Batch 810/938 Loss D: 0.2369, Loss G: 2.4649\n",
      "Epoch [15/85] Batch 820/938 Loss D: 0.1678, Loss G: 2.2530\n",
      "Epoch [15/85] Batch 830/938 Loss D: 0.1915, Loss G: 2.1534\n",
      "Epoch [15/85] Batch 840/938 Loss D: 0.2975, Loss G: 2.4729\n",
      "Epoch [15/85] Batch 850/938 Loss D: 0.2491, Loss G: 2.2660\n",
      "Epoch [15/85] Batch 860/938 Loss D: 0.3035, Loss G: 2.5034\n",
      "Epoch [15/85] Batch 870/938 Loss D: 0.2040, Loss G: 2.5334\n",
      "Epoch [15/85] Batch 880/938 Loss D: 0.3054, Loss G: 2.1579\n",
      "Epoch [15/85] Batch 890/938 Loss D: 0.2574, Loss G: 1.8711\n",
      "Epoch [15/85] Batch 900/938 Loss D: 0.2317, Loss G: 2.3726\n",
      "Epoch [15/85] Batch 910/938 Loss D: 0.2011, Loss G: 2.1524\n",
      "Epoch [15/85] Batch 920/938 Loss D: 0.2842, Loss G: 2.0897\n",
      "Epoch [15/85] Batch 930/938 Loss D: 0.2518, Loss G: 2.3308\n",
      "Epoch [16/85] Batch 0/938 Loss D: 0.2264, Loss G: 2.5007\n",
      "Epoch [16/85] Batch 10/938 Loss D: 0.2506, Loss G: 2.6898\n",
      "Epoch [16/85] Batch 20/938 Loss D: 0.1705, Loss G: 2.6831\n",
      "Epoch [16/85] Batch 30/938 Loss D: 0.2395, Loss G: 2.5800\n",
      "Epoch [16/85] Batch 40/938 Loss D: 0.2264, Loss G: 2.9016\n",
      "Epoch [16/85] Batch 50/938 Loss D: 0.1766, Loss G: 2.5149\n",
      "Epoch [16/85] Batch 60/938 Loss D: 0.2420, Loss G: 2.1982\n",
      "Epoch [16/85] Batch 70/938 Loss D: 0.3316, Loss G: 1.6730\n",
      "Epoch [16/85] Batch 80/938 Loss D: 0.2785, Loss G: 1.7539\n",
      "Epoch [16/85] Batch 90/938 Loss D: 0.2919, Loss G: 1.7438\n",
      "Epoch [16/85] Batch 100/938 Loss D: 0.2560, Loss G: 1.7445\n",
      "Epoch [16/85] Batch 110/938 Loss D: 0.2282, Loss G: 2.0493\n",
      "Epoch [16/85] Batch 120/938 Loss D: 0.3588, Loss G: 1.8900\n",
      "Epoch [16/85] Batch 130/938 Loss D: 0.2731, Loss G: 2.3352\n",
      "Epoch [16/85] Batch 140/938 Loss D: 0.3814, Loss G: 1.8931\n",
      "Epoch [16/85] Batch 150/938 Loss D: 0.2725, Loss G: 2.4184\n",
      "Epoch [16/85] Batch 160/938 Loss D: 0.1611, Loss G: 2.8810\n",
      "Epoch [16/85] Batch 170/938 Loss D: 0.2111, Loss G: 2.3774\n",
      "Epoch [16/85] Batch 180/938 Loss D: 0.3210, Loss G: 1.8769\n",
      "Epoch [16/85] Batch 190/938 Loss D: 0.2386, Loss G: 2.0488\n",
      "Epoch [16/85] Batch 200/938 Loss D: 0.2187, Loss G: 1.8388\n",
      "Epoch [16/85] Batch 210/938 Loss D: 0.2933, Loss G: 1.9057\n",
      "Epoch [16/85] Batch 220/938 Loss D: 0.2027, Loss G: 2.4479\n",
      "Epoch [16/85] Batch 230/938 Loss D: 0.3118, Loss G: 1.8394\n",
      "Epoch [16/85] Batch 240/938 Loss D: 0.2197, Loss G: 2.2417\n",
      "Epoch [16/85] Batch 250/938 Loss D: 0.2598, Loss G: 2.0678\n",
      "Epoch [16/85] Batch 260/938 Loss D: 0.2493, Loss G: 2.1371\n",
      "Epoch [16/85] Batch 270/938 Loss D: 0.3029, Loss G: 1.9365\n",
      "Epoch [16/85] Batch 280/938 Loss D: 0.1932, Loss G: 2.6227\n",
      "Epoch [16/85] Batch 290/938 Loss D: 0.2565, Loss G: 2.0926\n",
      "Epoch [16/85] Batch 300/938 Loss D: 0.2414, Loss G: 1.8640\n",
      "Epoch [16/85] Batch 310/938 Loss D: 0.1609, Loss G: 2.7124\n",
      "Epoch [16/85] Batch 320/938 Loss D: 0.3429, Loss G: 2.3864\n",
      "Epoch [16/85] Batch 330/938 Loss D: 0.2696, Loss G: 2.5190\n",
      "Epoch [16/85] Batch 340/938 Loss D: 0.2730, Loss G: 2.1208\n",
      "Epoch [16/85] Batch 350/938 Loss D: 0.2588, Loss G: 2.2176\n",
      "Epoch [16/85] Batch 360/938 Loss D: 0.2542, Loss G: 1.7752\n",
      "Epoch [16/85] Batch 370/938 Loss D: 0.2912, Loss G: 1.9341\n",
      "Epoch [16/85] Batch 380/938 Loss D: 0.2847, Loss G: 2.1725\n",
      "Epoch [16/85] Batch 390/938 Loss D: 0.3029, Loss G: 1.9134\n",
      "Epoch [16/85] Batch 400/938 Loss D: 0.2223, Loss G: 2.2225\n",
      "Epoch [16/85] Batch 410/938 Loss D: 0.2729, Loss G: 2.1875\n",
      "Epoch [16/85] Batch 420/938 Loss D: 0.3281, Loss G: 1.9759\n",
      "Epoch [16/85] Batch 430/938 Loss D: 0.2269, Loss G: 2.8013\n",
      "Epoch [16/85] Batch 440/938 Loss D: 0.1866, Loss G: 2.5204\n",
      "Epoch [16/85] Batch 450/938 Loss D: 0.1801, Loss G: 2.0642\n",
      "Epoch [16/85] Batch 460/938 Loss D: 0.2281, Loss G: 2.1792\n",
      "Epoch [16/85] Batch 470/938 Loss D: 0.2785, Loss G: 2.2754\n",
      "Epoch [16/85] Batch 480/938 Loss D: 0.2161, Loss G: 2.1154\n",
      "Epoch [16/85] Batch 490/938 Loss D: 0.2947, Loss G: 2.6655\n",
      "Epoch [16/85] Batch 500/938 Loss D: 0.3179, Loss G: 2.5016\n",
      "Epoch [16/85] Batch 510/938 Loss D: 0.2813, Loss G: 2.2476\n",
      "Epoch [16/85] Batch 520/938 Loss D: 0.3242, Loss G: 2.2450\n",
      "Epoch [16/85] Batch 530/938 Loss D: 0.3158, Loss G: 1.7211\n",
      "Epoch [16/85] Batch 540/938 Loss D: 0.1913, Loss G: 2.7179\n",
      "Epoch [16/85] Batch 550/938 Loss D: 0.2575, Loss G: 2.4271\n",
      "Epoch [16/85] Batch 560/938 Loss D: 0.2267, Loss G: 2.9529\n",
      "Epoch [16/85] Batch 570/938 Loss D: 0.3117, Loss G: 2.4891\n",
      "Epoch [16/85] Batch 580/938 Loss D: 0.3077, Loss G: 2.0844\n",
      "Epoch [16/85] Batch 590/938 Loss D: 0.2686, Loss G: 2.3415\n",
      "Epoch [16/85] Batch 600/938 Loss D: 0.2243, Loss G: 2.7078\n",
      "Epoch [16/85] Batch 610/938 Loss D: 0.1905, Loss G: 2.6953\n",
      "Epoch [16/85] Batch 620/938 Loss D: 0.2521, Loss G: 2.1566\n",
      "Epoch [16/85] Batch 630/938 Loss D: 0.2853, Loss G: 2.2282\n",
      "Epoch [16/85] Batch 640/938 Loss D: 0.2987, Loss G: 2.2484\n",
      "Epoch [16/85] Batch 650/938 Loss D: 0.2278, Loss G: 3.2678\n",
      "Epoch [16/85] Batch 660/938 Loss D: 0.2436, Loss G: 2.5361\n",
      "Epoch [16/85] Batch 670/938 Loss D: 0.3168, Loss G: 2.2085\n",
      "Epoch [16/85] Batch 680/938 Loss D: 0.2103, Loss G: 1.8483\n",
      "Epoch [16/85] Batch 690/938 Loss D: 0.2987, Loss G: 2.5456\n",
      "Epoch [16/85] Batch 700/938 Loss D: 0.2365, Loss G: 2.1058\n",
      "Epoch [16/85] Batch 710/938 Loss D: 0.1853, Loss G: 2.4853\n",
      "Epoch [16/85] Batch 720/938 Loss D: 0.2619, Loss G: 2.3438\n",
      "Epoch [16/85] Batch 730/938 Loss D: 0.2557, Loss G: 1.8808\n",
      "Epoch [16/85] Batch 740/938 Loss D: 0.2987, Loss G: 1.8538\n",
      "Epoch [16/85] Batch 750/938 Loss D: 0.1979, Loss G: 2.8321\n",
      "Epoch [16/85] Batch 760/938 Loss D: 0.3373, Loss G: 1.8473\n",
      "Epoch [16/85] Batch 770/938 Loss D: 0.2487, Loss G: 2.2680\n",
      "Epoch [16/85] Batch 780/938 Loss D: 0.2814, Loss G: 2.0539\n",
      "Epoch [16/85] Batch 790/938 Loss D: 0.1802, Loss G: 2.5109\n",
      "Epoch [16/85] Batch 800/938 Loss D: 0.3074, Loss G: 2.6756\n",
      "Epoch [16/85] Batch 810/938 Loss D: 0.2043, Loss G: 2.3995\n",
      "Epoch [16/85] Batch 820/938 Loss D: 0.3650, Loss G: 2.0264\n",
      "Epoch [16/85] Batch 830/938 Loss D: 0.2814, Loss G: 2.1467\n",
      "Epoch [16/85] Batch 840/938 Loss D: 0.2302, Loss G: 2.2455\n",
      "Epoch [16/85] Batch 850/938 Loss D: 0.2340, Loss G: 2.3989\n",
      "Epoch [16/85] Batch 860/938 Loss D: 0.3508, Loss G: 2.5571\n",
      "Epoch [16/85] Batch 870/938 Loss D: 0.2151, Loss G: 2.9279\n",
      "Epoch [16/85] Batch 880/938 Loss D: 0.2590, Loss G: 2.2234\n",
      "Epoch [16/85] Batch 890/938 Loss D: 0.1879, Loss G: 2.4905\n",
      "Epoch [16/85] Batch 900/938 Loss D: 0.2877, Loss G: 2.3653\n",
      "Epoch [16/85] Batch 910/938 Loss D: 0.2579, Loss G: 2.0904\n",
      "Epoch [16/85] Batch 920/938 Loss D: 0.2457, Loss G: 2.6607\n",
      "Epoch [16/85] Batch 930/938 Loss D: 0.3007, Loss G: 2.4218\n",
      "Epoch [17/85] Batch 0/938 Loss D: 0.2509, Loss G: 2.1691\n",
      "Epoch [17/85] Batch 10/938 Loss D: 0.2077, Loss G: 2.5948\n",
      "Epoch [17/85] Batch 20/938 Loss D: 0.2182, Loss G: 2.5351\n",
      "Epoch [17/85] Batch 30/938 Loss D: 0.2252, Loss G: 2.0728\n",
      "Epoch [17/85] Batch 40/938 Loss D: 0.2376, Loss G: 2.0318\n",
      "Epoch [17/85] Batch 50/938 Loss D: 0.2545, Loss G: 1.9759\n",
      "Epoch [17/85] Batch 60/938 Loss D: 0.3591, Loss G: 2.0361\n",
      "Epoch [17/85] Batch 70/938 Loss D: 0.2062, Loss G: 2.5754\n",
      "Epoch [17/85] Batch 80/938 Loss D: 0.2469, Loss G: 2.7068\n",
      "Epoch [17/85] Batch 90/938 Loss D: 0.2824, Loss G: 2.7801\n",
      "Epoch [17/85] Batch 100/938 Loss D: 0.2623, Loss G: 2.2578\n",
      "Epoch [17/85] Batch 110/938 Loss D: 0.2068, Loss G: 2.3882\n",
      "Epoch [17/85] Batch 120/938 Loss D: 0.1480, Loss G: 2.6919\n",
      "Epoch [17/85] Batch 130/938 Loss D: 0.2630, Loss G: 2.2987\n",
      "Epoch [17/85] Batch 140/938 Loss D: 0.1950, Loss G: 2.1345\n",
      "Epoch [17/85] Batch 150/938 Loss D: 0.3075, Loss G: 2.3446\n",
      "Epoch [17/85] Batch 160/938 Loss D: 0.2079, Loss G: 3.0752\n",
      "Epoch [17/85] Batch 170/938 Loss D: 0.2176, Loss G: 2.0951\n",
      "Epoch [17/85] Batch 180/938 Loss D: 0.3058, Loss G: 1.9848\n",
      "Epoch [17/85] Batch 190/938 Loss D: 0.1592, Loss G: 2.6907\n",
      "Epoch [17/85] Batch 200/938 Loss D: 0.2768, Loss G: 2.4562\n",
      "Epoch [17/85] Batch 210/938 Loss D: 0.3775, Loss G: 2.3136\n",
      "Epoch [17/85] Batch 220/938 Loss D: 0.2457, Loss G: 2.7271\n",
      "Epoch [17/85] Batch 230/938 Loss D: 0.2074, Loss G: 2.5608\n",
      "Epoch [17/85] Batch 240/938 Loss D: 0.2387, Loss G: 1.9805\n",
      "Epoch [17/85] Batch 250/938 Loss D: 0.2707, Loss G: 1.8505\n",
      "Epoch [17/85] Batch 260/938 Loss D: 0.2091, Loss G: 2.9004\n",
      "Epoch [17/85] Batch 270/938 Loss D: 0.2119, Loss G: 2.7819\n",
      "Epoch [17/85] Batch 280/938 Loss D: 0.3068, Loss G: 2.3927\n",
      "Epoch [17/85] Batch 290/938 Loss D: 0.2220, Loss G: 2.5687\n",
      "Epoch [17/85] Batch 300/938 Loss D: 0.2661, Loss G: 2.2733\n",
      "Epoch [17/85] Batch 310/938 Loss D: 0.3012, Loss G: 1.9131\n",
      "Epoch [17/85] Batch 320/938 Loss D: 0.1122, Loss G: 2.7169\n",
      "Epoch [17/85] Batch 330/938 Loss D: 0.2863, Loss G: 1.9740\n",
      "Epoch [17/85] Batch 340/938 Loss D: 0.2444, Loss G: 2.6454\n",
      "Epoch [17/85] Batch 350/938 Loss D: 0.2177, Loss G: 2.2701\n",
      "Epoch [17/85] Batch 360/938 Loss D: 0.1752, Loss G: 2.6258\n",
      "Epoch [17/85] Batch 370/938 Loss D: 0.2507, Loss G: 2.4813\n",
      "Epoch [17/85] Batch 380/938 Loss D: 0.2642, Loss G: 2.3598\n",
      "Epoch [17/85] Batch 390/938 Loss D: 0.1820, Loss G: 2.7667\n",
      "Epoch [17/85] Batch 400/938 Loss D: 0.2521, Loss G: 2.4827\n",
      "Epoch [17/85] Batch 410/938 Loss D: 0.2055, Loss G: 2.3175\n",
      "Epoch [17/85] Batch 420/938 Loss D: 0.3054, Loss G: 2.5019\n",
      "Epoch [17/85] Batch 430/938 Loss D: 0.2995, Loss G: 1.7447\n",
      "Epoch [17/85] Batch 440/938 Loss D: 0.2125, Loss G: 2.7217\n",
      "Epoch [17/85] Batch 450/938 Loss D: 0.2435, Loss G: 3.0772\n",
      "Epoch [17/85] Batch 460/938 Loss D: 0.2159, Loss G: 2.6070\n",
      "Epoch [17/85] Batch 470/938 Loss D: 0.2734, Loss G: 2.0794\n",
      "Epoch [17/85] Batch 480/938 Loss D: 0.1772, Loss G: 2.4394\n",
      "Epoch [17/85] Batch 490/938 Loss D: 0.2640, Loss G: 1.8213\n",
      "Epoch [17/85] Batch 500/938 Loss D: 0.2645, Loss G: 2.3037\n",
      "Epoch [17/85] Batch 510/938 Loss D: 0.2402, Loss G: 2.4024\n",
      "Epoch [17/85] Batch 520/938 Loss D: 0.3058, Loss G: 2.8380\n",
      "Epoch [17/85] Batch 530/938 Loss D: 0.1984, Loss G: 2.5235\n",
      "Epoch [17/85] Batch 540/938 Loss D: 0.3327, Loss G: 2.2266\n",
      "Epoch [17/85] Batch 550/938 Loss D: 0.2556, Loss G: 2.5347\n",
      "Epoch [17/85] Batch 560/938 Loss D: 0.2892, Loss G: 2.2506\n",
      "Epoch [17/85] Batch 570/938 Loss D: 0.2669, Loss G: 2.4294\n",
      "Epoch [17/85] Batch 580/938 Loss D: 0.2147, Loss G: 2.4400\n",
      "Epoch [17/85] Batch 590/938 Loss D: 0.2046, Loss G: 2.1485\n",
      "Epoch [17/85] Batch 600/938 Loss D: 0.2440, Loss G: 1.9769\n",
      "Epoch [17/85] Batch 610/938 Loss D: 0.1595, Loss G: 2.4804\n",
      "Epoch [17/85] Batch 620/938 Loss D: 0.2043, Loss G: 2.4672\n",
      "Epoch [17/85] Batch 630/938 Loss D: 0.2527, Loss G: 2.7201\n",
      "Epoch [17/85] Batch 640/938 Loss D: 0.3372, Loss G: 2.4301\n",
      "Epoch [17/85] Batch 650/938 Loss D: 0.2401, Loss G: 1.9778\n",
      "Epoch [17/85] Batch 660/938 Loss D: 0.2390, Loss G: 2.4245\n",
      "Epoch [17/85] Batch 670/938 Loss D: 0.2262, Loss G: 2.6339\n",
      "Epoch [17/85] Batch 680/938 Loss D: 0.2853, Loss G: 2.3785\n",
      "Epoch [17/85] Batch 690/938 Loss D: 0.2868, Loss G: 2.5279\n",
      "Epoch [17/85] Batch 700/938 Loss D: 0.1906, Loss G: 2.8573\n",
      "Epoch [17/85] Batch 710/938 Loss D: 0.2673, Loss G: 2.1206\n",
      "Epoch [17/85] Batch 720/938 Loss D: 0.3014, Loss G: 2.5679\n",
      "Epoch [17/85] Batch 730/938 Loss D: 0.3093, Loss G: 1.7665\n",
      "Epoch [17/85] Batch 740/938 Loss D: 0.2205, Loss G: 2.3911\n",
      "Epoch [17/85] Batch 750/938 Loss D: 0.3515, Loss G: 1.7321\n",
      "Epoch [17/85] Batch 760/938 Loss D: 0.2565, Loss G: 2.2174\n",
      "Epoch [17/85] Batch 770/938 Loss D: 0.1655, Loss G: 2.3797\n",
      "Epoch [17/85] Batch 780/938 Loss D: 0.2488, Loss G: 2.2608\n",
      "Epoch [17/85] Batch 790/938 Loss D: 0.2091, Loss G: 2.2415\n",
      "Epoch [17/85] Batch 800/938 Loss D: 0.2459, Loss G: 2.2434\n",
      "Epoch [17/85] Batch 810/938 Loss D: 0.2641, Loss G: 2.2226\n",
      "Epoch [17/85] Batch 820/938 Loss D: 0.3158, Loss G: 2.3119\n",
      "Epoch [17/85] Batch 830/938 Loss D: 0.2066, Loss G: 2.3367\n",
      "Epoch [17/85] Batch 840/938 Loss D: 0.1734, Loss G: 2.5418\n",
      "Epoch [17/85] Batch 850/938 Loss D: 0.3010, Loss G: 2.3537\n",
      "Epoch [17/85] Batch 860/938 Loss D: 0.2580, Loss G: 2.2574\n",
      "Epoch [17/85] Batch 870/938 Loss D: 0.2056, Loss G: 2.7295\n",
      "Epoch [17/85] Batch 880/938 Loss D: 0.2386, Loss G: 2.4671\n",
      "Epoch [17/85] Batch 890/938 Loss D: 0.2374, Loss G: 2.3564\n",
      "Epoch [17/85] Batch 900/938 Loss D: 0.2055, Loss G: 3.0955\n",
      "Epoch [17/85] Batch 910/938 Loss D: 0.1871, Loss G: 2.6195\n",
      "Epoch [17/85] Batch 920/938 Loss D: 0.1627, Loss G: 2.6496\n",
      "Epoch [17/85] Batch 930/938 Loss D: 0.2007, Loss G: 2.4766\n",
      "Epoch [18/85] Batch 0/938 Loss D: 0.2333, Loss G: 2.4021\n",
      "Epoch [18/85] Batch 10/938 Loss D: 0.2443, Loss G: 2.2528\n",
      "Epoch [18/85] Batch 20/938 Loss D: 0.2145, Loss G: 2.4501\n",
      "Epoch [18/85] Batch 30/938 Loss D: 0.2655, Loss G: 2.0487\n",
      "Epoch [18/85] Batch 40/938 Loss D: 0.2821, Loss G: 2.7900\n",
      "Epoch [18/85] Batch 50/938 Loss D: 0.2448, Loss G: 2.7050\n",
      "Epoch [18/85] Batch 60/938 Loss D: 0.2226, Loss G: 2.5369\n",
      "Epoch [18/85] Batch 70/938 Loss D: 0.2474, Loss G: 2.5501\n",
      "Epoch [18/85] Batch 80/938 Loss D: 0.2160, Loss G: 2.0181\n",
      "Epoch [18/85] Batch 90/938 Loss D: 0.2933, Loss G: 2.2588\n",
      "Epoch [18/85] Batch 100/938 Loss D: 0.2235, Loss G: 2.4159\n",
      "Epoch [18/85] Batch 110/938 Loss D: 0.2770, Loss G: 2.1973\n",
      "Epoch [18/85] Batch 120/938 Loss D: 0.2569, Loss G: 1.9824\n",
      "Epoch [18/85] Batch 130/938 Loss D: 0.1880, Loss G: 2.2559\n",
      "Epoch [18/85] Batch 140/938 Loss D: 0.2259, Loss G: 2.4103\n",
      "Epoch [18/85] Batch 150/938 Loss D: 0.2484, Loss G: 2.3374\n",
      "Epoch [18/85] Batch 160/938 Loss D: 0.2520, Loss G: 2.1886\n",
      "Epoch [18/85] Batch 170/938 Loss D: 0.2767, Loss G: 1.8715\n",
      "Epoch [18/85] Batch 180/938 Loss D: 0.2651, Loss G: 2.3454\n",
      "Epoch [18/85] Batch 190/938 Loss D: 0.3136, Loss G: 2.1450\n",
      "Epoch [18/85] Batch 200/938 Loss D: 0.2557, Loss G: 2.1125\n",
      "Epoch [18/85] Batch 210/938 Loss D: 0.2663, Loss G: 2.3909\n",
      "Epoch [18/85] Batch 220/938 Loss D: 0.2032, Loss G: 2.1109\n",
      "Epoch [18/85] Batch 230/938 Loss D: 0.1827, Loss G: 2.9156\n",
      "Epoch [18/85] Batch 240/938 Loss D: 0.1990, Loss G: 2.7369\n",
      "Epoch [18/85] Batch 250/938 Loss D: 0.3186, Loss G: 2.6894\n",
      "Epoch [18/85] Batch 260/938 Loss D: 0.3118, Loss G: 2.3861\n",
      "Epoch [18/85] Batch 270/938 Loss D: 0.2525, Loss G: 2.5802\n",
      "Epoch [18/85] Batch 280/938 Loss D: 0.2247, Loss G: 2.0094\n",
      "Epoch [18/85] Batch 290/938 Loss D: 0.2280, Loss G: 2.0781\n",
      "Epoch [18/85] Batch 300/938 Loss D: 0.2883, Loss G: 2.1688\n",
      "Epoch [18/85] Batch 310/938 Loss D: 0.3050, Loss G: 2.1286\n",
      "Epoch [18/85] Batch 320/938 Loss D: 0.3036, Loss G: 1.8294\n",
      "Epoch [18/85] Batch 330/938 Loss D: 0.1837, Loss G: 2.4926\n",
      "Epoch [18/85] Batch 340/938 Loss D: 0.2592, Loss G: 2.3806\n",
      "Epoch [18/85] Batch 350/938 Loss D: 0.2613, Loss G: 2.0526\n",
      "Epoch [18/85] Batch 360/938 Loss D: 0.3372, Loss G: 1.6515\n",
      "Epoch [18/85] Batch 370/938 Loss D: 0.3213, Loss G: 2.4016\n",
      "Epoch [18/85] Batch 380/938 Loss D: 0.2653, Loss G: 1.9606\n",
      "Epoch [18/85] Batch 390/938 Loss D: 0.2421, Loss G: 1.9965\n",
      "Epoch [18/85] Batch 400/938 Loss D: 0.2532, Loss G: 2.3466\n",
      "Epoch [18/85] Batch 410/938 Loss D: 0.2887, Loss G: 2.1893\n",
      "Epoch [18/85] Batch 420/938 Loss D: 0.2290, Loss G: 2.2947\n",
      "Epoch [18/85] Batch 430/938 Loss D: 0.2005, Loss G: 2.4159\n",
      "Epoch [18/85] Batch 440/938 Loss D: 0.3397, Loss G: 1.9453\n",
      "Epoch [18/85] Batch 450/938 Loss D: 0.2457, Loss G: 2.1550\n",
      "Epoch [18/85] Batch 460/938 Loss D: 0.2104, Loss G: 2.3867\n",
      "Epoch [18/85] Batch 470/938 Loss D: 0.2430, Loss G: 2.3059\n",
      "Epoch [18/85] Batch 480/938 Loss D: 0.3139, Loss G: 1.6369\n",
      "Epoch [18/85] Batch 490/938 Loss D: 0.3008, Loss G: 2.2259\n",
      "Epoch [18/85] Batch 500/938 Loss D: 0.2463, Loss G: 2.5952\n",
      "Epoch [18/85] Batch 510/938 Loss D: 0.2327, Loss G: 2.7656\n",
      "Epoch [18/85] Batch 520/938 Loss D: 0.3362, Loss G: 2.0146\n",
      "Epoch [18/85] Batch 530/938 Loss D: 0.2645, Loss G: 1.9572\n",
      "Epoch [18/85] Batch 540/938 Loss D: 0.4023, Loss G: 1.3215\n",
      "Epoch [18/85] Batch 550/938 Loss D: 0.3545, Loss G: 1.5619\n",
      "Epoch [18/85] Batch 560/938 Loss D: 0.3507, Loss G: 2.1619\n",
      "Epoch [18/85] Batch 570/938 Loss D: 0.1933, Loss G: 3.1486\n",
      "Epoch [18/85] Batch 580/938 Loss D: 0.2596, Loss G: 2.2824\n",
      "Epoch [18/85] Batch 590/938 Loss D: 0.2736, Loss G: 2.2121\n",
      "Epoch [18/85] Batch 600/938 Loss D: 0.3196, Loss G: 1.9195\n",
      "Epoch [18/85] Batch 610/938 Loss D: 0.3051, Loss G: 1.9080\n",
      "Epoch [18/85] Batch 620/938 Loss D: 0.2384, Loss G: 1.7974\n",
      "Epoch [18/85] Batch 630/938 Loss D: 0.1591, Loss G: 2.2654\n",
      "Epoch [18/85] Batch 640/938 Loss D: 0.3123, Loss G: 1.8240\n",
      "Epoch [18/85] Batch 650/938 Loss D: 0.3201, Loss G: 2.1925\n",
      "Epoch [18/85] Batch 660/938 Loss D: 0.2509, Loss G: 2.3607\n",
      "Epoch [18/85] Batch 670/938 Loss D: 0.2712, Loss G: 1.8500\n",
      "Epoch [18/85] Batch 680/938 Loss D: 0.1810, Loss G: 2.4813\n",
      "Epoch [18/85] Batch 690/938 Loss D: 0.2558, Loss G: 2.5628\n",
      "Epoch [18/85] Batch 700/938 Loss D: 0.2301, Loss G: 2.3239\n",
      "Epoch [18/85] Batch 710/938 Loss D: 0.2211, Loss G: 2.3159\n",
      "Epoch [18/85] Batch 720/938 Loss D: 0.1906, Loss G: 2.6718\n",
      "Epoch [18/85] Batch 730/938 Loss D: 0.1811, Loss G: 2.8698\n",
      "Epoch [18/85] Batch 740/938 Loss D: 0.3477, Loss G: 2.7671\n",
      "Epoch [18/85] Batch 750/938 Loss D: 0.2095, Loss G: 2.5303\n",
      "Epoch [18/85] Batch 760/938 Loss D: 0.3145, Loss G: 1.8498\n",
      "Epoch [18/85] Batch 770/938 Loss D: 0.1934, Loss G: 2.4707\n",
      "Epoch [18/85] Batch 780/938 Loss D: 0.2368, Loss G: 2.5870\n",
      "Epoch [18/85] Batch 790/938 Loss D: 0.2984, Loss G: 2.4665\n",
      "Epoch [18/85] Batch 800/938 Loss D: 0.2958, Loss G: 2.5157\n",
      "Epoch [18/85] Batch 810/938 Loss D: 0.2688, Loss G: 2.9755\n",
      "Epoch [18/85] Batch 820/938 Loss D: 0.2106, Loss G: 2.9103\n",
      "Epoch [18/85] Batch 830/938 Loss D: 0.3621, Loss G: 1.6875\n",
      "Epoch [18/85] Batch 840/938 Loss D: 0.2549, Loss G: 2.3063\n",
      "Epoch [18/85] Batch 850/938 Loss D: 0.2429, Loss G: 2.1461\n",
      "Epoch [18/85] Batch 860/938 Loss D: 0.2551, Loss G: 2.0752\n",
      "Epoch [18/85] Batch 870/938 Loss D: 0.2699, Loss G: 1.9884\n",
      "Epoch [18/85] Batch 880/938 Loss D: 0.2645, Loss G: 2.0027\n",
      "Epoch [18/85] Batch 890/938 Loss D: 0.2102, Loss G: 2.4194\n",
      "Epoch [18/85] Batch 900/938 Loss D: 0.2889, Loss G: 2.2044\n",
      "Epoch [18/85] Batch 910/938 Loss D: 0.2548, Loss G: 2.5628\n",
      "Epoch [18/85] Batch 920/938 Loss D: 0.2287, Loss G: 2.8608\n",
      "Epoch [18/85] Batch 930/938 Loss D: 0.1553, Loss G: 2.9323\n",
      "Epoch [19/85] Batch 0/938 Loss D: 0.3197, Loss G: 1.9572\n",
      "Epoch [19/85] Batch 10/938 Loss D: 0.1873, Loss G: 2.2769\n",
      "Epoch [19/85] Batch 20/938 Loss D: 0.1642, Loss G: 2.4743\n",
      "Epoch [19/85] Batch 30/938 Loss D: 0.2506, Loss G: 2.2445\n",
      "Epoch [19/85] Batch 40/938 Loss D: 0.2585, Loss G: 2.5268\n",
      "Epoch [19/85] Batch 50/938 Loss D: 0.2917, Loss G: 1.4536\n",
      "Epoch [19/85] Batch 60/938 Loss D: 0.2743, Loss G: 2.0144\n",
      "Epoch [19/85] Batch 70/938 Loss D: 0.2299, Loss G: 2.6469\n",
      "Epoch [19/85] Batch 80/938 Loss D: 0.3180, Loss G: 2.5428\n",
      "Epoch [19/85] Batch 90/938 Loss D: 0.2152, Loss G: 2.2527\n",
      "Epoch [19/85] Batch 100/938 Loss D: 0.1857, Loss G: 2.5425\n",
      "Epoch [19/85] Batch 110/938 Loss D: 0.2734, Loss G: 2.0249\n",
      "Epoch [19/85] Batch 120/938 Loss D: 0.2877, Loss G: 2.2819\n",
      "Epoch [19/85] Batch 130/938 Loss D: 0.1983, Loss G: 2.9258\n",
      "Epoch [19/85] Batch 140/938 Loss D: 0.2233, Loss G: 2.2696\n",
      "Epoch [19/85] Batch 150/938 Loss D: 0.2624, Loss G: 2.5185\n",
      "Epoch [19/85] Batch 160/938 Loss D: 0.1899, Loss G: 2.8837\n",
      "Epoch [19/85] Batch 170/938 Loss D: 0.1948, Loss G: 2.5952\n",
      "Epoch [19/85] Batch 180/938 Loss D: 0.1570, Loss G: 3.5686\n",
      "Epoch [19/85] Batch 190/938 Loss D: 0.2540, Loss G: 2.8360\n",
      "Epoch [19/85] Batch 200/938 Loss D: 0.3331, Loss G: 2.5361\n",
      "Epoch [19/85] Batch 210/938 Loss D: 0.1779, Loss G: 3.0615\n",
      "Epoch [19/85] Batch 220/938 Loss D: 0.2623, Loss G: 2.1265\n",
      "Epoch [19/85] Batch 230/938 Loss D: 0.2194, Loss G: 2.4943\n",
      "Epoch [19/85] Batch 240/938 Loss D: 0.2460, Loss G: 2.0797\n",
      "Epoch [19/85] Batch 250/938 Loss D: 0.2360, Loss G: 2.6719\n",
      "Epoch [19/85] Batch 260/938 Loss D: 0.2037, Loss G: 2.9122\n",
      "Epoch [19/85] Batch 270/938 Loss D: 0.2272, Loss G: 2.4485\n",
      "Epoch [19/85] Batch 280/938 Loss D: 0.2097, Loss G: 2.3902\n",
      "Epoch [19/85] Batch 290/938 Loss D: 0.2356, Loss G: 2.2554\n",
      "Epoch [19/85] Batch 300/938 Loss D: 0.3762, Loss G: 1.8563\n",
      "Epoch [19/85] Batch 310/938 Loss D: 0.2413, Loss G: 2.0765\n",
      "Epoch [19/85] Batch 320/938 Loss D: 0.2605, Loss G: 2.1246\n",
      "Epoch [19/85] Batch 330/938 Loss D: 0.2514, Loss G: 1.8683\n",
      "Epoch [19/85] Batch 340/938 Loss D: 0.1543, Loss G: 2.1912\n",
      "Epoch [19/85] Batch 350/938 Loss D: 0.2824, Loss G: 1.8461\n",
      "Epoch [19/85] Batch 360/938 Loss D: 0.2032, Loss G: 2.2853\n",
      "Epoch [19/85] Batch 370/938 Loss D: 0.2531, Loss G: 2.2549\n",
      "Epoch [19/85] Batch 380/938 Loss D: 0.2639, Loss G: 1.9572\n",
      "Epoch [19/85] Batch 390/938 Loss D: 0.1932, Loss G: 2.3279\n",
      "Epoch [19/85] Batch 400/938 Loss D: 0.1703, Loss G: 2.4824\n",
      "Epoch [19/85] Batch 410/938 Loss D: 0.1958, Loss G: 2.1632\n",
      "Epoch [19/85] Batch 420/938 Loss D: 0.1726, Loss G: 2.7226\n",
      "Epoch [19/85] Batch 430/938 Loss D: 0.2820, Loss G: 2.6980\n",
      "Epoch [19/85] Batch 440/938 Loss D: 0.1816, Loss G: 2.5876\n",
      "Epoch [19/85] Batch 450/938 Loss D: 0.1964, Loss G: 2.2397\n",
      "Epoch [19/85] Batch 460/938 Loss D: 0.2160, Loss G: 2.3416\n",
      "Epoch [19/85] Batch 470/938 Loss D: 0.2126, Loss G: 2.3732\n",
      "Epoch [19/85] Batch 480/938 Loss D: 0.3147, Loss G: 2.3750\n",
      "Epoch [19/85] Batch 490/938 Loss D: 0.2484, Loss G: 2.3382\n",
      "Epoch [19/85] Batch 500/938 Loss D: 0.2209, Loss G: 2.2777\n",
      "Epoch [19/85] Batch 510/938 Loss D: 0.1860, Loss G: 2.4642\n",
      "Epoch [19/85] Batch 520/938 Loss D: 0.2517, Loss G: 2.0751\n",
      "Epoch [19/85] Batch 530/938 Loss D: 0.2373, Loss G: 1.7975\n",
      "Epoch [19/85] Batch 540/938 Loss D: 0.2921, Loss G: 2.0664\n",
      "Epoch [19/85] Batch 550/938 Loss D: 0.2692, Loss G: 2.0432\n",
      "Epoch [19/85] Batch 560/938 Loss D: 0.2970, Loss G: 1.9033\n",
      "Epoch [19/85] Batch 570/938 Loss D: 0.3205, Loss G: 2.0978\n",
      "Epoch [19/85] Batch 580/938 Loss D: 0.2373, Loss G: 2.7268\n",
      "Epoch [19/85] Batch 590/938 Loss D: 0.3000, Loss G: 2.4381\n",
      "Epoch [19/85] Batch 600/938 Loss D: 0.2033, Loss G: 3.1682\n",
      "Epoch [19/85] Batch 610/938 Loss D: 0.2570, Loss G: 2.7178\n",
      "Epoch [19/85] Batch 620/938 Loss D: 0.2141, Loss G: 2.5106\n",
      "Epoch [19/85] Batch 630/938 Loss D: 0.2521, Loss G: 2.0006\n",
      "Epoch [19/85] Batch 640/938 Loss D: 0.2241, Loss G: 2.2105\n",
      "Epoch [19/85] Batch 650/938 Loss D: 0.2489, Loss G: 1.9024\n",
      "Epoch [19/85] Batch 660/938 Loss D: 0.2004, Loss G: 2.6474\n",
      "Epoch [19/85] Batch 670/938 Loss D: 0.1845, Loss G: 2.5103\n",
      "Epoch [19/85] Batch 680/938 Loss D: 0.3564, Loss G: 1.5589\n",
      "Epoch [19/85] Batch 690/938 Loss D: 0.2946, Loss G: 2.1148\n",
      "Epoch [19/85] Batch 700/938 Loss D: 0.3642, Loss G: 2.0122\n",
      "Epoch [19/85] Batch 710/938 Loss D: 0.1971, Loss G: 2.6968\n",
      "Epoch [19/85] Batch 720/938 Loss D: 0.2588, Loss G: 2.4039\n",
      "Epoch [19/85] Batch 730/938 Loss D: 0.1887, Loss G: 2.9037\n",
      "Epoch [19/85] Batch 740/938 Loss D: 0.2402, Loss G: 2.6609\n",
      "Epoch [19/85] Batch 750/938 Loss D: 0.2232, Loss G: 1.7754\n",
      "Epoch [19/85] Batch 760/938 Loss D: 0.1896, Loss G: 2.2183\n",
      "Epoch [19/85] Batch 770/938 Loss D: 0.3406, Loss G: 1.6560\n",
      "Epoch [19/85] Batch 780/938 Loss D: 0.2437, Loss G: 2.2235\n",
      "Epoch [19/85] Batch 790/938 Loss D: 0.3013, Loss G: 1.6983\n",
      "Epoch [19/85] Batch 800/938 Loss D: 0.2633, Loss G: 1.9968\n",
      "Epoch [19/85] Batch 810/938 Loss D: 0.2593, Loss G: 2.0729\n",
      "Epoch [19/85] Batch 820/938 Loss D: 0.2148, Loss G: 2.6349\n",
      "Epoch [19/85] Batch 830/938 Loss D: 0.2732, Loss G: 1.7427\n",
      "Epoch [19/85] Batch 840/938 Loss D: 0.2400, Loss G: 1.7361\n",
      "Epoch [19/85] Batch 850/938 Loss D: 0.2102, Loss G: 2.4391\n",
      "Epoch [19/85] Batch 860/938 Loss D: 0.2526, Loss G: 1.7685\n",
      "Epoch [19/85] Batch 870/938 Loss D: 0.2134, Loss G: 2.0878\n",
      "Epoch [19/85] Batch 880/938 Loss D: 0.1813, Loss G: 2.4033\n",
      "Epoch [19/85] Batch 890/938 Loss D: 0.1776, Loss G: 2.4763\n",
      "Epoch [19/85] Batch 900/938 Loss D: 0.2238, Loss G: 2.8099\n",
      "Epoch [19/85] Batch 910/938 Loss D: 0.2354, Loss G: 2.5125\n",
      "Epoch [19/85] Batch 920/938 Loss D: 0.2262, Loss G: 2.5882\n",
      "Epoch [19/85] Batch 930/938 Loss D: 0.2991, Loss G: 2.1652\n",
      "Epoch [20/85] Batch 0/938 Loss D: 0.2881, Loss G: 1.8426\n",
      "Epoch [20/85] Batch 10/938 Loss D: 0.2799, Loss G: 2.0176\n",
      "Epoch [20/85] Batch 20/938 Loss D: 0.2620, Loss G: 1.8951\n",
      "Epoch [20/85] Batch 30/938 Loss D: 0.3763, Loss G: 1.8104\n",
      "Epoch [20/85] Batch 40/938 Loss D: 0.2856, Loss G: 1.9631\n",
      "Epoch [20/85] Batch 50/938 Loss D: 0.3121, Loss G: 1.9346\n",
      "Epoch [20/85] Batch 60/938 Loss D: 0.2208, Loss G: 2.4593\n",
      "Epoch [20/85] Batch 70/938 Loss D: 0.2381, Loss G: 2.6474\n",
      "Epoch [20/85] Batch 80/938 Loss D: 0.2939, Loss G: 2.5624\n",
      "Epoch [20/85] Batch 90/938 Loss D: 0.2722, Loss G: 2.2347\n",
      "Epoch [20/85] Batch 100/938 Loss D: 0.2372, Loss G: 2.5326\n",
      "Epoch [20/85] Batch 110/938 Loss D: 0.2393, Loss G: 2.2285\n",
      "Epoch [20/85] Batch 120/938 Loss D: 0.1942, Loss G: 2.2424\n",
      "Epoch [20/85] Batch 130/938 Loss D: 0.1740, Loss G: 2.5394\n",
      "Epoch [20/85] Batch 140/938 Loss D: 0.2583, Loss G: 2.3233\n",
      "Epoch [20/85] Batch 150/938 Loss D: 0.3078, Loss G: 1.5803\n",
      "Epoch [20/85] Batch 160/938 Loss D: 0.2575, Loss G: 2.1411\n",
      "Epoch [20/85] Batch 170/938 Loss D: 0.3379, Loss G: 1.8353\n",
      "Epoch [20/85] Batch 180/938 Loss D: 0.1559, Loss G: 2.8820\n",
      "Epoch [20/85] Batch 190/938 Loss D: 0.2516, Loss G: 2.2327\n",
      "Epoch [20/85] Batch 200/938 Loss D: 0.2746, Loss G: 1.7363\n",
      "Epoch [20/85] Batch 210/938 Loss D: 0.3124, Loss G: 2.1072\n",
      "Epoch [20/85] Batch 220/938 Loss D: 0.3095, Loss G: 1.9398\n",
      "Epoch [20/85] Batch 230/938 Loss D: 0.2834, Loss G: 2.2167\n",
      "Epoch [20/85] Batch 240/938 Loss D: 0.1654, Loss G: 2.5566\n",
      "Epoch [20/85] Batch 250/938 Loss D: 0.2885, Loss G: 2.2969\n",
      "Epoch [20/85] Batch 260/938 Loss D: 0.1706, Loss G: 2.8703\n",
      "Epoch [20/85] Batch 270/938 Loss D: 0.2718, Loss G: 2.0326\n",
      "Epoch [20/85] Batch 280/938 Loss D: 0.3033, Loss G: 2.2681\n",
      "Epoch [20/85] Batch 290/938 Loss D: 0.2831, Loss G: 2.2754\n",
      "Epoch [20/85] Batch 300/938 Loss D: 0.2550, Loss G: 2.2747\n",
      "Epoch [20/85] Batch 310/938 Loss D: 0.1902, Loss G: 3.1808\n",
      "Epoch [20/85] Batch 320/938 Loss D: 0.3295, Loss G: 2.1818\n",
      "Epoch [20/85] Batch 330/938 Loss D: 0.2510, Loss G: 2.3538\n",
      "Epoch [20/85] Batch 340/938 Loss D: 0.3158, Loss G: 1.9752\n",
      "Epoch [20/85] Batch 350/938 Loss D: 0.3220, Loss G: 1.8011\n",
      "Epoch [20/85] Batch 360/938 Loss D: 0.2731, Loss G: 2.9777\n",
      "Epoch [20/85] Batch 370/938 Loss D: 0.3126, Loss G: 2.5028\n",
      "Epoch [20/85] Batch 380/938 Loss D: 0.2435, Loss G: 2.1806\n",
      "Epoch [20/85] Batch 390/938 Loss D: 0.2896, Loss G: 1.9731\n",
      "Epoch [20/85] Batch 400/938 Loss D: 0.2773, Loss G: 2.3129\n",
      "Epoch [20/85] Batch 410/938 Loss D: 0.2015, Loss G: 2.6930\n",
      "Epoch [20/85] Batch 420/938 Loss D: 0.2287, Loss G: 2.2068\n",
      "Epoch [20/85] Batch 430/938 Loss D: 0.1638, Loss G: 2.3571\n",
      "Epoch [20/85] Batch 440/938 Loss D: 0.2408, Loss G: 2.4362\n",
      "Epoch [20/85] Batch 450/938 Loss D: 0.2209, Loss G: 2.1202\n",
      "Epoch [20/85] Batch 460/938 Loss D: 0.2349, Loss G: 1.9401\n",
      "Epoch [20/85] Batch 470/938 Loss D: 0.3222, Loss G: 1.6575\n",
      "Epoch [20/85] Batch 480/938 Loss D: 0.2165, Loss G: 2.2681\n",
      "Epoch [20/85] Batch 490/938 Loss D: 0.1901, Loss G: 2.4111\n",
      "Epoch [20/85] Batch 500/938 Loss D: 0.2428, Loss G: 2.5569\n",
      "Epoch [20/85] Batch 510/938 Loss D: 0.1874, Loss G: 2.7780\n",
      "Epoch [20/85] Batch 520/938 Loss D: 0.1844, Loss G: 2.3473\n",
      "Epoch [20/85] Batch 530/938 Loss D: 0.2438, Loss G: 2.4071\n",
      "Epoch [20/85] Batch 540/938 Loss D: 0.2471, Loss G: 2.2258\n",
      "Epoch [20/85] Batch 550/938 Loss D: 0.3788, Loss G: 2.0790\n",
      "Epoch [20/85] Batch 560/938 Loss D: 0.2194, Loss G: 2.5203\n",
      "Epoch [20/85] Batch 570/938 Loss D: 0.2257, Loss G: 2.6617\n",
      "Epoch [20/85] Batch 580/938 Loss D: 0.3411, Loss G: 2.3103\n",
      "Epoch [20/85] Batch 590/938 Loss D: 0.2435, Loss G: 2.3122\n",
      "Epoch [20/85] Batch 600/938 Loss D: 0.3018, Loss G: 1.8613\n",
      "Epoch [20/85] Batch 610/938 Loss D: 0.2452, Loss G: 2.1987\n",
      "Epoch [20/85] Batch 620/938 Loss D: 0.2700, Loss G: 1.7486\n",
      "Epoch [20/85] Batch 630/938 Loss D: 0.2112, Loss G: 2.2680\n",
      "Epoch [20/85] Batch 640/938 Loss D: 0.2685, Loss G: 2.6960\n",
      "Epoch [20/85] Batch 650/938 Loss D: 0.3969, Loss G: 2.7607\n",
      "Epoch [20/85] Batch 660/938 Loss D: 0.1808, Loss G: 2.5388\n",
      "Epoch [20/85] Batch 670/938 Loss D: 0.1687, Loss G: 2.6688\n",
      "Epoch [20/85] Batch 680/938 Loss D: 0.3415, Loss G: 2.1901\n",
      "Epoch [20/85] Batch 690/938 Loss D: 0.2085, Loss G: 2.9717\n",
      "Epoch [20/85] Batch 700/938 Loss D: 0.3151, Loss G: 2.3451\n",
      "Epoch [20/85] Batch 710/938 Loss D: 0.2793, Loss G: 2.0118\n",
      "Epoch [20/85] Batch 720/938 Loss D: 0.2937, Loss G: 1.9063\n",
      "Epoch [20/85] Batch 730/938 Loss D: 0.1428, Loss G: 3.0110\n",
      "Epoch [20/85] Batch 740/938 Loss D: 0.2168, Loss G: 2.3939\n",
      "Epoch [20/85] Batch 750/938 Loss D: 0.2068, Loss G: 2.7658\n",
      "Epoch [20/85] Batch 760/938 Loss D: 0.2410, Loss G: 2.8996\n",
      "Epoch [20/85] Batch 770/938 Loss D: 0.1938, Loss G: 2.4526\n",
      "Epoch [20/85] Batch 780/938 Loss D: 0.1610, Loss G: 2.2091\n",
      "Epoch [20/85] Batch 790/938 Loss D: 0.2761, Loss G: 1.9740\n",
      "Epoch [20/85] Batch 800/938 Loss D: 0.2328, Loss G: 2.2275\n",
      "Epoch [20/85] Batch 810/938 Loss D: 0.3518, Loss G: 2.0335\n",
      "Epoch [20/85] Batch 820/938 Loss D: 0.2512, Loss G: 1.9749\n",
      "Epoch [20/85] Batch 830/938 Loss D: 0.2017, Loss G: 2.6787\n",
      "Epoch [20/85] Batch 840/938 Loss D: 0.2518, Loss G: 2.2956\n",
      "Epoch [20/85] Batch 850/938 Loss D: 0.2080, Loss G: 2.2034\n",
      "Epoch [20/85] Batch 860/938 Loss D: 0.2374, Loss G: 2.2365\n",
      "Epoch [20/85] Batch 870/938 Loss D: 0.2565, Loss G: 2.3824\n",
      "Epoch [20/85] Batch 880/938 Loss D: 0.2540, Loss G: 2.4099\n",
      "Epoch [20/85] Batch 890/938 Loss D: 0.2624, Loss G: 2.8626\n",
      "Epoch [20/85] Batch 900/938 Loss D: 0.2110, Loss G: 2.1388\n",
      "Epoch [20/85] Batch 910/938 Loss D: 0.1503, Loss G: 2.3935\n",
      "Epoch [20/85] Batch 920/938 Loss D: 0.2278, Loss G: 2.3837\n",
      "Epoch [20/85] Batch 930/938 Loss D: 0.3032, Loss G: 2.5866\n",
      "Epoch [21/85] Batch 0/938 Loss D: 0.3279, Loss G: 1.7019\n",
      "Epoch [21/85] Batch 10/938 Loss D: 0.2366, Loss G: 2.2538\n",
      "Epoch [21/85] Batch 20/938 Loss D: 0.2500, Loss G: 2.4589\n",
      "Epoch [21/85] Batch 30/938 Loss D: 0.2227, Loss G: 2.2683\n",
      "Epoch [21/85] Batch 40/938 Loss D: 0.2205, Loss G: 2.8040\n",
      "Epoch [21/85] Batch 50/938 Loss D: 0.2164, Loss G: 2.5422\n",
      "Epoch [21/85] Batch 60/938 Loss D: 0.1860, Loss G: 2.8398\n",
      "Epoch [21/85] Batch 70/938 Loss D: 0.2143, Loss G: 2.6131\n",
      "Epoch [21/85] Batch 80/938 Loss D: 0.3317, Loss G: 2.6322\n",
      "Epoch [21/85] Batch 90/938 Loss D: 0.1844, Loss G: 2.9190\n",
      "Epoch [21/85] Batch 100/938 Loss D: 0.3314, Loss G: 2.1991\n",
      "Epoch [21/85] Batch 110/938 Loss D: 0.3031, Loss G: 2.1061\n",
      "Epoch [21/85] Batch 120/938 Loss D: 0.2391, Loss G: 2.6842\n",
      "Epoch [21/85] Batch 130/938 Loss D: 0.3606, Loss G: 2.4296\n",
      "Epoch [21/85] Batch 140/938 Loss D: 0.2086, Loss G: 3.1586\n",
      "Epoch [21/85] Batch 150/938 Loss D: 0.2383, Loss G: 2.6606\n",
      "Epoch [21/85] Batch 160/938 Loss D: 0.1931, Loss G: 2.4440\n",
      "Epoch [21/85] Batch 170/938 Loss D: 0.3460, Loss G: 1.9271\n",
      "Epoch [21/85] Batch 180/938 Loss D: 0.2521, Loss G: 1.7673\n",
      "Epoch [21/85] Batch 190/938 Loss D: 0.2801, Loss G: 1.8777\n",
      "Epoch [21/85] Batch 200/938 Loss D: 0.2515, Loss G: 2.3418\n",
      "Epoch [21/85] Batch 210/938 Loss D: 0.2652, Loss G: 2.4466\n",
      "Epoch [21/85] Batch 220/938 Loss D: 0.1718, Loss G: 2.7684\n",
      "Epoch [21/85] Batch 230/938 Loss D: 0.1969, Loss G: 2.2738\n",
      "Epoch [21/85] Batch 240/938 Loss D: 0.2677, Loss G: 2.0550\n",
      "Epoch [21/85] Batch 250/938 Loss D: 0.1961, Loss G: 2.3992\n",
      "Epoch [21/85] Batch 260/938 Loss D: 0.3100, Loss G: 2.1421\n",
      "Epoch [21/85] Batch 270/938 Loss D: 0.2947, Loss G: 2.4127\n",
      "Epoch [21/85] Batch 280/938 Loss D: 0.2181, Loss G: 2.5142\n",
      "Epoch [21/85] Batch 290/938 Loss D: 0.4595, Loss G: 1.9780\n",
      "Epoch [21/85] Batch 300/938 Loss D: 0.3241, Loss G: 2.0242\n",
      "Epoch [21/85] Batch 310/938 Loss D: 0.2596, Loss G: 2.6631\n",
      "Epoch [21/85] Batch 320/938 Loss D: 0.2547, Loss G: 2.5381\n",
      "Epoch [21/85] Batch 330/938 Loss D: 0.2472, Loss G: 2.8403\n",
      "Epoch [21/85] Batch 340/938 Loss D: 0.2332, Loss G: 1.7123\n",
      "Epoch [21/85] Batch 350/938 Loss D: 0.3209, Loss G: 2.1059\n",
      "Epoch [21/85] Batch 360/938 Loss D: 0.2090, Loss G: 2.8104\n",
      "Epoch [21/85] Batch 370/938 Loss D: 0.2348, Loss G: 2.5366\n",
      "Epoch [21/85] Batch 380/938 Loss D: 0.1962, Loss G: 2.2148\n",
      "Epoch [21/85] Batch 390/938 Loss D: 0.2545, Loss G: 2.1695\n",
      "Epoch [21/85] Batch 400/938 Loss D: 0.3093, Loss G: 1.9749\n",
      "Epoch [21/85] Batch 410/938 Loss D: 0.2744, Loss G: 2.0666\n",
      "Epoch [21/85] Batch 420/938 Loss D: 0.2439, Loss G: 2.1924\n",
      "Epoch [21/85] Batch 430/938 Loss D: 0.3048, Loss G: 2.3663\n",
      "Epoch [21/85] Batch 440/938 Loss D: 0.3513, Loss G: 2.1621\n",
      "Epoch [21/85] Batch 450/938 Loss D: 0.2560, Loss G: 2.5581\n",
      "Epoch [21/85] Batch 460/938 Loss D: 0.1885, Loss G: 2.8409\n",
      "Epoch [21/85] Batch 470/938 Loss D: 0.2972, Loss G: 2.4637\n",
      "Epoch [21/85] Batch 480/938 Loss D: 0.2753, Loss G: 2.5138\n",
      "Epoch [21/85] Batch 490/938 Loss D: 0.2949, Loss G: 2.0593\n",
      "Epoch [21/85] Batch 500/938 Loss D: 0.2274, Loss G: 2.3020\n",
      "Epoch [21/85] Batch 510/938 Loss D: 0.2868, Loss G: 1.9924\n",
      "Epoch [21/85] Batch 520/938 Loss D: 0.2511, Loss G: 2.7413\n",
      "Epoch [21/85] Batch 530/938 Loss D: 0.2949, Loss G: 1.8092\n",
      "Epoch [21/85] Batch 540/938 Loss D: 0.2344, Loss G: 2.3112\n",
      "Epoch [21/85] Batch 550/938 Loss D: 0.2383, Loss G: 2.3224\n",
      "Epoch [21/85] Batch 560/938 Loss D: 0.3375, Loss G: 2.6496\n",
      "Epoch [21/85] Batch 570/938 Loss D: 0.2923, Loss G: 2.9847\n",
      "Epoch [21/85] Batch 580/938 Loss D: 0.2660, Loss G: 2.3769\n",
      "Epoch [21/85] Batch 590/938 Loss D: 0.2905, Loss G: 2.2947\n",
      "Epoch [21/85] Batch 600/938 Loss D: 0.3558, Loss G: 2.0231\n",
      "Epoch [21/85] Batch 610/938 Loss D: 0.2784, Loss G: 1.8884\n",
      "Epoch [21/85] Batch 620/938 Loss D: 0.2209, Loss G: 2.3934\n",
      "Epoch [21/85] Batch 630/938 Loss D: 0.1478, Loss G: 2.6661\n",
      "Epoch [21/85] Batch 640/938 Loss D: 0.2927, Loss G: 2.4015\n",
      "Epoch [21/85] Batch 650/938 Loss D: 0.2775, Loss G: 2.5080\n",
      "Epoch [21/85] Batch 660/938 Loss D: 0.2616, Loss G: 2.0911\n",
      "Epoch [21/85] Batch 670/938 Loss D: 0.2695, Loss G: 1.8527\n",
      "Epoch [21/85] Batch 680/938 Loss D: 0.3461, Loss G: 2.1218\n",
      "Epoch [21/85] Batch 690/938 Loss D: 0.2465, Loss G: 1.9639\n",
      "Epoch [21/85] Batch 700/938 Loss D: 0.2035, Loss G: 2.2264\n",
      "Epoch [21/85] Batch 710/938 Loss D: 0.3544, Loss G: 1.8690\n",
      "Epoch [21/85] Batch 720/938 Loss D: 0.2540, Loss G: 2.4934\n",
      "Epoch [21/85] Batch 730/938 Loss D: 0.1952, Loss G: 2.4921\n",
      "Epoch [21/85] Batch 740/938 Loss D: 0.2515, Loss G: 1.9356\n",
      "Epoch [21/85] Batch 750/938 Loss D: 0.2565, Loss G: 1.9422\n",
      "Epoch [21/85] Batch 760/938 Loss D: 0.3185, Loss G: 2.1540\n",
      "Epoch [21/85] Batch 770/938 Loss D: 0.1898, Loss G: 2.4352\n",
      "Epoch [21/85] Batch 780/938 Loss D: 0.2467, Loss G: 2.2245\n",
      "Epoch [21/85] Batch 790/938 Loss D: 0.2218, Loss G: 2.2076\n",
      "Epoch [21/85] Batch 800/938 Loss D: 0.2431, Loss G: 2.4384\n",
      "Epoch [21/85] Batch 810/938 Loss D: 0.2618, Loss G: 2.4225\n",
      "Epoch [21/85] Batch 820/938 Loss D: 0.3056, Loss G: 1.6561\n",
      "Epoch [21/85] Batch 830/938 Loss D: 0.1690, Loss G: 2.4781\n",
      "Epoch [21/85] Batch 840/938 Loss D: 0.2059, Loss G: 2.3805\n",
      "Epoch [21/85] Batch 850/938 Loss D: 0.3222, Loss G: 1.9439\n",
      "Epoch [21/85] Batch 860/938 Loss D: 0.3527, Loss G: 2.1859\n",
      "Epoch [21/85] Batch 870/938 Loss D: 0.2451, Loss G: 2.2457\n",
      "Epoch [21/85] Batch 880/938 Loss D: 0.2974, Loss G: 1.9746\n",
      "Epoch [21/85] Batch 890/938 Loss D: 0.2290, Loss G: 2.0892\n",
      "Epoch [21/85] Batch 900/938 Loss D: 0.1998, Loss G: 2.2447\n",
      "Epoch [21/85] Batch 910/938 Loss D: 0.2149, Loss G: 2.2097\n",
      "Epoch [21/85] Batch 920/938 Loss D: 0.3765, Loss G: 1.7040\n",
      "Epoch [21/85] Batch 930/938 Loss D: 0.2500, Loss G: 2.1115\n",
      "Epoch [22/85] Batch 0/938 Loss D: 0.2518, Loss G: 1.8176\n",
      "Epoch [22/85] Batch 10/938 Loss D: 0.2359, Loss G: 2.0122\n",
      "Epoch [22/85] Batch 20/938 Loss D: 0.3188, Loss G: 2.0730\n",
      "Epoch [22/85] Batch 30/938 Loss D: 0.2189, Loss G: 2.7833\n",
      "Epoch [22/85] Batch 40/938 Loss D: 0.2338, Loss G: 2.4700\n",
      "Epoch [22/85] Batch 50/938 Loss D: 0.2169, Loss G: 2.7633\n",
      "Epoch [22/85] Batch 60/938 Loss D: 0.2474, Loss G: 2.8359\n",
      "Epoch [22/85] Batch 70/938 Loss D: 0.2235, Loss G: 2.2552\n",
      "Epoch [22/85] Batch 80/938 Loss D: 0.2668, Loss G: 2.0177\n",
      "Epoch [22/85] Batch 90/938 Loss D: 0.2887, Loss G: 1.9847\n",
      "Epoch [22/85] Batch 100/938 Loss D: 0.4124, Loss G: 1.7009\n",
      "Epoch [22/85] Batch 110/938 Loss D: 0.3246, Loss G: 2.7534\n",
      "Epoch [22/85] Batch 120/938 Loss D: 0.3680, Loss G: 1.9732\n",
      "Epoch [22/85] Batch 130/938 Loss D: 0.2693, Loss G: 2.0474\n",
      "Epoch [22/85] Batch 140/938 Loss D: 0.2363, Loss G: 2.5967\n",
      "Epoch [22/85] Batch 150/938 Loss D: 0.2296, Loss G: 3.0435\n",
      "Epoch [22/85] Batch 160/938 Loss D: 0.2081, Loss G: 2.8243\n",
      "Epoch [22/85] Batch 170/938 Loss D: 0.2427, Loss G: 2.4062\n",
      "Epoch [22/85] Batch 180/938 Loss D: 0.2810, Loss G: 2.1701\n",
      "Epoch [22/85] Batch 190/938 Loss D: 0.3100, Loss G: 2.5039\n",
      "Epoch [22/85] Batch 200/938 Loss D: 0.2103, Loss G: 2.1178\n",
      "Epoch [22/85] Batch 210/938 Loss D: 0.3167, Loss G: 2.0809\n",
      "Epoch [22/85] Batch 220/938 Loss D: 0.2404, Loss G: 2.4109\n",
      "Epoch [22/85] Batch 230/938 Loss D: 0.2473, Loss G: 2.9058\n",
      "Epoch [22/85] Batch 240/938 Loss D: 0.3430, Loss G: 2.2025\n",
      "Epoch [22/85] Batch 250/938 Loss D: 0.3836, Loss G: 2.9266\n",
      "Epoch [22/85] Batch 260/938 Loss D: 0.2746, Loss G: 2.8839\n",
      "Epoch [22/85] Batch 270/938 Loss D: 0.1999, Loss G: 2.6129\n",
      "Epoch [22/85] Batch 280/938 Loss D: 0.3220, Loss G: 1.8889\n",
      "Epoch [22/85] Batch 290/938 Loss D: 0.1975, Loss G: 2.6782\n",
      "Epoch [22/85] Batch 300/938 Loss D: 0.2871, Loss G: 1.9602\n",
      "Epoch [22/85] Batch 310/938 Loss D: 0.2911, Loss G: 1.8749\n",
      "Epoch [22/85] Batch 320/938 Loss D: 0.2807, Loss G: 2.1239\n",
      "Epoch [22/85] Batch 330/938 Loss D: 0.2540, Loss G: 2.2616\n",
      "Epoch [22/85] Batch 340/938 Loss D: 0.3235, Loss G: 2.0926\n",
      "Epoch [22/85] Batch 350/938 Loss D: 0.3201, Loss G: 2.5342\n",
      "Epoch [22/85] Batch 360/938 Loss D: 0.2327, Loss G: 3.3982\n",
      "Epoch [22/85] Batch 370/938 Loss D: 0.2649, Loss G: 2.7570\n",
      "Epoch [22/85] Batch 380/938 Loss D: 0.2282, Loss G: 2.8585\n",
      "Epoch [22/85] Batch 390/938 Loss D: 0.2439, Loss G: 2.1651\n",
      "Epoch [22/85] Batch 400/938 Loss D: 0.2074, Loss G: 2.3998\n",
      "Epoch [22/85] Batch 410/938 Loss D: 0.2650, Loss G: 3.0177\n",
      "Epoch [22/85] Batch 420/938 Loss D: 0.3446, Loss G: 2.2102\n",
      "Epoch [22/85] Batch 430/938 Loss D: 0.2509, Loss G: 2.4723\n",
      "Epoch [22/85] Batch 440/938 Loss D: 0.2259, Loss G: 2.1551\n",
      "Epoch [22/85] Batch 450/938 Loss D: 0.2251, Loss G: 2.2011\n",
      "Epoch [22/85] Batch 460/938 Loss D: 0.2579, Loss G: 1.9142\n",
      "Epoch [22/85] Batch 470/938 Loss D: 0.2092, Loss G: 2.5838\n",
      "Epoch [22/85] Batch 480/938 Loss D: 0.3340, Loss G: 1.7626\n",
      "Epoch [22/85] Batch 490/938 Loss D: 0.2190, Loss G: 3.1802\n",
      "Epoch [22/85] Batch 500/938 Loss D: 0.2368, Loss G: 2.5666\n",
      "Epoch [22/85] Batch 510/938 Loss D: 0.2419, Loss G: 2.1164\n",
      "Epoch [22/85] Batch 520/938 Loss D: 0.3021, Loss G: 1.8383\n",
      "Epoch [22/85] Batch 530/938 Loss D: 0.3039, Loss G: 2.0670\n",
      "Epoch [22/85] Batch 540/938 Loss D: 0.2759, Loss G: 1.9899\n",
      "Epoch [22/85] Batch 550/938 Loss D: 0.2158, Loss G: 2.6607\n",
      "Epoch [22/85] Batch 560/938 Loss D: 0.1789, Loss G: 2.3678\n",
      "Epoch [22/85] Batch 570/938 Loss D: 0.2645, Loss G: 2.3595\n",
      "Epoch [22/85] Batch 580/938 Loss D: 0.3009, Loss G: 2.7213\n",
      "Epoch [22/85] Batch 590/938 Loss D: 0.3130, Loss G: 2.3634\n",
      "Epoch [22/85] Batch 600/938 Loss D: 0.1762, Loss G: 2.5814\n",
      "Epoch [22/85] Batch 610/938 Loss D: 0.2859, Loss G: 2.0275\n",
      "Epoch [22/85] Batch 620/938 Loss D: 0.2858, Loss G: 2.6366\n",
      "Epoch [22/85] Batch 630/938 Loss D: 0.3361, Loss G: 1.9665\n",
      "Epoch [22/85] Batch 640/938 Loss D: 0.2558, Loss G: 2.1524\n",
      "Epoch [22/85] Batch 650/938 Loss D: 0.3096, Loss G: 1.9818\n",
      "Epoch [22/85] Batch 660/938 Loss D: 0.2715, Loss G: 2.7209\n",
      "Epoch [22/85] Batch 670/938 Loss D: 0.2576, Loss G: 2.6750\n",
      "Epoch [22/85] Batch 680/938 Loss D: 0.2729, Loss G: 2.0858\n",
      "Epoch [22/85] Batch 690/938 Loss D: 0.2343, Loss G: 2.3389\n",
      "Epoch [22/85] Batch 700/938 Loss D: 0.3075, Loss G: 2.4138\n",
      "Epoch [22/85] Batch 710/938 Loss D: 0.2284, Loss G: 2.7681\n",
      "Epoch [22/85] Batch 720/938 Loss D: 0.1956, Loss G: 2.6150\n",
      "Epoch [22/85] Batch 730/938 Loss D: 0.3403, Loss G: 1.9996\n",
      "Epoch [22/85] Batch 740/938 Loss D: 0.2327, Loss G: 2.2576\n",
      "Epoch [22/85] Batch 750/938 Loss D: 0.3227, Loss G: 2.1363\n",
      "Epoch [22/85] Batch 760/938 Loss D: 0.4411, Loss G: 1.6170\n",
      "Epoch [22/85] Batch 770/938 Loss D: 0.2740, Loss G: 2.1379\n",
      "Epoch [22/85] Batch 780/938 Loss D: 0.2875, Loss G: 2.3475\n",
      "Epoch [22/85] Batch 790/938 Loss D: 0.1603, Loss G: 2.9339\n",
      "Epoch [22/85] Batch 800/938 Loss D: 0.2370, Loss G: 2.7364\n",
      "Epoch [22/85] Batch 810/938 Loss D: 0.1951, Loss G: 3.1376\n",
      "Epoch [22/85] Batch 820/938 Loss D: 0.2177, Loss G: 3.2688\n",
      "Epoch [22/85] Batch 830/938 Loss D: 0.1780, Loss G: 2.4237\n",
      "Epoch [22/85] Batch 840/938 Loss D: 0.3545, Loss G: 2.0639\n",
      "Epoch [22/85] Batch 850/938 Loss D: 0.4137, Loss G: 2.0290\n",
      "Epoch [22/85] Batch 860/938 Loss D: 0.2586, Loss G: 2.2873\n",
      "Epoch [22/85] Batch 870/938 Loss D: 0.2293, Loss G: 2.5036\n",
      "Epoch [22/85] Batch 880/938 Loss D: 0.2854, Loss G: 2.3566\n",
      "Epoch [22/85] Batch 890/938 Loss D: 0.2067, Loss G: 2.8476\n",
      "Epoch [22/85] Batch 900/938 Loss D: 0.2967, Loss G: 3.1141\n",
      "Epoch [22/85] Batch 910/938 Loss D: 0.1861, Loss G: 2.5485\n",
      "Epoch [22/85] Batch 920/938 Loss D: 0.2845, Loss G: 2.0365\n",
      "Epoch [22/85] Batch 930/938 Loss D: 0.3275, Loss G: 2.0113\n",
      "Epoch [23/85] Batch 0/938 Loss D: 0.2768, Loss G: 2.1176\n",
      "Epoch [23/85] Batch 10/938 Loss D: 0.1998, Loss G: 2.2116\n",
      "Epoch [23/85] Batch 20/938 Loss D: 0.3049, Loss G: 1.9834\n",
      "Epoch [23/85] Batch 30/938 Loss D: 0.2215, Loss G: 2.0937\n",
      "Epoch [23/85] Batch 40/938 Loss D: 0.2450, Loss G: 2.6882\n",
      "Epoch [23/85] Batch 50/938 Loss D: 0.2719, Loss G: 2.4624\n",
      "Epoch [23/85] Batch 60/938 Loss D: 0.2380, Loss G: 2.5405\n",
      "Epoch [23/85] Batch 70/938 Loss D: 0.2121, Loss G: 2.2138\n",
      "Epoch [23/85] Batch 80/938 Loss D: 0.3797, Loss G: 2.1478\n",
      "Epoch [23/85] Batch 90/938 Loss D: 0.2538, Loss G: 2.6845\n",
      "Epoch [23/85] Batch 100/938 Loss D: 0.3303, Loss G: 2.2002\n",
      "Epoch [23/85] Batch 110/938 Loss D: 0.2731, Loss G: 2.2956\n",
      "Epoch [23/85] Batch 120/938 Loss D: 0.4103, Loss G: 2.1813\n",
      "Epoch [23/85] Batch 130/938 Loss D: 0.2706, Loss G: 2.3432\n",
      "Epoch [23/85] Batch 140/938 Loss D: 0.2443, Loss G: 2.4606\n",
      "Epoch [23/85] Batch 150/938 Loss D: 0.2431, Loss G: 2.6823\n",
      "Epoch [23/85] Batch 160/938 Loss D: 0.3084, Loss G: 2.2010\n",
      "Epoch [23/85] Batch 170/938 Loss D: 0.2781, Loss G: 2.8398\n",
      "Epoch [23/85] Batch 180/938 Loss D: 0.3215, Loss G: 2.9001\n",
      "Epoch [23/85] Batch 190/938 Loss D: 0.2511, Loss G: 2.5821\n",
      "Epoch [23/85] Batch 200/938 Loss D: 0.2810, Loss G: 1.8814\n",
      "Epoch [23/85] Batch 210/938 Loss D: 0.2306, Loss G: 2.7402\n",
      "Epoch [23/85] Batch 220/938 Loss D: 0.2152, Loss G: 2.5871\n",
      "Epoch [23/85] Batch 230/938 Loss D: 0.2280, Loss G: 2.7876\n",
      "Epoch [23/85] Batch 240/938 Loss D: 0.3031, Loss G: 2.0288\n",
      "Epoch [23/85] Batch 250/938 Loss D: 0.2685, Loss G: 2.1485\n",
      "Epoch [23/85] Batch 260/938 Loss D: 0.3389, Loss G: 2.4867\n",
      "Epoch [23/85] Batch 270/938 Loss D: 0.1867, Loss G: 2.4183\n",
      "Epoch [23/85] Batch 280/938 Loss D: 0.3023, Loss G: 1.7616\n",
      "Epoch [23/85] Batch 290/938 Loss D: 0.2622, Loss G: 1.9686\n",
      "Epoch [23/85] Batch 300/938 Loss D: 0.2118, Loss G: 2.4590\n",
      "Epoch [23/85] Batch 310/938 Loss D: 0.2087, Loss G: 2.6376\n",
      "Epoch [23/85] Batch 320/938 Loss D: 0.3559, Loss G: 2.2164\n",
      "Epoch [23/85] Batch 330/938 Loss D: 0.1693, Loss G: 2.8520\n",
      "Epoch [23/85] Batch 340/938 Loss D: 0.3829, Loss G: 2.5373\n",
      "Epoch [23/85] Batch 350/938 Loss D: 0.2065, Loss G: 2.3167\n",
      "Epoch [23/85] Batch 360/938 Loss D: 0.2626, Loss G: 2.4283\n",
      "Epoch [23/85] Batch 370/938 Loss D: 0.2667, Loss G: 2.2813\n",
      "Epoch [23/85] Batch 380/938 Loss D: 0.2605, Loss G: 2.0468\n",
      "Epoch [23/85] Batch 390/938 Loss D: 0.2923, Loss G: 2.0243\n",
      "Epoch [23/85] Batch 400/938 Loss D: 0.2892, Loss G: 2.0986\n",
      "Epoch [23/85] Batch 410/938 Loss D: 0.2766, Loss G: 2.4574\n",
      "Epoch [23/85] Batch 420/938 Loss D: 0.2464, Loss G: 2.5206\n",
      "Epoch [23/85] Batch 430/938 Loss D: 0.2743, Loss G: 2.4356\n",
      "Epoch [23/85] Batch 440/938 Loss D: 0.3073, Loss G: 2.7249\n",
      "Epoch [23/85] Batch 450/938 Loss D: 0.2195, Loss G: 2.3632\n",
      "Epoch [23/85] Batch 460/938 Loss D: 0.4061, Loss G: 1.7525\n",
      "Epoch [23/85] Batch 470/938 Loss D: 0.3175, Loss G: 2.4881\n",
      "Epoch [23/85] Batch 480/938 Loss D: 0.4185, Loss G: 3.0161\n",
      "Epoch [23/85] Batch 490/938 Loss D: 0.2484, Loss G: 2.7390\n",
      "Epoch [23/85] Batch 500/938 Loss D: 0.3028, Loss G: 2.1456\n",
      "Epoch [23/85] Batch 510/938 Loss D: 0.2296, Loss G: 2.0398\n",
      "Epoch [23/85] Batch 520/938 Loss D: 0.3232, Loss G: 2.3671\n",
      "Epoch [23/85] Batch 530/938 Loss D: 0.3445, Loss G: 2.1082\n",
      "Epoch [23/85] Batch 540/938 Loss D: 0.2590, Loss G: 2.2285\n",
      "Epoch [23/85] Batch 550/938 Loss D: 0.3451, Loss G: 2.2694\n",
      "Epoch [23/85] Batch 560/938 Loss D: 0.2439, Loss G: 2.5590\n",
      "Epoch [23/85] Batch 570/938 Loss D: 0.2344, Loss G: 2.3607\n",
      "Epoch [23/85] Batch 580/938 Loss D: 0.3284, Loss G: 1.9421\n",
      "Epoch [23/85] Batch 590/938 Loss D: 0.3549, Loss G: 2.1390\n",
      "Epoch [23/85] Batch 600/938 Loss D: 0.2507, Loss G: 2.0140\n",
      "Epoch [23/85] Batch 610/938 Loss D: 0.2826, Loss G: 1.9133\n",
      "Epoch [23/85] Batch 620/938 Loss D: 0.2379, Loss G: 2.2215\n",
      "Epoch [23/85] Batch 630/938 Loss D: 0.2572, Loss G: 2.1443\n",
      "Epoch [23/85] Batch 640/938 Loss D: 0.2329, Loss G: 2.8471\n",
      "Epoch [23/85] Batch 650/938 Loss D: 0.2808, Loss G: 2.1816\n",
      "Epoch [23/85] Batch 660/938 Loss D: 0.2939, Loss G: 2.0174\n",
      "Epoch [23/85] Batch 670/938 Loss D: 0.2445, Loss G: 2.1463\n",
      "Epoch [23/85] Batch 680/938 Loss D: 0.3208, Loss G: 1.8849\n",
      "Epoch [23/85] Batch 690/938 Loss D: 0.2584, Loss G: 2.4964\n",
      "Epoch [23/85] Batch 700/938 Loss D: 0.2345, Loss G: 2.9263\n",
      "Epoch [23/85] Batch 710/938 Loss D: 0.3488, Loss G: 2.0682\n",
      "Epoch [23/85] Batch 720/938 Loss D: 0.2604, Loss G: 2.2290\n",
      "Epoch [23/85] Batch 730/938 Loss D: 0.2880, Loss G: 1.9059\n",
      "Epoch [23/85] Batch 740/938 Loss D: 0.2583, Loss G: 2.5174\n",
      "Epoch [23/85] Batch 750/938 Loss D: 0.3262, Loss G: 2.5337\n",
      "Epoch [23/85] Batch 760/938 Loss D: 0.2703, Loss G: 2.7574\n",
      "Epoch [23/85] Batch 770/938 Loss D: 0.3019, Loss G: 2.5373\n",
      "Epoch [23/85] Batch 780/938 Loss D: 0.3005, Loss G: 2.4303\n",
      "Epoch [23/85] Batch 790/938 Loss D: 0.2486, Loss G: 2.6107\n",
      "Epoch [23/85] Batch 800/938 Loss D: 0.2271, Loss G: 2.7825\n",
      "Epoch [23/85] Batch 810/938 Loss D: 0.3925, Loss G: 2.1141\n",
      "Epoch [23/85] Batch 820/938 Loss D: 0.2796, Loss G: 2.1338\n",
      "Epoch [23/85] Batch 830/938 Loss D: 0.2724, Loss G: 1.9850\n",
      "Epoch [23/85] Batch 840/938 Loss D: 0.3718, Loss G: 2.4373\n",
      "Epoch [23/85] Batch 850/938 Loss D: 0.2706, Loss G: 2.5555\n",
      "Epoch [23/85] Batch 860/938 Loss D: 0.3005, Loss G: 1.8890\n",
      "Epoch [23/85] Batch 870/938 Loss D: 0.4703, Loss G: 2.3293\n",
      "Epoch [23/85] Batch 880/938 Loss D: 0.2719, Loss G: 2.4819\n",
      "Epoch [23/85] Batch 890/938 Loss D: 0.3517, Loss G: 1.8091\n",
      "Epoch [23/85] Batch 900/938 Loss D: 0.3341, Loss G: 1.5423\n",
      "Epoch [23/85] Batch 910/938 Loss D: 0.3031, Loss G: 2.2348\n",
      "Epoch [23/85] Batch 920/938 Loss D: 0.2770, Loss G: 2.9858\n",
      "Epoch [23/85] Batch 930/938 Loss D: 0.3672, Loss G: 2.9837\n",
      "Epoch [24/85] Batch 0/938 Loss D: 0.2250, Loss G: 2.7725\n",
      "Epoch [24/85] Batch 10/938 Loss D: 0.2564, Loss G: 2.0782\n",
      "Epoch [24/85] Batch 20/938 Loss D: 0.3161, Loss G: 1.9244\n",
      "Epoch [24/85] Batch 30/938 Loss D: 0.2369, Loss G: 2.1074\n",
      "Epoch [24/85] Batch 40/938 Loss D: 0.2321, Loss G: 2.8424\n",
      "Epoch [24/85] Batch 50/938 Loss D: 0.2748, Loss G: 2.5864\n",
      "Epoch [24/85] Batch 60/938 Loss D: 0.2647, Loss G: 2.4478\n",
      "Epoch [24/85] Batch 70/938 Loss D: 0.2791, Loss G: 2.3703\n",
      "Epoch [24/85] Batch 80/938 Loss D: 0.1772, Loss G: 2.6615\n",
      "Epoch [24/85] Batch 90/938 Loss D: 0.3018, Loss G: 2.0003\n",
      "Epoch [24/85] Batch 100/938 Loss D: 0.1976, Loss G: 2.0352\n",
      "Epoch [24/85] Batch 110/938 Loss D: 0.2630, Loss G: 2.0239\n",
      "Epoch [24/85] Batch 120/938 Loss D: 0.2328, Loss G: 2.5344\n",
      "Epoch [24/85] Batch 130/938 Loss D: 0.2368, Loss G: 2.4520\n",
      "Epoch [24/85] Batch 140/938 Loss D: 0.3347, Loss G: 2.5684\n",
      "Epoch [24/85] Batch 150/938 Loss D: 0.3692, Loss G: 2.6705\n",
      "Epoch [24/85] Batch 160/938 Loss D: 0.3089, Loss G: 2.5114\n",
      "Epoch [24/85] Batch 170/938 Loss D: 0.2365, Loss G: 2.4035\n",
      "Epoch [24/85] Batch 180/938 Loss D: 0.2417, Loss G: 2.3528\n",
      "Epoch [24/85] Batch 190/938 Loss D: 0.2566, Loss G: 2.5385\n",
      "Epoch [24/85] Batch 200/938 Loss D: 0.2936, Loss G: 1.9649\n",
      "Epoch [24/85] Batch 210/938 Loss D: 0.2450, Loss G: 2.3334\n",
      "Epoch [24/85] Batch 220/938 Loss D: 0.3084, Loss G: 2.5312\n",
      "Epoch [24/85] Batch 230/938 Loss D: 0.2993, Loss G: 2.5154\n",
      "Epoch [24/85] Batch 240/938 Loss D: 0.2530, Loss G: 2.5478\n",
      "Epoch [24/85] Batch 250/938 Loss D: 0.1977, Loss G: 2.9817\n",
      "Epoch [24/85] Batch 260/938 Loss D: 0.2425, Loss G: 2.4325\n",
      "Epoch [24/85] Batch 270/938 Loss D: 0.2342, Loss G: 2.4906\n",
      "Epoch [24/85] Batch 280/938 Loss D: 0.2858, Loss G: 2.2737\n",
      "Epoch [24/85] Batch 290/938 Loss D: 0.2989, Loss G: 2.7711\n",
      "Epoch [24/85] Batch 300/938 Loss D: 0.2571, Loss G: 2.5942\n",
      "Epoch [24/85] Batch 310/938 Loss D: 0.2271, Loss G: 3.0698\n",
      "Epoch [24/85] Batch 320/938 Loss D: 0.1824, Loss G: 2.8822\n",
      "Epoch [24/85] Batch 330/938 Loss D: 0.2896, Loss G: 2.8148\n",
      "Epoch [24/85] Batch 340/938 Loss D: 0.2695, Loss G: 2.1567\n",
      "Epoch [24/85] Batch 350/938 Loss D: 0.2827, Loss G: 2.5668\n",
      "Epoch [24/85] Batch 360/938 Loss D: 0.4231, Loss G: 2.3600\n",
      "Epoch [24/85] Batch 370/938 Loss D: 0.2915, Loss G: 2.1316\n",
      "Epoch [24/85] Batch 380/938 Loss D: 0.2089, Loss G: 2.5208\n",
      "Epoch [24/85] Batch 390/938 Loss D: 0.2351, Loss G: 1.9556\n",
      "Epoch [24/85] Batch 400/938 Loss D: 0.2610, Loss G: 2.3946\n",
      "Epoch [24/85] Batch 410/938 Loss D: 0.2016, Loss G: 2.2087\n",
      "Epoch [24/85] Batch 420/938 Loss D: 0.2590, Loss G: 2.3344\n",
      "Epoch [24/85] Batch 430/938 Loss D: 0.3676, Loss G: 1.8040\n",
      "Epoch [24/85] Batch 440/938 Loss D: 0.2660, Loss G: 1.9362\n",
      "Epoch [24/85] Batch 450/938 Loss D: 0.2301, Loss G: 2.4254\n",
      "Epoch [24/85] Batch 460/938 Loss D: 0.2463, Loss G: 2.7273\n",
      "Epoch [24/85] Batch 470/938 Loss D: 0.2489, Loss G: 2.3829\n",
      "Epoch [24/85] Batch 480/938 Loss D: 0.3444, Loss G: 2.2189\n",
      "Epoch [24/85] Batch 490/938 Loss D: 0.3287, Loss G: 1.6626\n",
      "Epoch [24/85] Batch 500/938 Loss D: 0.2664, Loss G: 1.9581\n",
      "Epoch [24/85] Batch 510/938 Loss D: 0.2552, Loss G: 2.3316\n",
      "Epoch [24/85] Batch 520/938 Loss D: 0.2638, Loss G: 2.3959\n",
      "Epoch [24/85] Batch 530/938 Loss D: 0.2845, Loss G: 2.1535\n",
      "Epoch [24/85] Batch 540/938 Loss D: 0.2040, Loss G: 2.3067\n",
      "Epoch [24/85] Batch 550/938 Loss D: 0.3352, Loss G: 2.2323\n",
      "Epoch [24/85] Batch 560/938 Loss D: 0.2885, Loss G: 2.2684\n",
      "Epoch [24/85] Batch 570/938 Loss D: 0.3722, Loss G: 1.8317\n",
      "Epoch [24/85] Batch 580/938 Loss D: 0.2271, Loss G: 2.2420\n",
      "Epoch [24/85] Batch 590/938 Loss D: 0.2775, Loss G: 2.2128\n",
      "Epoch [24/85] Batch 600/938 Loss D: 0.2742, Loss G: 2.2609\n",
      "Epoch [24/85] Batch 610/938 Loss D: 0.2884, Loss G: 2.1952\n",
      "Epoch [24/85] Batch 620/938 Loss D: 0.2102, Loss G: 2.9446\n",
      "Epoch [24/85] Batch 630/938 Loss D: 0.3392, Loss G: 1.8811\n",
      "Epoch [24/85] Batch 640/938 Loss D: 0.2025, Loss G: 2.1727\n",
      "Epoch [24/85] Batch 650/938 Loss D: 0.2241, Loss G: 1.9700\n",
      "Epoch [24/85] Batch 660/938 Loss D: 0.3208, Loss G: 2.1177\n",
      "Epoch [24/85] Batch 670/938 Loss D: 0.2002, Loss G: 2.7013\n",
      "Epoch [24/85] Batch 680/938 Loss D: 0.3450, Loss G: 2.5820\n",
      "Epoch [24/85] Batch 690/938 Loss D: 0.2158, Loss G: 2.9348\n",
      "Epoch [24/85] Batch 700/938 Loss D: 0.3950, Loss G: 1.8716\n",
      "Epoch [24/85] Batch 710/938 Loss D: 0.2190, Loss G: 2.5717\n",
      "Epoch [24/85] Batch 720/938 Loss D: 0.2313, Loss G: 2.6888\n",
      "Epoch [24/85] Batch 730/938 Loss D: 0.2026, Loss G: 2.2714\n",
      "Epoch [24/85] Batch 740/938 Loss D: 0.2869, Loss G: 2.4161\n",
      "Epoch [24/85] Batch 750/938 Loss D: 0.2674, Loss G: 1.9221\n",
      "Epoch [24/85] Batch 760/938 Loss D: 0.3333, Loss G: 1.7336\n",
      "Epoch [24/85] Batch 770/938 Loss D: 0.2724, Loss G: 2.4624\n",
      "Epoch [24/85] Batch 780/938 Loss D: 0.1912, Loss G: 2.7812\n",
      "Epoch [24/85] Batch 790/938 Loss D: 0.3667, Loss G: 2.5029\n",
      "Epoch [24/85] Batch 800/938 Loss D: 0.2178, Loss G: 2.3193\n",
      "Epoch [24/85] Batch 810/938 Loss D: 0.3781, Loss G: 2.2706\n",
      "Epoch [24/85] Batch 820/938 Loss D: 0.2600, Loss G: 2.1139\n",
      "Epoch [24/85] Batch 830/938 Loss D: 0.3455, Loss G: 1.8578\n",
      "Epoch [24/85] Batch 840/938 Loss D: 0.2225, Loss G: 2.2487\n",
      "Epoch [24/85] Batch 850/938 Loss D: 0.2538, Loss G: 2.0575\n",
      "Epoch [24/85] Batch 860/938 Loss D: 0.2539, Loss G: 2.2852\n",
      "Epoch [24/85] Batch 870/938 Loss D: 0.3621, Loss G: 1.7456\n",
      "Epoch [24/85] Batch 880/938 Loss D: 0.2578, Loss G: 2.5413\n",
      "Epoch [24/85] Batch 890/938 Loss D: 0.4016, Loss G: 2.3707\n",
      "Epoch [24/85] Batch 900/938 Loss D: 0.3934, Loss G: 2.9726\n",
      "Epoch [24/85] Batch 910/938 Loss D: 0.2840, Loss G: 2.3417\n",
      "Epoch [24/85] Batch 920/938 Loss D: 0.2391, Loss G: 2.3269\n",
      "Epoch [24/85] Batch 930/938 Loss D: 0.3043, Loss G: 2.2536\n",
      "Epoch [25/85] Batch 0/938 Loss D: 0.1847, Loss G: 2.4822\n",
      "Epoch [25/85] Batch 10/938 Loss D: 0.3061, Loss G: 2.3278\n",
      "Epoch [25/85] Batch 20/938 Loss D: 0.2884, Loss G: 2.5914\n",
      "Epoch [25/85] Batch 30/938 Loss D: 0.3294, Loss G: 2.6572\n",
      "Epoch [25/85] Batch 40/938 Loss D: 0.3135, Loss G: 2.3963\n",
      "Epoch [25/85] Batch 50/938 Loss D: 0.3281, Loss G: 2.3691\n",
      "Epoch [25/85] Batch 60/938 Loss D: 0.2166, Loss G: 2.4950\n",
      "Epoch [25/85] Batch 70/938 Loss D: 0.1861, Loss G: 2.6526\n",
      "Epoch [25/85] Batch 80/938 Loss D: 0.2677, Loss G: 2.4004\n",
      "Epoch [25/85] Batch 90/938 Loss D: 0.3026, Loss G: 2.4569\n",
      "Epoch [25/85] Batch 100/938 Loss D: 0.2228, Loss G: 2.5913\n",
      "Epoch [25/85] Batch 110/938 Loss D: 0.2499, Loss G: 2.5172\n",
      "Epoch [25/85] Batch 120/938 Loss D: 0.2507, Loss G: 1.9758\n",
      "Epoch [25/85] Batch 130/938 Loss D: 0.2280, Loss G: 2.1079\n",
      "Epoch [25/85] Batch 140/938 Loss D: 0.2056, Loss G: 2.5520\n",
      "Epoch [25/85] Batch 150/938 Loss D: 0.2429, Loss G: 2.5492\n",
      "Epoch [25/85] Batch 160/938 Loss D: 0.2361, Loss G: 2.3672\n",
      "Epoch [25/85] Batch 170/938 Loss D: 0.1734, Loss G: 2.5848\n",
      "Epoch [25/85] Batch 180/938 Loss D: 0.3449, Loss G: 1.8427\n",
      "Epoch [25/85] Batch 190/938 Loss D: 0.2794, Loss G: 1.9402\n",
      "Epoch [25/85] Batch 200/938 Loss D: 0.2736, Loss G: 2.6249\n",
      "Epoch [25/85] Batch 210/938 Loss D: 0.2497, Loss G: 2.7836\n",
      "Epoch [25/85] Batch 220/938 Loss D: 0.2598, Loss G: 2.4668\n",
      "Epoch [25/85] Batch 230/938 Loss D: 0.1509, Loss G: 2.7814\n",
      "Epoch [25/85] Batch 240/938 Loss D: 0.2459, Loss G: 2.3417\n",
      "Epoch [25/85] Batch 250/938 Loss D: 0.2042, Loss G: 2.4286\n",
      "Epoch [25/85] Batch 260/938 Loss D: 0.2644, Loss G: 2.8565\n",
      "Epoch [25/85] Batch 270/938 Loss D: 0.2675, Loss G: 3.0639\n",
      "Epoch [25/85] Batch 280/938 Loss D: 0.1962, Loss G: 2.6952\n",
      "Epoch [25/85] Batch 290/938 Loss D: 0.2288, Loss G: 2.8236\n",
      "Epoch [25/85] Batch 300/938 Loss D: 0.3612, Loss G: 2.0716\n",
      "Epoch [25/85] Batch 310/938 Loss D: 0.2442, Loss G: 2.2731\n",
      "Epoch [25/85] Batch 320/938 Loss D: 0.2813, Loss G: 1.9947\n",
      "Epoch [25/85] Batch 330/938 Loss D: 0.3904, Loss G: 1.5743\n",
      "Epoch [25/85] Batch 340/938 Loss D: 0.2474, Loss G: 2.5429\n",
      "Epoch [25/85] Batch 350/938 Loss D: 0.2445, Loss G: 1.9591\n",
      "Epoch [25/85] Batch 360/938 Loss D: 0.3461, Loss G: 1.8895\n",
      "Epoch [25/85] Batch 370/938 Loss D: 0.2968, Loss G: 2.1437\n",
      "Epoch [25/85] Batch 380/938 Loss D: 0.3479, Loss G: 1.7321\n",
      "Epoch [25/85] Batch 390/938 Loss D: 0.3270, Loss G: 2.2576\n",
      "Epoch [25/85] Batch 400/938 Loss D: 0.2789, Loss G: 2.2791\n",
      "Epoch [25/85] Batch 410/938 Loss D: 0.3196, Loss G: 2.0404\n",
      "Epoch [25/85] Batch 420/938 Loss D: 0.2625, Loss G: 2.0521\n",
      "Epoch [25/85] Batch 430/938 Loss D: 0.2445, Loss G: 2.6482\n",
      "Epoch [25/85] Batch 440/938 Loss D: 0.2627, Loss G: 2.2112\n",
      "Epoch [25/85] Batch 450/938 Loss D: 0.2605, Loss G: 2.0755\n",
      "Epoch [25/85] Batch 460/938 Loss D: 0.2580, Loss G: 1.9252\n",
      "Epoch [25/85] Batch 470/938 Loss D: 0.2816, Loss G: 2.1561\n",
      "Epoch [25/85] Batch 480/938 Loss D: 0.3598, Loss G: 2.1544\n",
      "Epoch [25/85] Batch 490/938 Loss D: 0.2989, Loss G: 2.2422\n",
      "Epoch [25/85] Batch 500/938 Loss D: 0.2380, Loss G: 2.5783\n",
      "Epoch [25/85] Batch 510/938 Loss D: 0.3173, Loss G: 2.5896\n",
      "Epoch [25/85] Batch 520/938 Loss D: 0.2819, Loss G: 2.0112\n",
      "Epoch [25/85] Batch 530/938 Loss D: 0.2364, Loss G: 2.4461\n",
      "Epoch [25/85] Batch 540/938 Loss D: 0.3390, Loss G: 2.4081\n",
      "Epoch [25/85] Batch 550/938 Loss D: 0.2614, Loss G: 2.1953\n",
      "Epoch [25/85] Batch 560/938 Loss D: 0.2716, Loss G: 2.4680\n",
      "Epoch [25/85] Batch 570/938 Loss D: 0.3216, Loss G: 2.2206\n",
      "Epoch [25/85] Batch 580/938 Loss D: 0.3371, Loss G: 2.8614\n",
      "Epoch [25/85] Batch 590/938 Loss D: 0.3314, Loss G: 3.1561\n",
      "Epoch [25/85] Batch 600/938 Loss D: 0.3294, Loss G: 2.9790\n",
      "Epoch [25/85] Batch 610/938 Loss D: 0.1974, Loss G: 2.6760\n",
      "Epoch [25/85] Batch 620/938 Loss D: 0.1798, Loss G: 2.4684\n",
      "Epoch [25/85] Batch 630/938 Loss D: 0.3373, Loss G: 1.8540\n",
      "Epoch [25/85] Batch 640/938 Loss D: 0.2233, Loss G: 2.2741\n",
      "Epoch [25/85] Batch 650/938 Loss D: 0.2369, Loss G: 2.4019\n",
      "Epoch [25/85] Batch 660/938 Loss D: 0.2675, Loss G: 2.3672\n",
      "Epoch [25/85] Batch 670/938 Loss D: 0.2896, Loss G: 1.9811\n",
      "Epoch [25/85] Batch 680/938 Loss D: 0.4702, Loss G: 1.4975\n",
      "Epoch [25/85] Batch 690/938 Loss D: 0.3277, Loss G: 2.0623\n",
      "Epoch [25/85] Batch 700/938 Loss D: 0.2095, Loss G: 2.8911\n",
      "Epoch [25/85] Batch 710/938 Loss D: 0.2841, Loss G: 2.5931\n",
      "Epoch [25/85] Batch 720/938 Loss D: 0.2308, Loss G: 2.7345\n",
      "Epoch [25/85] Batch 730/938 Loss D: 0.2944, Loss G: 2.5550\n",
      "Epoch [25/85] Batch 740/938 Loss D: 0.2952, Loss G: 2.3155\n",
      "Epoch [25/85] Batch 750/938 Loss D: 0.2898, Loss G: 1.8809\n",
      "Epoch [25/85] Batch 760/938 Loss D: 0.2786, Loss G: 2.3768\n",
      "Epoch [25/85] Batch 770/938 Loss D: 0.2470, Loss G: 2.2825\n",
      "Epoch [25/85] Batch 780/938 Loss D: 0.2546, Loss G: 2.3850\n",
      "Epoch [25/85] Batch 790/938 Loss D: 0.3287, Loss G: 1.9473\n",
      "Epoch [25/85] Batch 800/938 Loss D: 0.1888, Loss G: 2.7276\n",
      "Epoch [25/85] Batch 810/938 Loss D: 0.3499, Loss G: 2.3682\n",
      "Epoch [25/85] Batch 820/938 Loss D: 0.3176, Loss G: 2.4013\n",
      "Epoch [25/85] Batch 830/938 Loss D: 0.3058, Loss G: 2.4658\n",
      "Epoch [25/85] Batch 840/938 Loss D: 0.2189, Loss G: 2.9669\n",
      "Epoch [25/85] Batch 850/938 Loss D: 0.3258, Loss G: 2.7246\n",
      "Epoch [25/85] Batch 860/938 Loss D: 0.3341, Loss G: 2.2093\n",
      "Epoch [25/85] Batch 870/938 Loss D: 0.2772, Loss G: 2.3244\n",
      "Epoch [25/85] Batch 880/938 Loss D: 0.2671, Loss G: 1.9719\n",
      "Epoch [25/85] Batch 890/938 Loss D: 0.2591, Loss G: 2.0529\n",
      "Epoch [25/85] Batch 900/938 Loss D: 0.1906, Loss G: 2.6103\n",
      "Epoch [25/85] Batch 910/938 Loss D: 0.2311, Loss G: 2.4095\n",
      "Epoch [25/85] Batch 920/938 Loss D: 0.3467, Loss G: 2.4130\n",
      "Epoch [25/85] Batch 930/938 Loss D: 0.3273, Loss G: 2.0972\n",
      "Epoch [26/85] Batch 0/938 Loss D: 0.3539, Loss G: 2.0570\n",
      "Epoch [26/85] Batch 10/938 Loss D: 0.2196, Loss G: 2.0205\n",
      "Epoch [26/85] Batch 20/938 Loss D: 0.2565, Loss G: 2.4164\n",
      "Epoch [26/85] Batch 30/938 Loss D: 0.3144, Loss G: 2.5001\n",
      "Epoch [26/85] Batch 40/938 Loss D: 0.2443, Loss G: 2.7481\n",
      "Epoch [26/85] Batch 50/938 Loss D: 0.2167, Loss G: 2.5662\n",
      "Epoch [26/85] Batch 60/938 Loss D: 0.3529, Loss G: 1.9659\n",
      "Epoch [26/85] Batch 70/938 Loss D: 0.2404, Loss G: 2.6420\n",
      "Epoch [26/85] Batch 80/938 Loss D: 0.2333, Loss G: 2.5755\n",
      "Epoch [26/85] Batch 90/938 Loss D: 0.2227, Loss G: 2.5765\n",
      "Epoch [26/85] Batch 100/938 Loss D: 0.2757, Loss G: 2.1118\n",
      "Epoch [26/85] Batch 110/938 Loss D: 0.3715, Loss G: 1.6595\n",
      "Epoch [26/85] Batch 120/938 Loss D: 0.2503, Loss G: 2.0205\n",
      "Epoch [26/85] Batch 130/938 Loss D: 0.3793, Loss G: 2.0275\n",
      "Epoch [26/85] Batch 140/938 Loss D: 0.3148, Loss G: 2.6274\n",
      "Epoch [26/85] Batch 150/938 Loss D: 0.3772, Loss G: 2.7016\n",
      "Epoch [26/85] Batch 160/938 Loss D: 0.2636, Loss G: 2.2619\n",
      "Epoch [26/85] Batch 170/938 Loss D: 0.3457, Loss G: 2.2930\n",
      "Epoch [26/85] Batch 180/938 Loss D: 0.2650, Loss G: 2.4011\n",
      "Epoch [26/85] Batch 190/938 Loss D: 0.3167, Loss G: 2.5749\n",
      "Epoch [26/85] Batch 200/938 Loss D: 0.2897, Loss G: 3.0981\n",
      "Epoch [26/85] Batch 210/938 Loss D: 0.2541, Loss G: 2.4735\n",
      "Epoch [26/85] Batch 220/938 Loss D: 0.3343, Loss G: 2.4790\n",
      "Epoch [26/85] Batch 230/938 Loss D: 0.2676, Loss G: 1.9790\n",
      "Epoch [26/85] Batch 240/938 Loss D: 0.1939, Loss G: 2.7603\n",
      "Epoch [26/85] Batch 250/938 Loss D: 0.3489, Loss G: 2.3261\n",
      "Epoch [26/85] Batch 260/938 Loss D: 0.3055, Loss G: 2.5436\n",
      "Epoch [26/85] Batch 270/938 Loss D: 0.2626, Loss G: 2.3133\n",
      "Epoch [26/85] Batch 280/938 Loss D: 0.2546, Loss G: 2.4222\n",
      "Epoch [26/85] Batch 290/938 Loss D: 0.2203, Loss G: 2.9547\n",
      "Epoch [26/85] Batch 300/938 Loss D: 0.2326, Loss G: 2.2338\n",
      "Epoch [26/85] Batch 310/938 Loss D: 0.2613, Loss G: 2.9686\n",
      "Epoch [26/85] Batch 320/938 Loss D: 0.2852, Loss G: 2.6488\n",
      "Epoch [26/85] Batch 330/938 Loss D: 0.2337, Loss G: 2.2787\n",
      "Epoch [26/85] Batch 340/938 Loss D: 0.1998, Loss G: 3.1356\n",
      "Epoch [26/85] Batch 350/938 Loss D: 0.3151, Loss G: 1.5763\n",
      "Epoch [26/85] Batch 360/938 Loss D: 0.2697, Loss G: 2.2191\n",
      "Epoch [26/85] Batch 370/938 Loss D: 0.3445, Loss G: 2.7057\n",
      "Epoch [26/85] Batch 380/938 Loss D: 0.3429, Loss G: 2.5547\n",
      "Epoch [26/85] Batch 390/938 Loss D: 0.2798, Loss G: 2.6156\n",
      "Epoch [26/85] Batch 400/938 Loss D: 0.3700, Loss G: 2.3838\n",
      "Epoch [26/85] Batch 410/938 Loss D: 0.2285, Loss G: 2.0595\n",
      "Epoch [26/85] Batch 420/938 Loss D: 0.2479, Loss G: 1.9129\n",
      "Epoch [26/85] Batch 430/938 Loss D: 0.2170, Loss G: 2.3121\n",
      "Epoch [26/85] Batch 440/938 Loss D: 0.3480, Loss G: 1.7261\n",
      "Epoch [26/85] Batch 450/938 Loss D: 0.2481, Loss G: 2.3533\n",
      "Epoch [26/85] Batch 460/938 Loss D: 0.2420, Loss G: 2.4980\n",
      "Epoch [26/85] Batch 470/938 Loss D: 0.3297, Loss G: 1.8058\n",
      "Epoch [26/85] Batch 480/938 Loss D: 0.3802, Loss G: 2.3249\n",
      "Epoch [26/85] Batch 490/938 Loss D: 0.1581, Loss G: 2.9296\n",
      "Epoch [26/85] Batch 500/938 Loss D: 0.2946, Loss G: 2.2267\n",
      "Epoch [26/85] Batch 510/938 Loss D: 0.2546, Loss G: 2.1139\n",
      "Epoch [26/85] Batch 520/938 Loss D: 0.2708, Loss G: 2.0464\n",
      "Epoch [26/85] Batch 530/938 Loss D: 0.2572, Loss G: 2.2685\n",
      "Epoch [26/85] Batch 540/938 Loss D: 0.2040, Loss G: 2.0736\n",
      "Epoch [26/85] Batch 550/938 Loss D: 0.3374, Loss G: 2.1447\n",
      "Epoch [26/85] Batch 560/938 Loss D: 0.2259, Loss G: 2.3639\n",
      "Epoch [26/85] Batch 570/938 Loss D: 0.2222, Loss G: 2.8430\n",
      "Epoch [26/85] Batch 580/938 Loss D: 0.3671, Loss G: 1.9099\n",
      "Epoch [26/85] Batch 590/938 Loss D: 0.2411, Loss G: 1.9949\n",
      "Epoch [26/85] Batch 600/938 Loss D: 0.1964, Loss G: 2.1778\n",
      "Epoch [26/85] Batch 610/938 Loss D: 0.2895, Loss G: 2.1921\n",
      "Epoch [26/85] Batch 620/938 Loss D: 0.2731, Loss G: 2.5028\n",
      "Epoch [26/85] Batch 630/938 Loss D: 0.2816, Loss G: 2.7040\n",
      "Epoch [26/85] Batch 640/938 Loss D: 0.2365, Loss G: 2.5785\n",
      "Epoch [26/85] Batch 650/938 Loss D: 0.2929, Loss G: 2.3618\n",
      "Epoch [26/85] Batch 660/938 Loss D: 0.2361, Loss G: 2.8117\n",
      "Epoch [26/85] Batch 670/938 Loss D: 0.2849, Loss G: 2.6124\n",
      "Epoch [26/85] Batch 680/938 Loss D: 0.3777, Loss G: 1.8498\n",
      "Epoch [26/85] Batch 690/938 Loss D: 0.2293, Loss G: 2.8731\n",
      "Epoch [26/85] Batch 700/938 Loss D: 0.2735, Loss G: 2.4155\n",
      "Epoch [26/85] Batch 710/938 Loss D: 0.2687, Loss G: 2.0354\n",
      "Epoch [26/85] Batch 720/938 Loss D: 0.2317, Loss G: 2.5418\n",
      "Epoch [26/85] Batch 730/938 Loss D: 0.2522, Loss G: 2.3952\n",
      "Epoch [26/85] Batch 740/938 Loss D: 0.2170, Loss G: 2.7946\n",
      "Epoch [26/85] Batch 750/938 Loss D: 0.2996, Loss G: 1.8015\n",
      "Epoch [26/85] Batch 760/938 Loss D: 0.2388, Loss G: 2.3683\n",
      "Epoch [26/85] Batch 770/938 Loss D: 0.2331, Loss G: 2.5764\n",
      "Epoch [26/85] Batch 780/938 Loss D: 0.3058, Loss G: 3.1289\n",
      "Epoch [26/85] Batch 790/938 Loss D: 0.2913, Loss G: 2.4005\n",
      "Epoch [26/85] Batch 800/938 Loss D: 0.2806, Loss G: 2.5912\n",
      "Epoch [26/85] Batch 810/938 Loss D: 0.1946, Loss G: 2.6353\n",
      "Epoch [26/85] Batch 820/938 Loss D: 0.3626, Loss G: 2.1680\n",
      "Epoch [26/85] Batch 830/938 Loss D: 0.2109, Loss G: 2.1138\n",
      "Epoch [26/85] Batch 840/938 Loss D: 0.3033, Loss G: 2.2555\n",
      "Epoch [26/85] Batch 850/938 Loss D: 0.2900, Loss G: 2.4138\n",
      "Epoch [26/85] Batch 860/938 Loss D: 0.2715, Loss G: 2.4976\n",
      "Epoch [26/85] Batch 870/938 Loss D: 0.3258, Loss G: 2.1306\n",
      "Epoch [26/85] Batch 880/938 Loss D: 0.2506, Loss G: 1.8493\n",
      "Epoch [26/85] Batch 890/938 Loss D: 0.3225, Loss G: 2.4288\n",
      "Epoch [26/85] Batch 900/938 Loss D: 0.1627, Loss G: 2.8210\n",
      "Epoch [26/85] Batch 910/938 Loss D: 0.3494, Loss G: 2.3399\n",
      "Epoch [26/85] Batch 920/938 Loss D: 0.4004, Loss G: 2.7130\n",
      "Epoch [26/85] Batch 930/938 Loss D: 0.2333, Loss G: 2.7674\n",
      "Epoch [27/85] Batch 0/938 Loss D: 0.3603, Loss G: 2.1119\n",
      "Epoch [27/85] Batch 10/938 Loss D: 0.2923, Loss G: 2.8930\n",
      "Epoch [27/85] Batch 20/938 Loss D: 0.2577, Loss G: 2.1787\n",
      "Epoch [27/85] Batch 30/938 Loss D: 0.4564, Loss G: 1.8974\n",
      "Epoch [27/85] Batch 40/938 Loss D: 0.2751, Loss G: 2.8049\n",
      "Epoch [27/85] Batch 50/938 Loss D: 0.3193, Loss G: 2.3767\n",
      "Epoch [27/85] Batch 60/938 Loss D: 0.2950, Loss G: 2.6399\n",
      "Epoch [27/85] Batch 70/938 Loss D: 0.3143, Loss G: 1.6865\n",
      "Epoch [27/85] Batch 80/938 Loss D: 0.4277, Loss G: 1.4615\n",
      "Epoch [27/85] Batch 90/938 Loss D: 0.2318, Loss G: 1.9419\n",
      "Epoch [27/85] Batch 100/938 Loss D: 0.2470, Loss G: 2.1435\n",
      "Epoch [27/85] Batch 110/938 Loss D: 0.2178, Loss G: 3.0897\n",
      "Epoch [27/85] Batch 120/938 Loss D: 0.1571, Loss G: 3.1983\n",
      "Epoch [27/85] Batch 130/938 Loss D: 0.2806, Loss G: 2.3987\n",
      "Epoch [27/85] Batch 140/938 Loss D: 0.2274, Loss G: 2.9601\n",
      "Epoch [27/85] Batch 150/938 Loss D: 0.2929, Loss G: 2.1434\n",
      "Epoch [27/85] Batch 160/938 Loss D: 0.3029, Loss G: 2.0260\n",
      "Epoch [27/85] Batch 170/938 Loss D: 0.3020, Loss G: 2.1379\n",
      "Epoch [27/85] Batch 180/938 Loss D: 0.1910, Loss G: 2.9282\n",
      "Epoch [27/85] Batch 190/938 Loss D: 0.2483, Loss G: 2.8840\n",
      "Epoch [27/85] Batch 200/938 Loss D: 0.3501, Loss G: 2.4131\n",
      "Epoch [27/85] Batch 210/938 Loss D: 0.2453, Loss G: 2.6194\n",
      "Epoch [27/85] Batch 220/938 Loss D: 0.3259, Loss G: 2.3916\n",
      "Epoch [27/85] Batch 230/938 Loss D: 0.2767, Loss G: 2.7618\n",
      "Epoch [27/85] Batch 240/938 Loss D: 0.3431, Loss G: 2.3906\n",
      "Epoch [27/85] Batch 250/938 Loss D: 0.5148, Loss G: 2.3988\n",
      "Epoch [27/85] Batch 260/938 Loss D: 0.3768, Loss G: 2.3656\n",
      "Epoch [27/85] Batch 270/938 Loss D: 0.3081, Loss G: 2.5904\n",
      "Epoch [27/85] Batch 280/938 Loss D: 0.2540, Loss G: 2.0821\n",
      "Epoch [27/85] Batch 290/938 Loss D: 0.1972, Loss G: 2.4733\n",
      "Epoch [27/85] Batch 300/938 Loss D: 0.2829, Loss G: 1.9137\n",
      "Epoch [27/85] Batch 310/938 Loss D: 0.3631, Loss G: 2.7343\n",
      "Epoch [27/85] Batch 320/938 Loss D: 0.3011, Loss G: 2.3206\n",
      "Epoch [27/85] Batch 330/938 Loss D: 0.2997, Loss G: 1.9929\n",
      "Epoch [27/85] Batch 340/938 Loss D: 0.3190, Loss G: 1.9018\n",
      "Epoch [27/85] Batch 350/938 Loss D: 0.3144, Loss G: 2.3192\n",
      "Epoch [27/85] Batch 360/938 Loss D: 0.3789, Loss G: 2.1401\n",
      "Epoch [27/85] Batch 370/938 Loss D: 0.2906, Loss G: 2.2294\n",
      "Epoch [27/85] Batch 380/938 Loss D: 0.2322, Loss G: 2.3808\n",
      "Epoch [27/85] Batch 390/938 Loss D: 0.2427, Loss G: 2.4438\n",
      "Epoch [27/85] Batch 400/938 Loss D: 0.3274, Loss G: 2.2668\n",
      "Epoch [27/85] Batch 410/938 Loss D: 0.2787, Loss G: 2.0642\n",
      "Epoch [27/85] Batch 420/938 Loss D: 0.2870, Loss G: 2.2864\n",
      "Epoch [27/85] Batch 430/938 Loss D: 0.3231, Loss G: 2.3370\n",
      "Epoch [27/85] Batch 440/938 Loss D: 0.3423, Loss G: 1.9347\n",
      "Epoch [27/85] Batch 450/938 Loss D: 0.3172, Loss G: 2.2657\n",
      "Epoch [27/85] Batch 460/938 Loss D: 0.3046, Loss G: 1.9647\n",
      "Epoch [27/85] Batch 470/938 Loss D: 0.2516, Loss G: 2.1670\n",
      "Epoch [27/85] Batch 480/938 Loss D: 0.2904, Loss G: 2.0578\n",
      "Epoch [27/85] Batch 490/938 Loss D: 0.2606, Loss G: 2.4996\n",
      "Epoch [27/85] Batch 500/938 Loss D: 0.2862, Loss G: 2.8880\n",
      "Epoch [27/85] Batch 510/938 Loss D: 0.3785, Loss G: 2.0506\n",
      "Epoch [27/85] Batch 520/938 Loss D: 0.3121, Loss G: 2.2062\n",
      "Epoch [27/85] Batch 530/938 Loss D: 0.2586, Loss G: 2.1987\n",
      "Epoch [27/85] Batch 540/938 Loss D: 0.2435, Loss G: 2.3091\n",
      "Epoch [27/85] Batch 550/938 Loss D: 0.2669, Loss G: 2.5039\n",
      "Epoch [27/85] Batch 560/938 Loss D: 0.2998, Loss G: 1.8244\n",
      "Epoch [27/85] Batch 570/938 Loss D: 0.2572, Loss G: 2.4135\n",
      "Epoch [27/85] Batch 580/938 Loss D: 0.2573, Loss G: 2.2467\n",
      "Epoch [27/85] Batch 590/938 Loss D: 0.3908, Loss G: 2.0435\n",
      "Epoch [27/85] Batch 600/938 Loss D: 0.3395, Loss G: 1.8099\n",
      "Epoch [27/85] Batch 610/938 Loss D: 0.2542, Loss G: 2.8723\n",
      "Epoch [27/85] Batch 620/938 Loss D: 0.2527, Loss G: 2.0230\n",
      "Epoch [27/85] Batch 630/938 Loss D: 0.2692, Loss G: 2.8767\n",
      "Epoch [27/85] Batch 640/938 Loss D: 0.3252, Loss G: 2.4974\n",
      "Epoch [27/85] Batch 650/938 Loss D: 0.1879, Loss G: 2.9359\n",
      "Epoch [27/85] Batch 660/938 Loss D: 0.2660, Loss G: 2.4935\n",
      "Epoch [27/85] Batch 670/938 Loss D: 0.3106, Loss G: 1.9584\n",
      "Epoch [27/85] Batch 680/938 Loss D: 0.2534, Loss G: 2.6053\n",
      "Epoch [27/85] Batch 690/938 Loss D: 0.2569, Loss G: 2.9862\n",
      "Epoch [27/85] Batch 700/938 Loss D: 0.2405, Loss G: 2.2387\n",
      "Epoch [27/85] Batch 710/938 Loss D: 0.3076, Loss G: 2.4936\n",
      "Epoch [27/85] Batch 720/938 Loss D: 0.2413, Loss G: 2.6900\n",
      "Epoch [27/85] Batch 730/938 Loss D: 0.3434, Loss G: 2.1840\n",
      "Epoch [27/85] Batch 740/938 Loss D: 0.2023, Loss G: 2.8533\n",
      "Epoch [27/85] Batch 750/938 Loss D: 0.1865, Loss G: 3.0334\n",
      "Epoch [27/85] Batch 760/938 Loss D: 0.2336, Loss G: 2.1606\n",
      "Epoch [27/85] Batch 770/938 Loss D: 0.2214, Loss G: 2.3383\n",
      "Epoch [27/85] Batch 780/938 Loss D: 0.3750, Loss G: 2.0229\n",
      "Epoch [27/85] Batch 790/938 Loss D: 0.3359, Loss G: 1.9856\n",
      "Epoch [27/85] Batch 800/938 Loss D: 0.2741, Loss G: 2.8669\n",
      "Epoch [27/85] Batch 810/938 Loss D: 0.3098, Loss G: 2.3638\n",
      "Epoch [27/85] Batch 820/938 Loss D: 0.2899, Loss G: 3.0596\n",
      "Epoch [27/85] Batch 830/938 Loss D: 0.3368, Loss G: 2.6909\n",
      "Epoch [27/85] Batch 840/938 Loss D: 0.2530, Loss G: 2.3623\n",
      "Epoch [27/85] Batch 850/938 Loss D: 0.3421, Loss G: 1.7090\n",
      "Epoch [27/85] Batch 860/938 Loss D: 0.2144, Loss G: 2.4837\n",
      "Epoch [27/85] Batch 870/938 Loss D: 0.1811, Loss G: 2.6726\n",
      "Epoch [27/85] Batch 880/938 Loss D: 0.2366, Loss G: 2.4100\n",
      "Epoch [27/85] Batch 890/938 Loss D: 0.3532, Loss G: 1.9524\n",
      "Epoch [27/85] Batch 900/938 Loss D: 0.3490, Loss G: 2.1308\n",
      "Epoch [27/85] Batch 910/938 Loss D: 0.2785, Loss G: 2.3528\n",
      "Epoch [27/85] Batch 920/938 Loss D: 0.3099, Loss G: 2.3738\n",
      "Epoch [27/85] Batch 930/938 Loss D: 0.1961, Loss G: 2.3152\n",
      "Epoch [28/85] Batch 0/938 Loss D: 0.1964, Loss G: 2.2600\n",
      "Epoch [28/85] Batch 10/938 Loss D: 0.2654, Loss G: 2.3912\n",
      "Epoch [28/85] Batch 20/938 Loss D: 0.3618, Loss G: 2.5338\n",
      "Epoch [28/85] Batch 30/938 Loss D: 0.3257, Loss G: 2.5073\n",
      "Epoch [28/85] Batch 40/938 Loss D: 0.2652, Loss G: 2.9200\n",
      "Epoch [28/85] Batch 50/938 Loss D: 0.2849, Loss G: 2.4084\n",
      "Epoch [28/85] Batch 60/938 Loss D: 0.2825, Loss G: 2.7456\n",
      "Epoch [28/85] Batch 70/938 Loss D: 0.3372, Loss G: 2.2848\n",
      "Epoch [28/85] Batch 80/938 Loss D: 0.2379, Loss G: 2.1509\n",
      "Epoch [28/85] Batch 90/938 Loss D: 0.2844, Loss G: 2.4084\n",
      "Epoch [28/85] Batch 100/938 Loss D: 0.2367, Loss G: 2.2405\n",
      "Epoch [28/85] Batch 110/938 Loss D: 0.3519, Loss G: 1.8527\n",
      "Epoch [28/85] Batch 120/938 Loss D: 0.3312, Loss G: 2.4187\n",
      "Epoch [28/85] Batch 130/938 Loss D: 0.2494, Loss G: 3.1509\n",
      "Epoch [28/85] Batch 140/938 Loss D: 0.3276, Loss G: 2.6882\n",
      "Epoch [28/85] Batch 150/938 Loss D: 0.2430, Loss G: 2.2967\n",
      "Epoch [28/85] Batch 160/938 Loss D: 0.4147, Loss G: 2.6138\n",
      "Epoch [28/85] Batch 170/938 Loss D: 0.3478, Loss G: 1.8753\n",
      "Epoch [28/85] Batch 180/938 Loss D: 0.3178, Loss G: 2.4020\n",
      "Epoch [28/85] Batch 190/938 Loss D: 0.2866, Loss G: 2.4728\n",
      "Epoch [28/85] Batch 200/938 Loss D: 0.2172, Loss G: 2.8068\n",
      "Epoch [28/85] Batch 210/938 Loss D: 0.2707, Loss G: 1.9997\n",
      "Epoch [28/85] Batch 220/938 Loss D: 0.2238, Loss G: 2.2213\n",
      "Epoch [28/85] Batch 230/938 Loss D: 0.2650, Loss G: 2.6451\n",
      "Epoch [28/85] Batch 240/938 Loss D: 0.3280, Loss G: 2.0481\n",
      "Epoch [28/85] Batch 250/938 Loss D: 0.2656, Loss G: 2.4582\n",
      "Epoch [28/85] Batch 260/938 Loss D: 0.2636, Loss G: 2.4755\n",
      "Epoch [28/85] Batch 270/938 Loss D: 0.2781, Loss G: 2.4151\n",
      "Epoch [28/85] Batch 280/938 Loss D: 0.3154, Loss G: 2.4797\n",
      "Epoch [28/85] Batch 290/938 Loss D: 0.2380, Loss G: 2.3816\n",
      "Epoch [28/85] Batch 300/938 Loss D: 0.1974, Loss G: 2.7438\n",
      "Epoch [28/85] Batch 310/938 Loss D: 0.3260, Loss G: 2.0723\n",
      "Epoch [28/85] Batch 320/938 Loss D: 0.2907, Loss G: 1.8486\n",
      "Epoch [28/85] Batch 330/938 Loss D: 0.2276, Loss G: 2.2972\n",
      "Epoch [28/85] Batch 340/938 Loss D: 0.1957, Loss G: 2.3972\n",
      "Epoch [28/85] Batch 350/938 Loss D: 0.2562, Loss G: 2.5618\n",
      "Epoch [28/85] Batch 360/938 Loss D: 0.2925, Loss G: 2.0708\n",
      "Epoch [28/85] Batch 370/938 Loss D: 0.2343, Loss G: 2.3068\n",
      "Epoch [28/85] Batch 380/938 Loss D: 0.2206, Loss G: 2.7228\n",
      "Epoch [28/85] Batch 390/938 Loss D: 0.3528, Loss G: 2.4605\n",
      "Epoch [28/85] Batch 400/938 Loss D: 0.2685, Loss G: 2.7527\n",
      "Epoch [28/85] Batch 410/938 Loss D: 0.2525, Loss G: 2.4784\n",
      "Epoch [28/85] Batch 420/938 Loss D: 0.2627, Loss G: 2.5348\n",
      "Epoch [28/85] Batch 430/938 Loss D: 0.3509, Loss G: 2.4957\n",
      "Epoch [28/85] Batch 440/938 Loss D: 0.3010, Loss G: 1.9066\n",
      "Epoch [28/85] Batch 450/938 Loss D: 0.2852, Loss G: 2.4625\n",
      "Epoch [28/85] Batch 460/938 Loss D: 0.2857, Loss G: 2.8263\n",
      "Epoch [28/85] Batch 470/938 Loss D: 0.1691, Loss G: 3.1202\n",
      "Epoch [28/85] Batch 480/938 Loss D: 0.2062, Loss G: 2.5790\n",
      "Epoch [28/85] Batch 490/938 Loss D: 0.2576, Loss G: 2.0731\n",
      "Epoch [28/85] Batch 500/938 Loss D: 0.2363, Loss G: 2.1401\n",
      "Epoch [28/85] Batch 510/938 Loss D: 0.2537, Loss G: 1.9350\n",
      "Epoch [28/85] Batch 520/938 Loss D: 0.2086, Loss G: 2.1760\n",
      "Epoch [28/85] Batch 530/938 Loss D: 0.2366, Loss G: 2.9462\n",
      "Epoch [28/85] Batch 540/938 Loss D: 0.2528, Loss G: 2.8198\n",
      "Epoch [28/85] Batch 550/938 Loss D: 0.3879, Loss G: 1.9182\n",
      "Epoch [28/85] Batch 560/938 Loss D: 0.2083, Loss G: 2.3639\n",
      "Epoch [28/85] Batch 570/938 Loss D: 0.2295, Loss G: 2.1537\n",
      "Epoch [28/85] Batch 580/938 Loss D: 0.3428, Loss G: 2.2793\n",
      "Epoch [28/85] Batch 590/938 Loss D: 0.3146, Loss G: 2.7361\n",
      "Epoch [28/85] Batch 600/938 Loss D: 0.2718, Loss G: 2.4273\n",
      "Epoch [28/85] Batch 610/938 Loss D: 0.3431, Loss G: 2.0989\n",
      "Epoch [28/85] Batch 620/938 Loss D: 0.2425, Loss G: 2.3723\n",
      "Epoch [28/85] Batch 630/938 Loss D: 0.4552, Loss G: 1.4479\n",
      "Epoch [28/85] Batch 640/938 Loss D: 0.1606, Loss G: 2.2008\n",
      "Epoch [28/85] Batch 650/938 Loss D: 0.3024, Loss G: 2.3171\n",
      "Epoch [28/85] Batch 660/938 Loss D: 0.3872, Loss G: 1.7324\n",
      "Epoch [28/85] Batch 670/938 Loss D: 0.2405, Loss G: 2.2585\n",
      "Epoch [28/85] Batch 680/938 Loss D: 0.3576, Loss G: 2.5511\n",
      "Epoch [28/85] Batch 690/938 Loss D: 0.2566, Loss G: 2.4159\n",
      "Epoch [28/85] Batch 700/938 Loss D: 0.2614, Loss G: 2.1610\n",
      "Epoch [28/85] Batch 710/938 Loss D: 0.2640, Loss G: 3.1170\n",
      "Epoch [28/85] Batch 720/938 Loss D: 0.3977, Loss G: 2.1455\n",
      "Epoch [28/85] Batch 730/938 Loss D: 0.3244, Loss G: 2.1182\n",
      "Epoch [28/85] Batch 740/938 Loss D: 0.2593, Loss G: 2.7442\n",
      "Epoch [28/85] Batch 750/938 Loss D: 0.2752, Loss G: 2.3303\n",
      "Epoch [28/85] Batch 760/938 Loss D: 0.2132, Loss G: 2.5549\n",
      "Epoch [28/85] Batch 770/938 Loss D: 0.2350, Loss G: 2.8787\n",
      "Epoch [28/85] Batch 780/938 Loss D: 0.3200, Loss G: 2.7475\n",
      "Epoch [28/85] Batch 790/938 Loss D: 0.4285, Loss G: 1.9726\n",
      "Epoch [28/85] Batch 800/938 Loss D: 0.3473, Loss G: 2.3997\n",
      "Epoch [28/85] Batch 810/938 Loss D: 0.3001, Loss G: 2.3661\n",
      "Epoch [28/85] Batch 820/938 Loss D: 0.1700, Loss G: 3.1952\n",
      "Epoch [28/85] Batch 830/938 Loss D: 0.2935, Loss G: 2.0633\n",
      "Epoch [28/85] Batch 840/938 Loss D: 0.3800, Loss G: 1.8629\n",
      "Epoch [28/85] Batch 850/938 Loss D: 0.2691, Loss G: 1.9794\n",
      "Epoch [28/85] Batch 860/938 Loss D: 0.2908, Loss G: 2.2653\n",
      "Epoch [28/85] Batch 870/938 Loss D: 0.3738, Loss G: 1.9502\n",
      "Epoch [28/85] Batch 880/938 Loss D: 0.2916, Loss G: 2.0521\n",
      "Epoch [28/85] Batch 890/938 Loss D: 0.2738, Loss G: 2.2878\n",
      "Epoch [28/85] Batch 900/938 Loss D: 0.2187, Loss G: 2.5968\n",
      "Epoch [28/85] Batch 910/938 Loss D: 0.2098, Loss G: 3.7341\n",
      "Epoch [28/85] Batch 920/938 Loss D: 0.3980, Loss G: 2.0476\n",
      "Epoch [28/85] Batch 930/938 Loss D: 0.2921, Loss G: 1.8279\n",
      "Epoch [29/85] Batch 0/938 Loss D: 0.2965, Loss G: 2.4895\n",
      "Epoch [29/85] Batch 10/938 Loss D: 0.3468, Loss G: 2.4703\n",
      "Epoch [29/85] Batch 20/938 Loss D: 0.2158, Loss G: 2.5079\n",
      "Epoch [29/85] Batch 30/938 Loss D: 0.2773, Loss G: 2.1772\n",
      "Epoch [29/85] Batch 40/938 Loss D: 0.2062, Loss G: 2.3728\n",
      "Epoch [29/85] Batch 50/938 Loss D: 0.2552, Loss G: 2.5169\n",
      "Epoch [29/85] Batch 60/938 Loss D: 0.2775, Loss G: 2.1359\n",
      "Epoch [29/85] Batch 70/938 Loss D: 0.2979, Loss G: 2.3335\n",
      "Epoch [29/85] Batch 80/938 Loss D: 0.2673, Loss G: 1.9648\n",
      "Epoch [29/85] Batch 90/938 Loss D: 0.2787, Loss G: 2.4741\n",
      "Epoch [29/85] Batch 100/938 Loss D: 0.3575, Loss G: 2.0381\n",
      "Epoch [29/85] Batch 110/938 Loss D: 0.2724, Loss G: 2.3878\n",
      "Epoch [29/85] Batch 120/938 Loss D: 0.3159, Loss G: 2.2985\n",
      "Epoch [29/85] Batch 130/938 Loss D: 0.2333, Loss G: 2.2516\n",
      "Epoch [29/85] Batch 140/938 Loss D: 0.3326, Loss G: 2.1670\n",
      "Epoch [29/85] Batch 150/938 Loss D: 0.2924, Loss G: 2.2088\n",
      "Epoch [29/85] Batch 160/938 Loss D: 0.2919, Loss G: 2.0408\n",
      "Epoch [29/85] Batch 170/938 Loss D: 0.3344, Loss G: 2.0570\n",
      "Epoch [29/85] Batch 180/938 Loss D: 0.2412, Loss G: 2.4386\n",
      "Epoch [29/85] Batch 190/938 Loss D: 0.2653, Loss G: 2.2025\n",
      "Epoch [29/85] Batch 200/938 Loss D: 0.3085, Loss G: 2.3325\n",
      "Epoch [29/85] Batch 210/938 Loss D: 0.0972, Loss G: 3.3457\n",
      "Epoch [29/85] Batch 220/938 Loss D: 0.2359, Loss G: 2.1550\n",
      "Epoch [29/85] Batch 230/938 Loss D: 0.1846, Loss G: 2.2130\n",
      "Epoch [29/85] Batch 240/938 Loss D: 0.2993, Loss G: 2.4005\n",
      "Epoch [29/85] Batch 250/938 Loss D: 0.2982, Loss G: 2.5590\n",
      "Epoch [29/85] Batch 260/938 Loss D: 0.2862, Loss G: 2.9046\n",
      "Epoch [29/85] Batch 270/938 Loss D: 0.4160, Loss G: 2.1521\n",
      "Epoch [29/85] Batch 280/938 Loss D: 0.2884, Loss G: 2.1160\n",
      "Epoch [29/85] Batch 290/938 Loss D: 0.3667, Loss G: 1.7718\n",
      "Epoch [29/85] Batch 300/938 Loss D: 0.3440, Loss G: 1.8896\n",
      "Epoch [29/85] Batch 310/938 Loss D: 0.3324, Loss G: 1.9290\n",
      "Epoch [29/85] Batch 320/938 Loss D: 0.3857, Loss G: 2.8561\n",
      "Epoch [29/85] Batch 330/938 Loss D: 0.2518, Loss G: 3.3938\n",
      "Epoch [29/85] Batch 340/938 Loss D: 0.3652, Loss G: 2.9604\n",
      "Epoch [29/85] Batch 350/938 Loss D: 0.2323, Loss G: 2.9702\n",
      "Epoch [29/85] Batch 360/938 Loss D: 0.2930, Loss G: 2.5688\n",
      "Epoch [29/85] Batch 370/938 Loss D: 0.2071, Loss G: 2.9265\n",
      "Epoch [29/85] Batch 380/938 Loss D: 0.1565, Loss G: 3.1120\n",
      "Epoch [29/85] Batch 390/938 Loss D: 0.1920, Loss G: 2.9104\n",
      "Epoch [29/85] Batch 400/938 Loss D: 0.2318, Loss G: 2.6386\n",
      "Epoch [29/85] Batch 410/938 Loss D: 0.2887, Loss G: 2.4947\n",
      "Epoch [29/85] Batch 420/938 Loss D: 0.1959, Loss G: 2.7492\n",
      "Epoch [29/85] Batch 430/938 Loss D: 0.2186, Loss G: 2.5911\n",
      "Epoch [29/85] Batch 440/938 Loss D: 0.3431, Loss G: 1.8780\n",
      "Epoch [29/85] Batch 450/938 Loss D: 0.2564, Loss G: 2.5418\n",
      "Epoch [29/85] Batch 460/938 Loss D: 0.2411, Loss G: 2.2104\n",
      "Epoch [29/85] Batch 470/938 Loss D: 0.2138, Loss G: 3.0110\n",
      "Epoch [29/85] Batch 480/938 Loss D: 0.2444, Loss G: 2.9835\n",
      "Epoch [29/85] Batch 490/938 Loss D: 0.2505, Loss G: 2.9270\n",
      "Epoch [29/85] Batch 500/938 Loss D: 0.3089, Loss G: 1.7790\n",
      "Epoch [29/85] Batch 510/938 Loss D: 0.2289, Loss G: 2.3682\n",
      "Epoch [29/85] Batch 520/938 Loss D: 0.2968, Loss G: 1.9967\n",
      "Epoch [29/85] Batch 530/938 Loss D: 0.2356, Loss G: 2.6403\n",
      "Epoch [29/85] Batch 540/938 Loss D: 0.1992, Loss G: 2.5796\n",
      "Epoch [29/85] Batch 550/938 Loss D: 0.1625, Loss G: 2.6390\n",
      "Epoch [29/85] Batch 560/938 Loss D: 0.2593, Loss G: 1.9012\n",
      "Epoch [29/85] Batch 570/938 Loss D: 0.3093, Loss G: 1.9359\n",
      "Epoch [29/85] Batch 580/938 Loss D: 0.2841, Loss G: 1.8534\n",
      "Epoch [29/85] Batch 590/938 Loss D: 0.3710, Loss G: 1.4936\n",
      "Epoch [29/85] Batch 600/938 Loss D: 0.1769, Loss G: 2.4873\n",
      "Epoch [29/85] Batch 610/938 Loss D: 0.3321, Loss G: 2.1301\n",
      "Epoch [29/85] Batch 620/938 Loss D: 0.3685, Loss G: 2.2019\n",
      "Epoch [29/85] Batch 630/938 Loss D: 0.2581, Loss G: 2.4779\n",
      "Epoch [29/85] Batch 640/938 Loss D: 0.2288, Loss G: 2.5527\n",
      "Epoch [29/85] Batch 650/938 Loss D: 0.2535, Loss G: 2.1951\n",
      "Epoch [29/85] Batch 660/938 Loss D: 0.3194, Loss G: 2.1376\n",
      "Epoch [29/85] Batch 670/938 Loss D: 0.3118, Loss G: 2.6154\n",
      "Epoch [29/85] Batch 680/938 Loss D: 0.2985, Loss G: 2.8867\n",
      "Epoch [29/85] Batch 690/938 Loss D: 0.2333, Loss G: 2.4962\n",
      "Epoch [29/85] Batch 700/938 Loss D: 0.2586, Loss G: 2.4837\n",
      "Epoch [29/85] Batch 710/938 Loss D: 0.1955, Loss G: 2.5238\n",
      "Epoch [29/85] Batch 720/938 Loss D: 0.2869, Loss G: 2.2376\n",
      "Epoch [29/85] Batch 730/938 Loss D: 0.2871, Loss G: 2.2338\n",
      "Epoch [29/85] Batch 740/938 Loss D: 0.2401, Loss G: 2.6958\n",
      "Epoch [29/85] Batch 750/938 Loss D: 0.1967, Loss G: 2.5029\n",
      "Epoch [29/85] Batch 760/938 Loss D: 0.1995, Loss G: 2.8050\n",
      "Epoch [29/85] Batch 770/938 Loss D: 0.2957, Loss G: 2.1580\n",
      "Epoch [29/85] Batch 780/938 Loss D: 0.2308, Loss G: 1.8992\n",
      "Epoch [29/85] Batch 790/938 Loss D: 0.2338, Loss G: 2.1133\n",
      "Epoch [29/85] Batch 800/938 Loss D: 0.4158, Loss G: 2.0389\n",
      "Epoch [29/85] Batch 810/938 Loss D: 0.2009, Loss G: 2.6047\n",
      "Epoch [29/85] Batch 820/938 Loss D: 0.2819, Loss G: 2.2314\n",
      "Epoch [29/85] Batch 830/938 Loss D: 0.1724, Loss G: 3.1375\n",
      "Epoch [29/85] Batch 840/938 Loss D: 0.3836, Loss G: 1.9183\n",
      "Epoch [29/85] Batch 850/938 Loss D: 0.2644, Loss G: 2.8943\n",
      "Epoch [29/85] Batch 860/938 Loss D: 0.3634, Loss G: 2.4689\n",
      "Epoch [29/85] Batch 870/938 Loss D: 0.2952, Loss G: 2.4175\n",
      "Epoch [29/85] Batch 880/938 Loss D: 0.2986, Loss G: 3.5468\n",
      "Epoch [29/85] Batch 890/938 Loss D: 0.3386, Loss G: 2.5676\n",
      "Epoch [29/85] Batch 900/938 Loss D: 0.2896, Loss G: 2.1198\n",
      "Epoch [29/85] Batch 910/938 Loss D: 0.3502, Loss G: 2.0807\n",
      "Epoch [29/85] Batch 920/938 Loss D: 0.2684, Loss G: 1.9091\n",
      "Epoch [29/85] Batch 930/938 Loss D: 0.3290, Loss G: 2.0632\n",
      "Epoch [30/85] Batch 0/938 Loss D: 0.2923, Loss G: 2.1805\n",
      "Epoch [30/85] Batch 10/938 Loss D: 0.2797, Loss G: 2.0132\n",
      "Epoch [30/85] Batch 20/938 Loss D: 0.3188, Loss G: 1.7187\n",
      "Epoch [30/85] Batch 30/938 Loss D: 0.1923, Loss G: 2.5433\n",
      "Epoch [30/85] Batch 40/938 Loss D: 0.2734, Loss G: 2.3161\n",
      "Epoch [30/85] Batch 50/938 Loss D: 0.3210, Loss G: 2.1219\n",
      "Epoch [30/85] Batch 60/938 Loss D: 0.3593, Loss G: 1.6180\n",
      "Epoch [30/85] Batch 70/938 Loss D: 0.2436, Loss G: 2.3299\n",
      "Epoch [30/85] Batch 80/938 Loss D: 0.2647, Loss G: 2.5323\n",
      "Epoch [30/85] Batch 90/938 Loss D: 0.3499, Loss G: 2.2107\n",
      "Epoch [30/85] Batch 100/938 Loss D: 0.2479, Loss G: 2.9300\n",
      "Epoch [30/85] Batch 110/938 Loss D: 0.2615, Loss G: 2.6322\n",
      "Epoch [30/85] Batch 120/938 Loss D: 0.2973, Loss G: 2.6917\n",
      "Epoch [30/85] Batch 130/938 Loss D: 0.2493, Loss G: 1.8221\n",
      "Epoch [30/85] Batch 140/938 Loss D: 0.2848, Loss G: 1.9747\n",
      "Epoch [30/85] Batch 150/938 Loss D: 0.2620, Loss G: 2.2462\n",
      "Epoch [30/85] Batch 160/938 Loss D: 0.3376, Loss G: 1.6387\n",
      "Epoch [30/85] Batch 170/938 Loss D: 0.1984, Loss G: 2.4653\n",
      "Epoch [30/85] Batch 180/938 Loss D: 0.3112, Loss G: 2.8830\n",
      "Epoch [30/85] Batch 190/938 Loss D: 0.3128, Loss G: 2.4902\n",
      "Epoch [30/85] Batch 200/938 Loss D: 0.2993, Loss G: 2.3030\n",
      "Epoch [30/85] Batch 210/938 Loss D: 0.3332, Loss G: 1.5889\n",
      "Epoch [30/85] Batch 220/938 Loss D: 0.3166, Loss G: 1.6625\n",
      "Epoch [30/85] Batch 230/938 Loss D: 0.1998, Loss G: 3.4308\n",
      "Epoch [30/85] Batch 240/938 Loss D: 0.4058, Loss G: 2.6486\n",
      "Epoch [30/85] Batch 250/938 Loss D: 0.3399, Loss G: 3.3979\n",
      "Epoch [30/85] Batch 260/938 Loss D: 0.2453, Loss G: 2.4506\n",
      "Epoch [30/85] Batch 270/938 Loss D: 0.3450, Loss G: 2.0741\n",
      "Epoch [30/85] Batch 280/938 Loss D: 0.2255, Loss G: 2.9267\n",
      "Epoch [30/85] Batch 290/938 Loss D: 0.2571, Loss G: 2.4488\n",
      "Epoch [30/85] Batch 300/938 Loss D: 0.3030, Loss G: 2.4741\n",
      "Epoch [30/85] Batch 310/938 Loss D: 0.3730, Loss G: 2.3355\n",
      "Epoch [30/85] Batch 320/938 Loss D: 0.2274, Loss G: 2.2576\n",
      "Epoch [30/85] Batch 330/938 Loss D: 0.2034, Loss G: 2.6742\n",
      "Epoch [30/85] Batch 340/938 Loss D: 0.3349, Loss G: 2.0575\n",
      "Epoch [30/85] Batch 350/938 Loss D: 0.2633, Loss G: 2.5405\n",
      "Epoch [30/85] Batch 360/938 Loss D: 0.2344, Loss G: 2.5177\n",
      "Epoch [30/85] Batch 370/938 Loss D: 0.3316, Loss G: 2.7829\n",
      "Epoch [30/85] Batch 380/938 Loss D: 0.2554, Loss G: 3.0552\n",
      "Epoch [30/85] Batch 390/938 Loss D: 0.2294, Loss G: 2.8446\n",
      "Epoch [30/85] Batch 400/938 Loss D: 0.1952, Loss G: 2.8286\n",
      "Epoch [30/85] Batch 410/938 Loss D: 0.2794, Loss G: 1.8362\n",
      "Epoch [30/85] Batch 420/938 Loss D: 0.4142, Loss G: 1.4396\n",
      "Epoch [30/85] Batch 430/938 Loss D: 0.3141, Loss G: 1.6134\n",
      "Epoch [30/85] Batch 440/938 Loss D: 0.3264, Loss G: 1.6537\n",
      "Epoch [30/85] Batch 450/938 Loss D: 0.1610, Loss G: 2.9198\n",
      "Epoch [30/85] Batch 460/938 Loss D: 0.2818, Loss G: 2.1053\n",
      "Epoch [30/85] Batch 470/938 Loss D: 0.2004, Loss G: 2.4102\n",
      "Epoch [30/85] Batch 480/938 Loss D: 0.2156, Loss G: 2.0810\n",
      "Epoch [30/85] Batch 490/938 Loss D: 0.4523, Loss G: 2.3170\n",
      "Epoch [30/85] Batch 500/938 Loss D: 0.1703, Loss G: 2.9433\n",
      "Epoch [30/85] Batch 510/938 Loss D: 0.2456, Loss G: 2.8495\n",
      "Epoch [30/85] Batch 520/938 Loss D: 0.2720, Loss G: 2.3921\n",
      "Epoch [30/85] Batch 530/938 Loss D: 0.3126, Loss G: 1.9481\n",
      "Epoch [30/85] Batch 540/938 Loss D: 0.3528, Loss G: 2.0350\n",
      "Epoch [30/85] Batch 550/938 Loss D: 0.2743, Loss G: 2.3829\n",
      "Epoch [30/85] Batch 560/938 Loss D: 0.2955, Loss G: 2.4086\n",
      "Epoch [30/85] Batch 570/938 Loss D: 0.1965, Loss G: 2.5874\n",
      "Epoch [30/85] Batch 580/938 Loss D: 0.1970, Loss G: 2.3361\n",
      "Epoch [30/85] Batch 590/938 Loss D: 0.2736, Loss G: 2.1318\n",
      "Epoch [30/85] Batch 600/938 Loss D: 0.2886, Loss G: 2.2339\n",
      "Epoch [30/85] Batch 610/938 Loss D: 0.2308, Loss G: 2.5810\n",
      "Epoch [30/85] Batch 620/938 Loss D: 0.3241, Loss G: 2.3751\n",
      "Epoch [30/85] Batch 630/938 Loss D: 0.3007, Loss G: 2.5606\n",
      "Epoch [30/85] Batch 640/938 Loss D: 0.1767, Loss G: 2.5268\n",
      "Epoch [30/85] Batch 650/938 Loss D: 0.2906, Loss G: 2.0322\n",
      "Epoch [30/85] Batch 660/938 Loss D: 0.1826, Loss G: 2.4656\n",
      "Epoch [30/85] Batch 670/938 Loss D: 0.2497, Loss G: 2.5993\n",
      "Epoch [30/85] Batch 680/938 Loss D: 0.2565, Loss G: 2.7713\n",
      "Epoch [30/85] Batch 690/938 Loss D: 0.2712, Loss G: 2.2843\n",
      "Epoch [30/85] Batch 700/938 Loss D: 0.3852, Loss G: 1.7760\n",
      "Epoch [30/85] Batch 710/938 Loss D: 0.3239, Loss G: 2.0045\n",
      "Epoch [30/85] Batch 720/938 Loss D: 0.2338, Loss G: 1.9949\n",
      "Epoch [30/85] Batch 730/938 Loss D: 0.2447, Loss G: 1.8002\n",
      "Epoch [30/85] Batch 740/938 Loss D: 0.2042, Loss G: 2.6106\n",
      "Epoch [30/85] Batch 750/938 Loss D: 0.2884, Loss G: 2.4321\n",
      "Epoch [30/85] Batch 760/938 Loss D: 0.2111, Loss G: 2.5923\n",
      "Epoch [30/85] Batch 770/938 Loss D: 0.2242, Loss G: 2.6803\n",
      "Epoch [30/85] Batch 780/938 Loss D: 0.2649, Loss G: 2.7597\n",
      "Epoch [30/85] Batch 790/938 Loss D: 0.3059, Loss G: 2.2224\n",
      "Epoch [30/85] Batch 800/938 Loss D: 0.2582, Loss G: 2.1554\n",
      "Epoch [30/85] Batch 810/938 Loss D: 0.2622, Loss G: 2.6738\n",
      "Epoch [30/85] Batch 820/938 Loss D: 0.2493, Loss G: 2.5984\n",
      "Epoch [30/85] Batch 830/938 Loss D: 0.2514, Loss G: 2.5291\n",
      "Epoch [30/85] Batch 840/938 Loss D: 0.4239, Loss G: 2.4302\n",
      "Epoch [30/85] Batch 850/938 Loss D: 0.2409, Loss G: 2.7285\n",
      "Epoch [30/85] Batch 860/938 Loss D: 0.2248, Loss G: 2.6828\n",
      "Epoch [30/85] Batch 870/938 Loss D: 0.2768, Loss G: 2.3286\n",
      "Epoch [30/85] Batch 880/938 Loss D: 0.2436, Loss G: 2.4807\n",
      "Epoch [30/85] Batch 890/938 Loss D: 0.2420, Loss G: 2.4046\n",
      "Epoch [30/85] Batch 900/938 Loss D: 0.2760, Loss G: 2.1002\n",
      "Epoch [30/85] Batch 910/938 Loss D: 0.2931, Loss G: 2.0489\n",
      "Epoch [30/85] Batch 920/938 Loss D: 0.2281, Loss G: 2.3415\n",
      "Epoch [30/85] Batch 930/938 Loss D: 0.3251, Loss G: 2.0770\n",
      "Epoch [31/85] Batch 0/938 Loss D: 0.2314, Loss G: 2.1701\n",
      "Epoch [31/85] Batch 10/938 Loss D: 0.2383, Loss G: 1.8860\n",
      "Epoch [31/85] Batch 20/938 Loss D: 0.2927, Loss G: 2.2814\n",
      "Epoch [31/85] Batch 30/938 Loss D: 0.3777, Loss G: 2.5633\n",
      "Epoch [31/85] Batch 40/938 Loss D: 0.2845, Loss G: 2.2068\n",
      "Epoch [31/85] Batch 50/938 Loss D: 0.4751, Loss G: 2.2397\n",
      "Epoch [31/85] Batch 60/938 Loss D: 0.3016, Loss G: 2.7650\n",
      "Epoch [31/85] Batch 70/938 Loss D: 0.2146, Loss G: 2.6885\n",
      "Epoch [31/85] Batch 80/938 Loss D: 0.2929, Loss G: 2.3096\n",
      "Epoch [31/85] Batch 90/938 Loss D: 0.3884, Loss G: 1.8608\n",
      "Epoch [31/85] Batch 100/938 Loss D: 0.2569, Loss G: 2.3467\n",
      "Epoch [31/85] Batch 110/938 Loss D: 0.2842, Loss G: 2.1965\n",
      "Epoch [31/85] Batch 120/938 Loss D: 0.3580, Loss G: 2.4032\n",
      "Epoch [31/85] Batch 130/938 Loss D: 0.2730, Loss G: 2.8405\n",
      "Epoch [31/85] Batch 140/938 Loss D: 0.3978, Loss G: 2.4075\n",
      "Epoch [31/85] Batch 150/938 Loss D: 0.2571, Loss G: 2.4831\n",
      "Epoch [31/85] Batch 160/938 Loss D: 0.2678, Loss G: 2.4499\n",
      "Epoch [31/85] Batch 170/938 Loss D: 0.2223, Loss G: 2.3560\n",
      "Epoch [31/85] Batch 180/938 Loss D: 0.2297, Loss G: 3.1065\n",
      "Epoch [31/85] Batch 190/938 Loss D: 0.2419, Loss G: 2.0886\n",
      "Epoch [31/85] Batch 200/938 Loss D: 0.2730, Loss G: 2.2465\n",
      "Epoch [31/85] Batch 210/938 Loss D: 0.3820, Loss G: 2.4047\n",
      "Epoch [31/85] Batch 220/938 Loss D: 0.1676, Loss G: 3.0432\n",
      "Epoch [31/85] Batch 230/938 Loss D: 0.3166, Loss G: 2.0987\n",
      "Epoch [31/85] Batch 240/938 Loss D: 0.3548, Loss G: 1.7775\n",
      "Epoch [31/85] Batch 250/938 Loss D: 0.2506, Loss G: 2.3646\n",
      "Epoch [31/85] Batch 260/938 Loss D: 0.2662, Loss G: 2.2717\n",
      "Epoch [31/85] Batch 270/938 Loss D: 0.2944, Loss G: 2.5391\n",
      "Epoch [31/85] Batch 280/938 Loss D: 0.3683, Loss G: 1.7812\n",
      "Epoch [31/85] Batch 290/938 Loss D: 0.2572, Loss G: 2.3578\n",
      "Epoch [31/85] Batch 300/938 Loss D: 0.2633, Loss G: 1.9415\n",
      "Epoch [31/85] Batch 310/938 Loss D: 0.3679, Loss G: 2.3108\n",
      "Epoch [31/85] Batch 320/938 Loss D: 0.3094, Loss G: 2.1932\n",
      "Epoch [31/85] Batch 330/938 Loss D: 0.3266, Loss G: 2.3753\n",
      "Epoch [31/85] Batch 340/938 Loss D: 0.3348, Loss G: 2.1930\n",
      "Epoch [31/85] Batch 350/938 Loss D: 0.3319, Loss G: 1.7857\n",
      "Epoch [31/85] Batch 360/938 Loss D: 0.2603, Loss G: 1.7973\n",
      "Epoch [31/85] Batch 370/938 Loss D: 0.2850, Loss G: 2.1557\n",
      "Epoch [31/85] Batch 380/938 Loss D: 0.2324, Loss G: 2.9390\n",
      "Epoch [31/85] Batch 390/938 Loss D: 0.3040, Loss G: 2.5710\n",
      "Epoch [31/85] Batch 400/938 Loss D: 0.3057, Loss G: 2.1098\n",
      "Epoch [31/85] Batch 410/938 Loss D: 0.2032, Loss G: 2.8448\n",
      "Epoch [31/85] Batch 420/938 Loss D: 0.3627, Loss G: 2.2657\n",
      "Epoch [31/85] Batch 430/938 Loss D: 0.3637, Loss G: 2.0980\n",
      "Epoch [31/85] Batch 440/938 Loss D: 0.2946, Loss G: 2.0572\n",
      "Epoch [31/85] Batch 450/938 Loss D: 0.2999, Loss G: 2.1157\n",
      "Epoch [31/85] Batch 460/938 Loss D: 0.2896, Loss G: 2.1425\n",
      "Epoch [31/85] Batch 470/938 Loss D: 0.3326, Loss G: 2.4318\n",
      "Epoch [31/85] Batch 480/938 Loss D: 0.2803, Loss G: 2.0828\n",
      "Epoch [31/85] Batch 490/938 Loss D: 0.2496, Loss G: 2.4558\n",
      "Epoch [31/85] Batch 500/938 Loss D: 0.2586, Loss G: 2.4736\n",
      "Epoch [31/85] Batch 510/938 Loss D: 0.3357, Loss G: 2.8145\n",
      "Epoch [31/85] Batch 520/938 Loss D: 0.3086, Loss G: 2.4699\n",
      "Epoch [31/85] Batch 530/938 Loss D: 0.2498, Loss G: 2.0401\n",
      "Epoch [31/85] Batch 540/938 Loss D: 0.2333, Loss G: 2.2815\n",
      "Epoch [31/85] Batch 550/938 Loss D: 0.3105, Loss G: 2.7421\n",
      "Epoch [31/85] Batch 560/938 Loss D: 0.3918, Loss G: 2.2908\n",
      "Epoch [31/85] Batch 570/938 Loss D: 0.3545, Loss G: 2.1380\n",
      "Epoch [31/85] Batch 580/938 Loss D: 0.2696, Loss G: 2.4183\n",
      "Epoch [31/85] Batch 590/938 Loss D: 0.3023, Loss G: 3.1832\n",
      "Epoch [31/85] Batch 600/938 Loss D: 0.2795, Loss G: 2.4241\n",
      "Epoch [31/85] Batch 610/938 Loss D: 0.2071, Loss G: 2.7543\n",
      "Epoch [31/85] Batch 620/938 Loss D: 0.2680, Loss G: 2.0735\n",
      "Epoch [31/85] Batch 630/938 Loss D: 0.3346, Loss G: 2.0629\n",
      "Epoch [31/85] Batch 640/938 Loss D: 0.4098, Loss G: 1.5325\n",
      "Epoch [31/85] Batch 650/938 Loss D: 0.2459, Loss G: 2.2336\n",
      "Epoch [31/85] Batch 660/938 Loss D: 0.2681, Loss G: 2.0855\n",
      "Epoch [31/85] Batch 670/938 Loss D: 0.3041, Loss G: 1.8494\n",
      "Epoch [31/85] Batch 680/938 Loss D: 0.3310, Loss G: 2.2917\n",
      "Epoch [31/85] Batch 690/938 Loss D: 0.1808, Loss G: 2.9344\n",
      "Epoch [31/85] Batch 700/938 Loss D: 0.2262, Loss G: 3.2097\n",
      "Epoch [31/85] Batch 710/938 Loss D: 0.2467, Loss G: 2.5787\n",
      "Epoch [31/85] Batch 720/938 Loss D: 0.2219, Loss G: 2.5797\n",
      "Epoch [31/85] Batch 730/938 Loss D: 0.3136, Loss G: 2.0521\n",
      "Epoch [31/85] Batch 740/938 Loss D: 0.2859, Loss G: 2.0802\n",
      "Epoch [31/85] Batch 750/938 Loss D: 0.2361, Loss G: 2.1499\n",
      "Epoch [31/85] Batch 760/938 Loss D: 0.2378, Loss G: 2.2790\n",
      "Epoch [31/85] Batch 770/938 Loss D: 0.2929, Loss G: 2.2532\n",
      "Epoch [31/85] Batch 780/938 Loss D: 0.2328, Loss G: 2.6688\n",
      "Epoch [31/85] Batch 790/938 Loss D: 0.3384, Loss G: 2.3785\n",
      "Epoch [31/85] Batch 800/938 Loss D: 0.2735, Loss G: 2.4497\n",
      "Epoch [31/85] Batch 810/938 Loss D: 0.2203, Loss G: 2.4029\n",
      "Epoch [31/85] Batch 820/938 Loss D: 0.4220, Loss G: 2.1538\n",
      "Epoch [31/85] Batch 830/938 Loss D: 0.2120, Loss G: 2.1873\n",
      "Epoch [31/85] Batch 840/938 Loss D: 0.2380, Loss G: 2.8648\n",
      "Epoch [31/85] Batch 850/938 Loss D: 0.2368, Loss G: 2.2627\n",
      "Epoch [31/85] Batch 860/938 Loss D: 0.3241, Loss G: 2.2537\n",
      "Epoch [31/85] Batch 870/938 Loss D: 0.3125, Loss G: 2.4654\n",
      "Epoch [31/85] Batch 880/938 Loss D: 0.3519, Loss G: 2.5694\n",
      "Epoch [31/85] Batch 890/938 Loss D: 0.2510, Loss G: 2.1972\n",
      "Epoch [31/85] Batch 900/938 Loss D: 0.3156, Loss G: 1.7683\n",
      "Epoch [31/85] Batch 910/938 Loss D: 0.2383, Loss G: 2.1368\n",
      "Epoch [31/85] Batch 920/938 Loss D: 0.4344, Loss G: 1.7015\n",
      "Epoch [31/85] Batch 930/938 Loss D: 0.3228, Loss G: 1.9290\n",
      "Epoch [32/85] Batch 0/938 Loss D: 0.2801, Loss G: 1.9709\n",
      "Epoch [32/85] Batch 10/938 Loss D: 0.2950, Loss G: 2.3258\n",
      "Epoch [32/85] Batch 20/938 Loss D: 0.3573, Loss G: 2.2316\n",
      "Epoch [32/85] Batch 30/938 Loss D: 0.2602, Loss G: 2.6797\n",
      "Epoch [32/85] Batch 40/938 Loss D: 0.2186, Loss G: 2.6608\n",
      "Epoch [32/85] Batch 50/938 Loss D: 0.2674, Loss G: 2.6591\n",
      "Epoch [32/85] Batch 60/938 Loss D: 0.3127, Loss G: 2.0915\n",
      "Epoch [32/85] Batch 70/938 Loss D: 0.3416, Loss G: 1.8080\n",
      "Epoch [32/85] Batch 80/938 Loss D: 0.2563, Loss G: 2.9160\n",
      "Epoch [32/85] Batch 90/938 Loss D: 0.3082, Loss G: 2.4360\n",
      "Epoch [32/85] Batch 100/938 Loss D: 0.2585, Loss G: 2.4304\n",
      "Epoch [32/85] Batch 110/938 Loss D: 0.1579, Loss G: 2.6875\n",
      "Epoch [32/85] Batch 120/938 Loss D: 0.2262, Loss G: 2.1654\n",
      "Epoch [32/85] Batch 130/938 Loss D: 0.3735, Loss G: 1.9273\n",
      "Epoch [32/85] Batch 140/938 Loss D: 0.3272, Loss G: 1.8758\n",
      "Epoch [32/85] Batch 150/938 Loss D: 0.2643, Loss G: 2.4239\n",
      "Epoch [32/85] Batch 160/938 Loss D: 0.3172, Loss G: 2.4846\n",
      "Epoch [32/85] Batch 170/938 Loss D: 0.2493, Loss G: 2.2656\n",
      "Epoch [32/85] Batch 180/938 Loss D: 0.2876, Loss G: 2.1947\n",
      "Epoch [32/85] Batch 190/938 Loss D: 0.2526, Loss G: 2.5923\n",
      "Epoch [32/85] Batch 200/938 Loss D: 0.2894, Loss G: 2.1646\n",
      "Epoch [32/85] Batch 210/938 Loss D: 0.2181, Loss G: 2.3993\n",
      "Epoch [32/85] Batch 220/938 Loss D: 0.2465, Loss G: 2.6581\n",
      "Epoch [32/85] Batch 230/938 Loss D: 0.2913, Loss G: 2.3645\n",
      "Epoch [32/85] Batch 240/938 Loss D: 0.2693, Loss G: 2.3029\n",
      "Epoch [32/85] Batch 250/938 Loss D: 0.2811, Loss G: 2.7789\n",
      "Epoch [32/85] Batch 260/938 Loss D: 0.2535, Loss G: 2.7966\n",
      "Epoch [32/85] Batch 270/938 Loss D: 0.3551, Loss G: 2.0152\n",
      "Epoch [32/85] Batch 280/938 Loss D: 0.1936, Loss G: 2.5661\n",
      "Epoch [32/85] Batch 290/938 Loss D: 0.3323, Loss G: 1.7770\n",
      "Epoch [32/85] Batch 300/938 Loss D: 0.3342, Loss G: 1.9041\n",
      "Epoch [32/85] Batch 310/938 Loss D: 0.2863, Loss G: 2.1411\n",
      "Epoch [32/85] Batch 320/938 Loss D: 0.2547, Loss G: 2.6766\n",
      "Epoch [32/85] Batch 330/938 Loss D: 0.3586, Loss G: 1.9271\n",
      "Epoch [32/85] Batch 340/938 Loss D: 0.2051, Loss G: 2.6707\n",
      "Epoch [32/85] Batch 350/938 Loss D: 0.3292, Loss G: 2.0613\n",
      "Epoch [32/85] Batch 360/938 Loss D: 0.3047, Loss G: 2.1370\n",
      "Epoch [32/85] Batch 370/938 Loss D: 0.2970, Loss G: 2.5566\n",
      "Epoch [32/85] Batch 380/938 Loss D: 0.3112, Loss G: 2.1657\n",
      "Epoch [32/85] Batch 390/938 Loss D: 0.2115, Loss G: 2.5699\n",
      "Epoch [32/85] Batch 400/938 Loss D: 0.2874, Loss G: 2.5629\n",
      "Epoch [32/85] Batch 410/938 Loss D: 0.3825, Loss G: 1.9840\n",
      "Epoch [32/85] Batch 420/938 Loss D: 0.4225, Loss G: 1.8013\n",
      "Epoch [32/85] Batch 430/938 Loss D: 0.2840, Loss G: 2.4151\n",
      "Epoch [32/85] Batch 440/938 Loss D: 0.2894, Loss G: 1.9496\n",
      "Epoch [32/85] Batch 450/938 Loss D: 0.3219, Loss G: 2.1165\n",
      "Epoch [32/85] Batch 460/938 Loss D: 0.2653, Loss G: 2.1846\n",
      "Epoch [32/85] Batch 470/938 Loss D: 0.4350, Loss G: 1.7038\n",
      "Epoch [32/85] Batch 480/938 Loss D: 0.3269, Loss G: 2.7623\n",
      "Epoch [32/85] Batch 490/938 Loss D: 0.2969, Loss G: 2.3182\n",
      "Epoch [32/85] Batch 500/938 Loss D: 0.3876, Loss G: 1.9578\n",
      "Epoch [32/85] Batch 510/938 Loss D: 0.3057, Loss G: 2.1483\n",
      "Epoch [32/85] Batch 520/938 Loss D: 0.2893, Loss G: 1.7074\n",
      "Epoch [32/85] Batch 530/938 Loss D: 0.2942, Loss G: 2.2230\n",
      "Epoch [32/85] Batch 540/938 Loss D: 0.1689, Loss G: 3.8001\n",
      "Epoch [32/85] Batch 550/938 Loss D: 0.3096, Loss G: 3.0344\n",
      "Epoch [32/85] Batch 560/938 Loss D: 0.3242, Loss G: 2.7259\n",
      "Epoch [32/85] Batch 570/938 Loss D: 0.3847, Loss G: 1.8789\n",
      "Epoch [32/85] Batch 580/938 Loss D: 0.3524, Loss G: 2.0020\n",
      "Epoch [32/85] Batch 590/938 Loss D: 0.2812, Loss G: 2.0621\n",
      "Epoch [32/85] Batch 600/938 Loss D: 0.2822, Loss G: 2.1051\n",
      "Epoch [32/85] Batch 610/938 Loss D: 0.2767, Loss G: 2.2528\n",
      "Epoch [32/85] Batch 620/938 Loss D: 0.4044, Loss G: 2.3571\n",
      "Epoch [32/85] Batch 630/938 Loss D: 0.3467, Loss G: 2.2085\n",
      "Epoch [32/85] Batch 640/938 Loss D: 0.3397, Loss G: 2.9088\n",
      "Epoch [32/85] Batch 650/938 Loss D: 0.2874, Loss G: 2.8585\n",
      "Epoch [32/85] Batch 660/938 Loss D: 0.3576, Loss G: 1.8011\n",
      "Epoch [32/85] Batch 670/938 Loss D: 0.2423, Loss G: 2.3324\n",
      "Epoch [32/85] Batch 680/938 Loss D: 0.3064, Loss G: 2.2707\n",
      "Epoch [32/85] Batch 690/938 Loss D: 0.2439, Loss G: 2.6505\n",
      "Epoch [32/85] Batch 700/938 Loss D: 0.2592, Loss G: 2.6767\n",
      "Epoch [32/85] Batch 710/938 Loss D: 0.2335, Loss G: 2.5712\n",
      "Epoch [32/85] Batch 720/938 Loss D: 0.2830, Loss G: 2.5752\n",
      "Epoch [32/85] Batch 730/938 Loss D: 0.3630, Loss G: 1.7803\n",
      "Epoch [32/85] Batch 740/938 Loss D: 0.2982, Loss G: 2.7376\n",
      "Epoch [32/85] Batch 750/938 Loss D: 0.2268, Loss G: 2.5302\n",
      "Epoch [32/85] Batch 760/938 Loss D: 0.3706, Loss G: 2.1744\n",
      "Epoch [32/85] Batch 770/938 Loss D: 0.4101, Loss G: 2.4421\n",
      "Epoch [32/85] Batch 780/938 Loss D: 0.5733, Loss G: 2.1630\n",
      "Epoch [32/85] Batch 790/938 Loss D: 0.2535, Loss G: 2.6270\n",
      "Epoch [32/85] Batch 800/938 Loss D: 0.2914, Loss G: 2.2930\n",
      "Epoch [32/85] Batch 810/938 Loss D: 0.2335, Loss G: 2.7263\n",
      "Epoch [32/85] Batch 820/938 Loss D: 0.3626, Loss G: 2.2940\n",
      "Epoch [32/85] Batch 830/938 Loss D: 0.2580, Loss G: 1.8703\n",
      "Epoch [32/85] Batch 840/938 Loss D: 0.2821, Loss G: 2.0325\n",
      "Epoch [32/85] Batch 850/938 Loss D: 0.2564, Loss G: 2.4738\n",
      "Epoch [32/85] Batch 860/938 Loss D: 0.3669, Loss G: 2.0428\n",
      "Epoch [32/85] Batch 870/938 Loss D: 0.3285, Loss G: 1.9692\n",
      "Epoch [32/85] Batch 880/938 Loss D: 0.1970, Loss G: 2.8630\n",
      "Epoch [32/85] Batch 890/938 Loss D: 0.2822, Loss G: 2.4199\n",
      "Epoch [32/85] Batch 900/938 Loss D: 0.3216, Loss G: 1.9144\n",
      "Epoch [32/85] Batch 910/938 Loss D: 0.3554, Loss G: 1.8406\n",
      "Epoch [32/85] Batch 920/938 Loss D: 0.2582, Loss G: 2.2063\n",
      "Epoch [32/85] Batch 930/938 Loss D: 0.2927, Loss G: 1.9669\n",
      "Epoch [33/85] Batch 0/938 Loss D: 0.3774, Loss G: 2.5009\n",
      "Epoch [33/85] Batch 10/938 Loss D: 0.2735, Loss G: 2.7405\n",
      "Epoch [33/85] Batch 20/938 Loss D: 0.4335, Loss G: 2.6217\n",
      "Epoch [33/85] Batch 30/938 Loss D: 0.3063, Loss G: 2.7691\n",
      "Epoch [33/85] Batch 40/938 Loss D: 0.2652, Loss G: 2.4533\n",
      "Epoch [33/85] Batch 50/938 Loss D: 0.3910, Loss G: 2.0105\n",
      "Epoch [33/85] Batch 60/938 Loss D: 0.2545, Loss G: 2.1765\n",
      "Epoch [33/85] Batch 70/938 Loss D: 0.3664, Loss G: 2.5270\n",
      "Epoch [33/85] Batch 80/938 Loss D: 0.2677, Loss G: 2.8944\n",
      "Epoch [33/85] Batch 90/938 Loss D: 0.3020, Loss G: 2.2673\n",
      "Epoch [33/85] Batch 100/938 Loss D: 0.3266, Loss G: 2.3278\n",
      "Epoch [33/85] Batch 110/938 Loss D: 0.2978, Loss G: 2.6651\n",
      "Epoch [33/85] Batch 120/938 Loss D: 0.2722, Loss G: 2.5127\n",
      "Epoch [33/85] Batch 130/938 Loss D: 0.3042, Loss G: 2.0685\n",
      "Epoch [33/85] Batch 140/938 Loss D: 0.3151, Loss G: 2.2071\n",
      "Epoch [33/85] Batch 150/938 Loss D: 0.3646, Loss G: 2.0568\n",
      "Epoch [33/85] Batch 160/938 Loss D: 0.3584, Loss G: 2.1510\n",
      "Epoch [33/85] Batch 170/938 Loss D: 0.2964, Loss G: 2.5714\n",
      "Epoch [33/85] Batch 180/938 Loss D: 0.2664, Loss G: 2.0983\n",
      "Epoch [33/85] Batch 190/938 Loss D: 0.2761, Loss G: 2.5428\n",
      "Epoch [33/85] Batch 200/938 Loss D: 0.2302, Loss G: 2.8668\n",
      "Epoch [33/85] Batch 210/938 Loss D: 0.3367, Loss G: 2.3116\n",
      "Epoch [33/85] Batch 220/938 Loss D: 0.2981, Loss G: 2.1367\n",
      "Epoch [33/85] Batch 230/938 Loss D: 0.3259, Loss G: 1.7794\n",
      "Epoch [33/85] Batch 240/938 Loss D: 0.3280, Loss G: 2.2227\n",
      "Epoch [33/85] Batch 250/938 Loss D: 0.2624, Loss G: 2.7881\n",
      "Epoch [33/85] Batch 260/938 Loss D: 0.3583, Loss G: 2.3919\n",
      "Epoch [33/85] Batch 270/938 Loss D: 0.2844, Loss G: 2.4563\n",
      "Epoch [33/85] Batch 280/938 Loss D: 0.3844, Loss G: 1.6779\n",
      "Epoch [33/85] Batch 290/938 Loss D: 0.2742, Loss G: 1.7601\n",
      "Epoch [33/85] Batch 300/938 Loss D: 0.2504, Loss G: 1.8645\n",
      "Epoch [33/85] Batch 310/938 Loss D: 0.2892, Loss G: 1.9338\n",
      "Epoch [33/85] Batch 320/938 Loss D: 0.3681, Loss G: 2.0078\n",
      "Epoch [33/85] Batch 330/938 Loss D: 0.2406, Loss G: 3.3023\n",
      "Epoch [33/85] Batch 340/938 Loss D: 0.2794, Loss G: 2.8892\n",
      "Epoch [33/85] Batch 350/938 Loss D: 0.2667, Loss G: 2.0873\n",
      "Epoch [33/85] Batch 360/938 Loss D: 0.2986, Loss G: 1.6398\n",
      "Epoch [33/85] Batch 370/938 Loss D: 0.2297, Loss G: 2.5268\n",
      "Epoch [33/85] Batch 380/938 Loss D: 0.2430, Loss G: 2.6062\n",
      "Epoch [33/85] Batch 390/938 Loss D: 0.2525, Loss G: 2.0935\n",
      "Epoch [33/85] Batch 400/938 Loss D: 0.3255, Loss G: 2.0164\n",
      "Epoch [33/85] Batch 410/938 Loss D: 0.3444, Loss G: 1.8804\n",
      "Epoch [33/85] Batch 420/938 Loss D: 0.2474, Loss G: 3.0878\n",
      "Epoch [33/85] Batch 430/938 Loss D: 0.3073, Loss G: 2.9161\n",
      "Epoch [33/85] Batch 440/938 Loss D: 0.2197, Loss G: 2.4516\n",
      "Epoch [33/85] Batch 450/938 Loss D: 0.2201, Loss G: 2.6351\n",
      "Epoch [33/85] Batch 460/938 Loss D: 0.3588, Loss G: 1.7706\n",
      "Epoch [33/85] Batch 470/938 Loss D: 0.3376, Loss G: 1.8592\n",
      "Epoch [33/85] Batch 480/938 Loss D: 0.3284, Loss G: 1.8273\n",
      "Epoch [33/85] Batch 490/938 Loss D: 0.4162, Loss G: 1.9556\n",
      "Epoch [33/85] Batch 500/938 Loss D: 0.2372, Loss G: 2.4666\n",
      "Epoch [33/85] Batch 510/938 Loss D: 0.2693, Loss G: 2.0772\n",
      "Epoch [33/85] Batch 520/938 Loss D: 0.3031, Loss G: 2.6840\n",
      "Epoch [33/85] Batch 530/938 Loss D: 0.3668, Loss G: 2.4057\n",
      "Epoch [33/85] Batch 540/938 Loss D: 0.3109, Loss G: 2.7779\n",
      "Epoch [33/85] Batch 550/938 Loss D: 0.2290, Loss G: 3.2035\n",
      "Epoch [33/85] Batch 560/938 Loss D: 0.2592, Loss G: 2.7875\n",
      "Epoch [33/85] Batch 570/938 Loss D: 0.3626, Loss G: 1.8574\n",
      "Epoch [33/85] Batch 580/938 Loss D: 0.1702, Loss G: 2.8302\n",
      "Epoch [33/85] Batch 590/938 Loss D: 0.2738, Loss G: 3.0259\n",
      "Epoch [33/85] Batch 600/938 Loss D: 0.2453, Loss G: 3.1259\n",
      "Epoch [33/85] Batch 610/938 Loss D: 0.2494, Loss G: 3.1731\n",
      "Epoch [33/85] Batch 620/938 Loss D: 0.2802, Loss G: 2.3015\n",
      "Epoch [33/85] Batch 630/938 Loss D: 0.2597, Loss G: 2.1820\n",
      "Epoch [33/85] Batch 640/938 Loss D: 0.3840, Loss G: 1.6168\n",
      "Epoch [33/85] Batch 650/938 Loss D: 0.2458, Loss G: 1.9807\n",
      "Epoch [33/85] Batch 660/938 Loss D: 0.3359, Loss G: 1.9137\n",
      "Epoch [33/85] Batch 670/938 Loss D: 0.3995, Loss G: 2.0806\n",
      "Epoch [33/85] Batch 680/938 Loss D: 0.2440, Loss G: 2.9192\n",
      "Epoch [33/85] Batch 690/938 Loss D: 0.2257, Loss G: 2.5553\n",
      "Epoch [33/85] Batch 700/938 Loss D: 0.2389, Loss G: 2.8552\n",
      "Epoch [33/85] Batch 710/938 Loss D: 0.3130, Loss G: 2.3110\n",
      "Epoch [33/85] Batch 720/938 Loss D: 0.2039, Loss G: 2.2415\n",
      "Epoch [33/85] Batch 730/938 Loss D: 0.3293, Loss G: 2.2837\n",
      "Epoch [33/85] Batch 740/938 Loss D: 0.2823, Loss G: 2.1461\n",
      "Epoch [33/85] Batch 750/938 Loss D: 0.3571, Loss G: 1.8716\n",
      "Epoch [33/85] Batch 760/938 Loss D: 0.2321, Loss G: 2.6669\n",
      "Epoch [33/85] Batch 770/938 Loss D: 0.2771, Loss G: 2.3165\n",
      "Epoch [33/85] Batch 780/938 Loss D: 0.2799, Loss G: 2.6939\n",
      "Epoch [33/85] Batch 790/938 Loss D: 0.2862, Loss G: 2.3529\n",
      "Epoch [33/85] Batch 800/938 Loss D: 0.3938, Loss G: 1.8659\n",
      "Epoch [33/85] Batch 810/938 Loss D: 0.2882, Loss G: 1.9104\n",
      "Epoch [33/85] Batch 820/938 Loss D: 0.2765, Loss G: 2.3160\n",
      "Epoch [33/85] Batch 830/938 Loss D: 0.3133, Loss G: 2.5600\n",
      "Epoch [33/85] Batch 840/938 Loss D: 0.2504, Loss G: 2.4084\n",
      "Epoch [33/85] Batch 850/938 Loss D: 0.3218, Loss G: 1.9787\n",
      "Epoch [33/85] Batch 860/938 Loss D: 0.3217, Loss G: 2.5452\n",
      "Epoch [33/85] Batch 870/938 Loss D: 0.3037, Loss G: 1.9939\n",
      "Epoch [33/85] Batch 880/938 Loss D: 0.3359, Loss G: 1.8671\n",
      "Epoch [33/85] Batch 890/938 Loss D: 0.2615, Loss G: 2.5701\n",
      "Epoch [33/85] Batch 900/938 Loss D: 0.3471, Loss G: 1.6855\n",
      "Epoch [33/85] Batch 910/938 Loss D: 0.2624, Loss G: 2.0407\n",
      "Epoch [33/85] Batch 920/938 Loss D: 0.2272, Loss G: 2.4466\n",
      "Epoch [33/85] Batch 930/938 Loss D: 0.2575, Loss G: 2.5494\n",
      "Epoch [34/85] Batch 0/938 Loss D: 0.3519, Loss G: 1.7132\n",
      "Epoch [34/85] Batch 10/938 Loss D: 0.3270, Loss G: 2.5367\n",
      "Epoch [34/85] Batch 20/938 Loss D: 0.3018, Loss G: 2.4407\n",
      "Epoch [34/85] Batch 30/938 Loss D: 0.2724, Loss G: 2.7908\n",
      "Epoch [34/85] Batch 40/938 Loss D: 0.3219, Loss G: 1.9990\n",
      "Epoch [34/85] Batch 50/938 Loss D: 0.2952, Loss G: 1.8600\n",
      "Epoch [34/85] Batch 60/938 Loss D: 0.3299, Loss G: 2.2235\n",
      "Epoch [34/85] Batch 70/938 Loss D: 0.1954, Loss G: 2.6621\n",
      "Epoch [34/85] Batch 80/938 Loss D: 0.3901, Loss G: 1.6598\n",
      "Epoch [34/85] Batch 90/938 Loss D: 0.2904, Loss G: 1.8028\n",
      "Epoch [34/85] Batch 100/938 Loss D: 0.2571, Loss G: 2.6772\n",
      "Epoch [34/85] Batch 110/938 Loss D: 0.3410, Loss G: 2.7175\n",
      "Epoch [34/85] Batch 120/938 Loss D: 0.3067, Loss G: 2.2501\n",
      "Epoch [34/85] Batch 130/938 Loss D: 0.2589, Loss G: 2.2502\n",
      "Epoch [34/85] Batch 140/938 Loss D: 0.3229, Loss G: 2.2478\n",
      "Epoch [34/85] Batch 150/938 Loss D: 0.3243, Loss G: 2.1185\n",
      "Epoch [34/85] Batch 160/938 Loss D: 0.3148, Loss G: 2.2271\n",
      "Epoch [34/85] Batch 170/938 Loss D: 0.2335, Loss G: 2.3512\n",
      "Epoch [34/85] Batch 180/938 Loss D: 0.3021, Loss G: 1.9975\n",
      "Epoch [34/85] Batch 190/938 Loss D: 0.2649, Loss G: 2.3391\n",
      "Epoch [34/85] Batch 200/938 Loss D: 0.3253, Loss G: 2.0585\n",
      "Epoch [34/85] Batch 210/938 Loss D: 0.2865, Loss G: 2.1032\n",
      "Epoch [34/85] Batch 220/938 Loss D: 0.3304, Loss G: 1.9190\n",
      "Epoch [34/85] Batch 230/938 Loss D: 0.3344, Loss G: 2.0226\n",
      "Epoch [34/85] Batch 240/938 Loss D: 0.2705, Loss G: 2.1053\n",
      "Epoch [34/85] Batch 250/938 Loss D: 0.3287, Loss G: 2.2539\n",
      "Epoch [34/85] Batch 260/938 Loss D: 0.3033, Loss G: 2.4077\n",
      "Epoch [34/85] Batch 270/938 Loss D: 0.1552, Loss G: 2.7038\n",
      "Epoch [34/85] Batch 280/938 Loss D: 0.3085, Loss G: 2.5916\n",
      "Epoch [34/85] Batch 290/938 Loss D: 0.3045, Loss G: 2.5177\n",
      "Epoch [34/85] Batch 300/938 Loss D: 0.2191, Loss G: 2.3268\n",
      "Epoch [34/85] Batch 310/938 Loss D: 0.2660, Loss G: 2.2887\n",
      "Epoch [34/85] Batch 320/938 Loss D: 0.1995, Loss G: 2.4382\n",
      "Epoch [34/85] Batch 330/938 Loss D: 0.2833, Loss G: 2.0429\n",
      "Epoch [34/85] Batch 340/938 Loss D: 0.2577, Loss G: 2.5687\n",
      "Epoch [34/85] Batch 350/938 Loss D: 0.3364, Loss G: 2.7459\n",
      "Epoch [34/85] Batch 360/938 Loss D: 0.3716, Loss G: 1.9793\n",
      "Epoch [34/85] Batch 370/938 Loss D: 0.2726, Loss G: 2.5098\n",
      "Epoch [34/85] Batch 380/938 Loss D: 0.2818, Loss G: 2.4326\n",
      "Epoch [34/85] Batch 390/938 Loss D: 0.2243, Loss G: 2.3625\n",
      "Epoch [34/85] Batch 400/938 Loss D: 0.2668, Loss G: 2.1835\n",
      "Epoch [34/85] Batch 410/938 Loss D: 0.2641, Loss G: 2.4701\n",
      "Epoch [34/85] Batch 420/938 Loss D: 0.2623, Loss G: 2.3630\n",
      "Epoch [34/85] Batch 430/938 Loss D: 0.2765, Loss G: 1.8020\n",
      "Epoch [34/85] Batch 440/938 Loss D: 0.3429, Loss G: 1.8634\n",
      "Epoch [34/85] Batch 450/938 Loss D: 0.2111, Loss G: 2.6719\n",
      "Epoch [34/85] Batch 460/938 Loss D: 0.3516, Loss G: 1.9782\n",
      "Epoch [34/85] Batch 470/938 Loss D: 0.2657, Loss G: 2.8428\n",
      "Epoch [34/85] Batch 480/938 Loss D: 0.3547, Loss G: 2.3698\n",
      "Epoch [34/85] Batch 490/938 Loss D: 0.4379, Loss G: 2.1291\n",
      "Epoch [34/85] Batch 500/938 Loss D: 0.3698, Loss G: 2.3435\n",
      "Epoch [34/85] Batch 510/938 Loss D: 0.3244, Loss G: 2.7521\n",
      "Epoch [34/85] Batch 520/938 Loss D: 0.2600, Loss G: 1.8877\n",
      "Epoch [34/85] Batch 530/938 Loss D: 0.3900, Loss G: 1.9270\n",
      "Epoch [34/85] Batch 540/938 Loss D: 0.3241, Loss G: 1.8138\n",
      "Epoch [34/85] Batch 550/938 Loss D: 0.2802, Loss G: 2.7683\n",
      "Epoch [34/85] Batch 560/938 Loss D: 0.3091, Loss G: 2.3829\n",
      "Epoch [34/85] Batch 570/938 Loss D: 0.4311, Loss G: 2.2520\n",
      "Epoch [34/85] Batch 580/938 Loss D: 0.3068, Loss G: 2.0475\n",
      "Epoch [34/85] Batch 590/938 Loss D: 0.3154, Loss G: 2.4115\n",
      "Epoch [34/85] Batch 600/938 Loss D: 0.2489, Loss G: 2.0756\n",
      "Epoch [34/85] Batch 610/938 Loss D: 0.3038, Loss G: 1.8422\n",
      "Epoch [34/85] Batch 620/938 Loss D: 0.2990, Loss G: 2.6059\n",
      "Epoch [34/85] Batch 630/938 Loss D: 0.3226, Loss G: 2.5081\n",
      "Epoch [34/85] Batch 640/938 Loss D: 0.3062, Loss G: 2.2660\n",
      "Epoch [34/85] Batch 650/938 Loss D: 0.2311, Loss G: 2.8362\n",
      "Epoch [34/85] Batch 660/938 Loss D: 0.3044, Loss G: 2.4516\n",
      "Epoch [34/85] Batch 670/938 Loss D: 0.2739, Loss G: 2.0700\n",
      "Epoch [34/85] Batch 680/938 Loss D: 0.5078, Loss G: 2.1331\n",
      "Epoch [34/85] Batch 690/938 Loss D: 0.3062, Loss G: 2.4209\n",
      "Epoch [34/85] Batch 700/938 Loss D: 0.2984, Loss G: 2.2892\n",
      "Epoch [34/85] Batch 710/938 Loss D: 0.2916, Loss G: 2.8845\n",
      "Epoch [34/85] Batch 720/938 Loss D: 0.5098, Loss G: 2.6909\n",
      "Epoch [34/85] Batch 730/938 Loss D: 0.3591, Loss G: 2.2101\n",
      "Epoch [34/85] Batch 740/938 Loss D: 0.2695, Loss G: 2.2434\n",
      "Epoch [34/85] Batch 750/938 Loss D: 0.2762, Loss G: 2.7298\n",
      "Epoch [34/85] Batch 760/938 Loss D: 0.3184, Loss G: 2.3060\n",
      "Epoch [34/85] Batch 770/938 Loss D: 0.2578, Loss G: 2.2590\n",
      "Epoch [34/85] Batch 780/938 Loss D: 0.3482, Loss G: 1.9679\n",
      "Epoch [34/85] Batch 790/938 Loss D: 0.2575, Loss G: 3.1036\n",
      "Epoch [34/85] Batch 800/938 Loss D: 0.3092, Loss G: 2.7634\n",
      "Epoch [34/85] Batch 810/938 Loss D: 0.3058, Loss G: 3.1665\n",
      "Epoch [34/85] Batch 820/938 Loss D: 0.4247, Loss G: 2.7573\n",
      "Epoch [34/85] Batch 830/938 Loss D: 0.3295, Loss G: 2.0398\n",
      "Epoch [34/85] Batch 840/938 Loss D: 0.2698, Loss G: 2.2641\n",
      "Epoch [34/85] Batch 850/938 Loss D: 0.3414, Loss G: 1.9925\n",
      "Epoch [34/85] Batch 860/938 Loss D: 0.3099, Loss G: 2.1218\n",
      "Epoch [34/85] Batch 870/938 Loss D: 0.2532, Loss G: 2.2810\n",
      "Epoch [34/85] Batch 880/938 Loss D: 0.3180, Loss G: 2.2496\n",
      "Epoch [34/85] Batch 890/938 Loss D: 0.2461, Loss G: 2.5486\n",
      "Epoch [34/85] Batch 900/938 Loss D: 0.3370, Loss G: 3.5201\n",
      "Epoch [34/85] Batch 910/938 Loss D: 0.3532, Loss G: 2.5398\n",
      "Epoch [34/85] Batch 920/938 Loss D: 0.3199, Loss G: 2.2492\n",
      "Epoch [34/85] Batch 930/938 Loss D: 0.2533, Loss G: 2.5961\n",
      "Epoch [35/85] Batch 0/938 Loss D: 0.2949, Loss G: 1.8808\n",
      "Epoch [35/85] Batch 10/938 Loss D: 0.2072, Loss G: 2.1467\n",
      "Epoch [35/85] Batch 20/938 Loss D: 0.2809, Loss G: 2.5023\n",
      "Epoch [35/85] Batch 30/938 Loss D: 0.3559, Loss G: 2.1585\n",
      "Epoch [35/85] Batch 40/938 Loss D: 0.3366, Loss G: 2.0150\n",
      "Epoch [35/85] Batch 50/938 Loss D: 0.2448, Loss G: 3.4867\n",
      "Epoch [35/85] Batch 60/938 Loss D: 0.3567, Loss G: 2.0795\n",
      "Epoch [35/85] Batch 70/938 Loss D: 0.3260, Loss G: 2.3102\n",
      "Epoch [35/85] Batch 80/938 Loss D: 0.2241, Loss G: 2.8342\n",
      "Epoch [35/85] Batch 90/938 Loss D: 0.2835, Loss G: 2.3558\n",
      "Epoch [35/85] Batch 100/938 Loss D: 0.3040, Loss G: 2.3019\n",
      "Epoch [35/85] Batch 110/938 Loss D: 0.2945, Loss G: 2.1367\n",
      "Epoch [35/85] Batch 120/938 Loss D: 0.2255, Loss G: 2.6957\n",
      "Epoch [35/85] Batch 130/938 Loss D: 0.3369, Loss G: 2.1314\n",
      "Epoch [35/85] Batch 140/938 Loss D: 0.3504, Loss G: 2.5640\n",
      "Epoch [35/85] Batch 150/938 Loss D: 0.2713, Loss G: 2.3450\n",
      "Epoch [35/85] Batch 160/938 Loss D: 0.2986, Loss G: 1.8991\n",
      "Epoch [35/85] Batch 170/938 Loss D: 0.2306, Loss G: 2.3393\n",
      "Epoch [35/85] Batch 180/938 Loss D: 0.2965, Loss G: 2.1388\n",
      "Epoch [35/85] Batch 190/938 Loss D: 0.2841, Loss G: 1.8988\n",
      "Epoch [35/85] Batch 200/938 Loss D: 0.2871, Loss G: 1.7693\n",
      "Epoch [35/85] Batch 210/938 Loss D: 0.2599, Loss G: 2.4107\n",
      "Epoch [35/85] Batch 220/938 Loss D: 0.2398, Loss G: 2.1634\n",
      "Epoch [35/85] Batch 230/938 Loss D: 0.4000, Loss G: 2.4032\n",
      "Epoch [35/85] Batch 240/938 Loss D: 0.3741, Loss G: 2.0181\n",
      "Epoch [35/85] Batch 250/938 Loss D: 0.2644, Loss G: 2.0739\n",
      "Epoch [35/85] Batch 260/938 Loss D: 0.5383, Loss G: 1.6097\n",
      "Epoch [35/85] Batch 270/938 Loss D: 0.4338, Loss G: 2.0674\n",
      "Epoch [35/85] Batch 280/938 Loss D: 0.3719, Loss G: 2.0279\n",
      "Epoch [35/85] Batch 290/938 Loss D: 0.3710, Loss G: 2.2014\n",
      "Epoch [35/85] Batch 300/938 Loss D: 0.1453, Loss G: 2.8251\n",
      "Epoch [35/85] Batch 310/938 Loss D: 0.3268, Loss G: 2.0382\n",
      "Epoch [35/85] Batch 320/938 Loss D: 0.3095, Loss G: 1.9861\n",
      "Epoch [35/85] Batch 330/938 Loss D: 0.2783, Loss G: 2.4026\n",
      "Epoch [35/85] Batch 340/938 Loss D: 0.2843, Loss G: 2.1875\n",
      "Epoch [35/85] Batch 350/938 Loss D: 0.2535, Loss G: 2.4780\n",
      "Epoch [35/85] Batch 360/938 Loss D: 0.2468, Loss G: 2.4043\n",
      "Epoch [35/85] Batch 370/938 Loss D: 0.2814, Loss G: 2.9967\n",
      "Epoch [35/85] Batch 380/938 Loss D: 0.3073, Loss G: 1.8330\n",
      "Epoch [35/85] Batch 390/938 Loss D: 0.3224, Loss G: 1.7360\n",
      "Epoch [35/85] Batch 400/938 Loss D: 0.2855, Loss G: 2.5903\n",
      "Epoch [35/85] Batch 410/938 Loss D: 0.1973, Loss G: 2.4728\n",
      "Epoch [35/85] Batch 420/938 Loss D: 0.3002, Loss G: 1.9303\n",
      "Epoch [35/85] Batch 430/938 Loss D: 0.3594, Loss G: 1.8128\n",
      "Epoch [35/85] Batch 440/938 Loss D: 0.3238, Loss G: 1.7473\n",
      "Epoch [35/85] Batch 450/938 Loss D: 0.3378, Loss G: 2.1926\n",
      "Epoch [35/85] Batch 460/938 Loss D: 0.4549, Loss G: 2.3839\n",
      "Epoch [35/85] Batch 470/938 Loss D: 0.2636, Loss G: 2.3000\n",
      "Epoch [35/85] Batch 480/938 Loss D: 0.2605, Loss G: 2.7505\n",
      "Epoch [35/85] Batch 490/938 Loss D: 0.3349, Loss G: 2.2322\n",
      "Epoch [35/85] Batch 500/938 Loss D: 0.3359, Loss G: 1.8840\n",
      "Epoch [35/85] Batch 510/938 Loss D: 0.2718, Loss G: 2.3696\n",
      "Epoch [35/85] Batch 520/938 Loss D: 0.2045, Loss G: 2.4376\n",
      "Epoch [35/85] Batch 530/938 Loss D: 0.2853, Loss G: 1.9393\n",
      "Epoch [35/85] Batch 540/938 Loss D: 0.3398, Loss G: 1.8091\n",
      "Epoch [35/85] Batch 550/938 Loss D: 0.4386, Loss G: 1.7101\n",
      "Epoch [35/85] Batch 560/938 Loss D: 0.4323, Loss G: 1.9335\n",
      "Epoch [35/85] Batch 570/938 Loss D: 0.3299, Loss G: 2.5956\n",
      "Epoch [35/85] Batch 580/938 Loss D: 0.2950, Loss G: 2.4583\n",
      "Epoch [35/85] Batch 590/938 Loss D: 0.2570, Loss G: 3.3055\n",
      "Epoch [35/85] Batch 600/938 Loss D: 0.3723, Loss G: 2.5327\n",
      "Epoch [35/85] Batch 610/938 Loss D: 0.4429, Loss G: 2.5426\n",
      "Epoch [35/85] Batch 620/938 Loss D: 0.2387, Loss G: 3.0842\n",
      "Epoch [35/85] Batch 630/938 Loss D: 0.2111, Loss G: 2.3537\n",
      "Epoch [35/85] Batch 640/938 Loss D: 0.3292, Loss G: 1.9029\n",
      "Epoch [35/85] Batch 650/938 Loss D: 0.2518, Loss G: 2.1119\n",
      "Epoch [35/85] Batch 660/938 Loss D: 0.3474, Loss G: 2.2655\n",
      "Epoch [35/85] Batch 670/938 Loss D: 0.4222, Loss G: 2.3011\n",
      "Epoch [35/85] Batch 680/938 Loss D: 0.3033, Loss G: 2.1665\n",
      "Epoch [35/85] Batch 690/938 Loss D: 0.2060, Loss G: 2.2686\n",
      "Epoch [35/85] Batch 700/938 Loss D: 0.2216, Loss G: 2.4720\n",
      "Epoch [35/85] Batch 710/938 Loss D: 0.3178, Loss G: 2.5221\n",
      "Epoch [35/85] Batch 720/938 Loss D: 0.2380, Loss G: 2.6780\n",
      "Epoch [35/85] Batch 730/938 Loss D: 0.2409, Loss G: 2.7671\n",
      "Epoch [35/85] Batch 740/938 Loss D: 0.3586, Loss G: 2.2494\n",
      "Epoch [35/85] Batch 750/938 Loss D: 0.4400, Loss G: 1.5316\n",
      "Epoch [35/85] Batch 760/938 Loss D: 0.3970, Loss G: 1.5222\n",
      "Epoch [35/85] Batch 770/938 Loss D: 0.4192, Loss G: 1.7637\n",
      "Epoch [35/85] Batch 780/938 Loss D: 0.3954, Loss G: 2.1177\n",
      "Epoch [35/85] Batch 790/938 Loss D: 0.2931, Loss G: 2.7306\n",
      "Epoch [35/85] Batch 800/938 Loss D: 0.3132, Loss G: 2.6107\n",
      "Epoch [35/85] Batch 810/938 Loss D: 0.2236, Loss G: 2.0269\n",
      "Epoch [35/85] Batch 820/938 Loss D: 0.2662, Loss G: 2.2271\n",
      "Epoch [35/85] Batch 830/938 Loss D: 0.3914, Loss G: 2.3360\n",
      "Epoch [35/85] Batch 840/938 Loss D: 0.2475, Loss G: 2.3929\n",
      "Epoch [35/85] Batch 850/938 Loss D: 0.2653, Loss G: 2.3036\n",
      "Epoch [35/85] Batch 860/938 Loss D: 0.2608, Loss G: 2.2373\n",
      "Epoch [35/85] Batch 870/938 Loss D: 0.2309, Loss G: 2.1242\n",
      "Epoch [35/85] Batch 880/938 Loss D: 0.3059, Loss G: 2.3757\n",
      "Epoch [35/85] Batch 890/938 Loss D: 0.2566, Loss G: 2.6110\n",
      "Epoch [35/85] Batch 900/938 Loss D: 0.2691, Loss G: 2.7738\n",
      "Epoch [35/85] Batch 910/938 Loss D: 0.3377, Loss G: 2.2875\n",
      "Epoch [35/85] Batch 920/938 Loss D: 0.2908, Loss G: 2.2500\n",
      "Epoch [35/85] Batch 930/938 Loss D: 0.2803, Loss G: 2.7141\n",
      "Epoch [36/85] Batch 0/938 Loss D: 0.2408, Loss G: 2.2511\n",
      "Epoch [36/85] Batch 10/938 Loss D: 0.2593, Loss G: 2.4672\n",
      "Epoch [36/85] Batch 20/938 Loss D: 0.3216, Loss G: 1.7435\n",
      "Epoch [36/85] Batch 30/938 Loss D: 0.2564, Loss G: 2.3925\n",
      "Epoch [36/85] Batch 40/938 Loss D: 0.3165, Loss G: 2.3618\n",
      "Epoch [36/85] Batch 50/938 Loss D: 0.4612, Loss G: 1.6031\n",
      "Epoch [36/85] Batch 60/938 Loss D: 0.1803, Loss G: 2.3672\n",
      "Epoch [36/85] Batch 70/938 Loss D: 0.2355, Loss G: 2.5076\n",
      "Epoch [36/85] Batch 80/938 Loss D: 0.3381, Loss G: 1.9039\n",
      "Epoch [36/85] Batch 90/938 Loss D: 0.2320, Loss G: 2.4578\n",
      "Epoch [36/85] Batch 100/938 Loss D: 0.3841, Loss G: 2.1571\n",
      "Epoch [36/85] Batch 110/938 Loss D: 0.4496, Loss G: 1.7606\n",
      "Epoch [36/85] Batch 120/938 Loss D: 0.3315, Loss G: 2.1197\n",
      "Epoch [36/85] Batch 130/938 Loss D: 0.2825, Loss G: 3.0032\n",
      "Epoch [36/85] Batch 140/938 Loss D: 0.3187, Loss G: 1.9198\n",
      "Epoch [36/85] Batch 150/938 Loss D: 0.3194, Loss G: 2.4745\n",
      "Epoch [36/85] Batch 160/938 Loss D: 0.4037, Loss G: 1.9284\n",
      "Epoch [36/85] Batch 170/938 Loss D: 0.3782, Loss G: 1.8460\n",
      "Epoch [36/85] Batch 180/938 Loss D: 0.3102, Loss G: 2.2176\n",
      "Epoch [36/85] Batch 190/938 Loss D: 0.2239, Loss G: 2.5445\n",
      "Epoch [36/85] Batch 200/938 Loss D: 0.3012, Loss G: 2.2792\n",
      "Epoch [36/85] Batch 210/938 Loss D: 0.2786, Loss G: 2.2187\n",
      "Epoch [36/85] Batch 220/938 Loss D: 0.2764, Loss G: 2.3095\n",
      "Epoch [36/85] Batch 230/938 Loss D: 0.2740, Loss G: 2.2094\n",
      "Epoch [36/85] Batch 240/938 Loss D: 0.3369, Loss G: 1.9404\n",
      "Epoch [36/85] Batch 250/938 Loss D: 0.2311, Loss G: 2.7414\n",
      "Epoch [36/85] Batch 260/938 Loss D: 0.2419, Loss G: 2.4332\n",
      "Epoch [36/85] Batch 270/938 Loss D: 0.2222, Loss G: 2.4529\n",
      "Epoch [36/85] Batch 280/938 Loss D: 0.3095, Loss G: 1.9667\n",
      "Epoch [36/85] Batch 290/938 Loss D: 0.2938, Loss G: 2.1780\n",
      "Epoch [36/85] Batch 300/938 Loss D: 0.3569, Loss G: 1.8950\n",
      "Epoch [36/85] Batch 310/938 Loss D: 0.1965, Loss G: 2.5961\n",
      "Epoch [36/85] Batch 320/938 Loss D: 0.4039, Loss G: 2.0768\n",
      "Epoch [36/85] Batch 330/938 Loss D: 0.2829, Loss G: 2.4070\n",
      "Epoch [36/85] Batch 340/938 Loss D: 0.3021, Loss G: 2.1784\n",
      "Epoch [36/85] Batch 350/938 Loss D: 0.3175, Loss G: 2.6269\n",
      "Epoch [36/85] Batch 360/938 Loss D: 0.2819, Loss G: 2.4812\n",
      "Epoch [36/85] Batch 370/938 Loss D: 0.2930, Loss G: 2.2787\n",
      "Epoch [36/85] Batch 380/938 Loss D: 0.3827, Loss G: 2.3084\n",
      "Epoch [36/85] Batch 390/938 Loss D: 0.3584, Loss G: 2.5091\n",
      "Epoch [36/85] Batch 400/938 Loss D: 0.2841, Loss G: 2.1792\n",
      "Epoch [36/85] Batch 410/938 Loss D: 0.2787, Loss G: 2.1757\n",
      "Epoch [36/85] Batch 420/938 Loss D: 0.3127, Loss G: 2.6388\n",
      "Epoch [36/85] Batch 430/938 Loss D: 0.2296, Loss G: 2.5724\n",
      "Epoch [36/85] Batch 440/938 Loss D: 0.3288, Loss G: 2.8303\n",
      "Epoch [36/85] Batch 450/938 Loss D: 0.3378, Loss G: 2.7971\n",
      "Epoch [36/85] Batch 460/938 Loss D: 0.2861, Loss G: 3.0292\n",
      "Epoch [36/85] Batch 470/938 Loss D: 0.2944, Loss G: 3.1378\n",
      "Epoch [36/85] Batch 480/938 Loss D: 0.2856, Loss G: 2.9552\n",
      "Epoch [36/85] Batch 490/938 Loss D: 0.3808, Loss G: 2.2917\n",
      "Epoch [36/85] Batch 500/938 Loss D: 0.2223, Loss G: 2.9014\n",
      "Epoch [36/85] Batch 510/938 Loss D: 0.2985, Loss G: 2.0357\n",
      "Epoch [36/85] Batch 520/938 Loss D: 0.3125, Loss G: 2.0698\n",
      "Epoch [36/85] Batch 530/938 Loss D: 0.2337, Loss G: 2.5742\n",
      "Epoch [36/85] Batch 540/938 Loss D: 0.4045, Loss G: 2.9462\n",
      "Epoch [36/85] Batch 550/938 Loss D: 0.3050, Loss G: 2.7167\n",
      "Epoch [36/85] Batch 560/938 Loss D: 0.3680, Loss G: 1.9577\n",
      "Epoch [36/85] Batch 570/938 Loss D: 0.3303, Loss G: 1.9438\n",
      "Epoch [36/85] Batch 580/938 Loss D: 0.2554, Loss G: 1.7599\n",
      "Epoch [36/85] Batch 590/938 Loss D: 0.2289, Loss G: 2.5574\n",
      "Epoch [36/85] Batch 600/938 Loss D: 0.1888, Loss G: 3.3502\n",
      "Epoch [36/85] Batch 610/938 Loss D: 0.4272, Loss G: 2.5230\n",
      "Epoch [36/85] Batch 620/938 Loss D: 0.3599, Loss G: 2.7190\n",
      "Epoch [36/85] Batch 630/938 Loss D: 0.2473, Loss G: 2.8123\n",
      "Epoch [36/85] Batch 640/938 Loss D: 0.2863, Loss G: 2.8164\n",
      "Epoch [36/85] Batch 650/938 Loss D: 0.3260, Loss G: 2.3444\n",
      "Epoch [36/85] Batch 660/938 Loss D: 0.4289, Loss G: 1.8088\n",
      "Epoch [36/85] Batch 670/938 Loss D: 0.2959, Loss G: 2.5341\n",
      "Epoch [36/85] Batch 680/938 Loss D: 0.4174, Loss G: 2.1273\n",
      "Epoch [36/85] Batch 690/938 Loss D: 0.2905, Loss G: 2.7046\n",
      "Epoch [36/85] Batch 700/938 Loss D: 0.3442, Loss G: 2.7697\n",
      "Epoch [36/85] Batch 710/938 Loss D: 0.2440, Loss G: 2.5619\n",
      "Epoch [36/85] Batch 720/938 Loss D: 0.2392, Loss G: 2.2925\n",
      "Epoch [36/85] Batch 730/938 Loss D: 0.2714, Loss G: 2.0528\n",
      "Epoch [36/85] Batch 740/938 Loss D: 0.2808, Loss G: 2.3283\n",
      "Epoch [36/85] Batch 750/938 Loss D: 0.3300, Loss G: 2.3110\n",
      "Epoch [36/85] Batch 760/938 Loss D: 0.2980, Loss G: 2.3462\n",
      "Epoch [36/85] Batch 770/938 Loss D: 0.3240, Loss G: 2.2438\n",
      "Epoch [36/85] Batch 780/938 Loss D: 0.2609, Loss G: 2.3781\n",
      "Epoch [36/85] Batch 790/938 Loss D: 0.2455, Loss G: 2.4974\n",
      "Epoch [36/85] Batch 800/938 Loss D: 0.1790, Loss G: 2.5657\n",
      "Epoch [36/85] Batch 810/938 Loss D: 0.2051, Loss G: 2.7832\n",
      "Epoch [36/85] Batch 820/938 Loss D: 0.2722, Loss G: 2.7586\n",
      "Epoch [36/85] Batch 830/938 Loss D: 0.3534, Loss G: 1.8093\n",
      "Epoch [36/85] Batch 840/938 Loss D: 0.3438, Loss G: 1.9317\n",
      "Epoch [36/85] Batch 850/938 Loss D: 0.1969, Loss G: 2.3464\n",
      "Epoch [36/85] Batch 860/938 Loss D: 0.3366, Loss G: 1.8791\n",
      "Epoch [36/85] Batch 870/938 Loss D: 0.2787, Loss G: 2.2885\n",
      "Epoch [36/85] Batch 880/938 Loss D: 0.3234, Loss G: 2.2413\n",
      "Epoch [36/85] Batch 890/938 Loss D: 0.2177, Loss G: 3.0150\n",
      "Epoch [36/85] Batch 900/938 Loss D: 0.3131, Loss G: 2.3560\n",
      "Epoch [36/85] Batch 910/938 Loss D: 0.3888, Loss G: 1.8413\n",
      "Epoch [36/85] Batch 920/938 Loss D: 0.3299, Loss G: 2.2534\n",
      "Epoch [36/85] Batch 930/938 Loss D: 0.2462, Loss G: 2.4860\n",
      "Epoch [37/85] Batch 0/938 Loss D: 0.2321, Loss G: 2.4036\n",
      "Epoch [37/85] Batch 10/938 Loss D: 0.2417, Loss G: 2.5212\n",
      "Epoch [37/85] Batch 20/938 Loss D: 0.3520, Loss G: 1.9951\n",
      "Epoch [37/85] Batch 30/938 Loss D: 0.2301, Loss G: 2.3356\n",
      "Epoch [37/85] Batch 40/938 Loss D: 0.3295, Loss G: 1.9247\n",
      "Epoch [37/85] Batch 50/938 Loss D: 0.2507, Loss G: 2.2626\n",
      "Epoch [37/85] Batch 60/938 Loss D: 0.3191, Loss G: 1.8705\n",
      "Epoch [37/85] Batch 70/938 Loss D: 0.3046, Loss G: 2.0332\n",
      "Epoch [37/85] Batch 80/938 Loss D: 0.2338, Loss G: 2.4926\n",
      "Epoch [37/85] Batch 90/938 Loss D: 0.2534, Loss G: 2.8920\n",
      "Epoch [37/85] Batch 100/938 Loss D: 0.3155, Loss G: 2.5082\n",
      "Epoch [37/85] Batch 110/938 Loss D: 0.2877, Loss G: 2.1876\n",
      "Epoch [37/85] Batch 120/938 Loss D: 0.3385, Loss G: 2.4357\n",
      "Epoch [37/85] Batch 130/938 Loss D: 0.2437, Loss G: 2.8016\n",
      "Epoch [37/85] Batch 140/938 Loss D: 0.1473, Loss G: 3.4714\n",
      "Epoch [37/85] Batch 150/938 Loss D: 0.3553, Loss G: 2.1923\n",
      "Epoch [37/85] Batch 160/938 Loss D: 0.1999, Loss G: 2.4905\n",
      "Epoch [37/85] Batch 170/938 Loss D: 0.2754, Loss G: 2.5332\n",
      "Epoch [37/85] Batch 180/938 Loss D: 0.2711, Loss G: 2.6989\n",
      "Epoch [37/85] Batch 190/938 Loss D: 0.3171, Loss G: 2.3945\n",
      "Epoch [37/85] Batch 200/938 Loss D: 0.2267, Loss G: 3.1526\n",
      "Epoch [37/85] Batch 210/938 Loss D: 0.3433, Loss G: 1.9337\n",
      "Epoch [37/85] Batch 220/938 Loss D: 0.2186, Loss G: 2.5539\n",
      "Epoch [37/85] Batch 230/938 Loss D: 0.2324, Loss G: 2.5583\n",
      "Epoch [37/85] Batch 240/938 Loss D: 0.3587, Loss G: 2.1010\n",
      "Epoch [37/85] Batch 250/938 Loss D: 0.3126, Loss G: 2.6013\n",
      "Epoch [37/85] Batch 260/938 Loss D: 0.4065, Loss G: 1.8308\n",
      "Epoch [37/85] Batch 270/938 Loss D: 0.2745, Loss G: 1.9829\n",
      "Epoch [37/85] Batch 280/938 Loss D: 0.3126, Loss G: 1.9384\n",
      "Epoch [37/85] Batch 290/938 Loss D: 0.2190, Loss G: 2.4431\n",
      "Epoch [37/85] Batch 300/938 Loss D: 0.2188, Loss G: 2.3421\n",
      "Epoch [37/85] Batch 310/938 Loss D: 0.3446, Loss G: 2.0392\n",
      "Epoch [37/85] Batch 320/938 Loss D: 0.3588, Loss G: 2.0159\n",
      "Epoch [37/85] Batch 330/938 Loss D: 0.3150, Loss G: 2.3668\n",
      "Epoch [37/85] Batch 340/938 Loss D: 0.4124, Loss G: 2.1982\n",
      "Epoch [37/85] Batch 350/938 Loss D: 0.3087, Loss G: 2.9620\n",
      "Epoch [37/85] Batch 360/938 Loss D: 0.1518, Loss G: 3.4247\n",
      "Epoch [37/85] Batch 370/938 Loss D: 0.2235, Loss G: 2.4152\n",
      "Epoch [37/85] Batch 380/938 Loss D: 0.1606, Loss G: 2.4298\n",
      "Epoch [37/85] Batch 390/938 Loss D: 0.2481, Loss G: 1.7811\n",
      "Epoch [37/85] Batch 400/938 Loss D: 0.3784, Loss G: 1.9017\n",
      "Epoch [37/85] Batch 410/938 Loss D: 0.2952, Loss G: 2.1761\n",
      "Epoch [37/85] Batch 420/938 Loss D: 0.2445, Loss G: 2.5180\n",
      "Epoch [37/85] Batch 430/938 Loss D: 0.3148, Loss G: 2.7024\n",
      "Epoch [37/85] Batch 440/938 Loss D: 0.2034, Loss G: 2.8071\n",
      "Epoch [37/85] Batch 450/938 Loss D: 0.3659, Loss G: 1.8325\n",
      "Epoch [37/85] Batch 460/938 Loss D: 0.3041, Loss G: 2.0691\n",
      "Epoch [37/85] Batch 470/938 Loss D: 0.2380, Loss G: 2.6333\n",
      "Epoch [37/85] Batch 480/938 Loss D: 0.4103, Loss G: 2.1269\n",
      "Epoch [37/85] Batch 490/938 Loss D: 0.2011, Loss G: 2.7359\n",
      "Epoch [37/85] Batch 500/938 Loss D: 0.2540, Loss G: 2.4676\n",
      "Epoch [37/85] Batch 510/938 Loss D: 0.4501, Loss G: 1.9130\n",
      "Epoch [37/85] Batch 520/938 Loss D: 0.2821, Loss G: 2.3045\n",
      "Epoch [37/85] Batch 530/938 Loss D: 0.2900, Loss G: 2.0626\n",
      "Epoch [37/85] Batch 540/938 Loss D: 0.4392, Loss G: 2.1908\n",
      "Epoch [37/85] Batch 550/938 Loss D: 0.2915, Loss G: 2.5304\n",
      "Epoch [37/85] Batch 560/938 Loss D: 0.3354, Loss G: 2.7442\n",
      "Epoch [37/85] Batch 570/938 Loss D: 0.2878, Loss G: 3.1009\n",
      "Epoch [37/85] Batch 580/938 Loss D: 0.3690, Loss G: 3.0392\n",
      "Epoch [37/85] Batch 590/938 Loss D: 0.2045, Loss G: 2.7268\n",
      "Epoch [37/85] Batch 600/938 Loss D: 0.3536, Loss G: 1.7665\n",
      "Epoch [37/85] Batch 610/938 Loss D: 0.2209, Loss G: 2.7983\n",
      "Epoch [37/85] Batch 620/938 Loss D: 0.2308, Loss G: 2.2383\n",
      "Epoch [37/85] Batch 630/938 Loss D: 0.2049, Loss G: 2.8234\n",
      "Epoch [37/85] Batch 640/938 Loss D: 0.3586, Loss G: 2.1527\n",
      "Epoch [37/85] Batch 650/938 Loss D: 0.3383, Loss G: 2.4775\n",
      "Epoch [37/85] Batch 660/938 Loss D: 0.2852, Loss G: 2.3372\n",
      "Epoch [37/85] Batch 670/938 Loss D: 0.2598, Loss G: 2.8105\n",
      "Epoch [37/85] Batch 680/938 Loss D: 0.2864, Loss G: 2.2661\n",
      "Epoch [37/85] Batch 690/938 Loss D: 0.2890, Loss G: 2.7493\n",
      "Epoch [37/85] Batch 700/938 Loss D: 0.2709, Loss G: 2.9326\n",
      "Epoch [37/85] Batch 710/938 Loss D: 0.3214, Loss G: 2.5874\n",
      "Epoch [37/85] Batch 720/938 Loss D: 0.2949, Loss G: 2.3503\n",
      "Epoch [37/85] Batch 730/938 Loss D: 0.4779, Loss G: 1.2757\n",
      "Epoch [37/85] Batch 740/938 Loss D: 0.2421, Loss G: 2.1483\n",
      "Epoch [37/85] Batch 750/938 Loss D: 0.2703, Loss G: 2.4709\n",
      "Epoch [37/85] Batch 760/938 Loss D: 0.2012, Loss G: 2.4080\n",
      "Epoch [37/85] Batch 770/938 Loss D: 0.3608, Loss G: 1.5035\n",
      "Epoch [37/85] Batch 780/938 Loss D: 0.3294, Loss G: 2.6840\n",
      "Epoch [37/85] Batch 790/938 Loss D: 0.2737, Loss G: 2.3150\n",
      "Epoch [37/85] Batch 800/938 Loss D: 0.5362, Loss G: 2.5602\n",
      "Epoch [37/85] Batch 810/938 Loss D: 0.2828, Loss G: 2.3827\n",
      "Epoch [37/85] Batch 820/938 Loss D: 0.2144, Loss G: 2.6745\n",
      "Epoch [37/85] Batch 830/938 Loss D: 0.1820, Loss G: 2.4540\n",
      "Epoch [37/85] Batch 840/938 Loss D: 0.2886, Loss G: 1.9926\n",
      "Epoch [37/85] Batch 850/938 Loss D: 0.3424, Loss G: 2.0885\n",
      "Epoch [37/85] Batch 860/938 Loss D: 0.2978, Loss G: 2.2692\n",
      "Epoch [37/85] Batch 870/938 Loss D: 0.4663, Loss G: 1.7702\n",
      "Epoch [37/85] Batch 880/938 Loss D: 0.3053, Loss G: 2.3572\n",
      "Epoch [37/85] Batch 890/938 Loss D: 0.2437, Loss G: 2.4006\n",
      "Epoch [37/85] Batch 900/938 Loss D: 0.4626, Loss G: 1.9146\n",
      "Epoch [37/85] Batch 910/938 Loss D: 0.2731, Loss G: 2.9110\n",
      "Epoch [37/85] Batch 920/938 Loss D: 0.3363, Loss G: 1.9570\n",
      "Epoch [37/85] Batch 930/938 Loss D: 0.2474, Loss G: 2.2113\n",
      "Epoch [38/85] Batch 0/938 Loss D: 0.3357, Loss G: 1.8137\n",
      "Epoch [38/85] Batch 10/938 Loss D: 0.2848, Loss G: 2.4192\n",
      "Epoch [38/85] Batch 20/938 Loss D: 0.2123, Loss G: 3.1911\n",
      "Epoch [38/85] Batch 30/938 Loss D: 0.2639, Loss G: 2.6501\n",
      "Epoch [38/85] Batch 40/938 Loss D: 0.3362, Loss G: 2.5958\n",
      "Epoch [38/85] Batch 50/938 Loss D: 0.2272, Loss G: 2.7140\n",
      "Epoch [38/85] Batch 60/938 Loss D: 0.2796, Loss G: 2.0873\n",
      "Epoch [38/85] Batch 70/938 Loss D: 0.2513, Loss G: 3.1907\n",
      "Epoch [38/85] Batch 80/938 Loss D: 0.2282, Loss G: 2.8361\n",
      "Epoch [38/85] Batch 90/938 Loss D: 0.3955, Loss G: 2.6872\n",
      "Epoch [38/85] Batch 100/938 Loss D: 0.2874, Loss G: 2.1629\n",
      "Epoch [38/85] Batch 110/938 Loss D: 0.2646, Loss G: 2.5805\n",
      "Epoch [38/85] Batch 120/938 Loss D: 0.2936, Loss G: 2.0165\n",
      "Epoch [38/85] Batch 130/938 Loss D: 0.3133, Loss G: 2.3475\n",
      "Epoch [38/85] Batch 140/938 Loss D: 0.2432, Loss G: 2.7824\n",
      "Epoch [38/85] Batch 150/938 Loss D: 0.4125, Loss G: 2.0565\n",
      "Epoch [38/85] Batch 160/938 Loss D: 0.3748, Loss G: 2.1723\n",
      "Epoch [38/85] Batch 170/938 Loss D: 0.3406, Loss G: 1.9040\n",
      "Epoch [38/85] Batch 180/938 Loss D: 0.2508, Loss G: 2.2631\n",
      "Epoch [38/85] Batch 190/938 Loss D: 0.3274, Loss G: 2.8881\n",
      "Epoch [38/85] Batch 200/938 Loss D: 0.2682, Loss G: 1.9752\n",
      "Epoch [38/85] Batch 210/938 Loss D: 0.3403, Loss G: 2.6091\n",
      "Epoch [38/85] Batch 220/938 Loss D: 0.3050, Loss G: 2.0025\n",
      "Epoch [38/85] Batch 230/938 Loss D: 0.2423, Loss G: 2.4287\n",
      "Epoch [38/85] Batch 240/938 Loss D: 0.3333, Loss G: 2.1865\n",
      "Epoch [38/85] Batch 250/938 Loss D: 0.3037, Loss G: 2.7209\n",
      "Epoch [38/85] Batch 260/938 Loss D: 0.2729, Loss G: 2.9228\n",
      "Epoch [38/85] Batch 270/938 Loss D: 0.3272, Loss G: 2.9840\n",
      "Epoch [38/85] Batch 280/938 Loss D: 0.3043, Loss G: 2.6168\n",
      "Epoch [38/85] Batch 290/938 Loss D: 0.2268, Loss G: 2.8618\n",
      "Epoch [38/85] Batch 300/938 Loss D: 0.3186, Loss G: 2.3106\n",
      "Epoch [38/85] Batch 310/938 Loss D: 0.4455, Loss G: 2.6323\n",
      "Epoch [38/85] Batch 320/938 Loss D: 0.2794, Loss G: 3.3140\n",
      "Epoch [38/85] Batch 330/938 Loss D: 0.3026, Loss G: 2.3902\n",
      "Epoch [38/85] Batch 340/938 Loss D: 0.2517, Loss G: 2.2550\n",
      "Epoch [38/85] Batch 350/938 Loss D: 0.3249, Loss G: 1.8933\n",
      "Epoch [38/85] Batch 360/938 Loss D: 0.2430, Loss G: 2.2200\n",
      "Epoch [38/85] Batch 370/938 Loss D: 0.4230, Loss G: 1.8022\n",
      "Epoch [38/85] Batch 380/938 Loss D: 0.3388, Loss G: 2.1651\n",
      "Epoch [38/85] Batch 390/938 Loss D: 0.2732, Loss G: 2.2047\n",
      "Epoch [38/85] Batch 400/938 Loss D: 0.3358, Loss G: 1.8735\n",
      "Epoch [38/85] Batch 410/938 Loss D: 0.3137, Loss G: 2.2497\n",
      "Epoch [38/85] Batch 420/938 Loss D: 0.2443, Loss G: 2.4155\n",
      "Epoch [38/85] Batch 430/938 Loss D: 0.3044, Loss G: 2.0877\n",
      "Epoch [38/85] Batch 440/938 Loss D: 0.2990, Loss G: 2.1210\n",
      "Epoch [38/85] Batch 450/938 Loss D: 0.2458, Loss G: 2.1945\n",
      "Epoch [38/85] Batch 460/938 Loss D: 0.2199, Loss G: 2.8693\n",
      "Epoch [38/85] Batch 470/938 Loss D: 0.3703, Loss G: 1.9493\n",
      "Epoch [38/85] Batch 480/938 Loss D: 0.3218, Loss G: 2.6237\n",
      "Epoch [38/85] Batch 490/938 Loss D: 0.2453, Loss G: 3.0089\n",
      "Epoch [38/85] Batch 500/938 Loss D: 0.4287, Loss G: 1.9385\n",
      "Epoch [38/85] Batch 510/938 Loss D: 0.2959, Loss G: 2.5895\n",
      "Epoch [38/85] Batch 520/938 Loss D: 0.2729, Loss G: 2.4009\n",
      "Epoch [38/85] Batch 530/938 Loss D: 0.2163, Loss G: 2.2746\n",
      "Epoch [38/85] Batch 540/938 Loss D: 0.3800, Loss G: 1.5217\n",
      "Epoch [38/85] Batch 550/938 Loss D: 0.2337, Loss G: 2.2150\n",
      "Epoch [38/85] Batch 560/938 Loss D: 0.2877, Loss G: 2.2054\n",
      "Epoch [38/85] Batch 570/938 Loss D: 0.3999, Loss G: 1.5769\n",
      "Epoch [38/85] Batch 580/938 Loss D: 0.3814, Loss G: 1.7723\n",
      "Epoch [38/85] Batch 590/938 Loss D: 0.3596, Loss G: 2.1990\n",
      "Epoch [38/85] Batch 600/938 Loss D: 0.2869, Loss G: 3.1508\n",
      "Epoch [38/85] Batch 610/938 Loss D: 0.2205, Loss G: 2.6374\n",
      "Epoch [38/85] Batch 620/938 Loss D: 0.3118, Loss G: 2.7699\n",
      "Epoch [38/85] Batch 630/938 Loss D: 0.3186, Loss G: 1.9682\n",
      "Epoch [38/85] Batch 640/938 Loss D: 0.3052, Loss G: 2.3268\n",
      "Epoch [38/85] Batch 650/938 Loss D: 0.4313, Loss G: 2.5668\n",
      "Epoch [38/85] Batch 660/938 Loss D: 0.3588, Loss G: 2.1871\n",
      "Epoch [38/85] Batch 670/938 Loss D: 0.3306, Loss G: 2.1522\n",
      "Epoch [38/85] Batch 680/938 Loss D: 0.3076, Loss G: 2.3053\n",
      "Epoch [38/85] Batch 690/938 Loss D: 0.3030, Loss G: 2.1126\n",
      "Epoch [38/85] Batch 700/938 Loss D: 0.3474, Loss G: 1.6131\n",
      "Epoch [38/85] Batch 710/938 Loss D: 0.3477, Loss G: 2.2530\n",
      "Epoch [38/85] Batch 720/938 Loss D: 0.3471, Loss G: 2.6568\n",
      "Epoch [38/85] Batch 730/938 Loss D: 0.3629, Loss G: 3.0032\n",
      "Epoch [38/85] Batch 740/938 Loss D: 0.2911, Loss G: 2.3675\n",
      "Epoch [38/85] Batch 750/938 Loss D: 0.2929, Loss G: 2.1631\n",
      "Epoch [38/85] Batch 760/938 Loss D: 0.3765, Loss G: 1.8968\n",
      "Epoch [38/85] Batch 770/938 Loss D: 0.2378, Loss G: 2.4158\n",
      "Epoch [38/85] Batch 780/938 Loss D: 0.3573, Loss G: 1.8516\n",
      "Epoch [38/85] Batch 790/938 Loss D: 0.2872, Loss G: 2.5171\n",
      "Epoch [38/85] Batch 800/938 Loss D: 0.2751, Loss G: 2.3729\n",
      "Epoch [38/85] Batch 810/938 Loss D: 0.2547, Loss G: 2.2329\n",
      "Epoch [38/85] Batch 820/938 Loss D: 0.4339, Loss G: 2.0238\n",
      "Epoch [38/85] Batch 830/938 Loss D: 0.3038, Loss G: 1.9328\n",
      "Epoch [38/85] Batch 840/938 Loss D: 0.2701, Loss G: 1.6796\n",
      "Epoch [38/85] Batch 850/938 Loss D: 0.3423, Loss G: 1.8415\n",
      "Epoch [38/85] Batch 860/938 Loss D: 0.3511, Loss G: 1.5692\n",
      "Epoch [38/85] Batch 870/938 Loss D: 0.3528, Loss G: 2.6828\n",
      "Epoch [38/85] Batch 880/938 Loss D: 0.2641, Loss G: 2.7954\n",
      "Epoch [38/85] Batch 890/938 Loss D: 0.4195, Loss G: 1.7783\n",
      "Epoch [38/85] Batch 900/938 Loss D: 0.3548, Loss G: 1.8556\n",
      "Epoch [38/85] Batch 910/938 Loss D: 0.3533, Loss G: 1.7087\n",
      "Epoch [38/85] Batch 920/938 Loss D: 0.3164, Loss G: 2.0624\n",
      "Epoch [38/85] Batch 930/938 Loss D: 0.2391, Loss G: 2.0551\n",
      "Epoch [39/85] Batch 0/938 Loss D: 0.2541, Loss G: 2.5126\n",
      "Epoch [39/85] Batch 10/938 Loss D: 0.2623, Loss G: 2.6025\n",
      "Epoch [39/85] Batch 20/938 Loss D: 0.3484, Loss G: 2.8801\n",
      "Epoch [39/85] Batch 30/938 Loss D: 0.3502, Loss G: 2.6544\n",
      "Epoch [39/85] Batch 40/938 Loss D: 0.3082, Loss G: 2.6880\n",
      "Epoch [39/85] Batch 50/938 Loss D: 0.3244, Loss G: 2.4926\n",
      "Epoch [39/85] Batch 60/938 Loss D: 0.3538, Loss G: 2.0538\n",
      "Epoch [39/85] Batch 70/938 Loss D: 0.3446, Loss G: 1.4474\n",
      "Epoch [39/85] Batch 80/938 Loss D: 0.2705, Loss G: 2.9360\n",
      "Epoch [39/85] Batch 90/938 Loss D: 0.3014, Loss G: 2.4507\n",
      "Epoch [39/85] Batch 100/938 Loss D: 0.1713, Loss G: 2.4687\n",
      "Epoch [39/85] Batch 110/938 Loss D: 0.2179, Loss G: 2.4493\n",
      "Epoch [39/85] Batch 120/938 Loss D: 0.3085, Loss G: 2.4406\n",
      "Epoch [39/85] Batch 130/938 Loss D: 0.2418, Loss G: 2.2278\n",
      "Epoch [39/85] Batch 140/938 Loss D: 0.3712, Loss G: 3.0241\n",
      "Epoch [39/85] Batch 150/938 Loss D: 0.3033, Loss G: 2.7309\n",
      "Epoch [39/85] Batch 160/938 Loss D: 0.4321, Loss G: 2.0181\n",
      "Epoch [39/85] Batch 170/938 Loss D: 0.4570, Loss G: 1.9381\n",
      "Epoch [39/85] Batch 180/938 Loss D: 0.3069, Loss G: 2.1380\n",
      "Epoch [39/85] Batch 190/938 Loss D: 0.3253, Loss G: 2.2786\n",
      "Epoch [39/85] Batch 200/938 Loss D: 0.1777, Loss G: 3.0570\n",
      "Epoch [39/85] Batch 210/938 Loss D: 0.2402, Loss G: 2.5697\n",
      "Epoch [39/85] Batch 220/938 Loss D: 0.4258, Loss G: 2.2722\n",
      "Epoch [39/85] Batch 230/938 Loss D: 0.2744, Loss G: 2.6885\n",
      "Epoch [39/85] Batch 240/938 Loss D: 0.3231, Loss G: 2.9609\n",
      "Epoch [39/85] Batch 250/938 Loss D: 0.2792, Loss G: 2.4664\n",
      "Epoch [39/85] Batch 260/938 Loss D: 0.3149, Loss G: 2.3003\n",
      "Epoch [39/85] Batch 270/938 Loss D: 0.2345, Loss G: 2.4633\n",
      "Epoch [39/85] Batch 280/938 Loss D: 0.3146, Loss G: 2.4230\n",
      "Epoch [39/85] Batch 290/938 Loss D: 0.2667, Loss G: 2.3224\n",
      "Epoch [39/85] Batch 300/938 Loss D: 0.3363, Loss G: 1.9127\n",
      "Epoch [39/85] Batch 310/938 Loss D: 0.2538, Loss G: 2.5201\n",
      "Epoch [39/85] Batch 320/938 Loss D: 0.3373, Loss G: 2.0046\n",
      "Epoch [39/85] Batch 330/938 Loss D: 0.1811, Loss G: 3.0782\n",
      "Epoch [39/85] Batch 340/938 Loss D: 0.2348, Loss G: 2.5018\n",
      "Epoch [39/85] Batch 350/938 Loss D: 0.2836, Loss G: 2.2079\n",
      "Epoch [39/85] Batch 360/938 Loss D: 0.2780, Loss G: 1.5970\n",
      "Epoch [39/85] Batch 370/938 Loss D: 0.4275, Loss G: 2.9501\n",
      "Epoch [39/85] Batch 380/938 Loss D: 0.1904, Loss G: 2.9778\n",
      "Epoch [39/85] Batch 390/938 Loss D: 0.2499, Loss G: 2.7456\n",
      "Epoch [39/85] Batch 400/938 Loss D: 0.3329, Loss G: 2.3189\n",
      "Epoch [39/85] Batch 410/938 Loss D: 0.2834, Loss G: 2.2486\n",
      "Epoch [39/85] Batch 420/938 Loss D: 0.2635, Loss G: 2.6217\n",
      "Epoch [39/85] Batch 430/938 Loss D: 0.3529, Loss G: 2.0069\n",
      "Epoch [39/85] Batch 440/938 Loss D: 0.3310, Loss G: 2.3423\n",
      "Epoch [39/85] Batch 450/938 Loss D: 0.4085, Loss G: 1.6468\n",
      "Epoch [39/85] Batch 460/938 Loss D: 0.3238, Loss G: 1.7735\n",
      "Epoch [39/85] Batch 470/938 Loss D: 0.3706, Loss G: 2.4983\n",
      "Epoch [39/85] Batch 480/938 Loss D: 0.2844, Loss G: 2.0278\n",
      "Epoch [39/85] Batch 490/938 Loss D: 0.2489, Loss G: 2.5266\n",
      "Epoch [39/85] Batch 500/938 Loss D: 0.3041, Loss G: 2.5241\n",
      "Epoch [39/85] Batch 510/938 Loss D: 0.2484, Loss G: 2.5240\n",
      "Epoch [39/85] Batch 520/938 Loss D: 0.1930, Loss G: 2.4632\n",
      "Epoch [39/85] Batch 530/938 Loss D: 0.2206, Loss G: 2.8758\n",
      "Epoch [39/85] Batch 540/938 Loss D: 0.2303, Loss G: 2.7042\n",
      "Epoch [39/85] Batch 550/938 Loss D: 0.4237, Loss G: 2.2652\n",
      "Epoch [39/85] Batch 560/938 Loss D: 0.2568, Loss G: 2.5320\n",
      "Epoch [39/85] Batch 570/938 Loss D: 0.3082, Loss G: 3.0365\n",
      "Epoch [39/85] Batch 580/938 Loss D: 0.3009, Loss G: 2.6909\n",
      "Epoch [39/85] Batch 590/938 Loss D: 0.2257, Loss G: 2.6998\n",
      "Epoch [39/85] Batch 600/938 Loss D: 0.3505, Loss G: 2.1028\n",
      "Epoch [39/85] Batch 610/938 Loss D: 0.5001, Loss G: 1.8228\n",
      "Epoch [39/85] Batch 620/938 Loss D: 0.2128, Loss G: 2.7079\n",
      "Epoch [39/85] Batch 630/938 Loss D: 0.2332, Loss G: 2.6028\n",
      "Epoch [39/85] Batch 640/938 Loss D: 0.2782, Loss G: 2.2702\n",
      "Epoch [39/85] Batch 650/938 Loss D: 0.4296, Loss G: 2.4459\n",
      "Epoch [39/85] Batch 660/938 Loss D: 0.2585, Loss G: 3.2643\n",
      "Epoch [39/85] Batch 670/938 Loss D: 0.2206, Loss G: 3.0275\n",
      "Epoch [39/85] Batch 680/938 Loss D: 0.4769, Loss G: 2.3905\n",
      "Epoch [39/85] Batch 690/938 Loss D: 0.3417, Loss G: 2.2998\n",
      "Epoch [39/85] Batch 700/938 Loss D: 0.2582, Loss G: 2.2212\n",
      "Epoch [39/85] Batch 710/938 Loss D: 0.2777, Loss G: 2.1324\n",
      "Epoch [39/85] Batch 720/938 Loss D: 0.3839, Loss G: 2.4301\n",
      "Epoch [39/85] Batch 730/938 Loss D: 0.3349, Loss G: 2.3462\n",
      "Epoch [39/85] Batch 740/938 Loss D: 0.2882, Loss G: 2.9559\n",
      "Epoch [39/85] Batch 750/938 Loss D: 0.3502, Loss G: 2.4794\n",
      "Epoch [39/85] Batch 760/938 Loss D: 0.3528, Loss G: 2.1579\n",
      "Epoch [39/85] Batch 770/938 Loss D: 0.3263, Loss G: 2.0849\n",
      "Epoch [39/85] Batch 780/938 Loss D: 0.3913, Loss G: 2.1829\n",
      "Epoch [39/85] Batch 790/938 Loss D: 0.2475, Loss G: 2.4849\n",
      "Epoch [39/85] Batch 800/938 Loss D: 0.3135, Loss G: 1.7172\n",
      "Epoch [39/85] Batch 810/938 Loss D: 0.2582, Loss G: 2.4116\n",
      "Epoch [39/85] Batch 820/938 Loss D: 0.1770, Loss G: 2.7993\n",
      "Epoch [39/85] Batch 830/938 Loss D: 0.2573, Loss G: 2.9318\n",
      "Epoch [39/85] Batch 840/938 Loss D: 0.3353, Loss G: 3.0763\n",
      "Epoch [39/85] Batch 850/938 Loss D: 0.3225, Loss G: 2.2110\n",
      "Epoch [39/85] Batch 860/938 Loss D: 0.2689, Loss G: 2.1578\n",
      "Epoch [39/85] Batch 870/938 Loss D: 0.1933, Loss G: 2.9714\n",
      "Epoch [39/85] Batch 880/938 Loss D: 0.2050, Loss G: 2.6617\n",
      "Epoch [39/85] Batch 890/938 Loss D: 0.3109, Loss G: 2.6486\n",
      "Epoch [39/85] Batch 900/938 Loss D: 0.3543, Loss G: 2.2960\n",
      "Epoch [39/85] Batch 910/938 Loss D: 0.2745, Loss G: 2.4840\n",
      "Epoch [39/85] Batch 920/938 Loss D: 0.3028, Loss G: 2.2946\n",
      "Epoch [39/85] Batch 930/938 Loss D: 0.2492, Loss G: 2.2830\n",
      "Epoch [40/85] Batch 0/938 Loss D: 0.3541, Loss G: 2.1862\n",
      "Epoch [40/85] Batch 10/938 Loss D: 0.2494, Loss G: 2.3815\n",
      "Epoch [40/85] Batch 20/938 Loss D: 0.2715, Loss G: 2.0793\n",
      "Epoch [40/85] Batch 30/938 Loss D: 0.2137, Loss G: 2.7376\n",
      "Epoch [40/85] Batch 40/938 Loss D: 0.3219, Loss G: 2.1655\n",
      "Epoch [40/85] Batch 50/938 Loss D: 0.2583, Loss G: 2.4863\n",
      "Epoch [40/85] Batch 60/938 Loss D: 0.3392, Loss G: 1.7651\n",
      "Epoch [40/85] Batch 70/938 Loss D: 0.3691, Loss G: 2.2954\n",
      "Epoch [40/85] Batch 80/938 Loss D: 0.3072, Loss G: 2.3709\n",
      "Epoch [40/85] Batch 90/938 Loss D: 0.2572, Loss G: 2.3933\n",
      "Epoch [40/85] Batch 100/938 Loss D: 0.3541, Loss G: 2.1437\n",
      "Epoch [40/85] Batch 110/938 Loss D: 0.2957, Loss G: 2.1256\n",
      "Epoch [40/85] Batch 120/938 Loss D: 0.1869, Loss G: 2.4978\n",
      "Epoch [40/85] Batch 130/938 Loss D: 0.3338, Loss G: 2.2118\n",
      "Epoch [40/85] Batch 140/938 Loss D: 0.2173, Loss G: 2.5045\n",
      "Epoch [40/85] Batch 150/938 Loss D: 0.2702, Loss G: 2.3571\n",
      "Epoch [40/85] Batch 160/938 Loss D: 0.3944, Loss G: 1.9774\n",
      "Epoch [40/85] Batch 170/938 Loss D: 0.3316, Loss G: 2.6628\n",
      "Epoch [40/85] Batch 180/938 Loss D: 0.2310, Loss G: 2.9057\n",
      "Epoch [40/85] Batch 190/938 Loss D: 0.2626, Loss G: 2.9799\n",
      "Epoch [40/85] Batch 200/938 Loss D: 0.2426, Loss G: 2.6656\n",
      "Epoch [40/85] Batch 210/938 Loss D: 0.3527, Loss G: 1.8001\n",
      "Epoch [40/85] Batch 220/938 Loss D: 0.3239, Loss G: 1.8693\n",
      "Epoch [40/85] Batch 230/938 Loss D: 0.2570, Loss G: 1.9010\n",
      "Epoch [40/85] Batch 240/938 Loss D: 0.2541, Loss G: 2.2374\n",
      "Epoch [40/85] Batch 250/938 Loss D: 0.2935, Loss G: 2.3764\n",
      "Epoch [40/85] Batch 260/938 Loss D: 0.3185, Loss G: 2.4769\n",
      "Epoch [40/85] Batch 270/938 Loss D: 0.2358, Loss G: 2.9107\n",
      "Epoch [40/85] Batch 280/938 Loss D: 0.2565, Loss G: 2.2337\n",
      "Epoch [40/85] Batch 290/938 Loss D: 0.3570, Loss G: 2.1505\n",
      "Epoch [40/85] Batch 300/938 Loss D: 0.2733, Loss G: 2.3766\n",
      "Epoch [40/85] Batch 310/938 Loss D: 0.2217, Loss G: 2.0582\n",
      "Epoch [40/85] Batch 320/938 Loss D: 0.3467, Loss G: 2.7573\n",
      "Epoch [40/85] Batch 330/938 Loss D: 0.4061, Loss G: 1.9738\n",
      "Epoch [40/85] Batch 340/938 Loss D: 0.3429, Loss G: 2.3321\n",
      "Epoch [40/85] Batch 350/938 Loss D: 0.2909, Loss G: 2.2767\n",
      "Epoch [40/85] Batch 360/938 Loss D: 0.2794, Loss G: 2.6053\n",
      "Epoch [40/85] Batch 370/938 Loss D: 0.2928, Loss G: 2.5856\n",
      "Epoch [40/85] Batch 380/938 Loss D: 0.2737, Loss G: 2.2439\n",
      "Epoch [40/85] Batch 390/938 Loss D: 0.2884, Loss G: 2.1298\n",
      "Epoch [40/85] Batch 400/938 Loss D: 0.3060, Loss G: 2.2780\n",
      "Epoch [40/85] Batch 410/938 Loss D: 0.2613, Loss G: 2.2357\n",
      "Epoch [40/85] Batch 420/938 Loss D: 0.3310, Loss G: 1.8424\n",
      "Epoch [40/85] Batch 430/938 Loss D: 0.3584, Loss G: 2.3554\n",
      "Epoch [40/85] Batch 440/938 Loss D: 0.3066, Loss G: 2.6404\n",
      "Epoch [40/85] Batch 450/938 Loss D: 0.3587, Loss G: 2.7273\n",
      "Epoch [40/85] Batch 460/938 Loss D: 0.3005, Loss G: 2.5333\n",
      "Epoch [40/85] Batch 470/938 Loss D: 0.2400, Loss G: 2.6345\n",
      "Epoch [40/85] Batch 480/938 Loss D: 0.3220, Loss G: 2.5861\n",
      "Epoch [40/85] Batch 490/938 Loss D: 0.3145, Loss G: 1.9688\n",
      "Epoch [40/85] Batch 500/938 Loss D: 0.2854, Loss G: 1.9176\n",
      "Epoch [40/85] Batch 510/938 Loss D: 0.2866, Loss G: 3.1533\n",
      "Epoch [40/85] Batch 520/938 Loss D: 0.5033, Loss G: 2.4271\n",
      "Epoch [40/85] Batch 530/938 Loss D: 0.3026, Loss G: 2.8574\n",
      "Epoch [40/85] Batch 540/938 Loss D: 0.3034, Loss G: 2.8672\n",
      "Epoch [40/85] Batch 550/938 Loss D: 0.2555, Loss G: 3.0596\n",
      "Epoch [40/85] Batch 560/938 Loss D: 0.3736, Loss G: 1.7687\n",
      "Epoch [40/85] Batch 570/938 Loss D: 0.3514, Loss G: 1.6998\n",
      "Epoch [40/85] Batch 580/938 Loss D: 0.3151, Loss G: 2.3115\n",
      "Epoch [40/85] Batch 590/938 Loss D: 0.4352, Loss G: 2.5746\n",
      "Epoch [40/85] Batch 600/938 Loss D: 0.3261, Loss G: 2.1655\n",
      "Epoch [40/85] Batch 610/938 Loss D: 0.2577, Loss G: 2.1867\n",
      "Epoch [40/85] Batch 620/938 Loss D: 0.3201, Loss G: 2.0427\n",
      "Epoch [40/85] Batch 630/938 Loss D: 0.2568, Loss G: 1.9951\n",
      "Epoch [40/85] Batch 640/938 Loss D: 0.3340, Loss G: 2.4325\n",
      "Epoch [40/85] Batch 650/938 Loss D: 0.2817, Loss G: 1.9462\n",
      "Epoch [40/85] Batch 660/938 Loss D: 0.2032, Loss G: 2.2955\n",
      "Epoch [40/85] Batch 670/938 Loss D: 0.2523, Loss G: 2.0121\n",
      "Epoch [40/85] Batch 680/938 Loss D: 0.2735, Loss G: 2.5172\n",
      "Epoch [40/85] Batch 690/938 Loss D: 0.3456, Loss G: 2.2374\n",
      "Epoch [40/85] Batch 700/938 Loss D: 0.3692, Loss G: 2.1157\n",
      "Epoch [40/85] Batch 710/938 Loss D: 0.3466, Loss G: 2.2203\n",
      "Epoch [40/85] Batch 720/938 Loss D: 0.2176, Loss G: 2.4511\n",
      "Epoch [40/85] Batch 730/938 Loss D: 0.4275, Loss G: 2.6150\n",
      "Epoch [40/85] Batch 740/938 Loss D: 0.2953, Loss G: 2.1592\n",
      "Epoch [40/85] Batch 750/938 Loss D: 0.3976, Loss G: 2.0537\n",
      "Epoch [40/85] Batch 760/938 Loss D: 0.2380, Loss G: 2.4953\n",
      "Epoch [40/85] Batch 770/938 Loss D: 0.2949, Loss G: 2.3760\n",
      "Epoch [40/85] Batch 780/938 Loss D: 0.3446, Loss G: 1.9770\n",
      "Epoch [40/85] Batch 790/938 Loss D: 0.4324, Loss G: 2.1419\n",
      "Epoch [40/85] Batch 800/938 Loss D: 0.2155, Loss G: 3.4848\n",
      "Epoch [40/85] Batch 810/938 Loss D: 0.4060, Loss G: 2.3576\n",
      "Epoch [40/85] Batch 820/938 Loss D: 0.3661, Loss G: 2.8042\n",
      "Epoch [40/85] Batch 830/938 Loss D: 0.4443, Loss G: 2.5124\n",
      "Epoch [40/85] Batch 840/938 Loss D: 0.2432, Loss G: 2.8508\n",
      "Epoch [40/85] Batch 850/938 Loss D: 0.2954, Loss G: 2.2945\n",
      "Epoch [40/85] Batch 860/938 Loss D: 0.3006, Loss G: 2.5181\n",
      "Epoch [40/85] Batch 870/938 Loss D: 0.1772, Loss G: 2.6850\n",
      "Epoch [40/85] Batch 880/938 Loss D: 0.2746, Loss G: 1.7543\n",
      "Epoch [40/85] Batch 890/938 Loss D: 0.3552, Loss G: 2.3577\n",
      "Epoch [40/85] Batch 900/938 Loss D: 0.3194, Loss G: 1.9611\n",
      "Epoch [40/85] Batch 910/938 Loss D: 0.2952, Loss G: 2.4327\n",
      "Epoch [40/85] Batch 920/938 Loss D: 0.3318, Loss G: 2.2642\n",
      "Epoch [40/85] Batch 930/938 Loss D: 0.2453, Loss G: 2.4908\n",
      "Epoch [41/85] Batch 0/938 Loss D: 0.2667, Loss G: 1.8446\n",
      "Epoch [41/85] Batch 10/938 Loss D: 0.3621, Loss G: 1.8963\n",
      "Epoch [41/85] Batch 20/938 Loss D: 0.3373, Loss G: 2.6301\n",
      "Epoch [41/85] Batch 30/938 Loss D: 0.2367, Loss G: 2.3561\n",
      "Epoch [41/85] Batch 40/938 Loss D: 0.3376, Loss G: 2.4962\n",
      "Epoch [41/85] Batch 50/938 Loss D: 0.3495, Loss G: 2.3838\n",
      "Epoch [41/85] Batch 60/938 Loss D: 0.2851, Loss G: 2.6079\n",
      "Epoch [41/85] Batch 70/938 Loss D: 0.3624, Loss G: 2.3265\n",
      "Epoch [41/85] Batch 80/938 Loss D: 0.3359, Loss G: 2.1535\n",
      "Epoch [41/85] Batch 90/938 Loss D: 0.2595, Loss G: 2.5898\n",
      "Epoch [41/85] Batch 100/938 Loss D: 0.2848, Loss G: 2.6704\n",
      "Epoch [41/85] Batch 110/938 Loss D: 0.3007, Loss G: 2.3673\n",
      "Epoch [41/85] Batch 120/938 Loss D: 0.4307, Loss G: 2.5362\n",
      "Epoch [41/85] Batch 130/938 Loss D: 0.3106, Loss G: 2.6092\n",
      "Epoch [41/85] Batch 140/938 Loss D: 0.3073, Loss G: 2.4349\n",
      "Epoch [41/85] Batch 150/938 Loss D: 0.2850, Loss G: 3.1247\n",
      "Epoch [41/85] Batch 160/938 Loss D: 0.3073, Loss G: 2.2863\n",
      "Epoch [41/85] Batch 170/938 Loss D: 0.2701, Loss G: 2.6090\n",
      "Epoch [41/85] Batch 180/938 Loss D: 0.4913, Loss G: 2.4820\n",
      "Epoch [41/85] Batch 190/938 Loss D: 0.3491, Loss G: 2.7279\n",
      "Epoch [41/85] Batch 200/938 Loss D: 0.2616, Loss G: 2.8033\n",
      "Epoch [41/85] Batch 210/938 Loss D: 0.2821, Loss G: 2.7862\n",
      "Epoch [41/85] Batch 220/938 Loss D: 0.2996, Loss G: 2.3462\n",
      "Epoch [41/85] Batch 230/938 Loss D: 0.3001, Loss G: 2.6042\n",
      "Epoch [41/85] Batch 240/938 Loss D: 0.2528, Loss G: 2.5852\n",
      "Epoch [41/85] Batch 250/938 Loss D: 0.3375, Loss G: 2.5441\n",
      "Epoch [41/85] Batch 260/938 Loss D: 0.2754, Loss G: 2.2180\n",
      "Epoch [41/85] Batch 270/938 Loss D: 0.2412, Loss G: 2.2695\n",
      "Epoch [41/85] Batch 280/938 Loss D: 0.1773, Loss G: 2.6104\n",
      "Epoch [41/85] Batch 290/938 Loss D: 0.3291, Loss G: 2.2989\n",
      "Epoch [41/85] Batch 300/938 Loss D: 0.3327, Loss G: 1.9540\n",
      "Epoch [41/85] Batch 310/938 Loss D: 0.3319, Loss G: 2.1396\n",
      "Epoch [41/85] Batch 320/938 Loss D: 0.3296, Loss G: 2.2476\n",
      "Epoch [41/85] Batch 330/938 Loss D: 0.3577, Loss G: 3.3829\n",
      "Epoch [41/85] Batch 340/938 Loss D: 0.3039, Loss G: 2.7273\n",
      "Epoch [41/85] Batch 350/938 Loss D: 0.2864, Loss G: 2.4113\n",
      "Epoch [41/85] Batch 360/938 Loss D: 0.2719, Loss G: 2.2731\n",
      "Epoch [41/85] Batch 370/938 Loss D: 0.3383, Loss G: 2.1913\n",
      "Epoch [41/85] Batch 380/938 Loss D: 0.3466, Loss G: 2.0499\n",
      "Epoch [41/85] Batch 390/938 Loss D: 0.2603, Loss G: 1.7124\n",
      "Epoch [41/85] Batch 400/938 Loss D: 0.3268, Loss G: 1.8200\n",
      "Epoch [41/85] Batch 410/938 Loss D: 0.1874, Loss G: 2.8136\n",
      "Epoch [41/85] Batch 420/938 Loss D: 0.4320, Loss G: 2.3927\n",
      "Epoch [41/85] Batch 430/938 Loss D: 0.2309, Loss G: 2.9907\n",
      "Epoch [41/85] Batch 440/938 Loss D: 0.3906, Loss G: 2.8972\n",
      "Epoch [41/85] Batch 450/938 Loss D: 0.4105, Loss G: 2.0782\n",
      "Epoch [41/85] Batch 460/938 Loss D: 0.4475, Loss G: 2.2703\n",
      "Epoch [41/85] Batch 470/938 Loss D: 0.3680, Loss G: 3.5753\n",
      "Epoch [41/85] Batch 480/938 Loss D: 0.3293, Loss G: 2.8291\n",
      "Epoch [41/85] Batch 490/938 Loss D: 0.2699, Loss G: 2.6896\n",
      "Epoch [41/85] Batch 500/938 Loss D: 0.2397, Loss G: 2.2664\n",
      "Epoch [41/85] Batch 510/938 Loss D: 0.2723, Loss G: 2.4405\n",
      "Epoch [41/85] Batch 520/938 Loss D: 0.2946, Loss G: 3.3175\n",
      "Epoch [41/85] Batch 530/938 Loss D: 0.3188, Loss G: 2.5876\n",
      "Epoch [41/85] Batch 540/938 Loss D: 0.2336, Loss G: 2.4812\n",
      "Epoch [41/85] Batch 550/938 Loss D: 0.2720, Loss G: 2.3817\n",
      "Epoch [41/85] Batch 560/938 Loss D: 0.2529, Loss G: 2.8861\n",
      "Epoch [41/85] Batch 570/938 Loss D: 0.3116, Loss G: 2.3114\n",
      "Epoch [41/85] Batch 580/938 Loss D: 0.3193, Loss G: 2.3968\n",
      "Epoch [41/85] Batch 590/938 Loss D: 0.2160, Loss G: 2.5706\n",
      "Epoch [41/85] Batch 600/938 Loss D: 0.3152, Loss G: 2.0067\n",
      "Epoch [41/85] Batch 610/938 Loss D: 0.3365, Loss G: 1.6637\n",
      "Epoch [41/85] Batch 620/938 Loss D: 0.2712, Loss G: 2.6271\n",
      "Epoch [41/85] Batch 630/938 Loss D: 0.2488, Loss G: 2.9427\n",
      "Epoch [41/85] Batch 640/938 Loss D: 0.3236, Loss G: 2.5261\n",
      "Epoch [41/85] Batch 650/938 Loss D: 0.2752, Loss G: 2.3979\n",
      "Epoch [41/85] Batch 660/938 Loss D: 0.2130, Loss G: 2.0675\n",
      "Epoch [41/85] Batch 670/938 Loss D: 0.3407, Loss G: 2.4696\n",
      "Epoch [41/85] Batch 680/938 Loss D: 0.2788, Loss G: 2.2683\n",
      "Epoch [41/85] Batch 690/938 Loss D: 0.4618, Loss G: 2.4901\n",
      "Epoch [41/85] Batch 700/938 Loss D: 0.2883, Loss G: 2.7873\n",
      "Epoch [41/85] Batch 710/938 Loss D: 0.3968, Loss G: 2.4114\n",
      "Epoch [41/85] Batch 720/938 Loss D: 0.3372, Loss G: 2.7237\n",
      "Epoch [41/85] Batch 730/938 Loss D: 0.3496, Loss G: 2.8644\n",
      "Epoch [41/85] Batch 740/938 Loss D: 0.3471, Loss G: 2.1144\n",
      "Epoch [41/85] Batch 750/938 Loss D: 0.2985, Loss G: 2.8137\n",
      "Epoch [41/85] Batch 760/938 Loss D: 0.3885, Loss G: 1.7271\n",
      "Epoch [41/85] Batch 770/938 Loss D: 0.3253, Loss G: 1.8142\n",
      "Epoch [41/85] Batch 780/938 Loss D: 0.3574, Loss G: 2.0970\n",
      "Epoch [41/85] Batch 790/938 Loss D: 0.3124, Loss G: 2.7821\n",
      "Epoch [41/85] Batch 800/938 Loss D: 0.2729, Loss G: 2.6545\n",
      "Epoch [41/85] Batch 810/938 Loss D: 0.2938, Loss G: 2.1938\n",
      "Epoch [41/85] Batch 820/938 Loss D: 0.1636, Loss G: 3.1008\n",
      "Epoch [41/85] Batch 830/938 Loss D: 0.3104, Loss G: 1.7745\n",
      "Epoch [41/85] Batch 840/938 Loss D: 0.3573, Loss G: 1.6726\n",
      "Epoch [41/85] Batch 850/938 Loss D: 0.4032, Loss G: 1.8055\n",
      "Epoch [41/85] Batch 860/938 Loss D: 0.3430, Loss G: 2.5912\n",
      "Epoch [41/85] Batch 870/938 Loss D: 0.3179, Loss G: 2.3274\n",
      "Epoch [41/85] Batch 880/938 Loss D: 0.3397, Loss G: 2.3807\n",
      "Epoch [41/85] Batch 890/938 Loss D: 0.3610, Loss G: 2.5606\n",
      "Epoch [41/85] Batch 900/938 Loss D: 0.2499, Loss G: 2.6548\n",
      "Epoch [41/85] Batch 910/938 Loss D: 0.2741, Loss G: 2.5435\n",
      "Epoch [41/85] Batch 920/938 Loss D: 0.3563, Loss G: 2.0988\n",
      "Epoch [41/85] Batch 930/938 Loss D: 0.3779, Loss G: 2.0843\n",
      "Epoch [42/85] Batch 0/938 Loss D: 0.2257, Loss G: 2.7130\n",
      "Epoch [42/85] Batch 10/938 Loss D: 0.2913, Loss G: 2.5825\n",
      "Epoch [42/85] Batch 20/938 Loss D: 0.3923, Loss G: 2.9924\n",
      "Epoch [42/85] Batch 30/938 Loss D: 0.3710, Loss G: 2.5840\n",
      "Epoch [42/85] Batch 40/938 Loss D: 0.2613, Loss G: 2.2583\n",
      "Epoch [42/85] Batch 50/938 Loss D: 0.2106, Loss G: 2.7177\n",
      "Epoch [42/85] Batch 60/938 Loss D: 0.3219, Loss G: 2.3411\n",
      "Epoch [42/85] Batch 70/938 Loss D: 0.3909, Loss G: 2.1167\n",
      "Epoch [42/85] Batch 80/938 Loss D: 0.2698, Loss G: 1.9645\n",
      "Epoch [42/85] Batch 90/938 Loss D: 0.3097, Loss G: 1.9998\n",
      "Epoch [42/85] Batch 100/938 Loss D: 0.3715, Loss G: 2.2631\n",
      "Epoch [42/85] Batch 110/938 Loss D: 0.3975, Loss G: 1.9361\n",
      "Epoch [42/85] Batch 120/938 Loss D: 0.3299, Loss G: 1.7199\n",
      "Epoch [42/85] Batch 130/938 Loss D: 0.2673, Loss G: 2.1974\n",
      "Epoch [42/85] Batch 140/938 Loss D: 0.2616, Loss G: 2.2295\n",
      "Epoch [42/85] Batch 150/938 Loss D: 0.3074, Loss G: 2.1828\n",
      "Epoch [42/85] Batch 160/938 Loss D: 0.3335, Loss G: 2.7863\n",
      "Epoch [42/85] Batch 170/938 Loss D: 0.4070, Loss G: 2.5075\n",
      "Epoch [42/85] Batch 180/938 Loss D: 0.3486, Loss G: 2.1034\n",
      "Epoch [42/85] Batch 190/938 Loss D: 0.3748, Loss G: 2.1530\n",
      "Epoch [42/85] Batch 200/938 Loss D: 0.2563, Loss G: 2.3315\n",
      "Epoch [42/85] Batch 210/938 Loss D: 0.3011, Loss G: 1.9331\n",
      "Epoch [42/85] Batch 220/938 Loss D: 0.3388, Loss G: 2.3353\n",
      "Epoch [42/85] Batch 230/938 Loss D: 0.3450, Loss G: 2.2958\n",
      "Epoch [42/85] Batch 240/938 Loss D: 0.3036, Loss G: 2.3576\n",
      "Epoch [42/85] Batch 250/938 Loss D: 0.2138, Loss G: 2.5182\n",
      "Epoch [42/85] Batch 260/938 Loss D: 0.3549, Loss G: 1.9332\n",
      "Epoch [42/85] Batch 270/938 Loss D: 0.5164, Loss G: 2.2939\n",
      "Epoch [42/85] Batch 280/938 Loss D: 0.1947, Loss G: 3.0685\n",
      "Epoch [42/85] Batch 290/938 Loss D: 0.2530, Loss G: 2.7379\n",
      "Epoch [42/85] Batch 300/938 Loss D: 0.2681, Loss G: 2.4785\n",
      "Epoch [42/85] Batch 310/938 Loss D: 0.2989, Loss G: 2.1489\n",
      "Epoch [42/85] Batch 320/938 Loss D: 0.2986, Loss G: 1.8631\n",
      "Epoch [42/85] Batch 330/938 Loss D: 0.2757, Loss G: 2.1017\n",
      "Epoch [42/85] Batch 340/938 Loss D: 0.2682, Loss G: 2.5009\n",
      "Epoch [42/85] Batch 350/938 Loss D: 0.3656, Loss G: 2.2006\n",
      "Epoch [42/85] Batch 360/938 Loss D: 0.3275, Loss G: 2.1261\n",
      "Epoch [42/85] Batch 370/938 Loss D: 0.2167, Loss G: 2.4113\n",
      "Epoch [42/85] Batch 380/938 Loss D: 0.2928, Loss G: 1.9514\n",
      "Epoch [42/85] Batch 390/938 Loss D: 0.2320, Loss G: 2.5289\n",
      "Epoch [42/85] Batch 400/938 Loss D: 0.3650, Loss G: 2.1334\n",
      "Epoch [42/85] Batch 410/938 Loss D: 0.2285, Loss G: 3.0532\n",
      "Epoch [42/85] Batch 420/938 Loss D: 0.3101, Loss G: 2.6344\n",
      "Epoch [42/85] Batch 430/938 Loss D: 0.3057, Loss G: 2.2906\n",
      "Epoch [42/85] Batch 440/938 Loss D: 0.2293, Loss G: 2.6059\n",
      "Epoch [42/85] Batch 450/938 Loss D: 0.2736, Loss G: 2.2108\n",
      "Epoch [42/85] Batch 460/938 Loss D: 0.4290, Loss G: 1.6320\n",
      "Epoch [42/85] Batch 470/938 Loss D: 0.3828, Loss G: 1.9993\n",
      "Epoch [42/85] Batch 480/938 Loss D: 0.2463, Loss G: 2.2630\n",
      "Epoch [42/85] Batch 490/938 Loss D: 0.3844, Loss G: 2.2718\n",
      "Epoch [42/85] Batch 500/938 Loss D: 0.2880, Loss G: 1.9273\n",
      "Epoch [42/85] Batch 510/938 Loss D: 0.2508, Loss G: 2.5331\n",
      "Epoch [42/85] Batch 520/938 Loss D: 0.2835, Loss G: 2.3385\n",
      "Epoch [42/85] Batch 530/938 Loss D: 0.3407, Loss G: 2.4467\n",
      "Epoch [42/85] Batch 540/938 Loss D: 0.3048, Loss G: 2.2452\n",
      "Epoch [42/85] Batch 550/938 Loss D: 0.3401, Loss G: 2.2431\n",
      "Epoch [42/85] Batch 560/938 Loss D: 0.2321, Loss G: 2.4993\n",
      "Epoch [42/85] Batch 570/938 Loss D: 0.2039, Loss G: 3.6462\n",
      "Epoch [42/85] Batch 580/938 Loss D: 0.3917, Loss G: 2.2704\n",
      "Epoch [42/85] Batch 590/938 Loss D: 0.2732, Loss G: 2.4080\n",
      "Epoch [42/85] Batch 600/938 Loss D: 0.3014, Loss G: 2.5203\n",
      "Epoch [42/85] Batch 610/938 Loss D: 0.3257, Loss G: 1.8986\n",
      "Epoch [42/85] Batch 620/938 Loss D: 0.3560, Loss G: 2.0659\n",
      "Epoch [42/85] Batch 630/938 Loss D: 0.3088, Loss G: 1.8678\n",
      "Epoch [42/85] Batch 640/938 Loss D: 0.3272, Loss G: 1.8125\n",
      "Epoch [42/85] Batch 650/938 Loss D: 0.2516, Loss G: 2.6945\n",
      "Epoch [42/85] Batch 660/938 Loss D: 0.2754, Loss G: 2.0073\n",
      "Epoch [42/85] Batch 670/938 Loss D: 0.3425, Loss G: 2.1261\n",
      "Epoch [42/85] Batch 680/938 Loss D: 0.3175, Loss G: 2.2534\n",
      "Epoch [42/85] Batch 690/938 Loss D: 0.2724, Loss G: 2.1868\n",
      "Epoch [42/85] Batch 700/938 Loss D: 0.3017, Loss G: 2.2461\n",
      "Epoch [42/85] Batch 710/938 Loss D: 0.3429, Loss G: 2.2064\n",
      "Epoch [42/85] Batch 720/938 Loss D: 0.3997, Loss G: 2.3269\n",
      "Epoch [42/85] Batch 730/938 Loss D: 0.3691, Loss G: 2.0792\n",
      "Epoch [42/85] Batch 740/938 Loss D: 0.2102, Loss G: 2.4586\n",
      "Epoch [42/85] Batch 750/938 Loss D: 0.2809, Loss G: 2.2847\n",
      "Epoch [42/85] Batch 760/938 Loss D: 0.3388, Loss G: 2.2593\n",
      "Epoch [42/85] Batch 770/938 Loss D: 0.2217, Loss G: 2.4354\n",
      "Epoch [42/85] Batch 780/938 Loss D: 0.2326, Loss G: 2.9243\n",
      "Epoch [42/85] Batch 790/938 Loss D: 0.3041, Loss G: 1.9584\n",
      "Epoch [42/85] Batch 800/938 Loss D: 0.3833, Loss G: 1.8066\n",
      "Epoch [42/85] Batch 810/938 Loss D: 0.3554, Loss G: 1.5720\n",
      "Epoch [42/85] Batch 820/938 Loss D: 0.3450, Loss G: 1.8032\n",
      "Epoch [42/85] Batch 830/938 Loss D: 0.4045, Loss G: 2.1374\n",
      "Epoch [42/85] Batch 840/938 Loss D: 0.3749, Loss G: 1.9338\n",
      "Epoch [42/85] Batch 850/938 Loss D: 0.3473, Loss G: 2.7501\n",
      "Epoch [42/85] Batch 860/938 Loss D: 0.1933, Loss G: 2.7698\n",
      "Epoch [42/85] Batch 870/938 Loss D: 0.3513, Loss G: 1.7848\n",
      "Epoch [42/85] Batch 880/938 Loss D: 0.3508, Loss G: 1.8537\n",
      "Epoch [42/85] Batch 890/938 Loss D: 0.2687, Loss G: 2.4363\n",
      "Epoch [42/85] Batch 900/938 Loss D: 0.2972, Loss G: 2.3647\n",
      "Epoch [42/85] Batch 910/938 Loss D: 0.2227, Loss G: 2.4250\n",
      "Epoch [42/85] Batch 920/938 Loss D: 0.3951, Loss G: 2.0493\n",
      "Epoch [42/85] Batch 930/938 Loss D: 0.5348, Loss G: 1.9679\n",
      "Epoch [43/85] Batch 0/938 Loss D: 0.2632, Loss G: 3.3044\n",
      "Epoch [43/85] Batch 10/938 Loss D: 0.2857, Loss G: 2.2910\n",
      "Epoch [43/85] Batch 20/938 Loss D: 0.2356, Loss G: 2.5538\n",
      "Epoch [43/85] Batch 30/938 Loss D: 0.3039, Loss G: 2.2217\n",
      "Epoch [43/85] Batch 40/938 Loss D: 0.4677, Loss G: 1.4951\n",
      "Epoch [43/85] Batch 50/938 Loss D: 0.2179, Loss G: 2.2501\n",
      "Epoch [43/85] Batch 60/938 Loss D: 0.3028, Loss G: 1.7642\n",
      "Epoch [43/85] Batch 70/938 Loss D: 0.2032, Loss G: 2.2741\n",
      "Epoch [43/85] Batch 80/938 Loss D: 0.2861, Loss G: 2.5107\n",
      "Epoch [43/85] Batch 90/938 Loss D: 0.2858, Loss G: 2.5382\n",
      "Epoch [43/85] Batch 100/938 Loss D: 0.2877, Loss G: 2.3785\n",
      "Epoch [43/85] Batch 110/938 Loss D: 0.3444, Loss G: 1.4543\n",
      "Epoch [43/85] Batch 120/938 Loss D: 0.2832, Loss G: 1.9510\n",
      "Epoch [43/85] Batch 130/938 Loss D: 0.3368, Loss G: 3.2869\n",
      "Epoch [43/85] Batch 140/938 Loss D: 0.3777, Loss G: 3.4736\n",
      "Epoch [43/85] Batch 150/938 Loss D: 0.2165, Loss G: 3.2123\n",
      "Epoch [43/85] Batch 160/938 Loss D: 0.2524, Loss G: 2.3445\n",
      "Epoch [43/85] Batch 170/938 Loss D: 0.2453, Loss G: 2.4933\n",
      "Epoch [43/85] Batch 180/938 Loss D: 0.4215, Loss G: 2.3248\n",
      "Epoch [43/85] Batch 190/938 Loss D: 0.2693, Loss G: 2.7270\n",
      "Epoch [43/85] Batch 200/938 Loss D: 0.3902, Loss G: 2.4208\n",
      "Epoch [43/85] Batch 210/938 Loss D: 0.2435, Loss G: 2.8632\n",
      "Epoch [43/85] Batch 220/938 Loss D: 0.2759, Loss G: 2.3933\n",
      "Epoch [43/85] Batch 230/938 Loss D: 0.2552, Loss G: 2.1889\n",
      "Epoch [43/85] Batch 240/938 Loss D: 0.2516, Loss G: 2.7679\n",
      "Epoch [43/85] Batch 250/938 Loss D: 0.2770, Loss G: 2.3249\n",
      "Epoch [43/85] Batch 260/938 Loss D: 0.3896, Loss G: 2.0950\n",
      "Epoch [43/85] Batch 270/938 Loss D: 0.3777, Loss G: 1.7907\n",
      "Epoch [43/85] Batch 280/938 Loss D: 0.5489, Loss G: 1.3532\n",
      "Epoch [43/85] Batch 290/938 Loss D: 0.3168, Loss G: 2.0146\n",
      "Epoch [43/85] Batch 300/938 Loss D: 0.2302, Loss G: 2.4713\n",
      "Epoch [43/85] Batch 310/938 Loss D: 0.3704, Loss G: 1.8318\n",
      "Epoch [43/85] Batch 320/938 Loss D: 0.4894, Loss G: 1.9300\n",
      "Epoch [43/85] Batch 330/938 Loss D: 0.2377, Loss G: 2.7457\n",
      "Epoch [43/85] Batch 340/938 Loss D: 0.2380, Loss G: 2.2494\n",
      "Epoch [43/85] Batch 350/938 Loss D: 0.2483, Loss G: 2.4027\n",
      "Epoch [43/85] Batch 360/938 Loss D: 0.3393, Loss G: 2.4419\n",
      "Epoch [43/85] Batch 370/938 Loss D: 0.3032, Loss G: 2.0001\n",
      "Epoch [43/85] Batch 380/938 Loss D: 0.2600, Loss G: 2.6033\n",
      "Epoch [43/85] Batch 390/938 Loss D: 0.2536, Loss G: 2.3177\n",
      "Epoch [43/85] Batch 400/938 Loss D: 0.2903, Loss G: 2.1677\n",
      "Epoch [43/85] Batch 410/938 Loss D: 0.2203, Loss G: 2.3585\n",
      "Epoch [43/85] Batch 420/938 Loss D: 0.4656, Loss G: 1.6173\n",
      "Epoch [43/85] Batch 430/938 Loss D: 0.2743, Loss G: 1.7900\n",
      "Epoch [43/85] Batch 440/938 Loss D: 0.2914, Loss G: 2.2963\n",
      "Epoch [43/85] Batch 450/938 Loss D: 0.1542, Loss G: 2.7186\n",
      "Epoch [43/85] Batch 460/938 Loss D: 0.1933, Loss G: 2.6777\n",
      "Epoch [43/85] Batch 470/938 Loss D: 0.2573, Loss G: 2.5461\n",
      "Epoch [43/85] Batch 480/938 Loss D: 0.3429, Loss G: 2.5609\n",
      "Epoch [43/85] Batch 490/938 Loss D: 0.3203, Loss G: 2.6045\n",
      "Epoch [43/85] Batch 500/938 Loss D: 0.2992, Loss G: 1.8781\n",
      "Epoch [43/85] Batch 510/938 Loss D: 0.2573, Loss G: 2.2757\n",
      "Epoch [43/85] Batch 520/938 Loss D: 0.3033, Loss G: 2.1601\n",
      "Epoch [43/85] Batch 530/938 Loss D: 0.2920, Loss G: 1.6617\n",
      "Epoch [43/85] Batch 540/938 Loss D: 0.2802, Loss G: 2.3852\n",
      "Epoch [43/85] Batch 550/938 Loss D: 0.4709, Loss G: 2.2357\n",
      "Epoch [43/85] Batch 560/938 Loss D: 0.3231, Loss G: 1.8884\n",
      "Epoch [43/85] Batch 570/938 Loss D: 0.3177, Loss G: 2.4126\n",
      "Epoch [43/85] Batch 580/938 Loss D: 0.3057, Loss G: 2.7138\n",
      "Epoch [43/85] Batch 590/938 Loss D: 0.2831, Loss G: 2.5902\n",
      "Epoch [43/85] Batch 600/938 Loss D: 0.3161, Loss G: 2.1444\n",
      "Epoch [43/85] Batch 610/938 Loss D: 0.2855, Loss G: 2.4753\n",
      "Epoch [43/85] Batch 620/938 Loss D: 0.3441, Loss G: 2.8821\n",
      "Epoch [43/85] Batch 630/938 Loss D: 0.3568, Loss G: 2.1129\n",
      "Epoch [43/85] Batch 640/938 Loss D: 0.1644, Loss G: 2.7065\n",
      "Epoch [43/85] Batch 650/938 Loss D: 0.3155, Loss G: 2.4553\n",
      "Epoch [43/85] Batch 660/938 Loss D: 0.2429, Loss G: 2.4204\n",
      "Epoch [43/85] Batch 670/938 Loss D: 0.2424, Loss G: 2.5652\n",
      "Epoch [43/85] Batch 680/938 Loss D: 0.3911, Loss G: 2.3891\n",
      "Epoch [43/85] Batch 690/938 Loss D: 0.4799, Loss G: 1.8764\n",
      "Epoch [43/85] Batch 700/938 Loss D: 0.3543, Loss G: 1.7534\n",
      "Epoch [43/85] Batch 710/938 Loss D: 0.2357, Loss G: 2.4018\n",
      "Epoch [43/85] Batch 720/938 Loss D: 0.4035, Loss G: 2.0224\n",
      "Epoch [43/85] Batch 730/938 Loss D: 0.2971, Loss G: 1.8777\n",
      "Epoch [43/85] Batch 740/938 Loss D: 0.2740, Loss G: 2.2603\n",
      "Epoch [43/85] Batch 750/938 Loss D: 0.2797, Loss G: 2.3647\n",
      "Epoch [43/85] Batch 760/938 Loss D: 0.3115, Loss G: 2.3873\n",
      "Epoch [43/85] Batch 770/938 Loss D: 0.3093, Loss G: 1.9418\n",
      "Epoch [43/85] Batch 780/938 Loss D: 0.3568, Loss G: 1.7214\n",
      "Epoch [43/85] Batch 790/938 Loss D: 0.2864, Loss G: 2.0419\n",
      "Epoch [43/85] Batch 800/938 Loss D: 0.3775, Loss G: 2.5392\n",
      "Epoch [43/85] Batch 810/938 Loss D: 0.3614, Loss G: 3.0466\n",
      "Epoch [43/85] Batch 820/938 Loss D: 0.2372, Loss G: 2.4037\n",
      "Epoch [43/85] Batch 830/938 Loss D: 0.4205, Loss G: 1.5877\n",
      "Epoch [43/85] Batch 840/938 Loss D: 0.3780, Loss G: 1.9382\n",
      "Epoch [43/85] Batch 850/938 Loss D: 0.3360, Loss G: 2.1628\n",
      "Epoch [43/85] Batch 860/938 Loss D: 0.3019, Loss G: 2.7978\n",
      "Epoch [43/85] Batch 870/938 Loss D: 0.3709, Loss G: 2.7628\n",
      "Epoch [43/85] Batch 880/938 Loss D: 0.3376, Loss G: 2.6794\n",
      "Epoch [43/85] Batch 890/938 Loss D: 0.3184, Loss G: 2.7072\n",
      "Epoch [43/85] Batch 900/938 Loss D: 0.1857, Loss G: 2.6637\n",
      "Epoch [43/85] Batch 910/938 Loss D: 0.4447, Loss G: 1.7142\n",
      "Epoch [43/85] Batch 920/938 Loss D: 0.3395, Loss G: 2.4688\n",
      "Epoch [43/85] Batch 930/938 Loss D: 0.2956, Loss G: 2.6403\n",
      "Epoch [44/85] Batch 0/938 Loss D: 0.2938, Loss G: 2.2055\n",
      "Epoch [44/85] Batch 10/938 Loss D: 0.3284, Loss G: 2.0709\n",
      "Epoch [44/85] Batch 20/938 Loss D: 0.2931, Loss G: 2.5739\n",
      "Epoch [44/85] Batch 30/938 Loss D: 0.2524, Loss G: 2.4903\n",
      "Epoch [44/85] Batch 40/938 Loss D: 0.2580, Loss G: 2.0894\n",
      "Epoch [44/85] Batch 50/938 Loss D: 0.2310, Loss G: 2.9658\n",
      "Epoch [44/85] Batch 60/938 Loss D: 0.2563, Loss G: 2.4375\n",
      "Epoch [44/85] Batch 70/938 Loss D: 0.3504, Loss G: 2.4142\n",
      "Epoch [44/85] Batch 80/938 Loss D: 0.2956, Loss G: 2.5508\n",
      "Epoch [44/85] Batch 90/938 Loss D: 0.3203, Loss G: 2.4964\n",
      "Epoch [44/85] Batch 100/938 Loss D: 0.2823, Loss G: 3.3962\n",
      "Epoch [44/85] Batch 110/938 Loss D: 0.3373, Loss G: 2.2713\n",
      "Epoch [44/85] Batch 120/938 Loss D: 0.2298, Loss G: 2.8237\n",
      "Epoch [44/85] Batch 130/938 Loss D: 0.2639, Loss G: 3.0637\n",
      "Epoch [44/85] Batch 140/938 Loss D: 0.2508, Loss G: 2.9314\n",
      "Epoch [44/85] Batch 150/938 Loss D: 0.3627, Loss G: 2.0296\n",
      "Epoch [44/85] Batch 160/938 Loss D: 0.3103, Loss G: 1.5870\n",
      "Epoch [44/85] Batch 170/938 Loss D: 0.2544, Loss G: 2.4610\n",
      "Epoch [44/85] Batch 180/938 Loss D: 0.3816, Loss G: 2.8480\n",
      "Epoch [44/85] Batch 190/938 Loss D: 0.2778, Loss G: 2.7077\n",
      "Epoch [44/85] Batch 200/938 Loss D: 0.1787, Loss G: 3.1972\n",
      "Epoch [44/85] Batch 210/938 Loss D: 0.2127, Loss G: 2.9159\n",
      "Epoch [44/85] Batch 220/938 Loss D: 0.3485, Loss G: 2.3584\n",
      "Epoch [44/85] Batch 230/938 Loss D: 0.2270, Loss G: 2.6913\n",
      "Epoch [44/85] Batch 240/938 Loss D: 0.3380, Loss G: 3.0712\n",
      "Epoch [44/85] Batch 250/938 Loss D: 0.4380, Loss G: 2.2948\n",
      "Epoch [44/85] Batch 260/938 Loss D: 0.2422, Loss G: 2.9994\n",
      "Epoch [44/85] Batch 270/938 Loss D: 0.2575, Loss G: 2.4888\n",
      "Epoch [44/85] Batch 280/938 Loss D: 0.2553, Loss G: 2.9213\n",
      "Epoch [44/85] Batch 290/938 Loss D: 0.2580, Loss G: 2.8916\n",
      "Epoch [44/85] Batch 300/938 Loss D: 0.3152, Loss G: 2.5169\n",
      "Epoch [44/85] Batch 310/938 Loss D: 0.2278, Loss G: 3.3204\n",
      "Epoch [44/85] Batch 320/938 Loss D: 0.3452, Loss G: 2.6051\n",
      "Epoch [44/85] Batch 330/938 Loss D: 0.2764, Loss G: 2.5857\n",
      "Epoch [44/85] Batch 340/938 Loss D: 0.2138, Loss G: 2.5205\n",
      "Epoch [44/85] Batch 350/938 Loss D: 0.2894, Loss G: 2.3787\n",
      "Epoch [44/85] Batch 360/938 Loss D: 0.3582, Loss G: 2.7743\n",
      "Epoch [44/85] Batch 370/938 Loss D: 0.2565, Loss G: 2.5170\n",
      "Epoch [44/85] Batch 380/938 Loss D: 0.2117, Loss G: 2.4692\n",
      "Epoch [44/85] Batch 390/938 Loss D: 0.1951, Loss G: 2.4403\n",
      "Epoch [44/85] Batch 400/938 Loss D: 0.2758, Loss G: 2.1291\n",
      "Epoch [44/85] Batch 410/938 Loss D: 0.3195, Loss G: 2.2726\n",
      "Epoch [44/85] Batch 420/938 Loss D: 0.5128, Loss G: 1.8466\n",
      "Epoch [44/85] Batch 430/938 Loss D: 0.3144, Loss G: 1.9305\n",
      "Epoch [44/85] Batch 440/938 Loss D: 0.3760, Loss G: 2.2392\n",
      "Epoch [44/85] Batch 450/938 Loss D: 0.2774, Loss G: 2.4370\n",
      "Epoch [44/85] Batch 460/938 Loss D: 0.2977, Loss G: 2.7954\n",
      "Epoch [44/85] Batch 470/938 Loss D: 0.2875, Loss G: 2.3091\n",
      "Epoch [44/85] Batch 480/938 Loss D: 0.2409, Loss G: 2.4574\n",
      "Epoch [44/85] Batch 490/938 Loss D: 0.2723, Loss G: 2.3868\n",
      "Epoch [44/85] Batch 500/938 Loss D: 0.3745, Loss G: 2.0893\n",
      "Epoch [44/85] Batch 510/938 Loss D: 0.3677, Loss G: 2.2339\n",
      "Epoch [44/85] Batch 520/938 Loss D: 0.2223, Loss G: 2.6683\n",
      "Epoch [44/85] Batch 530/938 Loss D: 0.2206, Loss G: 2.7872\n",
      "Epoch [44/85] Batch 540/938 Loss D: 0.2759, Loss G: 1.9599\n",
      "Epoch [44/85] Batch 550/938 Loss D: 0.3324, Loss G: 1.6630\n",
      "Epoch [44/85] Batch 560/938 Loss D: 0.2572, Loss G: 2.1519\n",
      "Epoch [44/85] Batch 570/938 Loss D: 0.3792, Loss G: 2.7639\n",
      "Epoch [44/85] Batch 580/938 Loss D: 0.3914, Loss G: 2.4940\n",
      "Epoch [44/85] Batch 590/938 Loss D: 0.4802, Loss G: 1.9838\n",
      "Epoch [44/85] Batch 600/938 Loss D: 0.2057, Loss G: 2.9402\n",
      "Epoch [44/85] Batch 610/938 Loss D: 0.1776, Loss G: 3.1618\n",
      "Epoch [44/85] Batch 620/938 Loss D: 0.3794, Loss G: 2.1673\n",
      "Epoch [44/85] Batch 630/938 Loss D: 0.3455, Loss G: 2.2805\n",
      "Epoch [44/85] Batch 640/938 Loss D: 0.2909, Loss G: 2.3084\n",
      "Epoch [44/85] Batch 650/938 Loss D: 0.3907, Loss G: 2.6942\n",
      "Epoch [44/85] Batch 660/938 Loss D: 0.4236, Loss G: 2.5829\n",
      "Epoch [44/85] Batch 670/938 Loss D: 0.3494, Loss G: 3.0689\n",
      "Epoch [44/85] Batch 680/938 Loss D: 0.2428, Loss G: 2.6051\n",
      "Epoch [44/85] Batch 690/938 Loss D: 0.2722, Loss G: 2.2632\n",
      "Epoch [44/85] Batch 700/938 Loss D: 0.3583, Loss G: 2.2530\n",
      "Epoch [44/85] Batch 710/938 Loss D: 0.2277, Loss G: 2.4513\n",
      "Epoch [44/85] Batch 720/938 Loss D: 0.3472, Loss G: 2.0615\n",
      "Epoch [44/85] Batch 730/938 Loss D: 0.2848, Loss G: 2.2009\n",
      "Epoch [44/85] Batch 740/938 Loss D: 0.2357, Loss G: 2.0803\n",
      "Epoch [44/85] Batch 750/938 Loss D: 0.3915, Loss G: 1.9116\n",
      "Epoch [44/85] Batch 760/938 Loss D: 0.2483, Loss G: 2.6969\n",
      "Epoch [44/85] Batch 770/938 Loss D: 0.2472, Loss G: 2.6196\n",
      "Epoch [44/85] Batch 780/938 Loss D: 0.2259, Loss G: 2.0578\n",
      "Epoch [44/85] Batch 790/938 Loss D: 0.2893, Loss G: 1.9843\n",
      "Epoch [44/85] Batch 800/938 Loss D: 0.3467, Loss G: 2.5235\n",
      "Epoch [44/85] Batch 810/938 Loss D: 0.3406, Loss G: 2.0414\n",
      "Epoch [44/85] Batch 820/938 Loss D: 0.4752, Loss G: 2.2430\n",
      "Epoch [44/85] Batch 830/938 Loss D: 0.3491, Loss G: 2.9430\n",
      "Epoch [44/85] Batch 840/938 Loss D: 0.3385, Loss G: 2.4413\n",
      "Epoch [44/85] Batch 850/938 Loss D: 0.2810, Loss G: 2.6092\n",
      "Epoch [44/85] Batch 860/938 Loss D: 0.2978, Loss G: 3.0159\n",
      "Epoch [44/85] Batch 870/938 Loss D: 0.3239, Loss G: 2.5593\n",
      "Epoch [44/85] Batch 880/938 Loss D: 0.2999, Loss G: 2.3559\n",
      "Epoch [44/85] Batch 890/938 Loss D: 0.3522, Loss G: 2.4493\n",
      "Epoch [44/85] Batch 900/938 Loss D: 0.3550, Loss G: 2.2127\n",
      "Epoch [44/85] Batch 910/938 Loss D: 0.2347, Loss G: 2.6989\n",
      "Epoch [44/85] Batch 920/938 Loss D: 0.3170, Loss G: 2.0888\n",
      "Epoch [44/85] Batch 930/938 Loss D: 0.2962, Loss G: 2.3321\n",
      "Epoch [45/85] Batch 0/938 Loss D: 0.3669, Loss G: 2.5761\n",
      "Epoch [45/85] Batch 10/938 Loss D: 0.2739, Loss G: 2.9049\n",
      "Epoch [45/85] Batch 20/938 Loss D: 0.2758, Loss G: 2.2510\n",
      "Epoch [45/85] Batch 30/938 Loss D: 0.2883, Loss G: 2.2763\n",
      "Epoch [45/85] Batch 40/938 Loss D: 0.3470, Loss G: 1.8248\n",
      "Epoch [45/85] Batch 50/938 Loss D: 0.1983, Loss G: 2.3212\n",
      "Epoch [45/85] Batch 60/938 Loss D: 0.2482, Loss G: 2.0905\n",
      "Epoch [45/85] Batch 70/938 Loss D: 0.3355, Loss G: 2.4247\n",
      "Epoch [45/85] Batch 80/938 Loss D: 0.2317, Loss G: 2.6881\n",
      "Epoch [45/85] Batch 90/938 Loss D: 0.3043, Loss G: 2.9737\n",
      "Epoch [45/85] Batch 100/938 Loss D: 0.2992, Loss G: 2.5427\n",
      "Epoch [45/85] Batch 110/938 Loss D: 0.2633, Loss G: 2.5557\n",
      "Epoch [45/85] Batch 120/938 Loss D: 0.2104, Loss G: 2.9503\n",
      "Epoch [45/85] Batch 130/938 Loss D: 0.3281, Loss G: 1.9457\n",
      "Epoch [45/85] Batch 140/938 Loss D: 0.3760, Loss G: 1.8586\n",
      "Epoch [45/85] Batch 150/938 Loss D: 0.2500, Loss G: 1.8856\n",
      "Epoch [45/85] Batch 160/938 Loss D: 0.2932, Loss G: 2.4877\n",
      "Epoch [45/85] Batch 170/938 Loss D: 0.4117, Loss G: 1.8321\n",
      "Epoch [45/85] Batch 180/938 Loss D: 0.2741, Loss G: 2.8525\n",
      "Epoch [45/85] Batch 190/938 Loss D: 0.3369, Loss G: 2.9049\n",
      "Epoch [45/85] Batch 200/938 Loss D: 0.3131, Loss G: 2.6074\n",
      "Epoch [45/85] Batch 210/938 Loss D: 0.3078, Loss G: 3.3625\n",
      "Epoch [45/85] Batch 220/938 Loss D: 0.3251, Loss G: 2.1857\n",
      "Epoch [45/85] Batch 230/938 Loss D: 0.2740, Loss G: 2.4018\n",
      "Epoch [45/85] Batch 240/938 Loss D: 0.3143, Loss G: 2.2636\n",
      "Epoch [45/85] Batch 250/938 Loss D: 0.2644, Loss G: 2.3707\n",
      "Epoch [45/85] Batch 260/938 Loss D: 0.2169, Loss G: 2.5145\n",
      "Epoch [45/85] Batch 270/938 Loss D: 0.2883, Loss G: 1.7626\n",
      "Epoch [45/85] Batch 280/938 Loss D: 0.2740, Loss G: 2.6189\n",
      "Epoch [45/85] Batch 290/938 Loss D: 0.3113, Loss G: 2.9706\n",
      "Epoch [45/85] Batch 300/938 Loss D: 0.2085, Loss G: 2.8513\n",
      "Epoch [45/85] Batch 310/938 Loss D: 0.2569, Loss G: 3.0593\n",
      "Epoch [45/85] Batch 320/938 Loss D: 0.2126, Loss G: 3.1716\n",
      "Epoch [45/85] Batch 330/938 Loss D: 0.3091, Loss G: 2.4330\n",
      "Epoch [45/85] Batch 340/938 Loss D: 0.2369, Loss G: 2.7538\n",
      "Epoch [45/85] Batch 350/938 Loss D: 0.1562, Loss G: 3.3161\n",
      "Epoch [45/85] Batch 360/938 Loss D: 0.2634, Loss G: 2.0290\n",
      "Epoch [45/85] Batch 370/938 Loss D: 0.3041, Loss G: 2.0129\n",
      "Epoch [45/85] Batch 380/938 Loss D: 0.3056, Loss G: 2.3933\n",
      "Epoch [45/85] Batch 390/938 Loss D: 0.1870, Loss G: 2.9117\n",
      "Epoch [45/85] Batch 400/938 Loss D: 0.3198, Loss G: 2.3043\n",
      "Epoch [45/85] Batch 410/938 Loss D: 0.2527, Loss G: 1.9579\n",
      "Epoch [45/85] Batch 420/938 Loss D: 0.2980, Loss G: 2.5341\n",
      "Epoch [45/85] Batch 430/938 Loss D: 0.2210, Loss G: 2.6956\n",
      "Epoch [45/85] Batch 440/938 Loss D: 0.3127, Loss G: 2.7185\n",
      "Epoch [45/85] Batch 450/938 Loss D: 0.3168, Loss G: 1.9626\n",
      "Epoch [45/85] Batch 460/938 Loss D: 0.3025, Loss G: 2.4872\n",
      "Epoch [45/85] Batch 470/938 Loss D: 0.3063, Loss G: 2.5061\n",
      "Epoch [45/85] Batch 480/938 Loss D: 0.2363, Loss G: 1.8450\n",
      "Epoch [45/85] Batch 490/938 Loss D: 0.3734, Loss G: 2.1751\n",
      "Epoch [45/85] Batch 500/938 Loss D: 0.3497, Loss G: 2.6115\n",
      "Epoch [45/85] Batch 510/938 Loss D: 0.3945, Loss G: 2.1881\n",
      "Epoch [45/85] Batch 520/938 Loss D: 0.3425, Loss G: 2.1716\n",
      "Epoch [45/85] Batch 530/938 Loss D: 0.3618, Loss G: 2.5541\n",
      "Epoch [45/85] Batch 540/938 Loss D: 0.5141, Loss G: 1.5576\n",
      "Epoch [45/85] Batch 550/938 Loss D: 0.2766, Loss G: 2.2704\n",
      "Epoch [45/85] Batch 560/938 Loss D: 0.3219, Loss G: 2.3261\n",
      "Epoch [45/85] Batch 570/938 Loss D: 0.3112, Loss G: 1.9741\n",
      "Epoch [45/85] Batch 580/938 Loss D: 0.3899, Loss G: 1.4664\n",
      "Epoch [45/85] Batch 590/938 Loss D: 0.3731, Loss G: 1.7063\n",
      "Epoch [45/85] Batch 600/938 Loss D: 0.3066, Loss G: 2.7227\n",
      "Epoch [45/85] Batch 610/938 Loss D: 0.2822, Loss G: 2.4279\n",
      "Epoch [45/85] Batch 620/938 Loss D: 0.4625, Loss G: 2.2682\n",
      "Epoch [45/85] Batch 630/938 Loss D: 0.2211, Loss G: 2.6969\n",
      "Epoch [45/85] Batch 640/938 Loss D: 0.3852, Loss G: 2.3845\n",
      "Epoch [45/85] Batch 650/938 Loss D: 0.2435, Loss G: 2.7347\n",
      "Epoch [45/85] Batch 660/938 Loss D: 0.2373, Loss G: 2.5164\n",
      "Epoch [45/85] Batch 670/938 Loss D: 0.4091, Loss G: 2.1382\n",
      "Epoch [45/85] Batch 680/938 Loss D: 0.3763, Loss G: 1.9149\n",
      "Epoch [45/85] Batch 690/938 Loss D: 0.2920, Loss G: 2.4483\n",
      "Epoch [45/85] Batch 700/938 Loss D: 0.1871, Loss G: 3.1726\n",
      "Epoch [45/85] Batch 710/938 Loss D: 0.3342, Loss G: 2.3757\n",
      "Epoch [45/85] Batch 720/938 Loss D: 0.3748, Loss G: 2.1163\n",
      "Epoch [45/85] Batch 730/938 Loss D: 0.3153, Loss G: 2.0637\n",
      "Epoch [45/85] Batch 740/938 Loss D: 0.3269, Loss G: 1.9127\n",
      "Epoch [45/85] Batch 750/938 Loss D: 0.3289, Loss G: 2.0004\n",
      "Epoch [45/85] Batch 760/938 Loss D: 0.2328, Loss G: 2.2969\n",
      "Epoch [45/85] Batch 770/938 Loss D: 0.2260, Loss G: 2.5630\n",
      "Epoch [45/85] Batch 780/938 Loss D: 0.3180, Loss G: 2.3907\n",
      "Epoch [45/85] Batch 790/938 Loss D: 0.3120, Loss G: 2.6910\n",
      "Epoch [45/85] Batch 800/938 Loss D: 0.3061, Loss G: 2.2941\n",
      "Epoch [45/85] Batch 810/938 Loss D: 0.3250, Loss G: 2.9293\n",
      "Epoch [45/85] Batch 820/938 Loss D: 0.2805, Loss G: 2.2136\n",
      "Epoch [45/85] Batch 830/938 Loss D: 0.2962, Loss G: 1.8544\n",
      "Epoch [45/85] Batch 840/938 Loss D: 0.2359, Loss G: 2.4135\n",
      "Epoch [45/85] Batch 850/938 Loss D: 0.3349, Loss G: 2.0099\n",
      "Epoch [45/85] Batch 860/938 Loss D: 0.2586, Loss G: 2.6002\n",
      "Epoch [45/85] Batch 870/938 Loss D: 0.3358, Loss G: 2.6022\n",
      "Epoch [45/85] Batch 880/938 Loss D: 0.3499, Loss G: 2.0815\n",
      "Epoch [45/85] Batch 890/938 Loss D: 0.4302, Loss G: 1.8700\n",
      "Epoch [45/85] Batch 900/938 Loss D: 0.2958, Loss G: 2.3393\n",
      "Epoch [45/85] Batch 910/938 Loss D: 0.2516, Loss G: 2.2328\n",
      "Epoch [45/85] Batch 920/938 Loss D: 0.3243, Loss G: 1.7741\n",
      "Epoch [45/85] Batch 930/938 Loss D: 0.2517, Loss G: 2.5033\n",
      "Epoch [46/85] Batch 0/938 Loss D: 0.3044, Loss G: 2.1761\n",
      "Epoch [46/85] Batch 10/938 Loss D: 0.3757, Loss G: 2.0020\n",
      "Epoch [46/85] Batch 20/938 Loss D: 0.2661, Loss G: 2.7799\n",
      "Epoch [46/85] Batch 30/938 Loss D: 0.2048, Loss G: 2.7986\n",
      "Epoch [46/85] Batch 40/938 Loss D: 0.3346, Loss G: 2.5882\n",
      "Epoch [46/85] Batch 50/938 Loss D: 0.2087, Loss G: 2.4869\n",
      "Epoch [46/85] Batch 60/938 Loss D: 0.2622, Loss G: 2.0663\n",
      "Epoch [46/85] Batch 70/938 Loss D: 0.2797, Loss G: 2.2833\n",
      "Epoch [46/85] Batch 80/938 Loss D: 0.2710, Loss G: 2.5106\n",
      "Epoch [46/85] Batch 90/938 Loss D: 0.2435, Loss G: 2.8541\n",
      "Epoch [46/85] Batch 100/938 Loss D: 0.4709, Loss G: 2.6245\n",
      "Epoch [46/85] Batch 110/938 Loss D: 0.2930, Loss G: 2.7443\n",
      "Epoch [46/85] Batch 120/938 Loss D: 0.2722, Loss G: 3.1419\n",
      "Epoch [46/85] Batch 130/938 Loss D: 0.3323, Loss G: 1.9535\n",
      "Epoch [46/85] Batch 140/938 Loss D: 0.3881, Loss G: 2.4804\n",
      "Epoch [46/85] Batch 150/938 Loss D: 0.2208, Loss G: 2.8876\n",
      "Epoch [46/85] Batch 160/938 Loss D: 0.3790, Loss G: 2.4695\n",
      "Epoch [46/85] Batch 170/938 Loss D: 0.2781, Loss G: 2.2821\n",
      "Epoch [46/85] Batch 180/938 Loss D: 0.3695, Loss G: 1.7339\n",
      "Epoch [46/85] Batch 190/938 Loss D: 0.3161, Loss G: 2.5132\n",
      "Epoch [46/85] Batch 200/938 Loss D: 0.3044, Loss G: 2.5749\n",
      "Epoch [46/85] Batch 210/938 Loss D: 0.2441, Loss G: 2.6438\n",
      "Epoch [46/85] Batch 220/938 Loss D: 0.1695, Loss G: 2.7819\n",
      "Epoch [46/85] Batch 230/938 Loss D: 0.4352, Loss G: 1.7601\n",
      "Epoch [46/85] Batch 240/938 Loss D: 0.3314, Loss G: 2.9057\n",
      "Epoch [46/85] Batch 250/938 Loss D: 0.2770, Loss G: 3.0567\n",
      "Epoch [46/85] Batch 260/938 Loss D: 0.3285, Loss G: 2.0485\n",
      "Epoch [46/85] Batch 270/938 Loss D: 0.2326, Loss G: 1.9805\n",
      "Epoch [46/85] Batch 280/938 Loss D: 0.3227, Loss G: 2.6970\n",
      "Epoch [46/85] Batch 290/938 Loss D: 0.2577, Loss G: 2.2752\n",
      "Epoch [46/85] Batch 300/938 Loss D: 0.3117, Loss G: 2.1457\n",
      "Epoch [46/85] Batch 310/938 Loss D: 0.2624, Loss G: 2.8129\n",
      "Epoch [46/85] Batch 320/938 Loss D: 0.3223, Loss G: 2.4161\n",
      "Epoch [46/85] Batch 330/938 Loss D: 0.2227, Loss G: 2.3135\n",
      "Epoch [46/85] Batch 340/938 Loss D: 0.3409, Loss G: 2.5087\n",
      "Epoch [46/85] Batch 350/938 Loss D: 0.2271, Loss G: 2.7083\n",
      "Epoch [46/85] Batch 360/938 Loss D: 0.2184, Loss G: 3.0564\n",
      "Epoch [46/85] Batch 370/938 Loss D: 0.4009, Loss G: 2.2087\n",
      "Epoch [46/85] Batch 380/938 Loss D: 0.3840, Loss G: 2.4966\n",
      "Epoch [46/85] Batch 390/938 Loss D: 0.4295, Loss G: 1.4883\n",
      "Epoch [46/85] Batch 400/938 Loss D: 0.4274, Loss G: 1.5817\n",
      "Epoch [46/85] Batch 410/938 Loss D: 0.3495, Loss G: 2.4685\n",
      "Epoch [46/85] Batch 420/938 Loss D: 0.2022, Loss G: 3.1197\n",
      "Epoch [46/85] Batch 430/938 Loss D: 0.2305, Loss G: 3.1892\n",
      "Epoch [46/85] Batch 440/938 Loss D: 0.3939, Loss G: 2.0552\n",
      "Epoch [46/85] Batch 450/938 Loss D: 0.2215, Loss G: 2.1166\n",
      "Epoch [46/85] Batch 460/938 Loss D: 0.2717, Loss G: 2.3064\n",
      "Epoch [46/85] Batch 470/938 Loss D: 0.2689, Loss G: 2.3396\n",
      "Epoch [46/85] Batch 480/938 Loss D: 0.2639, Loss G: 2.6155\n",
      "Epoch [46/85] Batch 490/938 Loss D: 0.3421, Loss G: 2.3427\n",
      "Epoch [46/85] Batch 500/938 Loss D: 0.2217, Loss G: 2.7126\n",
      "Epoch [46/85] Batch 510/938 Loss D: 0.2112, Loss G: 2.5286\n",
      "Epoch [46/85] Batch 520/938 Loss D: 0.5151, Loss G: 2.1218\n",
      "Epoch [46/85] Batch 530/938 Loss D: 0.2873, Loss G: 2.0313\n",
      "Epoch [46/85] Batch 540/938 Loss D: 0.5557, Loss G: 1.8239\n",
      "Epoch [46/85] Batch 550/938 Loss D: 0.4309, Loss G: 1.6145\n",
      "Epoch [46/85] Batch 560/938 Loss D: 0.3011, Loss G: 2.7320\n",
      "Epoch [46/85] Batch 570/938 Loss D: 0.2458, Loss G: 2.3525\n",
      "Epoch [46/85] Batch 580/938 Loss D: 0.2188, Loss G: 2.4036\n",
      "Epoch [46/85] Batch 590/938 Loss D: 0.2891, Loss G: 2.9646\n",
      "Epoch [46/85] Batch 600/938 Loss D: 0.1372, Loss G: 3.3816\n",
      "Epoch [46/85] Batch 610/938 Loss D: 0.2023, Loss G: 2.4344\n",
      "Epoch [46/85] Batch 620/938 Loss D: 0.3089, Loss G: 2.0440\n",
      "Epoch [46/85] Batch 630/938 Loss D: 0.3646, Loss G: 2.2045\n",
      "Epoch [46/85] Batch 640/938 Loss D: 0.1870, Loss G: 2.6935\n",
      "Epoch [46/85] Batch 650/938 Loss D: 0.1931, Loss G: 2.3632\n",
      "Epoch [46/85] Batch 660/938 Loss D: 0.2407, Loss G: 2.3646\n",
      "Epoch [46/85] Batch 670/938 Loss D: 0.3082, Loss G: 2.0133\n",
      "Epoch [46/85] Batch 680/938 Loss D: 0.2341, Loss G: 2.7277\n",
      "Epoch [46/85] Batch 690/938 Loss D: 0.2903, Loss G: 2.9741\n",
      "Epoch [46/85] Batch 700/938 Loss D: 0.4185, Loss G: 2.4573\n",
      "Epoch [46/85] Batch 710/938 Loss D: 0.2605, Loss G: 2.2114\n",
      "Epoch [46/85] Batch 720/938 Loss D: 0.3528, Loss G: 1.9610\n",
      "Epoch [46/85] Batch 730/938 Loss D: 0.2866, Loss G: 3.0955\n",
      "Epoch [46/85] Batch 740/938 Loss D: 0.3204, Loss G: 2.5950\n",
      "Epoch [46/85] Batch 750/938 Loss D: 0.2359, Loss G: 2.8933\n",
      "Epoch [46/85] Batch 760/938 Loss D: 0.3218, Loss G: 2.6441\n",
      "Epoch [46/85] Batch 770/938 Loss D: 0.1569, Loss G: 3.2065\n",
      "Epoch [46/85] Batch 780/938 Loss D: 0.2710, Loss G: 2.8683\n",
      "Epoch [46/85] Batch 790/938 Loss D: 0.3151, Loss G: 2.3405\n",
      "Epoch [46/85] Batch 800/938 Loss D: 0.3520, Loss G: 2.1058\n",
      "Epoch [46/85] Batch 810/938 Loss D: 0.2940, Loss G: 2.8938\n",
      "Epoch [46/85] Batch 820/938 Loss D: 0.3141, Loss G: 2.5911\n",
      "Epoch [46/85] Batch 830/938 Loss D: 0.1414, Loss G: 3.5163\n",
      "Epoch [46/85] Batch 840/938 Loss D: 0.2763, Loss G: 2.1494\n",
      "Epoch [46/85] Batch 850/938 Loss D: 0.2305, Loss G: 2.5851\n",
      "Epoch [46/85] Batch 860/938 Loss D: 0.3030, Loss G: 2.3410\n",
      "Epoch [46/85] Batch 870/938 Loss D: 0.2888, Loss G: 2.8841\n",
      "Epoch [46/85] Batch 880/938 Loss D: 0.3206, Loss G: 2.1656\n",
      "Epoch [46/85] Batch 890/938 Loss D: 0.2623, Loss G: 2.0297\n",
      "Epoch [46/85] Batch 900/938 Loss D: 0.3279, Loss G: 1.8291\n",
      "Epoch [46/85] Batch 910/938 Loss D: 0.2601, Loss G: 2.3086\n",
      "Epoch [46/85] Batch 920/938 Loss D: 0.2062, Loss G: 2.6302\n",
      "Epoch [46/85] Batch 930/938 Loss D: 0.2312, Loss G: 2.5100\n",
      "Epoch [47/85] Batch 0/938 Loss D: 0.3868, Loss G: 1.5917\n",
      "Epoch [47/85] Batch 10/938 Loss D: 0.3212, Loss G: 2.5364\n",
      "Epoch [47/85] Batch 20/938 Loss D: 0.3321, Loss G: 2.6133\n",
      "Epoch [47/85] Batch 30/938 Loss D: 0.3198, Loss G: 2.0960\n",
      "Epoch [47/85] Batch 40/938 Loss D: 0.4901, Loss G: 2.1359\n",
      "Epoch [47/85] Batch 50/938 Loss D: 0.3356, Loss G: 2.4899\n",
      "Epoch [47/85] Batch 60/938 Loss D: 0.2045, Loss G: 2.9432\n",
      "Epoch [47/85] Batch 70/938 Loss D: 0.1873, Loss G: 2.6887\n",
      "Epoch [47/85] Batch 80/938 Loss D: 0.2459, Loss G: 2.3219\n",
      "Epoch [47/85] Batch 90/938 Loss D: 0.3149, Loss G: 2.6691\n",
      "Epoch [47/85] Batch 100/938 Loss D: 0.2543, Loss G: 2.4194\n",
      "Epoch [47/85] Batch 110/938 Loss D: 0.3272, Loss G: 2.0012\n",
      "Epoch [47/85] Batch 120/938 Loss D: 0.4262, Loss G: 1.5965\n",
      "Epoch [47/85] Batch 130/938 Loss D: 0.2496, Loss G: 2.3804\n",
      "Epoch [47/85] Batch 140/938 Loss D: 0.3019, Loss G: 2.4699\n",
      "Epoch [47/85] Batch 150/938 Loss D: 0.3730, Loss G: 2.3197\n",
      "Epoch [47/85] Batch 160/938 Loss D: 0.3614, Loss G: 2.7081\n",
      "Epoch [47/85] Batch 170/938 Loss D: 0.3207, Loss G: 2.5751\n",
      "Epoch [47/85] Batch 180/938 Loss D: 0.2197, Loss G: 3.0746\n",
      "Epoch [47/85] Batch 190/938 Loss D: 0.3215, Loss G: 2.5247\n",
      "Epoch [47/85] Batch 200/938 Loss D: 0.2401, Loss G: 2.4703\n",
      "Epoch [47/85] Batch 210/938 Loss D: 0.4030, Loss G: 2.0858\n",
      "Epoch [47/85] Batch 220/938 Loss D: 0.2210, Loss G: 2.3831\n",
      "Epoch [47/85] Batch 230/938 Loss D: 0.3497, Loss G: 2.2871\n",
      "Epoch [47/85] Batch 240/938 Loss D: 0.2588, Loss G: 2.6731\n",
      "Epoch [47/85] Batch 250/938 Loss D: 0.3470, Loss G: 2.8409\n",
      "Epoch [47/85] Batch 260/938 Loss D: 0.2939, Loss G: 1.9570\n",
      "Epoch [47/85] Batch 270/938 Loss D: 0.3731, Loss G: 2.6923\n",
      "Epoch [47/85] Batch 280/938 Loss D: 0.3521, Loss G: 2.5423\n",
      "Epoch [47/85] Batch 290/938 Loss D: 0.3009, Loss G: 2.5768\n",
      "Epoch [47/85] Batch 300/938 Loss D: 0.4448, Loss G: 2.7611\n",
      "Epoch [47/85] Batch 310/938 Loss D: 0.3697, Loss G: 2.3061\n",
      "Epoch [47/85] Batch 320/938 Loss D: 0.3050, Loss G: 2.5087\n",
      "Epoch [47/85] Batch 330/938 Loss D: 0.2441, Loss G: 2.9189\n",
      "Epoch [47/85] Batch 340/938 Loss D: 0.2541, Loss G: 2.7415\n",
      "Epoch [47/85] Batch 350/938 Loss D: 0.2586, Loss G: 2.2871\n",
      "Epoch [47/85] Batch 360/938 Loss D: 0.3691, Loss G: 2.1565\n",
      "Epoch [47/85] Batch 370/938 Loss D: 0.3388, Loss G: 2.2096\n",
      "Epoch [47/85] Batch 380/938 Loss D: 0.3028, Loss G: 2.2240\n",
      "Epoch [47/85] Batch 390/938 Loss D: 0.3394, Loss G: 1.8955\n",
      "Epoch [47/85] Batch 400/938 Loss D: 0.2955, Loss G: 1.8068\n",
      "Epoch [47/85] Batch 410/938 Loss D: 0.3320, Loss G: 2.4066\n",
      "Epoch [47/85] Batch 420/938 Loss D: 0.2504, Loss G: 2.8657\n",
      "Epoch [47/85] Batch 430/938 Loss D: 0.2398, Loss G: 2.7843\n",
      "Epoch [47/85] Batch 440/938 Loss D: 0.3193, Loss G: 2.3156\n",
      "Epoch [47/85] Batch 450/938 Loss D: 0.4251, Loss G: 2.3672\n",
      "Epoch [47/85] Batch 460/938 Loss D: 0.3028, Loss G: 2.2376\n",
      "Epoch [47/85] Batch 470/938 Loss D: 0.3311, Loss G: 1.9609\n",
      "Epoch [47/85] Batch 480/938 Loss D: 0.4021, Loss G: 1.8550\n",
      "Epoch [47/85] Batch 490/938 Loss D: 0.4571, Loss G: 2.0073\n",
      "Epoch [47/85] Batch 500/938 Loss D: 0.3785, Loss G: 1.8867\n",
      "Epoch [47/85] Batch 510/938 Loss D: 0.2045, Loss G: 3.2959\n",
      "Epoch [47/85] Batch 520/938 Loss D: 0.3509, Loss G: 2.0342\n",
      "Epoch [47/85] Batch 530/938 Loss D: 0.2659, Loss G: 2.2548\n",
      "Epoch [47/85] Batch 540/938 Loss D: 0.3692, Loss G: 2.0446\n",
      "Epoch [47/85] Batch 550/938 Loss D: 0.3164, Loss G: 2.3397\n",
      "Epoch [47/85] Batch 560/938 Loss D: 0.3650, Loss G: 2.2629\n",
      "Epoch [47/85] Batch 570/938 Loss D: 0.4104, Loss G: 2.1784\n",
      "Epoch [47/85] Batch 580/938 Loss D: 0.3365, Loss G: 1.8648\n",
      "Epoch [47/85] Batch 590/938 Loss D: 0.3379, Loss G: 1.5878\n",
      "Epoch [47/85] Batch 600/938 Loss D: 0.2642, Loss G: 2.2529\n",
      "Epoch [47/85] Batch 610/938 Loss D: 0.2710, Loss G: 2.8097\n",
      "Epoch [47/85] Batch 620/938 Loss D: 0.3365, Loss G: 2.4061\n",
      "Epoch [47/85] Batch 630/938 Loss D: 0.2961, Loss G: 2.2945\n",
      "Epoch [47/85] Batch 640/938 Loss D: 0.3135, Loss G: 2.1133\n",
      "Epoch [47/85] Batch 650/938 Loss D: 0.2998, Loss G: 2.7112\n",
      "Epoch [47/85] Batch 660/938 Loss D: 0.2303, Loss G: 2.6104\n",
      "Epoch [47/85] Batch 670/938 Loss D: 0.3308, Loss G: 2.3288\n",
      "Epoch [47/85] Batch 680/938 Loss D: 0.4334, Loss G: 2.5418\n",
      "Epoch [47/85] Batch 690/938 Loss D: 0.2553, Loss G: 2.7889\n",
      "Epoch [47/85] Batch 700/938 Loss D: 0.4239, Loss G: 1.7453\n",
      "Epoch [47/85] Batch 710/938 Loss D: 0.2917, Loss G: 1.9045\n",
      "Epoch [47/85] Batch 720/938 Loss D: 0.3290, Loss G: 2.2945\n",
      "Epoch [47/85] Batch 730/938 Loss D: 0.3640, Loss G: 2.7771\n",
      "Epoch [47/85] Batch 740/938 Loss D: 0.4531, Loss G: 2.3929\n",
      "Epoch [47/85] Batch 750/938 Loss D: 0.3857, Loss G: 2.6757\n",
      "Epoch [47/85] Batch 760/938 Loss D: 0.3086, Loss G: 2.2434\n",
      "Epoch [47/85] Batch 770/938 Loss D: 0.3287, Loss G: 2.0999\n",
      "Epoch [47/85] Batch 780/938 Loss D: 0.3600, Loss G: 1.9559\n",
      "Epoch [47/85] Batch 790/938 Loss D: 0.2544, Loss G: 2.6590\n",
      "Epoch [47/85] Batch 800/938 Loss D: 0.2229, Loss G: 3.0672\n",
      "Epoch [47/85] Batch 810/938 Loss D: 0.3239, Loss G: 2.1792\n",
      "Epoch [47/85] Batch 820/938 Loss D: 0.3656, Loss G: 1.9297\n",
      "Epoch [47/85] Batch 830/938 Loss D: 0.3422, Loss G: 2.0234\n",
      "Epoch [47/85] Batch 840/938 Loss D: 0.1997, Loss G: 2.9775\n",
      "Epoch [47/85] Batch 850/938 Loss D: 0.2907, Loss G: 2.5655\n",
      "Epoch [47/85] Batch 860/938 Loss D: 0.2984, Loss G: 2.3066\n",
      "Epoch [47/85] Batch 870/938 Loss D: 0.3265, Loss G: 1.7793\n",
      "Epoch [47/85] Batch 880/938 Loss D: 0.2066, Loss G: 2.8541\n",
      "Epoch [47/85] Batch 890/938 Loss D: 0.3767, Loss G: 2.0165\n",
      "Epoch [47/85] Batch 900/938 Loss D: 0.2130, Loss G: 2.2162\n",
      "Epoch [47/85] Batch 910/938 Loss D: 0.2671, Loss G: 2.5010\n",
      "Epoch [47/85] Batch 920/938 Loss D: 0.3058, Loss G: 3.0126\n",
      "Epoch [47/85] Batch 930/938 Loss D: 0.3640, Loss G: 2.6645\n",
      "Epoch [48/85] Batch 0/938 Loss D: 0.2413, Loss G: 2.6739\n",
      "Epoch [48/85] Batch 10/938 Loss D: 0.2605, Loss G: 2.4965\n",
      "Epoch [48/85] Batch 20/938 Loss D: 0.2636, Loss G: 1.9938\n",
      "Epoch [48/85] Batch 30/938 Loss D: 0.3007, Loss G: 2.2459\n",
      "Epoch [48/85] Batch 40/938 Loss D: 0.3793, Loss G: 1.7747\n",
      "Epoch [48/85] Batch 50/938 Loss D: 0.4348, Loss G: 1.7010\n",
      "Epoch [48/85] Batch 60/938 Loss D: 0.4062, Loss G: 2.3813\n",
      "Epoch [48/85] Batch 70/938 Loss D: 0.3292, Loss G: 2.9282\n",
      "Epoch [48/85] Batch 80/938 Loss D: 0.2426, Loss G: 2.6492\n",
      "Epoch [48/85] Batch 90/938 Loss D: 0.3882, Loss G: 2.2539\n",
      "Epoch [48/85] Batch 100/938 Loss D: 0.2827, Loss G: 2.3260\n",
      "Epoch [48/85] Batch 110/938 Loss D: 0.3112, Loss G: 2.5724\n",
      "Epoch [48/85] Batch 120/938 Loss D: 0.2268, Loss G: 2.7232\n",
      "Epoch [48/85] Batch 130/938 Loss D: 0.2556, Loss G: 2.7364\n",
      "Epoch [48/85] Batch 140/938 Loss D: 0.2388, Loss G: 2.3515\n",
      "Epoch [48/85] Batch 150/938 Loss D: 0.2230, Loss G: 2.7113\n",
      "Epoch [48/85] Batch 160/938 Loss D: 0.2143, Loss G: 2.6606\n",
      "Epoch [48/85] Batch 170/938 Loss D: 0.2779, Loss G: 2.3265\n",
      "Epoch [48/85] Batch 180/938 Loss D: 0.2217, Loss G: 2.6702\n",
      "Epoch [48/85] Batch 190/938 Loss D: 0.2995, Loss G: 1.8216\n",
      "Epoch [48/85] Batch 200/938 Loss D: 0.3148, Loss G: 2.6786\n",
      "Epoch [48/85] Batch 210/938 Loss D: 0.2885, Loss G: 2.1864\n",
      "Epoch [48/85] Batch 220/938 Loss D: 0.1985, Loss G: 2.7797\n",
      "Epoch [48/85] Batch 230/938 Loss D: 0.2334, Loss G: 2.3014\n",
      "Epoch [48/85] Batch 240/938 Loss D: 0.2806, Loss G: 2.9820\n",
      "Epoch [48/85] Batch 250/938 Loss D: 0.2895, Loss G: 1.9028\n",
      "Epoch [48/85] Batch 260/938 Loss D: 0.3462, Loss G: 2.5455\n",
      "Epoch [48/85] Batch 270/938 Loss D: 0.2158, Loss G: 3.4379\n",
      "Epoch [48/85] Batch 280/938 Loss D: 0.3546, Loss G: 2.9133\n",
      "Epoch [48/85] Batch 290/938 Loss D: 0.3296, Loss G: 2.0029\n",
      "Epoch [48/85] Batch 300/938 Loss D: 0.3200, Loss G: 1.8935\n",
      "Epoch [48/85] Batch 310/938 Loss D: 0.2277, Loss G: 2.4783\n",
      "Epoch [48/85] Batch 320/938 Loss D: 0.2939, Loss G: 2.5589\n",
      "Epoch [48/85] Batch 330/938 Loss D: 0.2713, Loss G: 2.7911\n",
      "Epoch [48/85] Batch 340/938 Loss D: 0.2558, Loss G: 2.3769\n",
      "Epoch [48/85] Batch 350/938 Loss D: 0.4448, Loss G: 1.6588\n",
      "Epoch [48/85] Batch 360/938 Loss D: 0.2201, Loss G: 2.3744\n",
      "Epoch [48/85] Batch 370/938 Loss D: 0.2889, Loss G: 2.4439\n",
      "Epoch [48/85] Batch 380/938 Loss D: 0.2652, Loss G: 2.3233\n",
      "Epoch [48/85] Batch 390/938 Loss D: 0.4046, Loss G: 1.9725\n",
      "Epoch [48/85] Batch 400/938 Loss D: 0.3418, Loss G: 2.4087\n",
      "Epoch [48/85] Batch 410/938 Loss D: 0.3138, Loss G: 1.9731\n",
      "Epoch [48/85] Batch 420/938 Loss D: 0.2239, Loss G: 2.4217\n",
      "Epoch [48/85] Batch 430/938 Loss D: 0.2814, Loss G: 2.3077\n",
      "Epoch [48/85] Batch 440/938 Loss D: 0.2575, Loss G: 2.0218\n",
      "Epoch [48/85] Batch 450/938 Loss D: 0.4066, Loss G: 1.5874\n",
      "Epoch [48/85] Batch 460/938 Loss D: 0.3428, Loss G: 1.9158\n",
      "Epoch [48/85] Batch 470/938 Loss D: 0.2955, Loss G: 2.2793\n",
      "Epoch [48/85] Batch 480/938 Loss D: 0.2876, Loss G: 2.4339\n",
      "Epoch [48/85] Batch 490/938 Loss D: 0.2581, Loss G: 2.0394\n",
      "Epoch [48/85] Batch 500/938 Loss D: 0.3818, Loss G: 1.5449\n",
      "Epoch [48/85] Batch 510/938 Loss D: 0.3321, Loss G: 2.0036\n",
      "Epoch [48/85] Batch 520/938 Loss D: 0.3933, Loss G: 1.9609\n",
      "Epoch [48/85] Batch 530/938 Loss D: 0.3355, Loss G: 2.4182\n",
      "Epoch [48/85] Batch 540/938 Loss D: 0.2348, Loss G: 3.5205\n",
      "Epoch [48/85] Batch 550/938 Loss D: 0.2227, Loss G: 3.1940\n",
      "Epoch [48/85] Batch 560/938 Loss D: 0.3728, Loss G: 1.9474\n",
      "Epoch [48/85] Batch 570/938 Loss D: 0.2385, Loss G: 2.6025\n",
      "Epoch [48/85] Batch 580/938 Loss D: 0.3601, Loss G: 2.0278\n",
      "Epoch [48/85] Batch 590/938 Loss D: 0.3615, Loss G: 2.0780\n",
      "Epoch [48/85] Batch 600/938 Loss D: 0.3501, Loss G: 2.6347\n",
      "Epoch [48/85] Batch 610/938 Loss D: 0.2760, Loss G: 2.4154\n",
      "Epoch [48/85] Batch 620/938 Loss D: 0.2937, Loss G: 2.6769\n",
      "Epoch [48/85] Batch 630/938 Loss D: 0.2465, Loss G: 2.1372\n",
      "Epoch [48/85] Batch 640/938 Loss D: 0.3763, Loss G: 2.2637\n",
      "Epoch [48/85] Batch 650/938 Loss D: 0.2919, Loss G: 2.5041\n",
      "Epoch [48/85] Batch 660/938 Loss D: 0.3225, Loss G: 2.2420\n",
      "Epoch [48/85] Batch 670/938 Loss D: 0.2420, Loss G: 2.7962\n",
      "Epoch [48/85] Batch 680/938 Loss D: 0.3155, Loss G: 2.3500\n",
      "Epoch [48/85] Batch 690/938 Loss D: 0.2691, Loss G: 2.9029\n",
      "Epoch [48/85] Batch 700/938 Loss D: 0.2955, Loss G: 2.4998\n",
      "Epoch [48/85] Batch 710/938 Loss D: 0.3321, Loss G: 2.4498\n",
      "Epoch [48/85] Batch 720/938 Loss D: 0.2222, Loss G: 2.8384\n",
      "Epoch [48/85] Batch 730/938 Loss D: 0.3190, Loss G: 2.5059\n",
      "Epoch [48/85] Batch 740/938 Loss D: 0.2563, Loss G: 2.6371\n",
      "Epoch [48/85] Batch 750/938 Loss D: 0.2674, Loss G: 3.2132\n",
      "Epoch [48/85] Batch 760/938 Loss D: 0.3141, Loss G: 2.0913\n",
      "Epoch [48/85] Batch 770/938 Loss D: 0.3791, Loss G: 1.9855\n",
      "Epoch [48/85] Batch 780/938 Loss D: 0.2369, Loss G: 2.5980\n",
      "Epoch [48/85] Batch 790/938 Loss D: 0.3426, Loss G: 1.8888\n",
      "Epoch [48/85] Batch 800/938 Loss D: 0.3199, Loss G: 2.1196\n",
      "Epoch [48/85] Batch 810/938 Loss D: 0.3068, Loss G: 1.8083\n",
      "Epoch [48/85] Batch 820/938 Loss D: 0.3230, Loss G: 2.0170\n",
      "Epoch [48/85] Batch 830/938 Loss D: 0.2654, Loss G: 2.5987\n",
      "Epoch [48/85] Batch 840/938 Loss D: 0.3021, Loss G: 2.4151\n",
      "Epoch [48/85] Batch 850/938 Loss D: 0.2733, Loss G: 2.0898\n",
      "Epoch [48/85] Batch 860/938 Loss D: 0.3723, Loss G: 2.0902\n",
      "Epoch [48/85] Batch 870/938 Loss D: 0.2912, Loss G: 2.0977\n",
      "Epoch [48/85] Batch 880/938 Loss D: 0.2916, Loss G: 2.6828\n",
      "Epoch [48/85] Batch 890/938 Loss D: 0.2537, Loss G: 2.4981\n",
      "Epoch [48/85] Batch 900/938 Loss D: 0.2602, Loss G: 2.6845\n",
      "Epoch [48/85] Batch 910/938 Loss D: 0.2429, Loss G: 2.4777\n",
      "Epoch [48/85] Batch 920/938 Loss D: 0.3002, Loss G: 1.8781\n",
      "Epoch [48/85] Batch 930/938 Loss D: 0.2373, Loss G: 2.4372\n",
      "Epoch [49/85] Batch 0/938 Loss D: 0.2789, Loss G: 2.4738\n",
      "Epoch [49/85] Batch 10/938 Loss D: 0.3463, Loss G: 2.1225\n",
      "Epoch [49/85] Batch 20/938 Loss D: 0.2671, Loss G: 2.2876\n",
      "Epoch [49/85] Batch 30/938 Loss D: 0.2534, Loss G: 2.0646\n",
      "Epoch [49/85] Batch 40/938 Loss D: 0.2549, Loss G: 2.9131\n",
      "Epoch [49/85] Batch 50/938 Loss D: 0.3157, Loss G: 2.7349\n",
      "Epoch [49/85] Batch 60/938 Loss D: 0.3099, Loss G: 2.4725\n",
      "Epoch [49/85] Batch 70/938 Loss D: 0.2867, Loss G: 2.3867\n",
      "Epoch [49/85] Batch 80/938 Loss D: 0.2712, Loss G: 2.2098\n",
      "Epoch [49/85] Batch 90/938 Loss D: 0.2880, Loss G: 2.3599\n",
      "Epoch [49/85] Batch 100/938 Loss D: 0.3320, Loss G: 1.9502\n",
      "Epoch [49/85] Batch 110/938 Loss D: 0.2499, Loss G: 2.6172\n",
      "Epoch [49/85] Batch 120/938 Loss D: 0.2706, Loss G: 2.5374\n",
      "Epoch [49/85] Batch 130/938 Loss D: 0.3241, Loss G: 2.4181\n",
      "Epoch [49/85] Batch 140/938 Loss D: 0.1917, Loss G: 3.1499\n",
      "Epoch [49/85] Batch 150/938 Loss D: 0.3724, Loss G: 2.2606\n",
      "Epoch [49/85] Batch 160/938 Loss D: 0.3206, Loss G: 2.1241\n",
      "Epoch [49/85] Batch 170/938 Loss D: 0.2307, Loss G: 2.3974\n",
      "Epoch [49/85] Batch 180/938 Loss D: 0.3232, Loss G: 2.5536\n",
      "Epoch [49/85] Batch 190/938 Loss D: 0.2966, Loss G: 2.6584\n",
      "Epoch [49/85] Batch 200/938 Loss D: 0.3324, Loss G: 2.6497\n",
      "Epoch [49/85] Batch 210/938 Loss D: 0.4216, Loss G: 2.2287\n",
      "Epoch [49/85] Batch 220/938 Loss D: 0.4180, Loss G: 1.6765\n",
      "Epoch [49/85] Batch 230/938 Loss D: 0.2568, Loss G: 2.1312\n",
      "Epoch [49/85] Batch 240/938 Loss D: 0.3106, Loss G: 2.3197\n",
      "Epoch [49/85] Batch 250/938 Loss D: 0.2939, Loss G: 2.3046\n",
      "Epoch [49/85] Batch 260/938 Loss D: 0.3052, Loss G: 3.3958\n",
      "Epoch [49/85] Batch 270/938 Loss D: 0.3162, Loss G: 3.1248\n",
      "Epoch [49/85] Batch 280/938 Loss D: 0.4916, Loss G: 2.4129\n",
      "Epoch [49/85] Batch 290/938 Loss D: 0.3377, Loss G: 2.2375\n",
      "Epoch [49/85] Batch 300/938 Loss D: 0.2829, Loss G: 2.6414\n",
      "Epoch [49/85] Batch 310/938 Loss D: 0.3589, Loss G: 1.9217\n",
      "Epoch [49/85] Batch 320/938 Loss D: 0.3182, Loss G: 2.0614\n",
      "Epoch [49/85] Batch 330/938 Loss D: 0.1916, Loss G: 2.4632\n",
      "Epoch [49/85] Batch 340/938 Loss D: 0.3818, Loss G: 2.1294\n",
      "Epoch [49/85] Batch 350/938 Loss D: 0.4271, Loss G: 2.5473\n",
      "Epoch [49/85] Batch 360/938 Loss D: 0.1798, Loss G: 3.3668\n",
      "Epoch [49/85] Batch 370/938 Loss D: 0.5267, Loss G: 2.3887\n",
      "Epoch [49/85] Batch 380/938 Loss D: 0.2889, Loss G: 2.3422\n",
      "Epoch [49/85] Batch 390/938 Loss D: 0.2783, Loss G: 2.4456\n",
      "Epoch [49/85] Batch 400/938 Loss D: 0.3422, Loss G: 1.8904\n",
      "Epoch [49/85] Batch 410/938 Loss D: 0.2908, Loss G: 2.1120\n",
      "Epoch [49/85] Batch 420/938 Loss D: 0.3871, Loss G: 2.6840\n",
      "Epoch [49/85] Batch 430/938 Loss D: 0.2858, Loss G: 2.2777\n",
      "Epoch [49/85] Batch 440/938 Loss D: 0.2912, Loss G: 1.9181\n",
      "Epoch [49/85] Batch 450/938 Loss D: 0.2696, Loss G: 2.0390\n",
      "Epoch [49/85] Batch 460/938 Loss D: 0.2480, Loss G: 2.1933\n",
      "Epoch [49/85] Batch 470/938 Loss D: 0.2607, Loss G: 2.3471\n",
      "Epoch [49/85] Batch 480/938 Loss D: 0.2373, Loss G: 3.4361\n",
      "Epoch [49/85] Batch 490/938 Loss D: 0.4209, Loss G: 2.0175\n",
      "Epoch [49/85] Batch 500/938 Loss D: 0.3001, Loss G: 1.9616\n",
      "Epoch [49/85] Batch 510/938 Loss D: 0.3181, Loss G: 1.8869\n",
      "Epoch [49/85] Batch 520/938 Loss D: 0.3534, Loss G: 2.0015\n",
      "Epoch [49/85] Batch 530/938 Loss D: 0.3262, Loss G: 1.8018\n",
      "Epoch [49/85] Batch 540/938 Loss D: 0.1789, Loss G: 2.8512\n",
      "Epoch [49/85] Batch 550/938 Loss D: 0.2985, Loss G: 2.3770\n",
      "Epoch [49/85] Batch 560/938 Loss D: 0.2676, Loss G: 2.5529\n",
      "Epoch [49/85] Batch 570/938 Loss D: 0.3285, Loss G: 2.2086\n",
      "Epoch [49/85] Batch 580/938 Loss D: 0.2522, Loss G: 2.3508\n",
      "Epoch [49/85] Batch 590/938 Loss D: 0.2192, Loss G: 2.4104\n",
      "Epoch [49/85] Batch 600/938 Loss D: 0.3408, Loss G: 2.5998\n",
      "Epoch [49/85] Batch 610/938 Loss D: 0.2704, Loss G: 2.3506\n",
      "Epoch [49/85] Batch 620/938 Loss D: 0.3180, Loss G: 2.3018\n",
      "Epoch [49/85] Batch 630/938 Loss D: 0.2494, Loss G: 2.9623\n",
      "Epoch [49/85] Batch 640/938 Loss D: 0.2344, Loss G: 2.3708\n",
      "Epoch [49/85] Batch 650/938 Loss D: 0.2680, Loss G: 1.9547\n",
      "Epoch [49/85] Batch 660/938 Loss D: 0.2139, Loss G: 2.8180\n",
      "Epoch [49/85] Batch 670/938 Loss D: 0.4295, Loss G: 2.6063\n",
      "Epoch [49/85] Batch 680/938 Loss D: 0.4944, Loss G: 2.1285\n",
      "Epoch [49/85] Batch 690/938 Loss D: 0.3264, Loss G: 2.4892\n",
      "Epoch [49/85] Batch 700/938 Loss D: 0.2736, Loss G: 3.0772\n",
      "Epoch [49/85] Batch 710/938 Loss D: 0.3013, Loss G: 2.2820\n",
      "Epoch [49/85] Batch 720/938 Loss D: 0.3759, Loss G: 2.4132\n",
      "Epoch [49/85] Batch 730/938 Loss D: 0.3070, Loss G: 2.0712\n",
      "Epoch [49/85] Batch 740/938 Loss D: 0.2730, Loss G: 2.2024\n",
      "Epoch [49/85] Batch 750/938 Loss D: 0.3832, Loss G: 2.3151\n",
      "Epoch [49/85] Batch 760/938 Loss D: 0.2931, Loss G: 2.8798\n",
      "Epoch [49/85] Batch 770/938 Loss D: 0.3064, Loss G: 2.9944\n",
      "Epoch [49/85] Batch 780/938 Loss D: 0.2746, Loss G: 1.9882\n",
      "Epoch [49/85] Batch 790/938 Loss D: 0.3090, Loss G: 1.7680\n",
      "Epoch [49/85] Batch 800/938 Loss D: 0.3179, Loss G: 1.9759\n",
      "Epoch [49/85] Batch 810/938 Loss D: 0.3468, Loss G: 1.8325\n",
      "Epoch [49/85] Batch 820/938 Loss D: 0.3055, Loss G: 2.1603\n",
      "Epoch [49/85] Batch 830/938 Loss D: 0.3594, Loss G: 2.2994\n",
      "Epoch [49/85] Batch 840/938 Loss D: 0.2610, Loss G: 2.7370\n",
      "Epoch [49/85] Batch 850/938 Loss D: 0.2720, Loss G: 2.4082\n",
      "Epoch [49/85] Batch 860/938 Loss D: 0.3470, Loss G: 2.6629\n",
      "Epoch [49/85] Batch 870/938 Loss D: 0.3017, Loss G: 2.6720\n",
      "Epoch [49/85] Batch 880/938 Loss D: 0.3152, Loss G: 2.6989\n",
      "Epoch [49/85] Batch 890/938 Loss D: 0.2190, Loss G: 2.3230\n",
      "Epoch [49/85] Batch 900/938 Loss D: 0.3888, Loss G: 2.6827\n",
      "Epoch [49/85] Batch 910/938 Loss D: 0.3565, Loss G: 2.6539\n",
      "Epoch [49/85] Batch 920/938 Loss D: 0.3235, Loss G: 2.2925\n",
      "Epoch [49/85] Batch 930/938 Loss D: 0.2469, Loss G: 3.1135\n",
      "Epoch [50/85] Batch 0/938 Loss D: 0.3882, Loss G: 1.8856\n",
      "Epoch [50/85] Batch 10/938 Loss D: 0.3303, Loss G: 1.9774\n",
      "Epoch [50/85] Batch 20/938 Loss D: 0.2995, Loss G: 2.3323\n",
      "Epoch [50/85] Batch 30/938 Loss D: 0.3973, Loss G: 1.9603\n",
      "Epoch [50/85] Batch 40/938 Loss D: 0.1857, Loss G: 2.5973\n",
      "Epoch [50/85] Batch 50/938 Loss D: 0.3001, Loss G: 2.1498\n",
      "Epoch [50/85] Batch 60/938 Loss D: 0.3841, Loss G: 1.7855\n",
      "Epoch [50/85] Batch 70/938 Loss D: 0.3285, Loss G: 1.8052\n",
      "Epoch [50/85] Batch 80/938 Loss D: 0.2840, Loss G: 2.3525\n",
      "Epoch [50/85] Batch 90/938 Loss D: 0.2665, Loss G: 2.7763\n",
      "Epoch [50/85] Batch 100/938 Loss D: 0.2863, Loss G: 2.3419\n",
      "Epoch [50/85] Batch 110/938 Loss D: 0.4537, Loss G: 1.9617\n",
      "Epoch [50/85] Batch 120/938 Loss D: 0.3911, Loss G: 1.7809\n",
      "Epoch [50/85] Batch 130/938 Loss D: 0.3005, Loss G: 2.0097\n",
      "Epoch [50/85] Batch 140/938 Loss D: 0.3790, Loss G: 1.9863\n",
      "Epoch [50/85] Batch 150/938 Loss D: 0.3799, Loss G: 2.1004\n",
      "Epoch [50/85] Batch 160/938 Loss D: 0.2219, Loss G: 2.2418\n",
      "Epoch [50/85] Batch 170/938 Loss D: 0.3305, Loss G: 1.8055\n",
      "Epoch [50/85] Batch 180/938 Loss D: 0.3147, Loss G: 1.8927\n",
      "Epoch [50/85] Batch 190/938 Loss D: 0.4100, Loss G: 2.5099\n",
      "Epoch [50/85] Batch 200/938 Loss D: 0.3741, Loss G: 2.7939\n",
      "Epoch [50/85] Batch 210/938 Loss D: 0.3642, Loss G: 2.7843\n",
      "Epoch [50/85] Batch 220/938 Loss D: 0.2572, Loss G: 1.9814\n",
      "Epoch [50/85] Batch 230/938 Loss D: 0.3051, Loss G: 2.4380\n",
      "Epoch [50/85] Batch 240/938 Loss D: 0.3170, Loss G: 2.1656\n",
      "Epoch [50/85] Batch 250/938 Loss D: 0.2445, Loss G: 2.4257\n",
      "Epoch [50/85] Batch 260/938 Loss D: 0.2427, Loss G: 2.4091\n",
      "Epoch [50/85] Batch 270/938 Loss D: 0.2942, Loss G: 2.6295\n",
      "Epoch [50/85] Batch 280/938 Loss D: 0.2401, Loss G: 3.0006\n",
      "Epoch [50/85] Batch 290/938 Loss D: 0.3208, Loss G: 2.4530\n",
      "Epoch [50/85] Batch 300/938 Loss D: 0.3236, Loss G: 2.3908\n",
      "Epoch [50/85] Batch 310/938 Loss D: 0.3326, Loss G: 2.0540\n",
      "Epoch [50/85] Batch 320/938 Loss D: 0.2669, Loss G: 2.3943\n",
      "Epoch [50/85] Batch 330/938 Loss D: 0.3196, Loss G: 1.7049\n",
      "Epoch [50/85] Batch 340/938 Loss D: 0.3019, Loss G: 1.6684\n",
      "Epoch [50/85] Batch 350/938 Loss D: 0.3360, Loss G: 2.4072\n",
      "Epoch [50/85] Batch 360/938 Loss D: 0.2616, Loss G: 2.5344\n",
      "Epoch [50/85] Batch 370/938 Loss D: 0.3052, Loss G: 2.1070\n",
      "Epoch [50/85] Batch 380/938 Loss D: 0.4685, Loss G: 1.6851\n",
      "Epoch [50/85] Batch 390/938 Loss D: 0.3320, Loss G: 2.0168\n",
      "Epoch [50/85] Batch 400/938 Loss D: 0.3524, Loss G: 2.3955\n",
      "Epoch [50/85] Batch 410/938 Loss D: 0.2346, Loss G: 2.7616\n",
      "Epoch [50/85] Batch 420/938 Loss D: 0.2875, Loss G: 2.5436\n",
      "Epoch [50/85] Batch 430/938 Loss D: 0.2582, Loss G: 2.4702\n",
      "Epoch [50/85] Batch 440/938 Loss D: 0.2291, Loss G: 2.2875\n",
      "Epoch [50/85] Batch 450/938 Loss D: 0.3915, Loss G: 2.6692\n",
      "Epoch [50/85] Batch 460/938 Loss D: 0.2391, Loss G: 3.0527\n",
      "Epoch [50/85] Batch 470/938 Loss D: 0.3165, Loss G: 1.8026\n",
      "Epoch [50/85] Batch 480/938 Loss D: 0.2657, Loss G: 2.4204\n",
      "Epoch [50/85] Batch 490/938 Loss D: 0.2659, Loss G: 2.4440\n",
      "Epoch [50/85] Batch 500/938 Loss D: 0.3125, Loss G: 1.9786\n",
      "Epoch [50/85] Batch 510/938 Loss D: 0.3009, Loss G: 2.2176\n",
      "Epoch [50/85] Batch 520/938 Loss D: 0.2973, Loss G: 2.1951\n",
      "Epoch [50/85] Batch 530/938 Loss D: 0.2750, Loss G: 2.4560\n",
      "Epoch [50/85] Batch 540/938 Loss D: 0.2822, Loss G: 2.3898\n",
      "Epoch [50/85] Batch 550/938 Loss D: 0.2236, Loss G: 2.8202\n",
      "Epoch [50/85] Batch 560/938 Loss D: 0.2487, Loss G: 1.9834\n",
      "Epoch [50/85] Batch 570/938 Loss D: 0.3579, Loss G: 1.9507\n",
      "Epoch [50/85] Batch 580/938 Loss D: 0.2862, Loss G: 2.7938\n",
      "Epoch [50/85] Batch 590/938 Loss D: 0.2291, Loss G: 3.0082\n",
      "Epoch [50/85] Batch 600/938 Loss D: 0.3291, Loss G: 2.6157\n",
      "Epoch [50/85] Batch 610/938 Loss D: 0.2190, Loss G: 2.3731\n",
      "Epoch [50/85] Batch 620/938 Loss D: 0.2751, Loss G: 3.0736\n",
      "Epoch [50/85] Batch 630/938 Loss D: 0.3127, Loss G: 2.5100\n",
      "Epoch [50/85] Batch 640/938 Loss D: 0.2696, Loss G: 2.6812\n",
      "Epoch [50/85] Batch 650/938 Loss D: 0.3996, Loss G: 2.3159\n",
      "Epoch [50/85] Batch 660/938 Loss D: 0.3411, Loss G: 2.2030\n",
      "Epoch [50/85] Batch 670/938 Loss D: 0.3515, Loss G: 2.0814\n",
      "Epoch [50/85] Batch 680/938 Loss D: 0.3828, Loss G: 2.4513\n",
      "Epoch [50/85] Batch 690/938 Loss D: 0.2993, Loss G: 2.5782\n",
      "Epoch [50/85] Batch 700/938 Loss D: 0.4461, Loss G: 2.9299\n",
      "Epoch [50/85] Batch 710/938 Loss D: 0.2670, Loss G: 2.9786\n",
      "Epoch [50/85] Batch 720/938 Loss D: 0.2308, Loss G: 2.4741\n",
      "Epoch [50/85] Batch 730/938 Loss D: 0.2327, Loss G: 2.3482\n",
      "Epoch [50/85] Batch 740/938 Loss D: 0.2614, Loss G: 2.3855\n",
      "Epoch [50/85] Batch 750/938 Loss D: 0.3999, Loss G: 2.9588\n",
      "Epoch [50/85] Batch 760/938 Loss D: 0.2030, Loss G: 3.2402\n",
      "Epoch [50/85] Batch 770/938 Loss D: 0.4227, Loss G: 2.9709\n",
      "Epoch [50/85] Batch 780/938 Loss D: 0.6108, Loss G: 2.7544\n",
      "Epoch [50/85] Batch 790/938 Loss D: 0.3368, Loss G: 4.0692\n",
      "Epoch [50/85] Batch 800/938 Loss D: 0.3038, Loss G: 2.4452\n",
      "Epoch [50/85] Batch 810/938 Loss D: 0.3635, Loss G: 2.1819\n",
      "Epoch [50/85] Batch 820/938 Loss D: 0.3913, Loss G: 2.1628\n",
      "Epoch [50/85] Batch 830/938 Loss D: 0.3022, Loss G: 1.9123\n",
      "Epoch [50/85] Batch 840/938 Loss D: 0.2701, Loss G: 2.2386\n",
      "Epoch [50/85] Batch 850/938 Loss D: 0.3139, Loss G: 3.1463\n",
      "Epoch [50/85] Batch 860/938 Loss D: 0.2809, Loss G: 2.4763\n",
      "Epoch [50/85] Batch 870/938 Loss D: 0.2706, Loss G: 2.1344\n",
      "Epoch [50/85] Batch 880/938 Loss D: 0.3181, Loss G: 2.2284\n",
      "Epoch [50/85] Batch 890/938 Loss D: 0.3718, Loss G: 2.1236\n",
      "Epoch [50/85] Batch 900/938 Loss D: 0.3849, Loss G: 2.2455\n",
      "Epoch [50/85] Batch 910/938 Loss D: 0.3097, Loss G: 1.9864\n",
      "Epoch [50/85] Batch 920/938 Loss D: 0.3348, Loss G: 2.1168\n",
      "Epoch [50/85] Batch 930/938 Loss D: 0.2568, Loss G: 2.1673\n",
      "Epoch [51/85] Batch 0/938 Loss D: 0.2992, Loss G: 2.5143\n",
      "Epoch [51/85] Batch 10/938 Loss D: 0.3240, Loss G: 2.1236\n",
      "Epoch [51/85] Batch 20/938 Loss D: 0.3340, Loss G: 2.9938\n",
      "Epoch [51/85] Batch 30/938 Loss D: 0.3248, Loss G: 2.0554\n",
      "Epoch [51/85] Batch 40/938 Loss D: 0.2321, Loss G: 2.6083\n",
      "Epoch [51/85] Batch 50/938 Loss D: 0.2711, Loss G: 3.2494\n",
      "Epoch [51/85] Batch 60/938 Loss D: 0.2273, Loss G: 2.5382\n",
      "Epoch [51/85] Batch 70/938 Loss D: 0.2878, Loss G: 2.0696\n",
      "Epoch [51/85] Batch 80/938 Loss D: 0.2548, Loss G: 2.1908\n",
      "Epoch [51/85] Batch 90/938 Loss D: 0.2718, Loss G: 2.0973\n",
      "Epoch [51/85] Batch 100/938 Loss D: 0.4501, Loss G: 2.1001\n",
      "Epoch [51/85] Batch 110/938 Loss D: 0.3248, Loss G: 2.1430\n",
      "Epoch [51/85] Batch 120/938 Loss D: 0.2786, Loss G: 2.2745\n",
      "Epoch [51/85] Batch 130/938 Loss D: 0.3390, Loss G: 1.8685\n",
      "Epoch [51/85] Batch 140/938 Loss D: 0.2678, Loss G: 2.2579\n",
      "Epoch [51/85] Batch 150/938 Loss D: 0.3115, Loss G: 2.6205\n",
      "Epoch [51/85] Batch 160/938 Loss D: 0.2766, Loss G: 2.3690\n",
      "Epoch [51/85] Batch 170/938 Loss D: 0.3812, Loss G: 1.8289\n",
      "Epoch [51/85] Batch 180/938 Loss D: 0.2893, Loss G: 2.0738\n",
      "Epoch [51/85] Batch 190/938 Loss D: 0.2815, Loss G: 2.8639\n",
      "Epoch [51/85] Batch 200/938 Loss D: 0.2581, Loss G: 2.6350\n",
      "Epoch [51/85] Batch 210/938 Loss D: 0.2807, Loss G: 2.6381\n",
      "Epoch [51/85] Batch 220/938 Loss D: 0.1930, Loss G: 2.5673\n",
      "Epoch [51/85] Batch 230/938 Loss D: 0.2276, Loss G: 2.3084\n",
      "Epoch [51/85] Batch 240/938 Loss D: 0.2932, Loss G: 2.3965\n",
      "Epoch [51/85] Batch 250/938 Loss D: 0.1983, Loss G: 3.2711\n",
      "Epoch [51/85] Batch 260/938 Loss D: 0.2632, Loss G: 2.8888\n",
      "Epoch [51/85] Batch 270/938 Loss D: 0.2893, Loss G: 2.1160\n",
      "Epoch [51/85] Batch 280/938 Loss D: 0.2758, Loss G: 2.4571\n",
      "Epoch [51/85] Batch 290/938 Loss D: 0.2352, Loss G: 2.3538\n",
      "Epoch [51/85] Batch 300/938 Loss D: 0.2979, Loss G: 2.5335\n",
      "Epoch [51/85] Batch 310/938 Loss D: 0.3830, Loss G: 2.3559\n",
      "Epoch [51/85] Batch 320/938 Loss D: 0.5092, Loss G: 2.6468\n",
      "Epoch [51/85] Batch 330/938 Loss D: 0.2076, Loss G: 3.3331\n",
      "Epoch [51/85] Batch 340/938 Loss D: 0.2422, Loss G: 2.2420\n",
      "Epoch [51/85] Batch 350/938 Loss D: 0.2619, Loss G: 2.0271\n",
      "Epoch [51/85] Batch 360/938 Loss D: 0.3209, Loss G: 2.0108\n",
      "Epoch [51/85] Batch 370/938 Loss D: 0.2996, Loss G: 2.7548\n",
      "Epoch [51/85] Batch 380/938 Loss D: 0.2390, Loss G: 2.6681\n",
      "Epoch [51/85] Batch 390/938 Loss D: 0.4324, Loss G: 1.6266\n",
      "Epoch [51/85] Batch 400/938 Loss D: 0.3053, Loss G: 1.9638\n",
      "Epoch [51/85] Batch 410/938 Loss D: 0.2507, Loss G: 2.4884\n",
      "Epoch [51/85] Batch 420/938 Loss D: 0.3592, Loss G: 1.8080\n",
      "Epoch [51/85] Batch 430/938 Loss D: 0.2243, Loss G: 2.7656\n",
      "Epoch [51/85] Batch 440/938 Loss D: 0.3602, Loss G: 1.9771\n",
      "Epoch [51/85] Batch 450/938 Loss D: 0.3619, Loss G: 2.8856\n",
      "Epoch [51/85] Batch 460/938 Loss D: 0.3352, Loss G: 3.2805\n",
      "Epoch [51/85] Batch 470/938 Loss D: 0.3352, Loss G: 2.5795\n",
      "Epoch [51/85] Batch 480/938 Loss D: 0.3295, Loss G: 1.9381\n",
      "Epoch [51/85] Batch 490/938 Loss D: 0.3946, Loss G: 1.7597\n",
      "Epoch [51/85] Batch 500/938 Loss D: 0.3296, Loss G: 2.0409\n",
      "Epoch [51/85] Batch 510/938 Loss D: 0.5103, Loss G: 1.9349\n",
      "Epoch [51/85] Batch 520/938 Loss D: 0.3456, Loss G: 2.1934\n",
      "Epoch [51/85] Batch 530/938 Loss D: 0.4376, Loss G: 2.4315\n",
      "Epoch [51/85] Batch 540/938 Loss D: 0.3633, Loss G: 2.5886\n",
      "Epoch [51/85] Batch 550/938 Loss D: 0.2430, Loss G: 2.7781\n",
      "Epoch [51/85] Batch 560/938 Loss D: 0.2712, Loss G: 2.7914\n",
      "Epoch [51/85] Batch 570/938 Loss D: 0.3982, Loss G: 2.0254\n",
      "Epoch [51/85] Batch 580/938 Loss D: 0.2755, Loss G: 1.9948\n",
      "Epoch [51/85] Batch 590/938 Loss D: 0.2475, Loss G: 2.6253\n",
      "Epoch [51/85] Batch 600/938 Loss D: 0.4104, Loss G: 1.6489\n",
      "Epoch [51/85] Batch 610/938 Loss D: 0.2908, Loss G: 2.4437\n",
      "Epoch [51/85] Batch 620/938 Loss D: 0.3780, Loss G: 2.8692\n",
      "Epoch [51/85] Batch 630/938 Loss D: 0.4272, Loss G: 2.7096\n",
      "Epoch [51/85] Batch 640/938 Loss D: 0.3421, Loss G: 2.0239\n",
      "Epoch [51/85] Batch 650/938 Loss D: 0.2201, Loss G: 2.5313\n",
      "Epoch [51/85] Batch 660/938 Loss D: 0.2928, Loss G: 2.7135\n",
      "Epoch [51/85] Batch 670/938 Loss D: 0.2296, Loss G: 3.0902\n",
      "Epoch [51/85] Batch 680/938 Loss D: 0.3455, Loss G: 1.8713\n",
      "Epoch [51/85] Batch 690/938 Loss D: 0.2373, Loss G: 2.6766\n",
      "Epoch [51/85] Batch 700/938 Loss D: 0.2441, Loss G: 2.1288\n",
      "Epoch [51/85] Batch 710/938 Loss D: 0.2700, Loss G: 2.7950\n",
      "Epoch [51/85] Batch 720/938 Loss D: 0.2478, Loss G: 3.5176\n",
      "Epoch [51/85] Batch 730/938 Loss D: 0.4291, Loss G: 2.1918\n",
      "Epoch [51/85] Batch 740/938 Loss D: 0.2409, Loss G: 2.6986\n",
      "Epoch [51/85] Batch 750/938 Loss D: 0.2719, Loss G: 2.4283\n",
      "Epoch [51/85] Batch 760/938 Loss D: 0.3272, Loss G: 2.3372\n",
      "Epoch [51/85] Batch 770/938 Loss D: 0.2469, Loss G: 2.4374\n",
      "Epoch [51/85] Batch 780/938 Loss D: 0.4355, Loss G: 2.3343\n",
      "Epoch [51/85] Batch 790/938 Loss D: 0.3141, Loss G: 2.7034\n",
      "Epoch [51/85] Batch 800/938 Loss D: 0.2164, Loss G: 2.9146\n",
      "Epoch [51/85] Batch 810/938 Loss D: 0.2612, Loss G: 2.4509\n",
      "Epoch [51/85] Batch 820/938 Loss D: 0.2127, Loss G: 2.3080\n",
      "Epoch [51/85] Batch 830/938 Loss D: 0.3758, Loss G: 1.9401\n",
      "Epoch [51/85] Batch 840/938 Loss D: 0.2627, Loss G: 2.4699\n",
      "Epoch [51/85] Batch 850/938 Loss D: 0.3190, Loss G: 2.3129\n",
      "Epoch [51/85] Batch 860/938 Loss D: 0.2854, Loss G: 2.2872\n",
      "Epoch [51/85] Batch 870/938 Loss D: 0.2678, Loss G: 2.3626\n",
      "Epoch [51/85] Batch 880/938 Loss D: 0.2802, Loss G: 2.9832\n",
      "Epoch [51/85] Batch 890/938 Loss D: 0.4449, Loss G: 2.4177\n",
      "Epoch [51/85] Batch 900/938 Loss D: 0.2625, Loss G: 2.3531\n",
      "Epoch [51/85] Batch 910/938 Loss D: 0.3035, Loss G: 2.0156\n",
      "Epoch [51/85] Batch 920/938 Loss D: 0.2701, Loss G: 2.5736\n",
      "Epoch [51/85] Batch 930/938 Loss D: 0.4771, Loss G: 2.2315\n",
      "Epoch [52/85] Batch 0/938 Loss D: 0.2748, Loss G: 2.7146\n",
      "Epoch [52/85] Batch 10/938 Loss D: 0.2443, Loss G: 2.9746\n",
      "Epoch [52/85] Batch 20/938 Loss D: 0.3455, Loss G: 2.6965\n",
      "Epoch [52/85] Batch 30/938 Loss D: 0.2116, Loss G: 2.5547\n",
      "Epoch [52/85] Batch 40/938 Loss D: 0.3640, Loss G: 1.9999\n",
      "Epoch [52/85] Batch 50/938 Loss D: 0.2745, Loss G: 2.2305\n",
      "Epoch [52/85] Batch 60/938 Loss D: 0.3424, Loss G: 1.8591\n",
      "Epoch [52/85] Batch 70/938 Loss D: 0.3753, Loss G: 2.1257\n",
      "Epoch [52/85] Batch 80/938 Loss D: 0.3227, Loss G: 2.7462\n",
      "Epoch [52/85] Batch 90/938 Loss D: 0.2429, Loss G: 2.4932\n",
      "Epoch [52/85] Batch 100/938 Loss D: 0.3950, Loss G: 2.8411\n",
      "Epoch [52/85] Batch 110/938 Loss D: 0.2128, Loss G: 2.8800\n",
      "Epoch [52/85] Batch 120/938 Loss D: 0.3181, Loss G: 1.9688\n",
      "Epoch [52/85] Batch 130/938 Loss D: 0.2496, Loss G: 2.9610\n",
      "Epoch [52/85] Batch 140/938 Loss D: 0.2826, Loss G: 2.8693\n",
      "Epoch [52/85] Batch 150/938 Loss D: 0.3075, Loss G: 2.9359\n",
      "Epoch [52/85] Batch 160/938 Loss D: 0.3877, Loss G: 3.3306\n",
      "Epoch [52/85] Batch 170/938 Loss D: 0.3216, Loss G: 2.4415\n",
      "Epoch [52/85] Batch 180/938 Loss D: 0.2548, Loss G: 2.4375\n",
      "Epoch [52/85] Batch 190/938 Loss D: 0.3653, Loss G: 2.3304\n",
      "Epoch [52/85] Batch 200/938 Loss D: 0.3433, Loss G: 2.4307\n",
      "Epoch [52/85] Batch 210/938 Loss D: 0.3878, Loss G: 1.6916\n",
      "Epoch [52/85] Batch 220/938 Loss D: 0.2819, Loss G: 3.6519\n",
      "Epoch [52/85] Batch 230/938 Loss D: 0.2507, Loss G: 3.5252\n",
      "Epoch [52/85] Batch 240/938 Loss D: 0.3020, Loss G: 2.0582\n",
      "Epoch [52/85] Batch 250/938 Loss D: 0.3020, Loss G: 2.6038\n",
      "Epoch [52/85] Batch 260/938 Loss D: 0.3034, Loss G: 2.1632\n",
      "Epoch [52/85] Batch 270/938 Loss D: 0.3329, Loss G: 1.8384\n",
      "Epoch [52/85] Batch 280/938 Loss D: 0.3414, Loss G: 2.1601\n",
      "Epoch [52/85] Batch 290/938 Loss D: 0.2417, Loss G: 2.6407\n",
      "Epoch [52/85] Batch 300/938 Loss D: 0.3687, Loss G: 2.0571\n",
      "Epoch [52/85] Batch 310/938 Loss D: 0.4389, Loss G: 2.7486\n",
      "Epoch [52/85] Batch 320/938 Loss D: 0.3053, Loss G: 2.2709\n",
      "Epoch [52/85] Batch 330/938 Loss D: 0.4878, Loss G: 2.1545\n",
      "Epoch [52/85] Batch 340/938 Loss D: 0.2781, Loss G: 2.2666\n",
      "Epoch [52/85] Batch 350/938 Loss D: 0.3006, Loss G: 2.7060\n",
      "Epoch [52/85] Batch 360/938 Loss D: 0.3403, Loss G: 2.8181\n",
      "Epoch [52/85] Batch 370/938 Loss D: 0.2696, Loss G: 2.4769\n",
      "Epoch [52/85] Batch 380/938 Loss D: 0.3120, Loss G: 2.4996\n",
      "Epoch [52/85] Batch 390/938 Loss D: 0.3941, Loss G: 2.0856\n",
      "Epoch [52/85] Batch 400/938 Loss D: 0.3660, Loss G: 2.9722\n",
      "Epoch [52/85] Batch 410/938 Loss D: 0.3563, Loss G: 3.0068\n",
      "Epoch [52/85] Batch 420/938 Loss D: 0.3098, Loss G: 2.5373\n",
      "Epoch [52/85] Batch 430/938 Loss D: 0.3973, Loss G: 2.1766\n",
      "Epoch [52/85] Batch 440/938 Loss D: 0.2935, Loss G: 2.0016\n",
      "Epoch [52/85] Batch 450/938 Loss D: 0.2416, Loss G: 2.1727\n",
      "Epoch [52/85] Batch 460/938 Loss D: 0.4002, Loss G: 2.2507\n",
      "Epoch [52/85] Batch 470/938 Loss D: 0.4065, Loss G: 2.0648\n",
      "Epoch [52/85] Batch 480/938 Loss D: 0.4800, Loss G: 2.4885\n",
      "Epoch [52/85] Batch 490/938 Loss D: 0.2948, Loss G: 2.4664\n",
      "Epoch [52/85] Batch 500/938 Loss D: 0.3120, Loss G: 2.4984\n",
      "Epoch [52/85] Batch 510/938 Loss D: 0.3695, Loss G: 1.7517\n",
      "Epoch [52/85] Batch 520/938 Loss D: 0.4131, Loss G: 1.7186\n",
      "Epoch [52/85] Batch 530/938 Loss D: 0.2878, Loss G: 2.0015\n",
      "Epoch [52/85] Batch 540/938 Loss D: 0.3649, Loss G: 2.0838\n",
      "Epoch [52/85] Batch 550/938 Loss D: 0.3774, Loss G: 2.1156\n",
      "Epoch [52/85] Batch 560/938 Loss D: 0.2473, Loss G: 2.5733\n",
      "Epoch [52/85] Batch 570/938 Loss D: 0.2594, Loss G: 2.9185\n",
      "Epoch [52/85] Batch 580/938 Loss D: 0.4440, Loss G: 1.8821\n",
      "Epoch [52/85] Batch 590/938 Loss D: 0.2818, Loss G: 2.4335\n",
      "Epoch [52/85] Batch 600/938 Loss D: 0.3440, Loss G: 2.3725\n",
      "Epoch [52/85] Batch 610/938 Loss D: 0.2753, Loss G: 2.3958\n",
      "Epoch [52/85] Batch 620/938 Loss D: 0.2315, Loss G: 2.7734\n",
      "Epoch [52/85] Batch 630/938 Loss D: 0.3059, Loss G: 2.8127\n",
      "Epoch [52/85] Batch 640/938 Loss D: 0.3828, Loss G: 2.5184\n",
      "Epoch [52/85] Batch 650/938 Loss D: 0.3214, Loss G: 2.5515\n",
      "Epoch [52/85] Batch 660/938 Loss D: 0.4823, Loss G: 1.9865\n",
      "Epoch [52/85] Batch 670/938 Loss D: 0.2284, Loss G: 2.5531\n",
      "Epoch [52/85] Batch 680/938 Loss D: 0.3474, Loss G: 1.8853\n",
      "Epoch [52/85] Batch 690/938 Loss D: 0.2142, Loss G: 2.4715\n",
      "Epoch [52/85] Batch 700/938 Loss D: 0.3808, Loss G: 1.7357\n",
      "Epoch [52/85] Batch 710/938 Loss D: 0.3342, Loss G: 2.4315\n",
      "Epoch [52/85] Batch 720/938 Loss D: 0.3505, Loss G: 2.7710\n",
      "Epoch [52/85] Batch 730/938 Loss D: 0.3752, Loss G: 3.1145\n",
      "Epoch [52/85] Batch 740/938 Loss D: 0.2659, Loss G: 2.6881\n",
      "Epoch [52/85] Batch 750/938 Loss D: 0.2712, Loss G: 2.2370\n",
      "Epoch [52/85] Batch 760/938 Loss D: 0.4472, Loss G: 1.5423\n",
      "Epoch [52/85] Batch 770/938 Loss D: 0.2927, Loss G: 2.2283\n",
      "Epoch [52/85] Batch 780/938 Loss D: 0.2598, Loss G: 2.3058\n",
      "Epoch [52/85] Batch 790/938 Loss D: 0.2247, Loss G: 2.3164\n",
      "Epoch [52/85] Batch 800/938 Loss D: 0.3068, Loss G: 2.0282\n",
      "Epoch [52/85] Batch 810/938 Loss D: 0.3046, Loss G: 2.4611\n",
      "Epoch [52/85] Batch 820/938 Loss D: 0.5959, Loss G: 2.1953\n",
      "Epoch [52/85] Batch 830/938 Loss D: 0.3129, Loss G: 2.3002\n",
      "Epoch [52/85] Batch 840/938 Loss D: 0.2914, Loss G: 2.4769\n",
      "Epoch [52/85] Batch 850/938 Loss D: 0.1860, Loss G: 2.7413\n",
      "Epoch [52/85] Batch 860/938 Loss D: 0.2481, Loss G: 2.1848\n",
      "Epoch [52/85] Batch 870/938 Loss D: 0.3015, Loss G: 2.4136\n",
      "Epoch [52/85] Batch 880/938 Loss D: 0.4250, Loss G: 2.5751\n",
      "Epoch [52/85] Batch 890/938 Loss D: 0.3637, Loss G: 2.6110\n",
      "Epoch [52/85] Batch 900/938 Loss D: 0.4380, Loss G: 2.3235\n",
      "Epoch [52/85] Batch 910/938 Loss D: 0.1411, Loss G: 3.6857\n",
      "Epoch [52/85] Batch 920/938 Loss D: 0.3260, Loss G: 2.9840\n",
      "Epoch [52/85] Batch 930/938 Loss D: 0.2675, Loss G: 2.8783\n",
      "Epoch [53/85] Batch 0/938 Loss D: 0.3779, Loss G: 1.5788\n",
      "Epoch [53/85] Batch 10/938 Loss D: 0.2662, Loss G: 2.1373\n",
      "Epoch [53/85] Batch 20/938 Loss D: 0.3048, Loss G: 1.9614\n",
      "Epoch [53/85] Batch 30/938 Loss D: 0.3502, Loss G: 1.8530\n",
      "Epoch [53/85] Batch 40/938 Loss D: 0.2822, Loss G: 2.3632\n",
      "Epoch [53/85] Batch 50/938 Loss D: 0.2887, Loss G: 2.0618\n",
      "Epoch [53/85] Batch 60/938 Loss D: 0.3521, Loss G: 1.7201\n",
      "Epoch [53/85] Batch 70/938 Loss D: 0.3181, Loss G: 2.1064\n",
      "Epoch [53/85] Batch 80/938 Loss D: 0.2686, Loss G: 2.4859\n",
      "Epoch [53/85] Batch 90/938 Loss D: 0.3884, Loss G: 1.7461\n",
      "Epoch [53/85] Batch 100/938 Loss D: 0.3626, Loss G: 1.6970\n",
      "Epoch [53/85] Batch 110/938 Loss D: 0.3719, Loss G: 2.1633\n",
      "Epoch [53/85] Batch 120/938 Loss D: 0.3414, Loss G: 2.1865\n",
      "Epoch [53/85] Batch 130/938 Loss D: 0.3281, Loss G: 2.2632\n",
      "Epoch [53/85] Batch 140/938 Loss D: 0.2533, Loss G: 2.6988\n",
      "Epoch [53/85] Batch 150/938 Loss D: 0.3977, Loss G: 2.4146\n",
      "Epoch [53/85] Batch 160/938 Loss D: 0.2810, Loss G: 2.7473\n",
      "Epoch [53/85] Batch 170/938 Loss D: 0.4007, Loss G: 2.1710\n",
      "Epoch [53/85] Batch 180/938 Loss D: 0.2935, Loss G: 2.3441\n",
      "Epoch [53/85] Batch 190/938 Loss D: 0.4312, Loss G: 1.4308\n",
      "Epoch [53/85] Batch 200/938 Loss D: 0.3070, Loss G: 2.0750\n",
      "Epoch [53/85] Batch 210/938 Loss D: 0.3543, Loss G: 1.7213\n",
      "Epoch [53/85] Batch 220/938 Loss D: 0.3343, Loss G: 2.2762\n",
      "Epoch [53/85] Batch 230/938 Loss D: 0.2752, Loss G: 2.0913\n",
      "Epoch [53/85] Batch 240/938 Loss D: 0.2404, Loss G: 2.2613\n",
      "Epoch [53/85] Batch 250/938 Loss D: 0.3299, Loss G: 2.9918\n",
      "Epoch [53/85] Batch 260/938 Loss D: 0.3847, Loss G: 2.1416\n",
      "Epoch [53/85] Batch 270/938 Loss D: 0.2869, Loss G: 2.5285\n",
      "Epoch [53/85] Batch 280/938 Loss D: 0.3500, Loss G: 2.6155\n",
      "Epoch [53/85] Batch 290/938 Loss D: 0.3418, Loss G: 1.8811\n",
      "Epoch [53/85] Batch 300/938 Loss D: 0.2789, Loss G: 2.2323\n",
      "Epoch [53/85] Batch 310/938 Loss D: 0.2924, Loss G: 2.2158\n",
      "Epoch [53/85] Batch 320/938 Loss D: 0.3155, Loss G: 2.2583\n",
      "Epoch [53/85] Batch 330/938 Loss D: 0.3682, Loss G: 1.9176\n",
      "Epoch [53/85] Batch 340/938 Loss D: 0.3417, Loss G: 2.0852\n",
      "Epoch [53/85] Batch 350/938 Loss D: 0.3425, Loss G: 2.1633\n",
      "Epoch [53/85] Batch 360/938 Loss D: 0.3119, Loss G: 2.1554\n",
      "Epoch [53/85] Batch 370/938 Loss D: 0.4466, Loss G: 2.3588\n",
      "Epoch [53/85] Batch 380/938 Loss D: 0.4672, Loss G: 2.5664\n",
      "Epoch [53/85] Batch 390/938 Loss D: 0.2616, Loss G: 2.5610\n",
      "Epoch [53/85] Batch 400/938 Loss D: 0.2862, Loss G: 2.4430\n",
      "Epoch [53/85] Batch 410/938 Loss D: 0.2975, Loss G: 2.5828\n",
      "Epoch [53/85] Batch 420/938 Loss D: 0.2701, Loss G: 2.6288\n",
      "Epoch [53/85] Batch 430/938 Loss D: 0.2857, Loss G: 2.5567\n",
      "Epoch [53/85] Batch 440/938 Loss D: 0.2836, Loss G: 2.1163\n",
      "Epoch [53/85] Batch 450/938 Loss D: 0.2832, Loss G: 2.3717\n",
      "Epoch [53/85] Batch 460/938 Loss D: 0.3164, Loss G: 2.1067\n",
      "Epoch [53/85] Batch 470/938 Loss D: 0.2745, Loss G: 2.3584\n",
      "Epoch [53/85] Batch 480/938 Loss D: 0.2838, Loss G: 2.3520\n",
      "Epoch [53/85] Batch 490/938 Loss D: 0.2772, Loss G: 2.9628\n",
      "Epoch [53/85] Batch 500/938 Loss D: 0.2992, Loss G: 2.3540\n",
      "Epoch [53/85] Batch 510/938 Loss D: 0.2790, Loss G: 2.3706\n",
      "Epoch [53/85] Batch 520/938 Loss D: 0.2944, Loss G: 2.0267\n",
      "Epoch [53/85] Batch 530/938 Loss D: 0.2599, Loss G: 2.4257\n",
      "Epoch [53/85] Batch 540/938 Loss D: 0.2897, Loss G: 2.5144\n",
      "Epoch [53/85] Batch 550/938 Loss D: 0.3447, Loss G: 2.1631\n",
      "Epoch [53/85] Batch 560/938 Loss D: 0.3433, Loss G: 1.7626\n",
      "Epoch [53/85] Batch 570/938 Loss D: 0.2101, Loss G: 2.6574\n",
      "Epoch [53/85] Batch 580/938 Loss D: 0.3232, Loss G: 2.0757\n",
      "Epoch [53/85] Batch 590/938 Loss D: 0.3287, Loss G: 2.2772\n",
      "Epoch [53/85] Batch 600/938 Loss D: 0.3308, Loss G: 2.0754\n",
      "Epoch [53/85] Batch 610/938 Loss D: 0.3877, Loss G: 2.4183\n",
      "Epoch [53/85] Batch 620/938 Loss D: 0.2316, Loss G: 2.4338\n",
      "Epoch [53/85] Batch 630/938 Loss D: 0.2849, Loss G: 2.5422\n",
      "Epoch [53/85] Batch 640/938 Loss D: 0.2937, Loss G: 2.6455\n",
      "Epoch [53/85] Batch 650/938 Loss D: 0.2540, Loss G: 2.6321\n",
      "Epoch [53/85] Batch 660/938 Loss D: 0.2897, Loss G: 2.6667\n",
      "Epoch [53/85] Batch 670/938 Loss D: 0.2950, Loss G: 2.1395\n",
      "Epoch [53/85] Batch 680/938 Loss D: 0.2787, Loss G: 1.9156\n",
      "Epoch [53/85] Batch 690/938 Loss D: 0.4137, Loss G: 1.7772\n",
      "Epoch [53/85] Batch 700/938 Loss D: 0.3425, Loss G: 2.5690\n",
      "Epoch [53/85] Batch 710/938 Loss D: 0.3850, Loss G: 2.4258\n",
      "Epoch [53/85] Batch 720/938 Loss D: 0.2077, Loss G: 2.8916\n",
      "Epoch [53/85] Batch 730/938 Loss D: 0.3389, Loss G: 2.7794\n",
      "Epoch [53/85] Batch 740/938 Loss D: 0.3247, Loss G: 2.4905\n",
      "Epoch [53/85] Batch 750/938 Loss D: 0.3438, Loss G: 2.0395\n",
      "Epoch [53/85] Batch 760/938 Loss D: 0.2629, Loss G: 2.3690\n",
      "Epoch [53/85] Batch 770/938 Loss D: 0.3079, Loss G: 2.4727\n",
      "Epoch [53/85] Batch 780/938 Loss D: 0.3296, Loss G: 2.0801\n",
      "Epoch [53/85] Batch 790/938 Loss D: 0.2965, Loss G: 2.3513\n",
      "Epoch [53/85] Batch 800/938 Loss D: 0.2479, Loss G: 2.1084\n",
      "Epoch [53/85] Batch 810/938 Loss D: 0.3626, Loss G: 2.2282\n",
      "Epoch [53/85] Batch 820/938 Loss D: 0.4648, Loss G: 1.9871\n",
      "Epoch [53/85] Batch 830/938 Loss D: 0.3763, Loss G: 2.4569\n",
      "Epoch [53/85] Batch 840/938 Loss D: 0.3241, Loss G: 3.0833\n",
      "Epoch [53/85] Batch 850/938 Loss D: 0.3542, Loss G: 2.2862\n",
      "Epoch [53/85] Batch 860/938 Loss D: 0.4328, Loss G: 1.8982\n",
      "Epoch [53/85] Batch 870/938 Loss D: 0.4430, Loss G: 2.1437\n",
      "Epoch [53/85] Batch 880/938 Loss D: 0.2623, Loss G: 2.0708\n",
      "Epoch [53/85] Batch 890/938 Loss D: 0.5054, Loss G: 1.7413\n",
      "Epoch [53/85] Batch 900/938 Loss D: 0.3799, Loss G: 2.3277\n",
      "Epoch [53/85] Batch 910/938 Loss D: 0.2544, Loss G: 2.4726\n",
      "Epoch [53/85] Batch 920/938 Loss D: 0.1633, Loss G: 2.6599\n",
      "Epoch [53/85] Batch 930/938 Loss D: 0.2651, Loss G: 2.8387\n",
      "Epoch [54/85] Batch 0/938 Loss D: 0.3771, Loss G: 2.1381\n",
      "Epoch [54/85] Batch 10/938 Loss D: 0.2814, Loss G: 1.9414\n",
      "Epoch [54/85] Batch 20/938 Loss D: 0.3162, Loss G: 2.6437\n",
      "Epoch [54/85] Batch 30/938 Loss D: 0.2620, Loss G: 1.6351\n",
      "Epoch [54/85] Batch 40/938 Loss D: 0.3429, Loss G: 2.2927\n",
      "Epoch [54/85] Batch 50/938 Loss D: 0.3396, Loss G: 2.6160\n",
      "Epoch [54/85] Batch 60/938 Loss D: 0.2439, Loss G: 3.8285\n",
      "Epoch [54/85] Batch 70/938 Loss D: 0.2261, Loss G: 3.0564\n",
      "Epoch [54/85] Batch 80/938 Loss D: 0.3668, Loss G: 2.5221\n",
      "Epoch [54/85] Batch 90/938 Loss D: 0.2967, Loss G: 2.1612\n",
      "Epoch [54/85] Batch 100/938 Loss D: 0.3228, Loss G: 2.2591\n",
      "Epoch [54/85] Batch 110/938 Loss D: 0.4007, Loss G: 1.8444\n",
      "Epoch [54/85] Batch 120/938 Loss D: 0.4527, Loss G: 2.4268\n",
      "Epoch [54/85] Batch 130/938 Loss D: 0.3787, Loss G: 2.0900\n",
      "Epoch [54/85] Batch 140/938 Loss D: 0.2665, Loss G: 2.5332\n",
      "Epoch [54/85] Batch 150/938 Loss D: 0.3358, Loss G: 3.0429\n",
      "Epoch [54/85] Batch 160/938 Loss D: 0.2856, Loss G: 2.6202\n",
      "Epoch [54/85] Batch 170/938 Loss D: 0.3384, Loss G: 2.7207\n",
      "Epoch [54/85] Batch 180/938 Loss D: 0.3122, Loss G: 2.7932\n",
      "Epoch [54/85] Batch 190/938 Loss D: 0.3467, Loss G: 2.6410\n",
      "Epoch [54/85] Batch 200/938 Loss D: 0.2740, Loss G: 3.1936\n",
      "Epoch [54/85] Batch 210/938 Loss D: 0.2354, Loss G: 2.2669\n",
      "Epoch [54/85] Batch 220/938 Loss D: 0.3389, Loss G: 2.1984\n",
      "Epoch [54/85] Batch 230/938 Loss D: 0.1811, Loss G: 3.3436\n",
      "Epoch [54/85] Batch 240/938 Loss D: 0.3584, Loss G: 2.1956\n",
      "Epoch [54/85] Batch 250/938 Loss D: 0.3815, Loss G: 1.8881\n",
      "Epoch [54/85] Batch 260/938 Loss D: 0.2683, Loss G: 1.8843\n",
      "Epoch [54/85] Batch 270/938 Loss D: 0.2786, Loss G: 2.1681\n",
      "Epoch [54/85] Batch 280/938 Loss D: 0.2302, Loss G: 3.1454\n",
      "Epoch [54/85] Batch 290/938 Loss D: 0.6143, Loss G: 2.4919\n",
      "Epoch [54/85] Batch 300/938 Loss D: 0.4748, Loss G: 2.3110\n",
      "Epoch [54/85] Batch 310/938 Loss D: 0.2702, Loss G: 2.7417\n",
      "Epoch [54/85] Batch 320/938 Loss D: 0.4570, Loss G: 1.7069\n",
      "Epoch [54/85] Batch 330/938 Loss D: 0.3829, Loss G: 2.2055\n",
      "Epoch [54/85] Batch 340/938 Loss D: 0.2929, Loss G: 2.3341\n",
      "Epoch [54/85] Batch 350/938 Loss D: 0.3367, Loss G: 2.0922\n",
      "Epoch [54/85] Batch 360/938 Loss D: 0.4049, Loss G: 1.7356\n",
      "Epoch [54/85] Batch 370/938 Loss D: 0.3233, Loss G: 2.4499\n",
      "Epoch [54/85] Batch 380/938 Loss D: 0.3706, Loss G: 1.9564\n",
      "Epoch [54/85] Batch 390/938 Loss D: 0.3410, Loss G: 2.6054\n",
      "Epoch [54/85] Batch 400/938 Loss D: 0.4127, Loss G: 1.9801\n",
      "Epoch [54/85] Batch 410/938 Loss D: 0.3119, Loss G: 1.6787\n",
      "Epoch [54/85] Batch 420/938 Loss D: 0.2863, Loss G: 2.0126\n",
      "Epoch [54/85] Batch 430/938 Loss D: 0.3135, Loss G: 2.9714\n",
      "Epoch [54/85] Batch 440/938 Loss D: 0.3098, Loss G: 2.2880\n",
      "Epoch [54/85] Batch 450/938 Loss D: 0.4660, Loss G: 2.2981\n",
      "Epoch [54/85] Batch 460/938 Loss D: 0.3014, Loss G: 2.1306\n",
      "Epoch [54/85] Batch 470/938 Loss D: 0.2858, Loss G: 2.1991\n",
      "Epoch [54/85] Batch 480/938 Loss D: 0.2219, Loss G: 2.8003\n",
      "Epoch [54/85] Batch 490/938 Loss D: 0.1825, Loss G: 2.7429\n",
      "Epoch [54/85] Batch 500/938 Loss D: 0.2627, Loss G: 2.1701\n",
      "Epoch [54/85] Batch 510/938 Loss D: 0.2785, Loss G: 1.9135\n",
      "Epoch [54/85] Batch 520/938 Loss D: 0.3218, Loss G: 2.5178\n",
      "Epoch [54/85] Batch 530/938 Loss D: 0.4006, Loss G: 2.3369\n",
      "Epoch [54/85] Batch 540/938 Loss D: 0.4794, Loss G: 2.1635\n",
      "Epoch [54/85] Batch 550/938 Loss D: 0.2422, Loss G: 2.8066\n",
      "Epoch [54/85] Batch 560/938 Loss D: 0.1976, Loss G: 3.0155\n",
      "Epoch [54/85] Batch 570/938 Loss D: 0.2271, Loss G: 2.5711\n",
      "Epoch [54/85] Batch 580/938 Loss D: 0.3436, Loss G: 2.3875\n",
      "Epoch [54/85] Batch 590/938 Loss D: 0.2533, Loss G: 2.8765\n",
      "Epoch [54/85] Batch 600/938 Loss D: 0.3263, Loss G: 2.6999\n",
      "Epoch [54/85] Batch 610/938 Loss D: 0.2049, Loss G: 2.8166\n",
      "Epoch [54/85] Batch 620/938 Loss D: 0.2458, Loss G: 2.6432\n",
      "Epoch [54/85] Batch 630/938 Loss D: 0.2351, Loss G: 2.4651\n",
      "Epoch [54/85] Batch 640/938 Loss D: 0.2476, Loss G: 2.1745\n",
      "Epoch [54/85] Batch 650/938 Loss D: 0.2182, Loss G: 2.4716\n",
      "Epoch [54/85] Batch 660/938 Loss D: 0.5401, Loss G: 1.8996\n",
      "Epoch [54/85] Batch 670/938 Loss D: 0.3360, Loss G: 2.4963\n",
      "Epoch [54/85] Batch 680/938 Loss D: 0.3101, Loss G: 2.0419\n",
      "Epoch [54/85] Batch 690/938 Loss D: 0.2591, Loss G: 2.4657\n",
      "Epoch [54/85] Batch 700/938 Loss D: 0.4266, Loss G: 2.3810\n",
      "Epoch [54/85] Batch 710/938 Loss D: 0.1702, Loss G: 3.5840\n",
      "Epoch [54/85] Batch 720/938 Loss D: 0.1771, Loss G: 2.8208\n",
      "Epoch [54/85] Batch 730/938 Loss D: 0.2913, Loss G: 2.3030\n",
      "Epoch [54/85] Batch 740/938 Loss D: 0.3661, Loss G: 1.9236\n",
      "Epoch [54/85] Batch 750/938 Loss D: 0.3809, Loss G: 1.7141\n",
      "Epoch [54/85] Batch 760/938 Loss D: 0.3199, Loss G: 1.8785\n",
      "Epoch [54/85] Batch 770/938 Loss D: 0.2670, Loss G: 2.6766\n",
      "Epoch [54/85] Batch 780/938 Loss D: 0.2736, Loss G: 2.7628\n",
      "Epoch [54/85] Batch 790/938 Loss D: 0.2788, Loss G: 2.1393\n",
      "Epoch [54/85] Batch 800/938 Loss D: 0.3340, Loss G: 2.1636\n",
      "Epoch [54/85] Batch 810/938 Loss D: 0.3582, Loss G: 1.8598\n",
      "Epoch [54/85] Batch 820/938 Loss D: 0.2794, Loss G: 2.1102\n",
      "Epoch [54/85] Batch 830/938 Loss D: 0.2991, Loss G: 2.0043\n",
      "Epoch [54/85] Batch 840/938 Loss D: 0.3509, Loss G: 1.9319\n",
      "Epoch [54/85] Batch 850/938 Loss D: 0.2874, Loss G: 2.2134\n",
      "Epoch [54/85] Batch 860/938 Loss D: 0.1781, Loss G: 2.9253\n",
      "Epoch [54/85] Batch 870/938 Loss D: 0.3767, Loss G: 2.1457\n",
      "Epoch [54/85] Batch 880/938 Loss D: 0.2179, Loss G: 2.6850\n",
      "Epoch [54/85] Batch 890/938 Loss D: 0.2710, Loss G: 3.2797\n",
      "Epoch [54/85] Batch 900/938 Loss D: 0.2468, Loss G: 2.9274\n",
      "Epoch [54/85] Batch 910/938 Loss D: 0.1684, Loss G: 2.9721\n",
      "Epoch [54/85] Batch 920/938 Loss D: 0.4376, Loss G: 1.9114\n",
      "Epoch [54/85] Batch 930/938 Loss D: 0.2094, Loss G: 2.5872\n",
      "Epoch [55/85] Batch 0/938 Loss D: 0.3701, Loss G: 2.6652\n",
      "Epoch [55/85] Batch 10/938 Loss D: 0.2954, Loss G: 3.0279\n",
      "Epoch [55/85] Batch 20/938 Loss D: 0.3891, Loss G: 1.9663\n",
      "Epoch [55/85] Batch 30/938 Loss D: 0.2918, Loss G: 2.7360\n",
      "Epoch [55/85] Batch 40/938 Loss D: 0.4943, Loss G: 1.5498\n",
      "Epoch [55/85] Batch 50/938 Loss D: 0.4344, Loss G: 1.2802\n",
      "Epoch [55/85] Batch 60/938 Loss D: 0.2540, Loss G: 2.1539\n",
      "Epoch [55/85] Batch 70/938 Loss D: 0.3517, Loss G: 2.9091\n",
      "Epoch [55/85] Batch 80/938 Loss D: 0.4103, Loss G: 2.7275\n",
      "Epoch [55/85] Batch 90/938 Loss D: 0.2938, Loss G: 2.5558\n",
      "Epoch [55/85] Batch 100/938 Loss D: 0.4770, Loss G: 1.3879\n",
      "Epoch [55/85] Batch 110/938 Loss D: 0.2656, Loss G: 2.4887\n",
      "Epoch [55/85] Batch 120/938 Loss D: 0.3049, Loss G: 2.4887\n",
      "Epoch [55/85] Batch 130/938 Loss D: 0.2288, Loss G: 2.6034\n",
      "Epoch [55/85] Batch 140/938 Loss D: 0.2841, Loss G: 2.2027\n",
      "Epoch [55/85] Batch 150/938 Loss D: 0.3101, Loss G: 2.1106\n",
      "Epoch [55/85] Batch 160/938 Loss D: 0.2770, Loss G: 1.9953\n",
      "Epoch [55/85] Batch 170/938 Loss D: 0.3075, Loss G: 1.9984\n",
      "Epoch [55/85] Batch 180/938 Loss D: 0.3452, Loss G: 1.9455\n",
      "Epoch [55/85] Batch 190/938 Loss D: 0.3259, Loss G: 2.0182\n",
      "Epoch [55/85] Batch 200/938 Loss D: 0.2177, Loss G: 2.5233\n",
      "Epoch [55/85] Batch 210/938 Loss D: 0.3082, Loss G: 2.3347\n",
      "Epoch [55/85] Batch 220/938 Loss D: 0.3585, Loss G: 2.9477\n",
      "Epoch [55/85] Batch 230/938 Loss D: 0.2837, Loss G: 3.4827\n",
      "Epoch [55/85] Batch 240/938 Loss D: 0.3017, Loss G: 2.4136\n",
      "Epoch [55/85] Batch 250/938 Loss D: 0.3624, Loss G: 1.8228\n",
      "Epoch [55/85] Batch 260/938 Loss D: 0.3202, Loss G: 1.9556\n",
      "Epoch [55/85] Batch 270/938 Loss D: 0.2492, Loss G: 2.2951\n",
      "Epoch [55/85] Batch 280/938 Loss D: 0.1974, Loss G: 3.5723\n",
      "Epoch [55/85] Batch 290/938 Loss D: 0.4832, Loss G: 1.6973\n",
      "Epoch [55/85] Batch 300/938 Loss D: 0.2499, Loss G: 2.9388\n",
      "Epoch [55/85] Batch 310/938 Loss D: 0.2817, Loss G: 3.0496\n",
      "Epoch [55/85] Batch 320/938 Loss D: 0.2792, Loss G: 2.0143\n",
      "Epoch [55/85] Batch 330/938 Loss D: 0.3573, Loss G: 1.9143\n",
      "Epoch [55/85] Batch 340/938 Loss D: 0.3841, Loss G: 2.0120\n",
      "Epoch [55/85] Batch 350/938 Loss D: 0.3970, Loss G: 2.4039\n",
      "Epoch [55/85] Batch 360/938 Loss D: 0.2529, Loss G: 2.4966\n",
      "Epoch [55/85] Batch 370/938 Loss D: 0.3659, Loss G: 2.3553\n",
      "Epoch [55/85] Batch 380/938 Loss D: 0.4187, Loss G: 2.1468\n",
      "Epoch [55/85] Batch 390/938 Loss D: 0.2712, Loss G: 1.8494\n",
      "Epoch [55/85] Batch 400/938 Loss D: 0.3198, Loss G: 2.5919\n",
      "Epoch [55/85] Batch 410/938 Loss D: 0.1993, Loss G: 3.0979\n",
      "Epoch [55/85] Batch 420/938 Loss D: 0.3663, Loss G: 2.8697\n",
      "Epoch [55/85] Batch 430/938 Loss D: 0.1985, Loss G: 2.5650\n",
      "Epoch [55/85] Batch 440/938 Loss D: 0.3120, Loss G: 2.0479\n",
      "Epoch [55/85] Batch 450/938 Loss D: 0.4123, Loss G: 1.9871\n",
      "Epoch [55/85] Batch 460/938 Loss D: 0.4225, Loss G: 2.2421\n",
      "Epoch [55/85] Batch 470/938 Loss D: 0.2684, Loss G: 2.6061\n",
      "Epoch [55/85] Batch 480/938 Loss D: 0.2842, Loss G: 3.1355\n",
      "Epoch [55/85] Batch 490/938 Loss D: 0.4478, Loss G: 2.0769\n",
      "Epoch [55/85] Batch 500/938 Loss D: 0.3132, Loss G: 2.3571\n",
      "Epoch [55/85] Batch 510/938 Loss D: 0.3361, Loss G: 1.7257\n",
      "Epoch [55/85] Batch 520/938 Loss D: 0.2755, Loss G: 1.9951\n",
      "Epoch [55/85] Batch 530/938 Loss D: 0.4091, Loss G: 2.1473\n",
      "Epoch [55/85] Batch 540/938 Loss D: 0.2972, Loss G: 2.2318\n",
      "Epoch [55/85] Batch 550/938 Loss D: 0.4723, Loss G: 1.9056\n",
      "Epoch [55/85] Batch 560/938 Loss D: 0.2988, Loss G: 2.1661\n",
      "Epoch [55/85] Batch 570/938 Loss D: 0.2269, Loss G: 2.7856\n",
      "Epoch [55/85] Batch 580/938 Loss D: 0.4460, Loss G: 2.1035\n",
      "Epoch [55/85] Batch 590/938 Loss D: 0.4295, Loss G: 2.1847\n",
      "Epoch [55/85] Batch 600/938 Loss D: 0.2562, Loss G: 2.7900\n",
      "Epoch [55/85] Batch 610/938 Loss D: 0.2428, Loss G: 2.5021\n",
      "Epoch [55/85] Batch 620/938 Loss D: 0.3971, Loss G: 2.0621\n",
      "Epoch [55/85] Batch 630/938 Loss D: 0.3183, Loss G: 2.0086\n",
      "Epoch [55/85] Batch 640/938 Loss D: 0.3054, Loss G: 2.1519\n",
      "Epoch [55/85] Batch 650/938 Loss D: 0.3637, Loss G: 1.9767\n",
      "Epoch [55/85] Batch 660/938 Loss D: 0.2827, Loss G: 2.5893\n",
      "Epoch [55/85] Batch 670/938 Loss D: 0.3356, Loss G: 2.7935\n",
      "Epoch [55/85] Batch 680/938 Loss D: 0.2846, Loss G: 2.6256\n",
      "Epoch [55/85] Batch 690/938 Loss D: 0.2887, Loss G: 2.4773\n",
      "Epoch [55/85] Batch 700/938 Loss D: 0.3801, Loss G: 2.4094\n",
      "Epoch [55/85] Batch 710/938 Loss D: 0.2919, Loss G: 2.2091\n",
      "Epoch [55/85] Batch 720/938 Loss D: 0.3165, Loss G: 2.1908\n",
      "Epoch [55/85] Batch 730/938 Loss D: 0.3411, Loss G: 2.0359\n",
      "Epoch [55/85] Batch 740/938 Loss D: 0.3086, Loss G: 2.1408\n",
      "Epoch [55/85] Batch 750/938 Loss D: 0.3970, Loss G: 2.4479\n",
      "Epoch [55/85] Batch 760/938 Loss D: 0.3048, Loss G: 2.1171\n",
      "Epoch [55/85] Batch 770/938 Loss D: 0.3004, Loss G: 2.3540\n",
      "Epoch [55/85] Batch 780/938 Loss D: 0.2904, Loss G: 2.5473\n",
      "Epoch [55/85] Batch 790/938 Loss D: 0.2351, Loss G: 2.5451\n",
      "Epoch [55/85] Batch 800/938 Loss D: 0.4469, Loss G: 2.3187\n",
      "Epoch [55/85] Batch 810/938 Loss D: 0.3684, Loss G: 2.7121\n",
      "Epoch [55/85] Batch 820/938 Loss D: 0.2574, Loss G: 2.9436\n",
      "Epoch [55/85] Batch 830/938 Loss D: 0.4195, Loss G: 2.1142\n",
      "Epoch [55/85] Batch 840/938 Loss D: 0.2532, Loss G: 2.8960\n",
      "Epoch [55/85] Batch 850/938 Loss D: 0.2517, Loss G: 2.8889\n",
      "Epoch [55/85] Batch 860/938 Loss D: 0.3169, Loss G: 2.5729\n",
      "Epoch [55/85] Batch 870/938 Loss D: 0.2717, Loss G: 2.6555\n",
      "Epoch [55/85] Batch 880/938 Loss D: 0.3649, Loss G: 2.7347\n",
      "Epoch [55/85] Batch 890/938 Loss D: 0.3477, Loss G: 2.0559\n",
      "Epoch [55/85] Batch 900/938 Loss D: 0.2296, Loss G: 3.0873\n",
      "Epoch [55/85] Batch 910/938 Loss D: 0.5003, Loss G: 1.7416\n",
      "Epoch [55/85] Batch 920/938 Loss D: 0.3284, Loss G: 2.1160\n",
      "Epoch [55/85] Batch 930/938 Loss D: 0.1850, Loss G: 3.2373\n",
      "Epoch [56/85] Batch 0/938 Loss D: 0.2694, Loss G: 2.5791\n",
      "Epoch [56/85] Batch 10/938 Loss D: 0.2836, Loss G: 2.1522\n",
      "Epoch [56/85] Batch 20/938 Loss D: 0.3383, Loss G: 1.6538\n",
      "Epoch [56/85] Batch 30/938 Loss D: 0.3135, Loss G: 2.3168\n",
      "Epoch [56/85] Batch 40/938 Loss D: 0.2899, Loss G: 2.1355\n",
      "Epoch [56/85] Batch 50/938 Loss D: 0.2386, Loss G: 3.3335\n",
      "Epoch [56/85] Batch 60/938 Loss D: 0.2519, Loss G: 3.1215\n",
      "Epoch [56/85] Batch 70/938 Loss D: 0.3503, Loss G: 2.5883\n",
      "Epoch [56/85] Batch 80/938 Loss D: 0.2919, Loss G: 2.0414\n",
      "Epoch [56/85] Batch 90/938 Loss D: 0.3476, Loss G: 2.2658\n",
      "Epoch [56/85] Batch 100/938 Loss D: 0.3147, Loss G: 1.8340\n",
      "Epoch [56/85] Batch 110/938 Loss D: 0.3825, Loss G: 1.8633\n",
      "Epoch [56/85] Batch 120/938 Loss D: 0.5074, Loss G: 2.1173\n",
      "Epoch [56/85] Batch 130/938 Loss D: 0.1488, Loss G: 3.5294\n",
      "Epoch [56/85] Batch 140/938 Loss D: 0.3323, Loss G: 2.8580\n",
      "Epoch [56/85] Batch 150/938 Loss D: 0.3007, Loss G: 2.7208\n",
      "Epoch [56/85] Batch 160/938 Loss D: 0.4933, Loss G: 2.3902\n",
      "Epoch [56/85] Batch 170/938 Loss D: 0.3176, Loss G: 2.3322\n",
      "Epoch [56/85] Batch 180/938 Loss D: 0.3471, Loss G: 2.5154\n",
      "Epoch [56/85] Batch 190/938 Loss D: 0.3290, Loss G: 1.9917\n",
      "Epoch [56/85] Batch 200/938 Loss D: 0.3080, Loss G: 1.8712\n",
      "Epoch [56/85] Batch 210/938 Loss D: 0.3201, Loss G: 2.2899\n",
      "Epoch [56/85] Batch 220/938 Loss D: 0.2857, Loss G: 2.2318\n",
      "Epoch [56/85] Batch 230/938 Loss D: 0.3326, Loss G: 1.7967\n",
      "Epoch [56/85] Batch 240/938 Loss D: 0.3036, Loss G: 2.1861\n",
      "Epoch [56/85] Batch 250/938 Loss D: 0.3206, Loss G: 2.0142\n",
      "Epoch [56/85] Batch 260/938 Loss D: 0.3488, Loss G: 2.0201\n",
      "Epoch [56/85] Batch 270/938 Loss D: 0.2668, Loss G: 2.3832\n",
      "Epoch [56/85] Batch 280/938 Loss D: 0.3701, Loss G: 2.4305\n",
      "Epoch [56/85] Batch 290/938 Loss D: 0.2268, Loss G: 2.5591\n",
      "Epoch [56/85] Batch 300/938 Loss D: 0.3657, Loss G: 2.2928\n",
      "Epoch [56/85] Batch 310/938 Loss D: 0.1748, Loss G: 2.9811\n",
      "Epoch [56/85] Batch 320/938 Loss D: 0.1942, Loss G: 3.1302\n",
      "Epoch [56/85] Batch 330/938 Loss D: 0.2506, Loss G: 2.7432\n",
      "Epoch [56/85] Batch 340/938 Loss D: 0.3751, Loss G: 1.8702\n",
      "Epoch [56/85] Batch 350/938 Loss D: 0.3289, Loss G: 2.2596\n",
      "Epoch [56/85] Batch 360/938 Loss D: 0.1600, Loss G: 2.9022\n",
      "Epoch [56/85] Batch 370/938 Loss D: 0.2529, Loss G: 2.4630\n",
      "Epoch [56/85] Batch 380/938 Loss D: 0.2255, Loss G: 2.5858\n",
      "Epoch [56/85] Batch 390/938 Loss D: 0.3006, Loss G: 2.5327\n",
      "Epoch [56/85] Batch 400/938 Loss D: 0.3210, Loss G: 2.7569\n",
      "Epoch [56/85] Batch 410/938 Loss D: 0.4099, Loss G: 2.4275\n",
      "Epoch [56/85] Batch 420/938 Loss D: 0.2465, Loss G: 2.7767\n",
      "Epoch [56/85] Batch 430/938 Loss D: 0.2995, Loss G: 2.0822\n",
      "Epoch [56/85] Batch 440/938 Loss D: 0.3671, Loss G: 1.9990\n",
      "Epoch [56/85] Batch 450/938 Loss D: 0.2391, Loss G: 2.6117\n",
      "Epoch [56/85] Batch 460/938 Loss D: 0.4212, Loss G: 2.0734\n",
      "Epoch [56/85] Batch 470/938 Loss D: 0.3669, Loss G: 2.1931\n",
      "Epoch [56/85] Batch 480/938 Loss D: 0.4217, Loss G: 1.7570\n",
      "Epoch [56/85] Batch 490/938 Loss D: 0.2796, Loss G: 2.1526\n",
      "Epoch [56/85] Batch 500/938 Loss D: 0.1972, Loss G: 2.6011\n",
      "Epoch [56/85] Batch 510/938 Loss D: 0.3952, Loss G: 1.9025\n",
      "Epoch [56/85] Batch 520/938 Loss D: 0.2340, Loss G: 3.2350\n",
      "Epoch [56/85] Batch 530/938 Loss D: 0.3221, Loss G: 2.5324\n",
      "Epoch [56/85] Batch 540/938 Loss D: 0.2097, Loss G: 2.7965\n",
      "Epoch [56/85] Batch 550/938 Loss D: 0.2663, Loss G: 2.2303\n",
      "Epoch [56/85] Batch 560/938 Loss D: 0.3219, Loss G: 2.4050\n",
      "Epoch [56/85] Batch 570/938 Loss D: 0.3219, Loss G: 2.7068\n",
      "Epoch [56/85] Batch 580/938 Loss D: 0.4184, Loss G: 2.1280\n",
      "Epoch [56/85] Batch 590/938 Loss D: 0.3063, Loss G: 1.9060\n",
      "Epoch [56/85] Batch 600/938 Loss D: 0.3829, Loss G: 1.6603\n",
      "Epoch [56/85] Batch 610/938 Loss D: 0.2783, Loss G: 1.9809\n",
      "Epoch [56/85] Batch 620/938 Loss D: 0.2653, Loss G: 2.5738\n",
      "Epoch [56/85] Batch 630/938 Loss D: 0.3533, Loss G: 2.4707\n",
      "Epoch [56/85] Batch 640/938 Loss D: 0.3453, Loss G: 2.4709\n",
      "Epoch [56/85] Batch 650/938 Loss D: 0.2957, Loss G: 2.5275\n",
      "Epoch [56/85] Batch 660/938 Loss D: 0.2977, Loss G: 2.2916\n",
      "Epoch [56/85] Batch 670/938 Loss D: 0.3208, Loss G: 2.3736\n",
      "Epoch [56/85] Batch 680/938 Loss D: 0.3097, Loss G: 2.5669\n",
      "Epoch [56/85] Batch 690/938 Loss D: 0.2507, Loss G: 2.1263\n",
      "Epoch [56/85] Batch 700/938 Loss D: 0.2356, Loss G: 2.3727\n",
      "Epoch [56/85] Batch 710/938 Loss D: 0.3264, Loss G: 2.2638\n",
      "Epoch [56/85] Batch 720/938 Loss D: 0.2901, Loss G: 2.9838\n",
      "Epoch [56/85] Batch 730/938 Loss D: 0.2968, Loss G: 2.2234\n",
      "Epoch [56/85] Batch 740/938 Loss D: 0.2290, Loss G: 3.4659\n",
      "Epoch [56/85] Batch 750/938 Loss D: 0.2308, Loss G: 2.8993\n",
      "Epoch [56/85] Batch 760/938 Loss D: 0.4366, Loss G: 2.4871\n",
      "Epoch [56/85] Batch 770/938 Loss D: 0.3492, Loss G: 3.0407\n",
      "Epoch [56/85] Batch 780/938 Loss D: 0.3545, Loss G: 2.1088\n",
      "Epoch [56/85] Batch 790/938 Loss D: 0.3459, Loss G: 1.9552\n",
      "Epoch [56/85] Batch 800/938 Loss D: 0.4682, Loss G: 1.9674\n",
      "Epoch [56/85] Batch 810/938 Loss D: 0.4113, Loss G: 2.2419\n",
      "Epoch [56/85] Batch 820/938 Loss D: 0.4281, Loss G: 1.7577\n",
      "Epoch [56/85] Batch 830/938 Loss D: 0.3185, Loss G: 1.8780\n",
      "Epoch [56/85] Batch 840/938 Loss D: 0.4221, Loss G: 2.5221\n",
      "Epoch [56/85] Batch 850/938 Loss D: 0.3823, Loss G: 2.1198\n",
      "Epoch [56/85] Batch 860/938 Loss D: 0.2820, Loss G: 2.0952\n",
      "Epoch [56/85] Batch 870/938 Loss D: 0.1952, Loss G: 2.4661\n",
      "Epoch [56/85] Batch 880/938 Loss D: 0.3489, Loss G: 1.7719\n",
      "Epoch [56/85] Batch 890/938 Loss D: 0.3745, Loss G: 2.6991\n",
      "Epoch [56/85] Batch 900/938 Loss D: 0.2829, Loss G: 2.3251\n",
      "Epoch [56/85] Batch 910/938 Loss D: 0.3415, Loss G: 2.8688\n",
      "Epoch [56/85] Batch 920/938 Loss D: 0.2941, Loss G: 2.6429\n",
      "Epoch [56/85] Batch 930/938 Loss D: 0.2096, Loss G: 2.5876\n",
      "Epoch [57/85] Batch 0/938 Loss D: 0.4869, Loss G: 1.9530\n",
      "Epoch [57/85] Batch 10/938 Loss D: 0.3557, Loss G: 2.4100\n",
      "Epoch [57/85] Batch 20/938 Loss D: 0.2565, Loss G: 2.5819\n",
      "Epoch [57/85] Batch 30/938 Loss D: 0.3466, Loss G: 2.0143\n",
      "Epoch [57/85] Batch 40/938 Loss D: 0.3227, Loss G: 3.1345\n",
      "Epoch [57/85] Batch 50/938 Loss D: 0.2738, Loss G: 2.7698\n",
      "Epoch [57/85] Batch 60/938 Loss D: 0.2841, Loss G: 2.1577\n",
      "Epoch [57/85] Batch 70/938 Loss D: 0.3056, Loss G: 2.5609\n",
      "Epoch [57/85] Batch 80/938 Loss D: 0.3850, Loss G: 1.9792\n",
      "Epoch [57/85] Batch 90/938 Loss D: 0.2435, Loss G: 2.4520\n",
      "Epoch [57/85] Batch 100/938 Loss D: 0.2495, Loss G: 2.2570\n",
      "Epoch [57/85] Batch 110/938 Loss D: 0.2651, Loss G: 2.2497\n",
      "Epoch [57/85] Batch 120/938 Loss D: 0.3273, Loss G: 1.9335\n",
      "Epoch [57/85] Batch 130/938 Loss D: 0.2617, Loss G: 2.3520\n",
      "Epoch [57/85] Batch 140/938 Loss D: 0.2453, Loss G: 2.2450\n",
      "Epoch [57/85] Batch 150/938 Loss D: 0.2375, Loss G: 2.4460\n",
      "Epoch [57/85] Batch 160/938 Loss D: 0.3002, Loss G: 2.2168\n",
      "Epoch [57/85] Batch 170/938 Loss D: 0.3553, Loss G: 1.9140\n",
      "Epoch [57/85] Batch 180/938 Loss D: 0.2737, Loss G: 2.0985\n",
      "Epoch [57/85] Batch 190/938 Loss D: 0.3372, Loss G: 2.0656\n",
      "Epoch [57/85] Batch 200/938 Loss D: 0.2916, Loss G: 2.4806\n",
      "Epoch [57/85] Batch 210/938 Loss D: 0.2736, Loss G: 2.4662\n",
      "Epoch [57/85] Batch 220/938 Loss D: 0.2824, Loss G: 2.1793\n",
      "Epoch [57/85] Batch 230/938 Loss D: 0.2524, Loss G: 2.2702\n",
      "Epoch [57/85] Batch 240/938 Loss D: 0.2860, Loss G: 2.4224\n",
      "Epoch [57/85] Batch 250/938 Loss D: 0.3459, Loss G: 2.7688\n",
      "Epoch [57/85] Batch 260/938 Loss D: 0.2229, Loss G: 3.0627\n",
      "Epoch [57/85] Batch 270/938 Loss D: 0.3467, Loss G: 2.3254\n",
      "Epoch [57/85] Batch 280/938 Loss D: 0.3298, Loss G: 1.9822\n",
      "Epoch [57/85] Batch 290/938 Loss D: 0.3558, Loss G: 2.0508\n",
      "Epoch [57/85] Batch 300/938 Loss D: 0.3042, Loss G: 2.3119\n",
      "Epoch [57/85] Batch 310/938 Loss D: 0.2902, Loss G: 2.2667\n",
      "Epoch [57/85] Batch 320/938 Loss D: 0.3479, Loss G: 2.3975\n",
      "Epoch [57/85] Batch 330/938 Loss D: 0.2995, Loss G: 2.5138\n",
      "Epoch [57/85] Batch 340/938 Loss D: 0.3133, Loss G: 2.0506\n",
      "Epoch [57/85] Batch 350/938 Loss D: 0.2832, Loss G: 2.4037\n",
      "Epoch [57/85] Batch 360/938 Loss D: 0.3840, Loss G: 2.7891\n",
      "Epoch [57/85] Batch 370/938 Loss D: 0.3215, Loss G: 1.9876\n",
      "Epoch [57/85] Batch 380/938 Loss D: 0.3029, Loss G: 2.4304\n",
      "Epoch [57/85] Batch 390/938 Loss D: 0.3718, Loss G: 2.2745\n",
      "Epoch [57/85] Batch 400/938 Loss D: 0.3358, Loss G: 2.4688\n",
      "Epoch [57/85] Batch 410/938 Loss D: 0.3768, Loss G: 3.6048\n",
      "Epoch [57/85] Batch 420/938 Loss D: 0.2540, Loss G: 2.9155\n",
      "Epoch [57/85] Batch 430/938 Loss D: 0.4018, Loss G: 2.6666\n",
      "Epoch [57/85] Batch 440/938 Loss D: 0.2739, Loss G: 2.7002\n",
      "Epoch [57/85] Batch 450/938 Loss D: 0.4061, Loss G: 2.4079\n",
      "Epoch [57/85] Batch 460/938 Loss D: 0.2663, Loss G: 2.0337\n",
      "Epoch [57/85] Batch 470/938 Loss D: 0.3186, Loss G: 1.9217\n",
      "Epoch [57/85] Batch 480/938 Loss D: 0.3156, Loss G: 1.8338\n",
      "Epoch [57/85] Batch 490/938 Loss D: 0.3343, Loss G: 2.0471\n",
      "Epoch [57/85] Batch 500/938 Loss D: 0.4614, Loss G: 1.7215\n",
      "Epoch [57/85] Batch 510/938 Loss D: 0.4161, Loss G: 1.8222\n",
      "Epoch [57/85] Batch 520/938 Loss D: 0.3431, Loss G: 2.0575\n",
      "Epoch [57/85] Batch 530/938 Loss D: 0.2101, Loss G: 2.6558\n",
      "Epoch [57/85] Batch 540/938 Loss D: 0.3622, Loss G: 2.0262\n",
      "Epoch [57/85] Batch 550/938 Loss D: 0.2871, Loss G: 2.3885\n",
      "Epoch [57/85] Batch 560/938 Loss D: 0.1890, Loss G: 3.0891\n",
      "Epoch [57/85] Batch 570/938 Loss D: 0.5317, Loss G: 2.0941\n",
      "Epoch [57/85] Batch 580/938 Loss D: 0.4858, Loss G: 1.3646\n",
      "Epoch [57/85] Batch 590/938 Loss D: 0.3770, Loss G: 1.7686\n",
      "Epoch [57/85] Batch 600/938 Loss D: 0.4230, Loss G: 1.6507\n",
      "Epoch [57/85] Batch 610/938 Loss D: 0.3522, Loss G: 3.0675\n",
      "Epoch [57/85] Batch 620/938 Loss D: 0.3335, Loss G: 2.6069\n",
      "Epoch [57/85] Batch 630/938 Loss D: 0.2541, Loss G: 2.6781\n",
      "Epoch [57/85] Batch 640/938 Loss D: 0.3278, Loss G: 2.0536\n",
      "Epoch [57/85] Batch 650/938 Loss D: 0.2855, Loss G: 2.2337\n",
      "Epoch [57/85] Batch 660/938 Loss D: 0.3033, Loss G: 2.2941\n",
      "Epoch [57/85] Batch 670/938 Loss D: 0.3749, Loss G: 2.4209\n",
      "Epoch [57/85] Batch 680/938 Loss D: 0.3601, Loss G: 2.3955\n",
      "Epoch [57/85] Batch 690/938 Loss D: 0.2223, Loss G: 2.6446\n",
      "Epoch [57/85] Batch 700/938 Loss D: 0.4309, Loss G: 2.4001\n",
      "Epoch [57/85] Batch 710/938 Loss D: 0.2811, Loss G: 2.4391\n",
      "Epoch [57/85] Batch 720/938 Loss D: 0.3736, Loss G: 2.2148\n",
      "Epoch [57/85] Batch 730/938 Loss D: 0.3462, Loss G: 2.0754\n",
      "Epoch [57/85] Batch 740/938 Loss D: 0.2229, Loss G: 2.8927\n",
      "Epoch [57/85] Batch 750/938 Loss D: 0.2965, Loss G: 2.4471\n",
      "Epoch [57/85] Batch 760/938 Loss D: 0.3819, Loss G: 2.5191\n",
      "Epoch [57/85] Batch 770/938 Loss D: 0.2587, Loss G: 2.3368\n",
      "Epoch [57/85] Batch 780/938 Loss D: 0.3534, Loss G: 2.0628\n",
      "Epoch [57/85] Batch 790/938 Loss D: 0.3708, Loss G: 1.7307\n",
      "Epoch [57/85] Batch 800/938 Loss D: 0.5173, Loss G: 1.6522\n",
      "Epoch [57/85] Batch 810/938 Loss D: 0.3168, Loss G: 2.0065\n",
      "Epoch [57/85] Batch 820/938 Loss D: 0.3007, Loss G: 2.4801\n",
      "Epoch [57/85] Batch 830/938 Loss D: 0.3702, Loss G: 2.2679\n",
      "Epoch [57/85] Batch 840/938 Loss D: 0.3885, Loss G: 2.0033\n",
      "Epoch [57/85] Batch 850/938 Loss D: 0.2958, Loss G: 2.2617\n",
      "Epoch [57/85] Batch 860/938 Loss D: 0.4244, Loss G: 1.6935\n",
      "Epoch [57/85] Batch 870/938 Loss D: 0.3398, Loss G: 2.0199\n",
      "Epoch [57/85] Batch 880/938 Loss D: 0.3145, Loss G: 2.3984\n",
      "Epoch [57/85] Batch 890/938 Loss D: 0.3348, Loss G: 2.1082\n",
      "Epoch [57/85] Batch 900/938 Loss D: 0.3134, Loss G: 2.2103\n",
      "Epoch [57/85] Batch 910/938 Loss D: 0.3384, Loss G: 1.9819\n",
      "Epoch [57/85] Batch 920/938 Loss D: 0.2412, Loss G: 2.5653\n",
      "Epoch [57/85] Batch 930/938 Loss D: 0.3591, Loss G: 2.5734\n",
      "Epoch [58/85] Batch 0/938 Loss D: 0.5067, Loss G: 2.7160\n",
      "Epoch [58/85] Batch 10/938 Loss D: 0.3611, Loss G: 2.6181\n",
      "Epoch [58/85] Batch 20/938 Loss D: 0.3019, Loss G: 2.7258\n",
      "Epoch [58/85] Batch 30/938 Loss D: 0.3216, Loss G: 2.4775\n",
      "Epoch [58/85] Batch 40/938 Loss D: 0.2451, Loss G: 2.5515\n",
      "Epoch [58/85] Batch 50/938 Loss D: 0.3766, Loss G: 2.2320\n",
      "Epoch [58/85] Batch 60/938 Loss D: 0.3192, Loss G: 2.2428\n",
      "Epoch [58/85] Batch 70/938 Loss D: 0.2320, Loss G: 2.9080\n",
      "Epoch [58/85] Batch 80/938 Loss D: 0.2606, Loss G: 1.9325\n",
      "Epoch [58/85] Batch 90/938 Loss D: 0.3654, Loss G: 2.0254\n",
      "Epoch [58/85] Batch 100/938 Loss D: 0.3050, Loss G: 2.2942\n",
      "Epoch [58/85] Batch 110/938 Loss D: 0.2517, Loss G: 2.5274\n",
      "Epoch [58/85] Batch 120/938 Loss D: 0.2212, Loss G: 2.9179\n",
      "Epoch [58/85] Batch 130/938 Loss D: 0.4117, Loss G: 2.0035\n",
      "Epoch [58/85] Batch 140/938 Loss D: 0.3724, Loss G: 1.5315\n",
      "Epoch [58/85] Batch 150/938 Loss D: 0.2892, Loss G: 1.9458\n",
      "Epoch [58/85] Batch 160/938 Loss D: 0.3034, Loss G: 2.4697\n",
      "Epoch [58/85] Batch 170/938 Loss D: 0.5060, Loss G: 2.3249\n",
      "Epoch [58/85] Batch 180/938 Loss D: 0.3278, Loss G: 2.3128\n",
      "Epoch [58/85] Batch 190/938 Loss D: 0.3622, Loss G: 2.5777\n",
      "Epoch [58/85] Batch 200/938 Loss D: 0.3338, Loss G: 2.1910\n",
      "Epoch [58/85] Batch 210/938 Loss D: 0.2438, Loss G: 2.4255\n",
      "Epoch [58/85] Batch 220/938 Loss D: 0.4725, Loss G: 1.8841\n",
      "Epoch [58/85] Batch 230/938 Loss D: 0.3775, Loss G: 1.9774\n",
      "Epoch [58/85] Batch 240/938 Loss D: 0.2234, Loss G: 2.8519\n",
      "Epoch [58/85] Batch 250/938 Loss D: 0.3252, Loss G: 2.7041\n",
      "Epoch [58/85] Batch 260/938 Loss D: 0.3200, Loss G: 2.1625\n",
      "Epoch [58/85] Batch 270/938 Loss D: 0.2513, Loss G: 2.3235\n",
      "Epoch [58/85] Batch 280/938 Loss D: 0.2699, Loss G: 2.7394\n",
      "Epoch [58/85] Batch 290/938 Loss D: 0.2876, Loss G: 2.4371\n",
      "Epoch [58/85] Batch 300/938 Loss D: 0.2265, Loss G: 2.1355\n",
      "Epoch [58/85] Batch 310/938 Loss D: 0.1790, Loss G: 3.5862\n",
      "Epoch [58/85] Batch 320/938 Loss D: 0.2466, Loss G: 3.0089\n",
      "Epoch [58/85] Batch 330/938 Loss D: 0.3564, Loss G: 3.0107\n",
      "Epoch [58/85] Batch 340/938 Loss D: 0.3300, Loss G: 2.5395\n",
      "Epoch [58/85] Batch 350/938 Loss D: 0.2305, Loss G: 2.5483\n",
      "Epoch [58/85] Batch 360/938 Loss D: 0.3550, Loss G: 1.9024\n",
      "Epoch [58/85] Batch 370/938 Loss D: 0.1802, Loss G: 2.7751\n",
      "Epoch [58/85] Batch 380/938 Loss D: 0.1914, Loss G: 2.7849\n",
      "Epoch [58/85] Batch 390/938 Loss D: 0.3984, Loss G: 1.9233\n",
      "Epoch [58/85] Batch 400/938 Loss D: 0.2621, Loss G: 2.3693\n",
      "Epoch [58/85] Batch 410/938 Loss D: 0.2833, Loss G: 2.3293\n",
      "Epoch [58/85] Batch 420/938 Loss D: 0.3292, Loss G: 2.9107\n",
      "Epoch [58/85] Batch 430/938 Loss D: 0.3584, Loss G: 2.7542\n",
      "Epoch [58/85] Batch 440/938 Loss D: 0.1954, Loss G: 2.6421\n",
      "Epoch [58/85] Batch 450/938 Loss D: 0.3313, Loss G: 1.9244\n",
      "Epoch [58/85] Batch 460/938 Loss D: 0.2882, Loss G: 2.4277\n",
      "Epoch [58/85] Batch 470/938 Loss D: 0.2544, Loss G: 2.4094\n",
      "Epoch [58/85] Batch 480/938 Loss D: 0.2655, Loss G: 2.9460\n",
      "Epoch [58/85] Batch 490/938 Loss D: 0.2766, Loss G: 2.7797\n",
      "Epoch [58/85] Batch 500/938 Loss D: 0.2421, Loss G: 2.6908\n",
      "Epoch [58/85] Batch 510/938 Loss D: 0.3343, Loss G: 2.1094\n",
      "Epoch [58/85] Batch 520/938 Loss D: 0.2677, Loss G: 2.2084\n",
      "Epoch [58/85] Batch 530/938 Loss D: 0.2950, Loss G: 2.4411\n",
      "Epoch [58/85] Batch 540/938 Loss D: 0.3383, Loss G: 2.1356\n",
      "Epoch [58/85] Batch 550/938 Loss D: 0.2665, Loss G: 2.7753\n",
      "Epoch [58/85] Batch 560/938 Loss D: 0.3248, Loss G: 2.4957\n",
      "Epoch [58/85] Batch 570/938 Loss D: 0.3229, Loss G: 2.6950\n",
      "Epoch [58/85] Batch 580/938 Loss D: 0.3290, Loss G: 2.2811\n",
      "Epoch [58/85] Batch 590/938 Loss D: 0.2965, Loss G: 1.8579\n",
      "Epoch [58/85] Batch 600/938 Loss D: 0.2935, Loss G: 2.3225\n",
      "Epoch [58/85] Batch 610/938 Loss D: 0.4273, Loss G: 1.6125\n",
      "Epoch [58/85] Batch 620/938 Loss D: 0.4569, Loss G: 1.8730\n",
      "Epoch [58/85] Batch 630/938 Loss D: 0.2703, Loss G: 2.1859\n",
      "Epoch [58/85] Batch 640/938 Loss D: 0.1844, Loss G: 2.9104\n",
      "Epoch [58/85] Batch 650/938 Loss D: 0.2725, Loss G: 2.8090\n",
      "Epoch [58/85] Batch 660/938 Loss D: 0.3734, Loss G: 1.8307\n",
      "Epoch [58/85] Batch 670/938 Loss D: 0.2255, Loss G: 2.0679\n",
      "Epoch [58/85] Batch 680/938 Loss D: 0.2255, Loss G: 2.1225\n",
      "Epoch [58/85] Batch 690/938 Loss D: 0.2055, Loss G: 2.3673\n",
      "Epoch [58/85] Batch 700/938 Loss D: 0.4401, Loss G: 1.6269\n",
      "Epoch [58/85] Batch 710/938 Loss D: 0.2570, Loss G: 2.6267\n",
      "Epoch [58/85] Batch 720/938 Loss D: 0.2596, Loss G: 2.4949\n",
      "Epoch [58/85] Batch 730/938 Loss D: 0.3561, Loss G: 1.8893\n",
      "Epoch [58/85] Batch 740/938 Loss D: 0.4014, Loss G: 1.6662\n",
      "Epoch [58/85] Batch 750/938 Loss D: 0.3914, Loss G: 1.8672\n",
      "Epoch [58/85] Batch 760/938 Loss D: 0.3477, Loss G: 1.8464\n",
      "Epoch [58/85] Batch 770/938 Loss D: 0.3655, Loss G: 2.9438\n",
      "Epoch [58/85] Batch 780/938 Loss D: 0.3926, Loss G: 2.8170\n",
      "Epoch [58/85] Batch 790/938 Loss D: 0.3068, Loss G: 2.4755\n",
      "Epoch [58/85] Batch 800/938 Loss D: 0.3429, Loss G: 2.7438\n",
      "Epoch [58/85] Batch 810/938 Loss D: 0.4119, Loss G: 1.8769\n",
      "Epoch [58/85] Batch 820/938 Loss D: 0.2548, Loss G: 2.7894\n",
      "Epoch [58/85] Batch 830/938 Loss D: 0.1632, Loss G: 3.2851\n",
      "Epoch [58/85] Batch 840/938 Loss D: 0.3347, Loss G: 3.0109\n",
      "Epoch [58/85] Batch 850/938 Loss D: 0.3252, Loss G: 2.5997\n",
      "Epoch [58/85] Batch 860/938 Loss D: 0.2798, Loss G: 1.8364\n",
      "Epoch [58/85] Batch 870/938 Loss D: 0.1734, Loss G: 3.5307\n",
      "Epoch [58/85] Batch 880/938 Loss D: 0.5176, Loss G: 2.0705\n",
      "Epoch [58/85] Batch 890/938 Loss D: 0.2753, Loss G: 2.0505\n",
      "Epoch [58/85] Batch 900/938 Loss D: 0.3709, Loss G: 2.3581\n",
      "Epoch [58/85] Batch 910/938 Loss D: 0.3281, Loss G: 1.8315\n",
      "Epoch [58/85] Batch 920/938 Loss D: 0.3336, Loss G: 2.1455\n",
      "Epoch [58/85] Batch 930/938 Loss D: 0.4383, Loss G: 2.6734\n",
      "Epoch [59/85] Batch 0/938 Loss D: 0.2211, Loss G: 2.5808\n",
      "Epoch [59/85] Batch 10/938 Loss D: 0.3087, Loss G: 2.0122\n",
      "Epoch [59/85] Batch 20/938 Loss D: 0.2157, Loss G: 2.6780\n",
      "Epoch [59/85] Batch 30/938 Loss D: 0.3753, Loss G: 1.4360\n",
      "Epoch [59/85] Batch 40/938 Loss D: 0.3109, Loss G: 2.1157\n",
      "Epoch [59/85] Batch 50/938 Loss D: 0.2997, Loss G: 2.0267\n",
      "Epoch [59/85] Batch 60/938 Loss D: 0.2840, Loss G: 2.2425\n",
      "Epoch [59/85] Batch 70/938 Loss D: 0.2574, Loss G: 2.7412\n",
      "Epoch [59/85] Batch 80/938 Loss D: 0.2893, Loss G: 2.7474\n",
      "Epoch [59/85] Batch 90/938 Loss D: 0.2778, Loss G: 2.7906\n",
      "Epoch [59/85] Batch 100/938 Loss D: 0.3143, Loss G: 2.6181\n",
      "Epoch [59/85] Batch 110/938 Loss D: 0.3552, Loss G: 1.7497\n",
      "Epoch [59/85] Batch 120/938 Loss D: 0.2079, Loss G: 2.5069\n",
      "Epoch [59/85] Batch 130/938 Loss D: 0.3152, Loss G: 1.6861\n",
      "Epoch [59/85] Batch 140/938 Loss D: 0.3715, Loss G: 2.4848\n",
      "Epoch [59/85] Batch 150/938 Loss D: 0.2473, Loss G: 2.4019\n",
      "Epoch [59/85] Batch 160/938 Loss D: 0.3464, Loss G: 2.1200\n",
      "Epoch [59/85] Batch 170/938 Loss D: 0.2254, Loss G: 2.7904\n",
      "Epoch [59/85] Batch 180/938 Loss D: 0.2677, Loss G: 2.9748\n",
      "Epoch [59/85] Batch 190/938 Loss D: 0.3329, Loss G: 2.8288\n",
      "Epoch [59/85] Batch 200/938 Loss D: 0.3244, Loss G: 2.0478\n",
      "Epoch [59/85] Batch 210/938 Loss D: 0.2296, Loss G: 2.4279\n",
      "Epoch [59/85] Batch 220/938 Loss D: 0.2010, Loss G: 3.0835\n",
      "Epoch [59/85] Batch 230/938 Loss D: 0.2629, Loss G: 2.9910\n",
      "Epoch [59/85] Batch 240/938 Loss D: 0.3280, Loss G: 3.0494\n",
      "Epoch [59/85] Batch 250/938 Loss D: 0.3041, Loss G: 2.2571\n",
      "Epoch [59/85] Batch 260/938 Loss D: 0.3191, Loss G: 1.8881\n",
      "Epoch [59/85] Batch 270/938 Loss D: 0.4687, Loss G: 1.9008\n",
      "Epoch [59/85] Batch 280/938 Loss D: 0.3042, Loss G: 2.7726\n",
      "Epoch [59/85] Batch 290/938 Loss D: 0.2672, Loss G: 2.7444\n",
      "Epoch [59/85] Batch 300/938 Loss D: 0.3648, Loss G: 2.2968\n",
      "Epoch [59/85] Batch 310/938 Loss D: 0.2883, Loss G: 1.9084\n",
      "Epoch [59/85] Batch 320/938 Loss D: 0.3322, Loss G: 2.4581\n",
      "Epoch [59/85] Batch 330/938 Loss D: 0.3965, Loss G: 1.9242\n",
      "Epoch [59/85] Batch 340/938 Loss D: 0.2832, Loss G: 2.0716\n",
      "Epoch [59/85] Batch 350/938 Loss D: 0.2246, Loss G: 2.7002\n",
      "Epoch [59/85] Batch 360/938 Loss D: 0.2775, Loss G: 2.5263\n",
      "Epoch [59/85] Batch 370/938 Loss D: 0.2050, Loss G: 2.4393\n",
      "Epoch [59/85] Batch 380/938 Loss D: 0.3580, Loss G: 2.3062\n",
      "Epoch [59/85] Batch 390/938 Loss D: 0.3132, Loss G: 2.1003\n",
      "Epoch [59/85] Batch 400/938 Loss D: 0.1689, Loss G: 3.1989\n",
      "Epoch [59/85] Batch 410/938 Loss D: 0.2641, Loss G: 2.7712\n",
      "Epoch [59/85] Batch 420/938 Loss D: 0.2500, Loss G: 2.7142\n",
      "Epoch [59/85] Batch 430/938 Loss D: 0.3109, Loss G: 2.1429\n",
      "Epoch [59/85] Batch 440/938 Loss D: 0.3294, Loss G: 2.4846\n",
      "Epoch [59/85] Batch 450/938 Loss D: 0.4083, Loss G: 2.1581\n",
      "Epoch [59/85] Batch 460/938 Loss D: 0.3256, Loss G: 2.3019\n",
      "Epoch [59/85] Batch 470/938 Loss D: 0.2389, Loss G: 2.5941\n",
      "Epoch [59/85] Batch 480/938 Loss D: 0.4228, Loss G: 2.3629\n",
      "Epoch [59/85] Batch 490/938 Loss D: 0.3084, Loss G: 2.2732\n",
      "Epoch [59/85] Batch 500/938 Loss D: 0.2277, Loss G: 2.9455\n",
      "Epoch [59/85] Batch 510/938 Loss D: 0.2123, Loss G: 2.8413\n",
      "Epoch [59/85] Batch 520/938 Loss D: 0.2051, Loss G: 2.4784\n",
      "Epoch [59/85] Batch 530/938 Loss D: 0.3149, Loss G: 2.9815\n",
      "Epoch [59/85] Batch 540/938 Loss D: 0.3302, Loss G: 2.1735\n",
      "Epoch [59/85] Batch 550/938 Loss D: 0.4414, Loss G: 1.7774\n",
      "Epoch [59/85] Batch 560/938 Loss D: 0.2088, Loss G: 2.6164\n",
      "Epoch [59/85] Batch 570/938 Loss D: 0.3016, Loss G: 3.0505\n",
      "Epoch [59/85] Batch 580/938 Loss D: 0.3379, Loss G: 2.7622\n",
      "Epoch [59/85] Batch 590/938 Loss D: 0.2341, Loss G: 2.5261\n",
      "Epoch [59/85] Batch 600/938 Loss D: 0.2747, Loss G: 3.0563\n",
      "Epoch [59/85] Batch 610/938 Loss D: 0.2404, Loss G: 3.1797\n",
      "Epoch [59/85] Batch 620/938 Loss D: 0.3914, Loss G: 2.4503\n",
      "Epoch [59/85] Batch 630/938 Loss D: 0.3960, Loss G: 1.7183\n",
      "Epoch [59/85] Batch 640/938 Loss D: 0.1588, Loss G: 2.5211\n",
      "Epoch [59/85] Batch 650/938 Loss D: 0.3156, Loss G: 2.0734\n",
      "Epoch [59/85] Batch 660/938 Loss D: 0.2524, Loss G: 2.5579\n",
      "Epoch [59/85] Batch 670/938 Loss D: 0.3029, Loss G: 2.0346\n",
      "Epoch [59/85] Batch 680/938 Loss D: 0.2266, Loss G: 2.3007\n",
      "Epoch [59/85] Batch 690/938 Loss D: 0.2686, Loss G: 2.7749\n",
      "Epoch [59/85] Batch 700/938 Loss D: 0.3669, Loss G: 2.6791\n",
      "Epoch [59/85] Batch 710/938 Loss D: 0.2896, Loss G: 2.7136\n",
      "Epoch [59/85] Batch 720/938 Loss D: 0.2413, Loss G: 2.8923\n",
      "Epoch [59/85] Batch 730/938 Loss D: 0.4395, Loss G: 2.0644\n",
      "Epoch [59/85] Batch 740/938 Loss D: 0.3679, Loss G: 1.7982\n",
      "Epoch [59/85] Batch 750/938 Loss D: 0.3666, Loss G: 2.3260\n",
      "Epoch [59/85] Batch 760/938 Loss D: 0.2822, Loss G: 2.0816\n",
      "Epoch [59/85] Batch 770/938 Loss D: 0.2336, Loss G: 2.2127\n",
      "Epoch [59/85] Batch 780/938 Loss D: 0.4134, Loss G: 2.0680\n",
      "Epoch [59/85] Batch 790/938 Loss D: 0.1905, Loss G: 2.7439\n",
      "Epoch [59/85] Batch 800/938 Loss D: 0.3765, Loss G: 2.2271\n",
      "Epoch [59/85] Batch 810/938 Loss D: 0.2043, Loss G: 2.4728\n",
      "Epoch [59/85] Batch 820/938 Loss D: 0.3212, Loss G: 2.3012\n",
      "Epoch [59/85] Batch 830/938 Loss D: 0.2624, Loss G: 2.1183\n",
      "Epoch [59/85] Batch 840/938 Loss D: 0.2941, Loss G: 1.7130\n",
      "Epoch [59/85] Batch 850/938 Loss D: 0.3886, Loss G: 1.7302\n",
      "Epoch [59/85] Batch 860/938 Loss D: 0.3069, Loss G: 2.3787\n",
      "Epoch [59/85] Batch 870/938 Loss D: 0.2402, Loss G: 2.3889\n",
      "Epoch [59/85] Batch 880/938 Loss D: 0.2869, Loss G: 3.5277\n",
      "Epoch [59/85] Batch 890/938 Loss D: 0.2715, Loss G: 2.6419\n",
      "Epoch [59/85] Batch 900/938 Loss D: 0.3837, Loss G: 1.9215\n",
      "Epoch [59/85] Batch 910/938 Loss D: 0.4197, Loss G: 1.8854\n",
      "Epoch [59/85] Batch 920/938 Loss D: 0.2878, Loss G: 2.1716\n",
      "Epoch [59/85] Batch 930/938 Loss D: 0.3365, Loss G: 1.5007\n",
      "Epoch [60/85] Batch 0/938 Loss D: 0.2700, Loss G: 2.9392\n",
      "Epoch [60/85] Batch 10/938 Loss D: 0.2246, Loss G: 2.7801\n",
      "Epoch [60/85] Batch 20/938 Loss D: 0.2695, Loss G: 2.0589\n",
      "Epoch [60/85] Batch 30/938 Loss D: 0.3287, Loss G: 1.6671\n",
      "Epoch [60/85] Batch 40/938 Loss D: 0.2453, Loss G: 2.7958\n",
      "Epoch [60/85] Batch 50/938 Loss D: 0.4782, Loss G: 1.8722\n",
      "Epoch [60/85] Batch 60/938 Loss D: 0.1988, Loss G: 2.9060\n",
      "Epoch [60/85] Batch 70/938 Loss D: 0.3572, Loss G: 2.2928\n",
      "Epoch [60/85] Batch 80/938 Loss D: 0.1736, Loss G: 3.1296\n",
      "Epoch [60/85] Batch 90/938 Loss D: 0.1841, Loss G: 3.4523\n",
      "Epoch [60/85] Batch 100/938 Loss D: 0.3574, Loss G: 2.3987\n",
      "Epoch [60/85] Batch 110/938 Loss D: 0.2972, Loss G: 2.2990\n",
      "Epoch [60/85] Batch 120/938 Loss D: 0.3176, Loss G: 2.1185\n",
      "Epoch [60/85] Batch 130/938 Loss D: 0.3183, Loss G: 2.2581\n",
      "Epoch [60/85] Batch 140/938 Loss D: 0.2678, Loss G: 2.6677\n",
      "Epoch [60/85] Batch 150/938 Loss D: 0.2358, Loss G: 2.3297\n",
      "Epoch [60/85] Batch 160/938 Loss D: 0.3837, Loss G: 2.1130\n",
      "Epoch [60/85] Batch 170/938 Loss D: 0.2878, Loss G: 2.5498\n",
      "Epoch [60/85] Batch 180/938 Loss D: 0.2325, Loss G: 2.8039\n",
      "Epoch [60/85] Batch 190/938 Loss D: 0.2927, Loss G: 2.1559\n",
      "Epoch [60/85] Batch 200/938 Loss D: 0.2521, Loss G: 3.2476\n",
      "Epoch [60/85] Batch 210/938 Loss D: 0.3082, Loss G: 2.9100\n",
      "Epoch [60/85] Batch 220/938 Loss D: 0.2741, Loss G: 2.3177\n",
      "Epoch [60/85] Batch 230/938 Loss D: 0.2299, Loss G: 2.4918\n",
      "Epoch [60/85] Batch 240/938 Loss D: 0.2417, Loss G: 2.6225\n",
      "Epoch [60/85] Batch 250/938 Loss D: 0.3378, Loss G: 2.0877\n",
      "Epoch [60/85] Batch 260/938 Loss D: 0.2608, Loss G: 2.4870\n",
      "Epoch [60/85] Batch 270/938 Loss D: 0.4971, Loss G: 2.4566\n",
      "Epoch [60/85] Batch 280/938 Loss D: 0.3155, Loss G: 2.7132\n",
      "Epoch [60/85] Batch 290/938 Loss D: 0.3008, Loss G: 2.3300\n",
      "Epoch [60/85] Batch 300/938 Loss D: 0.3264, Loss G: 2.3350\n",
      "Epoch [60/85] Batch 310/938 Loss D: 0.2730, Loss G: 2.4527\n",
      "Epoch [60/85] Batch 320/938 Loss D: 0.2921, Loss G: 2.2136\n",
      "Epoch [60/85] Batch 330/938 Loss D: 0.3028, Loss G: 2.0512\n",
      "Epoch [60/85] Batch 340/938 Loss D: 0.2714, Loss G: 3.1111\n",
      "Epoch [60/85] Batch 350/938 Loss D: 0.3593, Loss G: 2.5165\n",
      "Epoch [60/85] Batch 360/938 Loss D: 0.3024, Loss G: 2.6789\n",
      "Epoch [60/85] Batch 370/938 Loss D: 0.5151, Loss G: 2.7303\n",
      "Epoch [60/85] Batch 380/938 Loss D: 0.4438, Loss G: 2.4630\n",
      "Epoch [60/85] Batch 390/938 Loss D: 0.2220, Loss G: 3.2822\n",
      "Epoch [60/85] Batch 400/938 Loss D: 0.3981, Loss G: 2.5098\n",
      "Epoch [60/85] Batch 410/938 Loss D: 0.2718, Loss G: 2.5707\n",
      "Epoch [60/85] Batch 420/938 Loss D: 0.4393, Loss G: 2.1655\n",
      "Epoch [60/85] Batch 430/938 Loss D: 0.2993, Loss G: 2.2290\n",
      "Epoch [60/85] Batch 440/938 Loss D: 0.2860, Loss G: 1.9581\n",
      "Epoch [60/85] Batch 450/938 Loss D: 0.3825, Loss G: 2.3202\n",
      "Epoch [60/85] Batch 460/938 Loss D: 0.4419, Loss G: 2.2644\n",
      "Epoch [60/85] Batch 470/938 Loss D: 0.3180, Loss G: 2.2418\n",
      "Epoch [60/85] Batch 480/938 Loss D: 0.1800, Loss G: 3.3605\n",
      "Epoch [60/85] Batch 490/938 Loss D: 0.3539, Loss G: 2.1088\n",
      "Epoch [60/85] Batch 500/938 Loss D: 0.2146, Loss G: 2.9129\n",
      "Epoch [60/85] Batch 510/938 Loss D: 0.2565, Loss G: 2.6320\n",
      "Epoch [60/85] Batch 520/938 Loss D: 0.3582, Loss G: 3.2000\n",
      "Epoch [60/85] Batch 530/938 Loss D: 0.2821, Loss G: 3.2308\n",
      "Epoch [60/85] Batch 540/938 Loss D: 0.2100, Loss G: 3.3187\n",
      "Epoch [60/85] Batch 550/938 Loss D: 0.1888, Loss G: 3.5371\n",
      "Epoch [60/85] Batch 560/938 Loss D: 0.2000, Loss G: 2.8860\n",
      "Epoch [60/85] Batch 570/938 Loss D: 0.3297, Loss G: 2.2188\n",
      "Epoch [60/85] Batch 580/938 Loss D: 0.4223, Loss G: 2.3009\n",
      "Epoch [60/85] Batch 590/938 Loss D: 0.4190, Loss G: 2.2797\n",
      "Epoch [60/85] Batch 600/938 Loss D: 0.3457, Loss G: 2.8754\n",
      "Epoch [60/85] Batch 610/938 Loss D: 0.4633, Loss G: 2.4242\n",
      "Epoch [60/85] Batch 620/938 Loss D: 0.2245, Loss G: 3.4938\n",
      "Epoch [60/85] Batch 630/938 Loss D: 0.2419, Loss G: 2.3043\n",
      "Epoch [60/85] Batch 640/938 Loss D: 0.3223, Loss G: 2.1866\n",
      "Epoch [60/85] Batch 650/938 Loss D: 0.4536, Loss G: 1.7181\n",
      "Epoch [60/85] Batch 660/938 Loss D: 0.4118, Loss G: 1.7308\n",
      "Epoch [60/85] Batch 670/938 Loss D: 0.2048, Loss G: 2.4389\n",
      "Epoch [60/85] Batch 680/938 Loss D: 0.2829, Loss G: 2.0438\n",
      "Epoch [60/85] Batch 690/938 Loss D: 0.3892, Loss G: 1.7359\n",
      "Epoch [60/85] Batch 700/938 Loss D: 0.2563, Loss G: 2.3469\n",
      "Epoch [60/85] Batch 710/938 Loss D: 0.2797, Loss G: 2.7912\n",
      "Epoch [60/85] Batch 720/938 Loss D: 0.2244, Loss G: 2.5240\n",
      "Epoch [60/85] Batch 730/938 Loss D: 0.4023, Loss G: 2.1264\n",
      "Epoch [60/85] Batch 740/938 Loss D: 0.2200, Loss G: 2.6937\n",
      "Epoch [60/85] Batch 750/938 Loss D: 0.1899, Loss G: 3.2666\n",
      "Epoch [60/85] Batch 760/938 Loss D: 0.2030, Loss G: 2.9341\n",
      "Epoch [60/85] Batch 770/938 Loss D: 0.2328, Loss G: 3.3346\n",
      "Epoch [60/85] Batch 780/938 Loss D: 0.3231, Loss G: 2.4712\n",
      "Epoch [60/85] Batch 790/938 Loss D: 0.3054, Loss G: 1.9547\n",
      "Epoch [60/85] Batch 800/938 Loss D: 0.2664, Loss G: 2.1719\n",
      "Epoch [60/85] Batch 810/938 Loss D: 0.3649, Loss G: 2.1127\n",
      "Epoch [60/85] Batch 820/938 Loss D: 0.2587, Loss G: 2.9361\n",
      "Epoch [60/85] Batch 830/938 Loss D: 0.2523, Loss G: 2.8195\n",
      "Epoch [60/85] Batch 840/938 Loss D: 0.3058, Loss G: 1.9695\n",
      "Epoch [60/85] Batch 850/938 Loss D: 0.2872, Loss G: 1.9271\n",
      "Epoch [60/85] Batch 860/938 Loss D: 0.2576, Loss G: 2.2025\n",
      "Epoch [60/85] Batch 870/938 Loss D: 0.2106, Loss G: 2.6270\n",
      "Epoch [60/85] Batch 880/938 Loss D: 0.2804, Loss G: 2.2248\n",
      "Epoch [60/85] Batch 890/938 Loss D: 0.3198, Loss G: 2.2050\n",
      "Epoch [60/85] Batch 900/938 Loss D: 0.3016, Loss G: 2.6583\n",
      "Epoch [60/85] Batch 910/938 Loss D: 0.2800, Loss G: 2.8674\n",
      "Epoch [60/85] Batch 920/938 Loss D: 0.3574, Loss G: 2.5792\n",
      "Epoch [60/85] Batch 930/938 Loss D: 0.4263, Loss G: 1.8349\n",
      "Epoch [61/85] Batch 0/938 Loss D: 0.2911, Loss G: 1.6845\n",
      "Epoch [61/85] Batch 10/938 Loss D: 0.2445, Loss G: 1.9587\n",
      "Epoch [61/85] Batch 20/938 Loss D: 0.2087, Loss G: 3.0485\n",
      "Epoch [61/85] Batch 30/938 Loss D: 0.3187, Loss G: 2.2188\n",
      "Epoch [61/85] Batch 40/938 Loss D: 0.2783, Loss G: 1.8422\n",
      "Epoch [61/85] Batch 50/938 Loss D: 0.2903, Loss G: 2.2455\n",
      "Epoch [61/85] Batch 60/938 Loss D: 0.1983, Loss G: 2.5561\n",
      "Epoch [61/85] Batch 70/938 Loss D: 0.2192, Loss G: 3.5556\n",
      "Epoch [61/85] Batch 80/938 Loss D: 0.2484, Loss G: 2.4219\n",
      "Epoch [61/85] Batch 90/938 Loss D: 0.1709, Loss G: 3.1675\n",
      "Epoch [61/85] Batch 100/938 Loss D: 0.2869, Loss G: 2.1489\n",
      "Epoch [61/85] Batch 110/938 Loss D: 0.4645, Loss G: 2.1328\n",
      "Epoch [61/85] Batch 120/938 Loss D: 0.2564, Loss G: 2.7473\n",
      "Epoch [61/85] Batch 130/938 Loss D: 0.4127, Loss G: 2.0585\n",
      "Epoch [61/85] Batch 140/938 Loss D: 0.3183, Loss G: 2.0981\n",
      "Epoch [61/85] Batch 150/938 Loss D: 0.2715, Loss G: 2.4946\n",
      "Epoch [61/85] Batch 160/938 Loss D: 0.3458, Loss G: 3.1342\n",
      "Epoch [61/85] Batch 170/938 Loss D: 0.2613, Loss G: 2.6360\n",
      "Epoch [61/85] Batch 180/938 Loss D: 0.3429, Loss G: 2.8903\n",
      "Epoch [61/85] Batch 190/938 Loss D: 0.2853, Loss G: 2.4624\n",
      "Epoch [61/85] Batch 200/938 Loss D: 0.2812, Loss G: 2.6304\n",
      "Epoch [61/85] Batch 210/938 Loss D: 0.2462, Loss G: 2.8992\n",
      "Epoch [61/85] Batch 220/938 Loss D: 0.2431, Loss G: 2.7753\n",
      "Epoch [61/85] Batch 230/938 Loss D: 0.2082, Loss G: 2.4670\n",
      "Epoch [61/85] Batch 240/938 Loss D: 0.3247, Loss G: 1.8792\n",
      "Epoch [61/85] Batch 250/938 Loss D: 0.2407, Loss G: 2.9298\n",
      "Epoch [61/85] Batch 260/938 Loss D: 0.3683, Loss G: 2.7766\n",
      "Epoch [61/85] Batch 270/938 Loss D: 0.3254, Loss G: 2.2749\n",
      "Epoch [61/85] Batch 280/938 Loss D: 0.2957, Loss G: 2.8673\n",
      "Epoch [61/85] Batch 290/938 Loss D: 0.4090, Loss G: 2.3297\n",
      "Epoch [61/85] Batch 300/938 Loss D: 0.3151, Loss G: 1.9916\n",
      "Epoch [61/85] Batch 310/938 Loss D: 0.1695, Loss G: 2.9150\n",
      "Epoch [61/85] Batch 320/938 Loss D: 0.1690, Loss G: 2.6495\n",
      "Epoch [61/85] Batch 330/938 Loss D: 0.1689, Loss G: 3.3341\n",
      "Epoch [61/85] Batch 340/938 Loss D: 0.2138, Loss G: 3.0704\n",
      "Epoch [61/85] Batch 350/938 Loss D: 0.2549, Loss G: 3.3417\n",
      "Epoch [61/85] Batch 360/938 Loss D: 0.2334, Loss G: 2.4759\n",
      "Epoch [61/85] Batch 370/938 Loss D: 0.2715, Loss G: 3.1989\n",
      "Epoch [61/85] Batch 380/938 Loss D: 0.3250, Loss G: 3.5502\n",
      "Epoch [61/85] Batch 390/938 Loss D: 0.1915, Loss G: 3.2286\n",
      "Epoch [61/85] Batch 400/938 Loss D: 0.2929, Loss G: 2.2519\n",
      "Epoch [61/85] Batch 410/938 Loss D: 0.3062, Loss G: 2.1020\n",
      "Epoch [61/85] Batch 420/938 Loss D: 0.2858, Loss G: 2.5760\n",
      "Epoch [61/85] Batch 430/938 Loss D: 0.2772, Loss G: 2.3818\n",
      "Epoch [61/85] Batch 440/938 Loss D: 0.3295, Loss G: 2.0591\n",
      "Epoch [61/85] Batch 450/938 Loss D: 0.2575, Loss G: 2.1508\n",
      "Epoch [61/85] Batch 460/938 Loss D: 0.2564, Loss G: 2.9642\n",
      "Epoch [61/85] Batch 470/938 Loss D: 0.2982, Loss G: 2.4173\n",
      "Epoch [61/85] Batch 480/938 Loss D: 0.2829, Loss G: 3.1259\n",
      "Epoch [61/85] Batch 490/938 Loss D: 0.2180, Loss G: 2.5492\n",
      "Epoch [61/85] Batch 500/938 Loss D: 0.3407, Loss G: 2.4314\n",
      "Epoch [61/85] Batch 510/938 Loss D: 0.3802, Loss G: 2.4306\n",
      "Epoch [61/85] Batch 520/938 Loss D: 0.4410, Loss G: 1.9044\n",
      "Epoch [61/85] Batch 530/938 Loss D: 0.2979, Loss G: 2.0247\n",
      "Epoch [61/85] Batch 540/938 Loss D: 0.2357, Loss G: 2.7126\n",
      "Epoch [61/85] Batch 550/938 Loss D: 0.3464, Loss G: 2.1222\n",
      "Epoch [61/85] Batch 560/938 Loss D: 0.2436, Loss G: 3.1565\n",
      "Epoch [61/85] Batch 570/938 Loss D: 0.2797, Loss G: 2.8116\n",
      "Epoch [61/85] Batch 580/938 Loss D: 0.2830, Loss G: 2.5218\n",
      "Epoch [61/85] Batch 590/938 Loss D: 0.2859, Loss G: 2.1236\n",
      "Epoch [61/85] Batch 600/938 Loss D: 0.4272, Loss G: 2.0172\n",
      "Epoch [61/85] Batch 610/938 Loss D: 0.2384, Loss G: 2.7129\n",
      "Epoch [61/85] Batch 620/938 Loss D: 0.3344, Loss G: 2.7300\n",
      "Epoch [61/85] Batch 630/938 Loss D: 0.2330, Loss G: 2.5780\n",
      "Epoch [61/85] Batch 640/938 Loss D: 0.2819, Loss G: 2.6807\n",
      "Epoch [61/85] Batch 650/938 Loss D: 0.3422, Loss G: 2.3401\n",
      "Epoch [61/85] Batch 660/938 Loss D: 0.2649, Loss G: 2.9100\n",
      "Epoch [61/85] Batch 670/938 Loss D: 0.1619, Loss G: 3.2864\n",
      "Epoch [61/85] Batch 680/938 Loss D: 0.2246, Loss G: 2.5825\n",
      "Epoch [61/85] Batch 690/938 Loss D: 0.3012, Loss G: 2.2888\n",
      "Epoch [61/85] Batch 700/938 Loss D: 0.2961, Loss G: 2.5898\n",
      "Epoch [61/85] Batch 710/938 Loss D: 0.3304, Loss G: 3.4080\n",
      "Epoch [61/85] Batch 720/938 Loss D: 0.2978, Loss G: 2.2452\n",
      "Epoch [61/85] Batch 730/938 Loss D: 0.2037, Loss G: 2.9440\n",
      "Epoch [61/85] Batch 740/938 Loss D: 0.2399, Loss G: 2.9362\n",
      "Epoch [61/85] Batch 750/938 Loss D: 0.1588, Loss G: 3.4388\n",
      "Epoch [61/85] Batch 760/938 Loss D: 0.2008, Loss G: 3.2155\n",
      "Epoch [61/85] Batch 770/938 Loss D: 0.2512, Loss G: 2.6373\n",
      "Epoch [61/85] Batch 780/938 Loss D: 0.3078, Loss G: 1.8676\n",
      "Epoch [61/85] Batch 790/938 Loss D: 0.2723, Loss G: 2.1765\n",
      "Epoch [61/85] Batch 800/938 Loss D: 0.2265, Loss G: 3.0400\n",
      "Epoch [61/85] Batch 810/938 Loss D: 0.2998, Loss G: 2.3552\n",
      "Epoch [61/85] Batch 820/938 Loss D: 0.2467, Loss G: 2.2610\n",
      "Epoch [61/85] Batch 830/938 Loss D: 0.3560, Loss G: 2.0806\n",
      "Epoch [61/85] Batch 840/938 Loss D: 0.2816, Loss G: 2.6985\n",
      "Epoch [61/85] Batch 850/938 Loss D: 0.3274, Loss G: 2.5132\n",
      "Epoch [61/85] Batch 860/938 Loss D: 0.3005, Loss G: 2.6691\n",
      "Epoch [61/85] Batch 870/938 Loss D: 0.2413, Loss G: 2.7470\n",
      "Epoch [61/85] Batch 880/938 Loss D: 0.2853, Loss G: 1.9790\n",
      "Epoch [61/85] Batch 890/938 Loss D: 0.2747, Loss G: 2.4299\n",
      "Epoch [61/85] Batch 900/938 Loss D: 0.3832, Loss G: 2.3125\n",
      "Epoch [61/85] Batch 910/938 Loss D: 0.3059, Loss G: 2.4255\n",
      "Epoch [61/85] Batch 920/938 Loss D: 0.2181, Loss G: 2.5442\n",
      "Epoch [61/85] Batch 930/938 Loss D: 0.3470, Loss G: 2.6336\n",
      "Epoch [62/85] Batch 0/938 Loss D: 0.4461, Loss G: 1.5819\n",
      "Epoch [62/85] Batch 10/938 Loss D: 0.2624, Loss G: 2.0624\n",
      "Epoch [62/85] Batch 20/938 Loss D: 0.2974, Loss G: 2.0227\n",
      "Epoch [62/85] Batch 30/938 Loss D: 0.4111, Loss G: 2.1371\n",
      "Epoch [62/85] Batch 40/938 Loss D: 0.3390, Loss G: 2.0989\n",
      "Epoch [62/85] Batch 50/938 Loss D: 0.3230, Loss G: 2.4841\n",
      "Epoch [62/85] Batch 60/938 Loss D: 0.2664, Loss G: 2.3249\n",
      "Epoch [62/85] Batch 70/938 Loss D: 0.2068, Loss G: 2.9911\n",
      "Epoch [62/85] Batch 80/938 Loss D: 0.3725, Loss G: 1.9108\n",
      "Epoch [62/85] Batch 90/938 Loss D: 0.2286, Loss G: 2.0533\n",
      "Epoch [62/85] Batch 100/938 Loss D: 0.3358, Loss G: 1.6566\n",
      "Epoch [62/85] Batch 110/938 Loss D: 0.2931, Loss G: 2.2480\n",
      "Epoch [62/85] Batch 120/938 Loss D: 0.2746, Loss G: 2.7960\n",
      "Epoch [62/85] Batch 130/938 Loss D: 0.3452, Loss G: 2.2292\n",
      "Epoch [62/85] Batch 140/938 Loss D: 0.3116, Loss G: 2.5466\n",
      "Epoch [62/85] Batch 150/938 Loss D: 0.2771, Loss G: 2.1981\n",
      "Epoch [62/85] Batch 160/938 Loss D: 0.2560, Loss G: 2.5380\n",
      "Epoch [62/85] Batch 170/938 Loss D: 0.2579, Loss G: 2.9203\n",
      "Epoch [62/85] Batch 180/938 Loss D: 0.2829, Loss G: 2.9000\n",
      "Epoch [62/85] Batch 190/938 Loss D: 0.2264, Loss G: 2.8076\n",
      "Epoch [62/85] Batch 200/938 Loss D: 0.2411, Loss G: 2.6328\n",
      "Epoch [62/85] Batch 210/938 Loss D: 0.3455, Loss G: 2.4113\n",
      "Epoch [62/85] Batch 220/938 Loss D: 0.4219, Loss G: 2.2304\n",
      "Epoch [62/85] Batch 230/938 Loss D: 0.3314, Loss G: 2.1854\n",
      "Epoch [62/85] Batch 240/938 Loss D: 0.2629, Loss G: 3.0847\n",
      "Epoch [62/85] Batch 250/938 Loss D: 0.2368, Loss G: 2.7095\n",
      "Epoch [62/85] Batch 260/938 Loss D: 0.2719, Loss G: 2.9507\n",
      "Epoch [62/85] Batch 270/938 Loss D: 0.2687, Loss G: 1.9776\n",
      "Epoch [62/85] Batch 280/938 Loss D: 0.2800, Loss G: 2.3788\n",
      "Epoch [62/85] Batch 290/938 Loss D: 0.3128, Loss G: 2.3589\n",
      "Epoch [62/85] Batch 300/938 Loss D: 0.2652, Loss G: 2.1825\n",
      "Epoch [62/85] Batch 310/938 Loss D: 0.3086, Loss G: 2.4902\n",
      "Epoch [62/85] Batch 320/938 Loss D: 0.3992, Loss G: 2.6898\n",
      "Epoch [62/85] Batch 330/938 Loss D: 0.3299, Loss G: 1.8260\n",
      "Epoch [62/85] Batch 340/938 Loss D: 0.2464, Loss G: 2.4060\n",
      "Epoch [62/85] Batch 350/938 Loss D: 0.2467, Loss G: 2.7745\n",
      "Epoch [62/85] Batch 360/938 Loss D: 0.2712, Loss G: 2.5479\n",
      "Epoch [62/85] Batch 370/938 Loss D: 0.3380, Loss G: 2.5148\n",
      "Epoch [62/85] Batch 380/938 Loss D: 0.3559, Loss G: 2.5513\n",
      "Epoch [62/85] Batch 390/938 Loss D: 0.4840, Loss G: 1.9932\n",
      "Epoch [62/85] Batch 400/938 Loss D: 0.2073, Loss G: 3.4240\n",
      "Epoch [62/85] Batch 410/938 Loss D: 0.3255, Loss G: 2.0866\n",
      "Epoch [62/85] Batch 420/938 Loss D: 0.3046, Loss G: 2.4286\n",
      "Epoch [62/85] Batch 430/938 Loss D: 0.3151, Loss G: 2.2898\n",
      "Epoch [62/85] Batch 440/938 Loss D: 0.3311, Loss G: 2.4674\n",
      "Epoch [62/85] Batch 450/938 Loss D: 0.2476, Loss G: 2.2670\n",
      "Epoch [62/85] Batch 460/938 Loss D: 0.4237, Loss G: 2.1135\n",
      "Epoch [62/85] Batch 470/938 Loss D: 0.5230, Loss G: 2.2656\n",
      "Epoch [62/85] Batch 480/938 Loss D: 0.3530, Loss G: 2.0565\n",
      "Epoch [62/85] Batch 490/938 Loss D: 0.3052, Loss G: 2.3764\n",
      "Epoch [62/85] Batch 500/938 Loss D: 0.2690, Loss G: 2.3783\n",
      "Epoch [62/85] Batch 510/938 Loss D: 0.2727, Loss G: 2.5800\n",
      "Epoch [62/85] Batch 520/938 Loss D: 0.2903, Loss G: 2.1931\n",
      "Epoch [62/85] Batch 530/938 Loss D: 0.2662, Loss G: 2.3608\n",
      "Epoch [62/85] Batch 540/938 Loss D: 0.3330, Loss G: 2.4153\n",
      "Epoch [62/85] Batch 550/938 Loss D: 0.2596, Loss G: 2.6551\n",
      "Epoch [62/85] Batch 560/938 Loss D: 0.3098, Loss G: 2.4892\n",
      "Epoch [62/85] Batch 570/938 Loss D: 0.2633, Loss G: 2.3122\n",
      "Epoch [62/85] Batch 580/938 Loss D: 0.3023, Loss G: 2.3318\n",
      "Epoch [62/85] Batch 590/938 Loss D: 0.3232, Loss G: 2.4413\n",
      "Epoch [62/85] Batch 600/938 Loss D: 0.2382, Loss G: 2.7350\n",
      "Epoch [62/85] Batch 610/938 Loss D: 0.3090, Loss G: 1.8495\n",
      "Epoch [62/85] Batch 620/938 Loss D: 0.3378, Loss G: 1.6734\n",
      "Epoch [62/85] Batch 630/938 Loss D: 0.3195, Loss G: 1.6028\n",
      "Epoch [62/85] Batch 640/938 Loss D: 0.1908, Loss G: 3.1424\n",
      "Epoch [62/85] Batch 650/938 Loss D: 0.2950, Loss G: 2.2446\n",
      "Epoch [62/85] Batch 660/938 Loss D: 0.2744, Loss G: 2.0119\n",
      "Epoch [62/85] Batch 670/938 Loss D: 0.3085, Loss G: 2.2761\n",
      "Epoch [62/85] Batch 680/938 Loss D: 0.1966, Loss G: 3.0588\n",
      "Epoch [62/85] Batch 690/938 Loss D: 0.2970, Loss G: 2.6748\n",
      "Epoch [62/85] Batch 700/938 Loss D: 0.2518, Loss G: 2.3172\n",
      "Epoch [62/85] Batch 710/938 Loss D: 0.3409, Loss G: 2.0585\n",
      "Epoch [62/85] Batch 720/938 Loss D: 0.4842, Loss G: 1.8277\n",
      "Epoch [62/85] Batch 730/938 Loss D: 0.3020, Loss G: 2.2008\n",
      "Epoch [62/85] Batch 740/938 Loss D: 0.3126, Loss G: 2.5973\n",
      "Epoch [62/85] Batch 750/938 Loss D: 0.3146, Loss G: 1.8815\n",
      "Epoch [62/85] Batch 760/938 Loss D: 0.3707, Loss G: 1.7429\n",
      "Epoch [62/85] Batch 770/938 Loss D: 0.3420, Loss G: 2.6684\n",
      "Epoch [62/85] Batch 780/938 Loss D: 0.3571, Loss G: 3.0511\n",
      "Epoch [62/85] Batch 790/938 Loss D: 0.2788, Loss G: 2.3491\n",
      "Epoch [62/85] Batch 800/938 Loss D: 0.2937, Loss G: 2.8985\n",
      "Epoch [62/85] Batch 810/938 Loss D: 0.2446, Loss G: 2.5367\n",
      "Epoch [62/85] Batch 820/938 Loss D: 0.3602, Loss G: 1.6245\n",
      "Epoch [62/85] Batch 830/938 Loss D: 0.2842, Loss G: 2.7446\n",
      "Epoch [62/85] Batch 840/938 Loss D: 0.1840, Loss G: 3.6005\n",
      "Epoch [62/85] Batch 850/938 Loss D: 0.3903, Loss G: 2.3987\n",
      "Epoch [62/85] Batch 860/938 Loss D: 0.2565, Loss G: 2.4191\n",
      "Epoch [62/85] Batch 870/938 Loss D: 0.2513, Loss G: 2.4242\n",
      "Epoch [62/85] Batch 880/938 Loss D: 0.3768, Loss G: 2.0427\n",
      "Epoch [62/85] Batch 890/938 Loss D: 0.2736, Loss G: 2.5784\n",
      "Epoch [62/85] Batch 900/938 Loss D: 0.1733, Loss G: 3.1811\n",
      "Epoch [62/85] Batch 910/938 Loss D: 0.4476, Loss G: 1.9330\n",
      "Epoch [62/85] Batch 920/938 Loss D: 0.3204, Loss G: 2.0179\n",
      "Epoch [62/85] Batch 930/938 Loss D: 0.2499, Loss G: 1.7283\n",
      "Epoch [63/85] Batch 0/938 Loss D: 0.2987, Loss G: 2.3043\n",
      "Epoch [63/85] Batch 10/938 Loss D: 0.1996, Loss G: 2.8893\n",
      "Epoch [63/85] Batch 20/938 Loss D: 0.3885, Loss G: 2.5972\n",
      "Epoch [63/85] Batch 30/938 Loss D: 0.2042, Loss G: 3.0101\n",
      "Epoch [63/85] Batch 40/938 Loss D: 0.3094, Loss G: 2.3490\n",
      "Epoch [63/85] Batch 50/938 Loss D: 0.2727, Loss G: 1.7039\n",
      "Epoch [63/85] Batch 60/938 Loss D: 0.3099, Loss G: 2.5439\n",
      "Epoch [63/85] Batch 70/938 Loss D: 0.2107, Loss G: 3.0521\n",
      "Epoch [63/85] Batch 80/938 Loss D: 0.2688, Loss G: 2.2890\n",
      "Epoch [63/85] Batch 90/938 Loss D: 0.2320, Loss G: 2.9539\n",
      "Epoch [63/85] Batch 100/938 Loss D: 0.2340, Loss G: 3.0744\n",
      "Epoch [63/85] Batch 110/938 Loss D: 0.3753, Loss G: 2.0123\n",
      "Epoch [63/85] Batch 120/938 Loss D: 0.3294, Loss G: 2.8240\n",
      "Epoch [63/85] Batch 130/938 Loss D: 0.3361, Loss G: 2.2538\n",
      "Epoch [63/85] Batch 140/938 Loss D: 0.3324, Loss G: 2.6723\n",
      "Epoch [63/85] Batch 150/938 Loss D: 0.2902, Loss G: 2.1862\n",
      "Epoch [63/85] Batch 160/938 Loss D: 0.3196, Loss G: 2.5280\n",
      "Epoch [63/85] Batch 170/938 Loss D: 0.3339, Loss G: 2.0267\n",
      "Epoch [63/85] Batch 180/938 Loss D: 0.2540, Loss G: 2.0918\n",
      "Epoch [63/85] Batch 190/938 Loss D: 0.3173, Loss G: 1.8972\n",
      "Epoch [63/85] Batch 200/938 Loss D: 0.2704, Loss G: 2.1990\n",
      "Epoch [63/85] Batch 210/938 Loss D: 0.2145, Loss G: 2.5510\n",
      "Epoch [63/85] Batch 220/938 Loss D: 0.3440, Loss G: 4.4487\n",
      "Epoch [63/85] Batch 230/938 Loss D: 0.2707, Loss G: 3.7907\n",
      "Epoch [63/85] Batch 240/938 Loss D: 0.3229, Loss G: 2.5612\n",
      "Epoch [63/85] Batch 250/938 Loss D: 0.2561, Loss G: 2.5543\n",
      "Epoch [63/85] Batch 260/938 Loss D: 0.2088, Loss G: 2.7918\n",
      "Epoch [63/85] Batch 270/938 Loss D: 0.3812, Loss G: 2.1594\n",
      "Epoch [63/85] Batch 280/938 Loss D: 0.2079, Loss G: 2.7068\n",
      "Epoch [63/85] Batch 290/938 Loss D: 0.2408, Loss G: 2.8017\n",
      "Epoch [63/85] Batch 300/938 Loss D: 0.3667, Loss G: 2.6341\n",
      "Epoch [63/85] Batch 310/938 Loss D: 0.2894, Loss G: 2.4535\n",
      "Epoch [63/85] Batch 320/938 Loss D: 0.3327, Loss G: 1.9821\n",
      "Epoch [63/85] Batch 330/938 Loss D: 0.3789, Loss G: 1.9309\n",
      "Epoch [63/85] Batch 340/938 Loss D: 0.3108, Loss G: 2.6196\n",
      "Epoch [63/85] Batch 350/938 Loss D: 0.2689, Loss G: 2.4158\n",
      "Epoch [63/85] Batch 360/938 Loss D: 0.3223, Loss G: 2.0455\n",
      "Epoch [63/85] Batch 370/938 Loss D: 0.3091, Loss G: 1.6660\n",
      "Epoch [63/85] Batch 380/938 Loss D: 0.3789, Loss G: 1.4431\n",
      "Epoch [63/85] Batch 390/938 Loss D: 0.2341, Loss G: 2.5713\n",
      "Epoch [63/85] Batch 400/938 Loss D: 0.2219, Loss G: 2.7242\n",
      "Epoch [63/85] Batch 410/938 Loss D: 0.3127, Loss G: 2.5030\n",
      "Epoch [63/85] Batch 420/938 Loss D: 0.3177, Loss G: 2.1314\n",
      "Epoch [63/85] Batch 430/938 Loss D: 0.3086, Loss G: 2.2935\n",
      "Epoch [63/85] Batch 440/938 Loss D: 0.2172, Loss G: 2.8792\n",
      "Epoch [63/85] Batch 450/938 Loss D: 0.2553, Loss G: 2.1048\n",
      "Epoch [63/85] Batch 460/938 Loss D: 0.4183, Loss G: 1.9850\n",
      "Epoch [63/85] Batch 470/938 Loss D: 0.3396, Loss G: 2.7055\n",
      "Epoch [63/85] Batch 480/938 Loss D: 0.3390, Loss G: 2.6571\n",
      "Epoch [63/85] Batch 490/938 Loss D: 0.4983, Loss G: 1.7489\n",
      "Epoch [63/85] Batch 500/938 Loss D: 0.3222, Loss G: 2.6603\n",
      "Epoch [63/85] Batch 510/938 Loss D: 0.2966, Loss G: 2.7463\n",
      "Epoch [63/85] Batch 520/938 Loss D: 0.3849, Loss G: 2.1063\n",
      "Epoch [63/85] Batch 530/938 Loss D: 0.3683, Loss G: 2.0157\n",
      "Epoch [63/85] Batch 540/938 Loss D: 0.4342, Loss G: 2.1102\n",
      "Epoch [63/85] Batch 550/938 Loss D: 0.2941, Loss G: 2.9115\n",
      "Epoch [63/85] Batch 560/938 Loss D: 0.3170, Loss G: 2.7930\n",
      "Epoch [63/85] Batch 570/938 Loss D: 0.3547, Loss G: 1.8236\n",
      "Epoch [63/85] Batch 580/938 Loss D: 0.1739, Loss G: 3.0614\n",
      "Epoch [63/85] Batch 590/938 Loss D: 0.2315, Loss G: 2.5326\n",
      "Epoch [63/85] Batch 600/938 Loss D: 0.2613, Loss G: 2.5910\n",
      "Epoch [63/85] Batch 610/938 Loss D: 0.2359, Loss G: 2.2899\n",
      "Epoch [63/85] Batch 620/938 Loss D: 0.2669, Loss G: 1.8724\n",
      "Epoch [63/85] Batch 630/938 Loss D: 0.2431, Loss G: 1.9811\n",
      "Epoch [63/85] Batch 640/938 Loss D: 0.2729, Loss G: 1.9484\n",
      "Epoch [63/85] Batch 650/938 Loss D: 0.2782, Loss G: 2.5498\n",
      "Epoch [63/85] Batch 660/938 Loss D: 0.3567, Loss G: 3.0207\n",
      "Epoch [63/85] Batch 670/938 Loss D: 0.2744, Loss G: 2.9325\n",
      "Epoch [63/85] Batch 680/938 Loss D: 0.2766, Loss G: 2.4217\n",
      "Epoch [63/85] Batch 690/938 Loss D: 0.4436, Loss G: 1.7810\n",
      "Epoch [63/85] Batch 700/938 Loss D: 0.4482, Loss G: 1.2432\n",
      "Epoch [63/85] Batch 710/938 Loss D: 0.3232, Loss G: 1.9230\n",
      "Epoch [63/85] Batch 720/938 Loss D: 0.3655, Loss G: 2.1352\n",
      "Epoch [63/85] Batch 730/938 Loss D: 0.3526, Loss G: 1.9807\n",
      "Epoch [63/85] Batch 740/938 Loss D: 0.2714, Loss G: 1.9745\n",
      "Epoch [63/85] Batch 750/938 Loss D: 0.2425, Loss G: 2.0139\n",
      "Epoch [63/85] Batch 760/938 Loss D: 0.3888, Loss G: 2.0826\n",
      "Epoch [63/85] Batch 770/938 Loss D: 0.2271, Loss G: 2.3536\n",
      "Epoch [63/85] Batch 780/938 Loss D: 0.2673, Loss G: 2.3173\n",
      "Epoch [63/85] Batch 790/938 Loss D: 0.2132, Loss G: 2.7688\n",
      "Epoch [63/85] Batch 800/938 Loss D: 0.4590, Loss G: 2.4087\n",
      "Epoch [63/85] Batch 810/938 Loss D: 0.3070, Loss G: 2.6301\n",
      "Epoch [63/85] Batch 820/938 Loss D: 0.4222, Loss G: 1.7276\n",
      "Epoch [63/85] Batch 830/938 Loss D: 0.3035, Loss G: 1.9240\n",
      "Epoch [63/85] Batch 840/938 Loss D: 0.3670, Loss G: 2.0726\n",
      "Epoch [63/85] Batch 850/938 Loss D: 0.3536, Loss G: 3.2279\n",
      "Epoch [63/85] Batch 860/938 Loss D: 0.3317, Loss G: 2.4013\n",
      "Epoch [63/85] Batch 870/938 Loss D: 0.3194, Loss G: 1.6337\n",
      "Epoch [63/85] Batch 880/938 Loss D: 0.3501, Loss G: 2.2845\n",
      "Epoch [63/85] Batch 890/938 Loss D: 0.2914, Loss G: 2.7391\n",
      "Epoch [63/85] Batch 900/938 Loss D: 0.2478, Loss G: 2.3288\n",
      "Epoch [63/85] Batch 910/938 Loss D: 0.2581, Loss G: 2.4408\n",
      "Epoch [63/85] Batch 920/938 Loss D: 0.2368, Loss G: 2.2901\n",
      "Epoch [63/85] Batch 930/938 Loss D: 0.3074, Loss G: 2.1274\n",
      "Epoch [64/85] Batch 0/938 Loss D: 0.3976, Loss G: 2.1174\n",
      "Epoch [64/85] Batch 10/938 Loss D: 0.2568, Loss G: 2.6198\n",
      "Epoch [64/85] Batch 20/938 Loss D: 0.3428, Loss G: 2.4047\n",
      "Epoch [64/85] Batch 30/938 Loss D: 0.2453, Loss G: 2.5564\n",
      "Epoch [64/85] Batch 40/938 Loss D: 0.2853, Loss G: 2.5281\n",
      "Epoch [64/85] Batch 50/938 Loss D: 0.1848, Loss G: 2.7061\n",
      "Epoch [64/85] Batch 60/938 Loss D: 0.1352, Loss G: 3.6700\n",
      "Epoch [64/85] Batch 70/938 Loss D: 0.1728, Loss G: 3.3366\n",
      "Epoch [64/85] Batch 80/938 Loss D: 0.3055, Loss G: 3.4538\n",
      "Epoch [64/85] Batch 90/938 Loss D: 0.2782, Loss G: 4.3600\n",
      "Epoch [64/85] Batch 100/938 Loss D: 0.1821, Loss G: 3.2830\n",
      "Epoch [64/85] Batch 110/938 Loss D: 0.2598, Loss G: 2.4266\n",
      "Epoch [64/85] Batch 120/938 Loss D: 0.4020, Loss G: 1.9639\n",
      "Epoch [64/85] Batch 130/938 Loss D: 0.2983, Loss G: 2.7467\n",
      "Epoch [64/85] Batch 140/938 Loss D: 0.2357, Loss G: 2.1141\n",
      "Epoch [64/85] Batch 150/938 Loss D: 0.2741, Loss G: 2.2362\n",
      "Epoch [64/85] Batch 160/938 Loss D: 0.3230, Loss G: 1.9970\n",
      "Epoch [64/85] Batch 170/938 Loss D: 0.2752, Loss G: 2.3171\n",
      "Epoch [64/85] Batch 180/938 Loss D: 0.2877, Loss G: 2.7445\n",
      "Epoch [64/85] Batch 190/938 Loss D: 0.1893, Loss G: 3.0214\n",
      "Epoch [64/85] Batch 200/938 Loss D: 0.2730, Loss G: 2.6966\n",
      "Epoch [64/85] Batch 210/938 Loss D: 0.2512, Loss G: 2.4338\n",
      "Epoch [64/85] Batch 220/938 Loss D: 0.3498, Loss G: 2.2568\n",
      "Epoch [64/85] Batch 230/938 Loss D: 0.2709, Loss G: 2.5696\n",
      "Epoch [64/85] Batch 240/938 Loss D: 0.2376, Loss G: 2.5130\n",
      "Epoch [64/85] Batch 250/938 Loss D: 0.4549, Loss G: 2.3227\n",
      "Epoch [64/85] Batch 260/938 Loss D: 0.4747, Loss G: 2.9551\n",
      "Epoch [64/85] Batch 270/938 Loss D: 0.3077, Loss G: 2.9409\n",
      "Epoch [64/85] Batch 280/938 Loss D: 0.3826, Loss G: 2.4070\n",
      "Epoch [64/85] Batch 290/938 Loss D: 0.2565, Loss G: 2.6109\n",
      "Epoch [64/85] Batch 300/938 Loss D: 0.3803, Loss G: 2.4354\n",
      "Epoch [64/85] Batch 310/938 Loss D: 0.4047, Loss G: 1.9121\n",
      "Epoch [64/85] Batch 320/938 Loss D: 0.3631, Loss G: 1.7264\n",
      "Epoch [64/85] Batch 330/938 Loss D: 0.3054, Loss G: 2.2429\n",
      "Epoch [64/85] Batch 340/938 Loss D: 0.3712, Loss G: 2.6549\n",
      "Epoch [64/85] Batch 350/938 Loss D: 0.3826, Loss G: 1.9508\n",
      "Epoch [64/85] Batch 360/938 Loss D: 0.3715, Loss G: 2.7782\n",
      "Epoch [64/85] Batch 370/938 Loss D: 0.3106, Loss G: 2.5403\n",
      "Epoch [64/85] Batch 380/938 Loss D: 0.2422, Loss G: 3.1160\n",
      "Epoch [64/85] Batch 390/938 Loss D: 0.2155, Loss G: 2.4167\n",
      "Epoch [64/85] Batch 400/938 Loss D: 0.2964, Loss G: 2.3011\n",
      "Epoch [64/85] Batch 410/938 Loss D: 0.4443, Loss G: 1.7823\n",
      "Epoch [64/85] Batch 420/938 Loss D: 0.2306, Loss G: 2.6651\n",
      "Epoch [64/85] Batch 430/938 Loss D: 0.2985, Loss G: 2.0880\n",
      "Epoch [64/85] Batch 440/938 Loss D: 0.3298, Loss G: 2.0336\n",
      "Epoch [64/85] Batch 450/938 Loss D: 0.2632, Loss G: 2.6904\n",
      "Epoch [64/85] Batch 460/938 Loss D: 0.2044, Loss G: 3.0400\n",
      "Epoch [64/85] Batch 470/938 Loss D: 0.3774, Loss G: 2.0641\n",
      "Epoch [64/85] Batch 480/938 Loss D: 0.3299, Loss G: 2.7290\n",
      "Epoch [64/85] Batch 490/938 Loss D: 0.3825, Loss G: 2.4783\n",
      "Epoch [64/85] Batch 500/938 Loss D: 0.2504, Loss G: 2.6796\n",
      "Epoch [64/85] Batch 510/938 Loss D: 0.1965, Loss G: 2.4279\n",
      "Epoch [64/85] Batch 520/938 Loss D: 0.1411, Loss G: 3.1307\n",
      "Epoch [64/85] Batch 530/938 Loss D: 0.2832, Loss G: 3.6684\n",
      "Epoch [64/85] Batch 540/938 Loss D: 0.2377, Loss G: 3.1058\n",
      "Epoch [64/85] Batch 550/938 Loss D: 0.2689, Loss G: 2.6968\n",
      "Epoch [64/85] Batch 560/938 Loss D: 0.2333, Loss G: 2.4382\n",
      "Epoch [64/85] Batch 570/938 Loss D: 0.1709, Loss G: 2.8668\n",
      "Epoch [64/85] Batch 580/938 Loss D: 0.1471, Loss G: 2.9652\n",
      "Epoch [64/85] Batch 590/938 Loss D: 0.2978, Loss G: 2.1555\n",
      "Epoch [64/85] Batch 600/938 Loss D: 0.3893, Loss G: 1.7141\n",
      "Epoch [64/85] Batch 610/938 Loss D: 0.3082, Loss G: 2.2613\n",
      "Epoch [64/85] Batch 620/938 Loss D: 0.2360, Loss G: 2.5045\n",
      "Epoch [64/85] Batch 630/938 Loss D: 0.4134, Loss G: 2.5453\n",
      "Epoch [64/85] Batch 640/938 Loss D: 0.3508, Loss G: 2.2932\n",
      "Epoch [64/85] Batch 650/938 Loss D: 0.3281, Loss G: 2.4880\n",
      "Epoch [64/85] Batch 660/938 Loss D: 0.3817, Loss G: 2.0767\n",
      "Epoch [64/85] Batch 670/938 Loss D: 0.2302, Loss G: 3.3565\n",
      "Epoch [64/85] Batch 680/938 Loss D: 0.2389, Loss G: 2.5702\n",
      "Epoch [64/85] Batch 690/938 Loss D: 0.3925, Loss G: 1.3836\n",
      "Epoch [64/85] Batch 700/938 Loss D: 0.2601, Loss G: 2.4972\n",
      "Epoch [64/85] Batch 710/938 Loss D: 0.1811, Loss G: 2.8885\n",
      "Epoch [64/85] Batch 720/938 Loss D: 0.2718, Loss G: 2.5793\n",
      "Epoch [64/85] Batch 730/938 Loss D: 0.3639, Loss G: 2.6098\n",
      "Epoch [64/85] Batch 740/938 Loss D: 0.2837, Loss G: 2.4009\n",
      "Epoch [64/85] Batch 750/938 Loss D: 0.1866, Loss G: 2.7132\n",
      "Epoch [64/85] Batch 760/938 Loss D: 0.2548, Loss G: 2.2584\n",
      "Epoch [64/85] Batch 770/938 Loss D: 0.2065, Loss G: 2.5961\n",
      "Epoch [64/85] Batch 780/938 Loss D: 0.3048, Loss G: 2.3247\n",
      "Epoch [64/85] Batch 790/938 Loss D: 0.3481, Loss G: 2.0822\n",
      "Epoch [64/85] Batch 800/938 Loss D: 0.2942, Loss G: 2.9067\n",
      "Epoch [64/85] Batch 810/938 Loss D: 0.1950, Loss G: 3.3129\n",
      "Epoch [64/85] Batch 820/938 Loss D: 0.2982, Loss G: 2.0558\n",
      "Epoch [64/85] Batch 830/938 Loss D: 0.3551, Loss G: 2.4820\n",
      "Epoch [64/85] Batch 840/938 Loss D: 0.2323, Loss G: 3.0771\n",
      "Epoch [64/85] Batch 850/938 Loss D: 0.4220, Loss G: 3.2548\n",
      "Epoch [64/85] Batch 860/938 Loss D: 0.2903, Loss G: 2.2637\n",
      "Epoch [64/85] Batch 870/938 Loss D: 0.3726, Loss G: 1.9318\n",
      "Epoch [64/85] Batch 880/938 Loss D: 0.4256, Loss G: 1.5907\n",
      "Epoch [64/85] Batch 890/938 Loss D: 0.3713, Loss G: 1.9761\n",
      "Epoch [64/85] Batch 900/938 Loss D: 0.1932, Loss G: 2.9136\n",
      "Epoch [64/85] Batch 910/938 Loss D: 0.1858, Loss G: 2.5880\n",
      "Epoch [64/85] Batch 920/938 Loss D: 0.2782, Loss G: 2.4869\n",
      "Epoch [64/85] Batch 930/938 Loss D: 0.2658, Loss G: 2.5759\n",
      "Epoch [65/85] Batch 0/938 Loss D: 0.2112, Loss G: 2.8783\n",
      "Epoch [65/85] Batch 10/938 Loss D: 0.2077, Loss G: 3.3707\n",
      "Epoch [65/85] Batch 20/938 Loss D: 0.2264, Loss G: 3.1106\n",
      "Epoch [65/85] Batch 30/938 Loss D: 0.3158, Loss G: 1.9670\n",
      "Epoch [65/85] Batch 40/938 Loss D: 0.3125, Loss G: 1.9659\n",
      "Epoch [65/85] Batch 50/938 Loss D: 0.2480, Loss G: 2.3096\n",
      "Epoch [65/85] Batch 60/938 Loss D: 0.2205, Loss G: 3.4243\n",
      "Epoch [65/85] Batch 70/938 Loss D: 0.2690, Loss G: 2.4421\n",
      "Epoch [65/85] Batch 80/938 Loss D: 0.2653, Loss G: 2.8427\n",
      "Epoch [65/85] Batch 90/938 Loss D: 0.1581, Loss G: 2.4405\n",
      "Epoch [65/85] Batch 100/938 Loss D: 0.2271, Loss G: 2.4465\n",
      "Epoch [65/85] Batch 110/938 Loss D: 0.2436, Loss G: 2.2865\n",
      "Epoch [65/85] Batch 120/938 Loss D: 0.2738, Loss G: 2.3676\n",
      "Epoch [65/85] Batch 130/938 Loss D: 0.2346, Loss G: 2.9607\n",
      "Epoch [65/85] Batch 140/938 Loss D: 0.2860, Loss G: 2.0983\n",
      "Epoch [65/85] Batch 150/938 Loss D: 0.2890, Loss G: 2.0761\n",
      "Epoch [65/85] Batch 160/938 Loss D: 0.2734, Loss G: 2.3436\n",
      "Epoch [65/85] Batch 170/938 Loss D: 0.4078, Loss G: 1.9268\n",
      "Epoch [65/85] Batch 180/938 Loss D: 0.3098, Loss G: 2.0647\n",
      "Epoch [65/85] Batch 190/938 Loss D: 0.3529, Loss G: 2.0448\n",
      "Epoch [65/85] Batch 200/938 Loss D: 0.2190, Loss G: 2.7603\n",
      "Epoch [65/85] Batch 210/938 Loss D: 0.2690, Loss G: 2.7790\n",
      "Epoch [65/85] Batch 220/938 Loss D: 0.2330, Loss G: 3.1656\n",
      "Epoch [65/85] Batch 230/938 Loss D: 0.3378, Loss G: 2.3399\n",
      "Epoch [65/85] Batch 240/938 Loss D: 0.2704, Loss G: 2.1500\n",
      "Epoch [65/85] Batch 250/938 Loss D: 0.2750, Loss G: 2.7634\n",
      "Epoch [65/85] Batch 260/938 Loss D: 0.2859, Loss G: 2.7051\n",
      "Epoch [65/85] Batch 270/938 Loss D: 0.3298, Loss G: 2.6958\n",
      "Epoch [65/85] Batch 280/938 Loss D: 0.3155, Loss G: 1.9678\n",
      "Epoch [65/85] Batch 290/938 Loss D: 0.2722, Loss G: 2.5713\n",
      "Epoch [65/85] Batch 300/938 Loss D: 0.3198, Loss G: 2.1987\n",
      "Epoch [65/85] Batch 310/938 Loss D: 0.3305, Loss G: 2.3956\n",
      "Epoch [65/85] Batch 320/938 Loss D: 0.2188, Loss G: 2.4992\n",
      "Epoch [65/85] Batch 330/938 Loss D: 0.4383, Loss G: 1.9705\n",
      "Epoch [65/85] Batch 340/938 Loss D: 0.3097, Loss G: 2.3591\n",
      "Epoch [65/85] Batch 350/938 Loss D: 0.1802, Loss G: 3.0682\n",
      "Epoch [65/85] Batch 360/938 Loss D: 0.2863, Loss G: 2.5627\n",
      "Epoch [65/85] Batch 370/938 Loss D: 0.2694, Loss G: 2.6888\n",
      "Epoch [65/85] Batch 380/938 Loss D: 0.3429, Loss G: 1.7861\n",
      "Epoch [65/85] Batch 390/938 Loss D: 0.2559, Loss G: 2.3103\n",
      "Epoch [65/85] Batch 400/938 Loss D: 0.2451, Loss G: 3.4453\n",
      "Epoch [65/85] Batch 410/938 Loss D: 0.4771, Loss G: 2.8875\n",
      "Epoch [65/85] Batch 420/938 Loss D: 0.3673, Loss G: 3.2873\n",
      "Epoch [65/85] Batch 430/938 Loss D: 0.1963, Loss G: 3.2461\n",
      "Epoch [65/85] Batch 440/938 Loss D: 0.2565, Loss G: 2.9901\n",
      "Epoch [65/85] Batch 450/938 Loss D: 0.4650, Loss G: 1.8366\n",
      "Epoch [65/85] Batch 460/938 Loss D: 0.3167, Loss G: 1.8499\n",
      "Epoch [65/85] Batch 470/938 Loss D: 0.3132, Loss G: 2.0185\n",
      "Epoch [65/85] Batch 480/938 Loss D: 0.2758, Loss G: 2.9298\n",
      "Epoch [65/85] Batch 490/938 Loss D: 0.3095, Loss G: 2.1206\n",
      "Epoch [65/85] Batch 500/938 Loss D: 0.3621, Loss G: 2.4066\n",
      "Epoch [65/85] Batch 510/938 Loss D: 0.3354, Loss G: 1.8859\n",
      "Epoch [65/85] Batch 520/938 Loss D: 0.3424, Loss G: 2.2312\n",
      "Epoch [65/85] Batch 530/938 Loss D: 0.2564, Loss G: 2.3036\n",
      "Epoch [65/85] Batch 540/938 Loss D: 0.2431, Loss G: 2.7857\n",
      "Epoch [65/85] Batch 550/938 Loss D: 0.3137, Loss G: 2.9356\n",
      "Epoch [65/85] Batch 560/938 Loss D: 0.2959, Loss G: 2.5657\n",
      "Epoch [65/85] Batch 570/938 Loss D: 0.3836, Loss G: 2.3037\n",
      "Epoch [65/85] Batch 580/938 Loss D: 0.3299, Loss G: 2.2761\n",
      "Epoch [65/85] Batch 590/938 Loss D: 0.3817, Loss G: 2.3132\n",
      "Epoch [65/85] Batch 600/938 Loss D: 0.2125, Loss G: 3.0715\n",
      "Epoch [65/85] Batch 610/938 Loss D: 0.2447, Loss G: 3.4284\n",
      "Epoch [65/85] Batch 620/938 Loss D: 0.1966, Loss G: 2.9691\n",
      "Epoch [65/85] Batch 630/938 Loss D: 0.3170, Loss G: 2.0605\n",
      "Epoch [65/85] Batch 640/938 Loss D: 0.2117, Loss G: 2.2242\n",
      "Epoch [65/85] Batch 650/938 Loss D: 0.3560, Loss G: 2.7350\n",
      "Epoch [65/85] Batch 660/938 Loss D: 0.3454, Loss G: 2.1702\n",
      "Epoch [65/85] Batch 670/938 Loss D: 0.3176, Loss G: 1.8732\n",
      "Epoch [65/85] Batch 680/938 Loss D: 0.2717, Loss G: 2.5642\n",
      "Epoch [65/85] Batch 690/938 Loss D: 0.3035, Loss G: 2.3464\n",
      "Epoch [65/85] Batch 700/938 Loss D: 0.3884, Loss G: 2.5301\n",
      "Epoch [65/85] Batch 710/938 Loss D: 0.3945, Loss G: 2.2850\n",
      "Epoch [65/85] Batch 720/938 Loss D: 0.2909, Loss G: 2.3380\n",
      "Epoch [65/85] Batch 730/938 Loss D: 0.3202, Loss G: 2.9837\n",
      "Epoch [65/85] Batch 740/938 Loss D: 0.2687, Loss G: 2.3052\n",
      "Epoch [65/85] Batch 750/938 Loss D: 0.2903, Loss G: 1.7784\n",
      "Epoch [65/85] Batch 760/938 Loss D: 0.3667, Loss G: 2.5970\n",
      "Epoch [65/85] Batch 770/938 Loss D: 0.3400, Loss G: 2.7725\n",
      "Epoch [65/85] Batch 780/938 Loss D: 0.4442, Loss G: 2.7257\n",
      "Epoch [65/85] Batch 790/938 Loss D: 0.3574, Loss G: 2.9528\n",
      "Epoch [65/85] Batch 800/938 Loss D: 0.3306, Loss G: 2.1217\n",
      "Epoch [65/85] Batch 810/938 Loss D: 0.2620, Loss G: 2.7860\n",
      "Epoch [65/85] Batch 820/938 Loss D: 0.2965, Loss G: 2.6633\n",
      "Epoch [65/85] Batch 830/938 Loss D: 0.4389, Loss G: 1.7092\n",
      "Epoch [65/85] Batch 840/938 Loss D: 0.2474, Loss G: 2.2186\n",
      "Epoch [65/85] Batch 850/938 Loss D: 0.3084, Loss G: 2.0721\n",
      "Epoch [65/85] Batch 860/938 Loss D: 0.4229, Loss G: 2.2564\n",
      "Epoch [65/85] Batch 870/938 Loss D: 0.3503, Loss G: 1.7434\n",
      "Epoch [65/85] Batch 880/938 Loss D: 0.4207, Loss G: 1.6393\n",
      "Epoch [65/85] Batch 890/938 Loss D: 0.3523, Loss G: 1.9378\n",
      "Epoch [65/85] Batch 900/938 Loss D: 0.2687, Loss G: 2.7458\n",
      "Epoch [65/85] Batch 910/938 Loss D: 0.3146, Loss G: 2.1754\n",
      "Epoch [65/85] Batch 920/938 Loss D: 0.3226, Loss G: 2.4818\n",
      "Epoch [65/85] Batch 930/938 Loss D: 0.2692, Loss G: 2.2042\n",
      "Epoch [66/85] Batch 0/938 Loss D: 0.2748, Loss G: 2.3555\n",
      "Epoch [66/85] Batch 10/938 Loss D: 0.3499, Loss G: 2.1418\n",
      "Epoch [66/85] Batch 20/938 Loss D: 0.1355, Loss G: 4.3149\n",
      "Epoch [66/85] Batch 30/938 Loss D: 0.2439, Loss G: 2.7715\n",
      "Epoch [66/85] Batch 40/938 Loss D: 0.2568, Loss G: 2.2242\n",
      "Epoch [66/85] Batch 50/938 Loss D: 0.3447, Loss G: 1.9371\n",
      "Epoch [66/85] Batch 60/938 Loss D: 0.2370, Loss G: 2.4269\n",
      "Epoch [66/85] Batch 70/938 Loss D: 0.3714, Loss G: 2.0810\n",
      "Epoch [66/85] Batch 80/938 Loss D: 0.2328, Loss G: 2.9285\n",
      "Epoch [66/85] Batch 90/938 Loss D: 0.2457, Loss G: 3.0293\n",
      "Epoch [66/85] Batch 100/938 Loss D: 0.2710, Loss G: 2.5221\n",
      "Epoch [66/85] Batch 110/938 Loss D: 0.3622, Loss G: 2.4889\n",
      "Epoch [66/85] Batch 120/938 Loss D: 0.2555, Loss G: 2.6133\n",
      "Epoch [66/85] Batch 130/938 Loss D: 0.4975, Loss G: 2.3698\n",
      "Epoch [66/85] Batch 140/938 Loss D: 0.3124, Loss G: 2.2160\n",
      "Epoch [66/85] Batch 150/938 Loss D: 0.3265, Loss G: 2.4390\n",
      "Epoch [66/85] Batch 160/938 Loss D: 0.2573, Loss G: 2.5526\n",
      "Epoch [66/85] Batch 170/938 Loss D: 0.2721, Loss G: 2.3902\n",
      "Epoch [66/85] Batch 180/938 Loss D: 0.3240, Loss G: 2.2930\n",
      "Epoch [66/85] Batch 190/938 Loss D: 0.2617, Loss G: 1.8935\n",
      "Epoch [66/85] Batch 200/938 Loss D: 0.5373, Loss G: 1.9611\n",
      "Epoch [66/85] Batch 210/938 Loss D: 0.1422, Loss G: 2.5437\n",
      "Epoch [66/85] Batch 220/938 Loss D: 0.2587, Loss G: 2.7826\n",
      "Epoch [66/85] Batch 230/938 Loss D: 0.2472, Loss G: 2.9068\n",
      "Epoch [66/85] Batch 240/938 Loss D: 0.5234, Loss G: 1.9662\n",
      "Epoch [66/85] Batch 250/938 Loss D: 0.2881, Loss G: 2.1840\n",
      "Epoch [66/85] Batch 260/938 Loss D: 0.3425, Loss G: 2.3256\n",
      "Epoch [66/85] Batch 270/938 Loss D: 0.2694, Loss G: 2.7026\n",
      "Epoch [66/85] Batch 280/938 Loss D: 0.2931, Loss G: 2.2555\n",
      "Epoch [66/85] Batch 290/938 Loss D: 0.1924, Loss G: 2.6001\n",
      "Epoch [66/85] Batch 300/938 Loss D: 0.3286, Loss G: 2.3612\n",
      "Epoch [66/85] Batch 310/938 Loss D: 0.3767, Loss G: 3.0607\n",
      "Epoch [66/85] Batch 320/938 Loss D: 0.2043, Loss G: 2.4616\n",
      "Epoch [66/85] Batch 330/938 Loss D: 0.2244, Loss G: 2.7379\n",
      "Epoch [66/85] Batch 340/938 Loss D: 0.1328, Loss G: 3.2380\n",
      "Epoch [66/85] Batch 350/938 Loss D: 0.1961, Loss G: 3.4481\n",
      "Epoch [66/85] Batch 360/938 Loss D: 0.3264, Loss G: 2.8610\n",
      "Epoch [66/85] Batch 370/938 Loss D: 0.3117, Loss G: 2.5726\n",
      "Epoch [66/85] Batch 380/938 Loss D: 0.4048, Loss G: 2.3746\n",
      "Epoch [66/85] Batch 390/938 Loss D: 0.2801, Loss G: 2.1884\n",
      "Epoch [66/85] Batch 400/938 Loss D: 0.2198, Loss G: 2.8037\n",
      "Epoch [66/85] Batch 410/938 Loss D: 0.4419, Loss G: 1.5624\n",
      "Epoch [66/85] Batch 420/938 Loss D: 0.2774, Loss G: 2.3852\n",
      "Epoch [66/85] Batch 430/938 Loss D: 0.4349, Loss G: 1.8062\n",
      "Epoch [66/85] Batch 440/938 Loss D: 0.4754, Loss G: 1.5368\n",
      "Epoch [66/85] Batch 450/938 Loss D: 0.2336, Loss G: 2.6225\n",
      "Epoch [66/85] Batch 460/938 Loss D: 0.2891, Loss G: 2.1714\n",
      "Epoch [66/85] Batch 470/938 Loss D: 0.2907, Loss G: 2.5938\n",
      "Epoch [66/85] Batch 480/938 Loss D: 0.2890, Loss G: 2.6350\n",
      "Epoch [66/85] Batch 490/938 Loss D: 0.2969, Loss G: 2.7513\n",
      "Epoch [66/85] Batch 500/938 Loss D: 0.3073, Loss G: 2.2391\n",
      "Epoch [66/85] Batch 510/938 Loss D: 0.3155, Loss G: 2.1546\n",
      "Epoch [66/85] Batch 520/938 Loss D: 0.3669, Loss G: 2.2796\n",
      "Epoch [66/85] Batch 530/938 Loss D: 0.3492, Loss G: 2.0404\n",
      "Epoch [66/85] Batch 540/938 Loss D: 0.4116, Loss G: 2.5190\n",
      "Epoch [66/85] Batch 550/938 Loss D: 0.2228, Loss G: 2.2501\n",
      "Epoch [66/85] Batch 560/938 Loss D: 0.3283, Loss G: 2.1263\n",
      "Epoch [66/85] Batch 570/938 Loss D: 0.3288, Loss G: 2.2751\n",
      "Epoch [66/85] Batch 580/938 Loss D: 0.2996, Loss G: 3.1743\n",
      "Epoch [66/85] Batch 590/938 Loss D: 0.3536, Loss G: 3.9745\n",
      "Epoch [66/85] Batch 600/938 Loss D: 0.1979, Loss G: 3.4261\n",
      "Epoch [66/85] Batch 610/938 Loss D: 0.2711, Loss G: 2.5152\n",
      "Epoch [66/85] Batch 620/938 Loss D: 0.3946, Loss G: 1.8610\n",
      "Epoch [66/85] Batch 630/938 Loss D: 0.2848, Loss G: 2.4789\n",
      "Epoch [66/85] Batch 640/938 Loss D: 0.2151, Loss G: 2.4019\n",
      "Epoch [66/85] Batch 650/938 Loss D: 0.4393, Loss G: 2.2948\n",
      "Epoch [66/85] Batch 660/938 Loss D: 0.2622, Loss G: 2.5737\n",
      "Epoch [66/85] Batch 670/938 Loss D: 0.2169, Loss G: 2.1861\n",
      "Epoch [66/85] Batch 680/938 Loss D: 0.1487, Loss G: 3.1996\n",
      "Epoch [66/85] Batch 690/938 Loss D: 0.2245, Loss G: 2.8471\n",
      "Epoch [66/85] Batch 700/938 Loss D: 0.2699, Loss G: 2.0687\n",
      "Epoch [66/85] Batch 710/938 Loss D: 0.2629, Loss G: 2.4789\n",
      "Epoch [66/85] Batch 720/938 Loss D: 0.3192, Loss G: 2.5674\n",
      "Epoch [66/85] Batch 730/938 Loss D: 0.3089, Loss G: 2.7845\n",
      "Epoch [66/85] Batch 740/938 Loss D: 0.3371, Loss G: 2.4631\n",
      "Epoch [66/85] Batch 750/938 Loss D: 0.2469, Loss G: 2.5309\n",
      "Epoch [66/85] Batch 760/938 Loss D: 0.3422, Loss G: 2.2202\n",
      "Epoch [66/85] Batch 770/938 Loss D: 0.2868, Loss G: 2.5028\n",
      "Epoch [66/85] Batch 780/938 Loss D: 0.4147, Loss G: 2.4198\n",
      "Epoch [66/85] Batch 790/938 Loss D: 0.2512, Loss G: 2.8415\n",
      "Epoch [66/85] Batch 800/938 Loss D: 0.3201, Loss G: 2.1217\n",
      "Epoch [66/85] Batch 810/938 Loss D: 0.4082, Loss G: 1.3106\n",
      "Epoch [66/85] Batch 820/938 Loss D: 0.2510, Loss G: 1.8628\n",
      "Epoch [66/85] Batch 830/938 Loss D: 0.2009, Loss G: 2.6041\n",
      "Epoch [66/85] Batch 840/938 Loss D: 0.2765, Loss G: 2.7201\n",
      "Epoch [66/85] Batch 850/938 Loss D: 0.3076, Loss G: 2.3467\n",
      "Epoch [66/85] Batch 860/938 Loss D: 0.2552, Loss G: 2.0828\n",
      "Epoch [66/85] Batch 870/938 Loss D: 0.3581, Loss G: 2.2228\n",
      "Epoch [66/85] Batch 880/938 Loss D: 0.2856, Loss G: 1.9901\n",
      "Epoch [66/85] Batch 890/938 Loss D: 0.2146, Loss G: 2.7731\n",
      "Epoch [66/85] Batch 900/938 Loss D: 0.4512, Loss G: 2.0653\n",
      "Epoch [66/85] Batch 910/938 Loss D: 0.3512, Loss G: 1.9779\n",
      "Epoch [66/85] Batch 920/938 Loss D: 0.2935, Loss G: 2.3013\n",
      "Epoch [66/85] Batch 930/938 Loss D: 0.3041, Loss G: 2.2907\n",
      "Epoch [67/85] Batch 0/938 Loss D: 0.3092, Loss G: 2.0589\n",
      "Epoch [67/85] Batch 10/938 Loss D: 0.4295, Loss G: 2.4382\n",
      "Epoch [67/85] Batch 20/938 Loss D: 0.2888, Loss G: 2.6251\n",
      "Epoch [67/85] Batch 30/938 Loss D: 0.2272, Loss G: 2.2267\n",
      "Epoch [67/85] Batch 40/938 Loss D: 0.2686, Loss G: 2.6351\n",
      "Epoch [67/85] Batch 50/938 Loss D: 0.2508, Loss G: 2.4546\n",
      "Epoch [67/85] Batch 60/938 Loss D: 0.2178, Loss G: 2.7794\n",
      "Epoch [67/85] Batch 70/938 Loss D: 0.3941, Loss G: 1.8661\n",
      "Epoch [67/85] Batch 80/938 Loss D: 0.3538, Loss G: 2.5921\n",
      "Epoch [67/85] Batch 90/938 Loss D: 0.4201, Loss G: 3.2218\n",
      "Epoch [67/85] Batch 100/938 Loss D: 0.2525, Loss G: 3.1098\n",
      "Epoch [67/85] Batch 110/938 Loss D: 0.2046, Loss G: 2.9709\n",
      "Epoch [67/85] Batch 120/938 Loss D: 0.2417, Loss G: 2.3663\n",
      "Epoch [67/85] Batch 130/938 Loss D: 0.4139, Loss G: 1.7018\n",
      "Epoch [67/85] Batch 140/938 Loss D: 0.3031, Loss G: 2.8248\n",
      "Epoch [67/85] Batch 150/938 Loss D: 0.2701, Loss G: 2.8215\n",
      "Epoch [67/85] Batch 160/938 Loss D: 0.4972, Loss G: 2.8464\n",
      "Epoch [67/85] Batch 170/938 Loss D: 0.2751, Loss G: 3.2473\n",
      "Epoch [67/85] Batch 180/938 Loss D: 0.1813, Loss G: 3.4491\n",
      "Epoch [67/85] Batch 190/938 Loss D: 0.3079, Loss G: 2.1253\n",
      "Epoch [67/85] Batch 200/938 Loss D: 0.3123, Loss G: 3.6963\n",
      "Epoch [67/85] Batch 210/938 Loss D: 0.3025, Loss G: 3.1023\n",
      "Epoch [67/85] Batch 220/938 Loss D: 0.4237, Loss G: 1.8773\n",
      "Epoch [67/85] Batch 230/938 Loss D: 0.3364, Loss G: 1.9063\n",
      "Epoch [67/85] Batch 240/938 Loss D: 0.3709, Loss G: 2.1371\n",
      "Epoch [67/85] Batch 250/938 Loss D: 0.3422, Loss G: 2.0453\n",
      "Epoch [67/85] Batch 260/938 Loss D: 0.2516, Loss G: 2.5061\n",
      "Epoch [67/85] Batch 270/938 Loss D: 0.1865, Loss G: 2.5997\n",
      "Epoch [67/85] Batch 280/938 Loss D: 0.3365, Loss G: 1.7890\n",
      "Epoch [67/85] Batch 290/938 Loss D: 0.2407, Loss G: 2.8488\n",
      "Epoch [67/85] Batch 300/938 Loss D: 0.2008, Loss G: 3.6138\n",
      "Epoch [67/85] Batch 310/938 Loss D: 0.3593, Loss G: 1.9981\n",
      "Epoch [67/85] Batch 320/938 Loss D: 0.3140, Loss G: 2.1218\n",
      "Epoch [67/85] Batch 330/938 Loss D: 0.2964, Loss G: 2.5900\n",
      "Epoch [67/85] Batch 340/938 Loss D: 0.3069, Loss G: 2.4612\n",
      "Epoch [67/85] Batch 350/938 Loss D: 0.2452, Loss G: 3.1006\n",
      "Epoch [67/85] Batch 360/938 Loss D: 0.3280, Loss G: 2.9033\n",
      "Epoch [67/85] Batch 370/938 Loss D: 0.2318, Loss G: 2.4017\n",
      "Epoch [67/85] Batch 380/938 Loss D: 0.3625, Loss G: 1.8554\n",
      "Epoch [67/85] Batch 390/938 Loss D: 0.3194, Loss G: 2.2434\n",
      "Epoch [67/85] Batch 400/938 Loss D: 0.2965, Loss G: 2.4095\n",
      "Epoch [67/85] Batch 410/938 Loss D: 0.1714, Loss G: 3.1075\n",
      "Epoch [67/85] Batch 420/938 Loss D: 0.2432, Loss G: 2.3731\n",
      "Epoch [67/85] Batch 430/938 Loss D: 0.1909, Loss G: 3.2631\n",
      "Epoch [67/85] Batch 440/938 Loss D: 0.2128, Loss G: 2.6534\n",
      "Epoch [67/85] Batch 450/938 Loss D: 0.4388, Loss G: 1.9585\n",
      "Epoch [67/85] Batch 460/938 Loss D: 0.4033, Loss G: 2.7765\n",
      "Epoch [67/85] Batch 470/938 Loss D: 0.3615, Loss G: 2.8954\n",
      "Epoch [67/85] Batch 480/938 Loss D: 0.3905, Loss G: 3.3219\n",
      "Epoch [67/85] Batch 490/938 Loss D: 0.3731, Loss G: 2.2935\n",
      "Epoch [67/85] Batch 500/938 Loss D: 0.2948, Loss G: 2.4086\n",
      "Epoch [67/85] Batch 510/938 Loss D: 0.2869, Loss G: 2.8766\n",
      "Epoch [67/85] Batch 520/938 Loss D: 0.3176, Loss G: 3.1629\n",
      "Epoch [67/85] Batch 530/938 Loss D: 0.2133, Loss G: 2.5546\n",
      "Epoch [67/85] Batch 540/938 Loss D: 0.3668, Loss G: 2.1443\n",
      "Epoch [67/85] Batch 550/938 Loss D: 0.2051, Loss G: 2.6667\n",
      "Epoch [67/85] Batch 560/938 Loss D: 0.2394, Loss G: 2.3576\n",
      "Epoch [67/85] Batch 570/938 Loss D: 0.2439, Loss G: 3.2660\n",
      "Epoch [67/85] Batch 580/938 Loss D: 0.4080, Loss G: 2.2111\n",
      "Epoch [67/85] Batch 590/938 Loss D: 0.3418, Loss G: 2.1339\n",
      "Epoch [67/85] Batch 600/938 Loss D: 0.3345, Loss G: 2.3156\n",
      "Epoch [67/85] Batch 610/938 Loss D: 0.2324, Loss G: 3.2567\n",
      "Epoch [67/85] Batch 620/938 Loss D: 0.3064, Loss G: 2.6568\n",
      "Epoch [67/85] Batch 630/938 Loss D: 0.1990, Loss G: 2.7350\n",
      "Epoch [67/85] Batch 640/938 Loss D: 0.2488, Loss G: 2.6197\n",
      "Epoch [67/85] Batch 650/938 Loss D: 0.1966, Loss G: 3.4888\n",
      "Epoch [67/85] Batch 660/938 Loss D: 0.3220, Loss G: 1.7671\n",
      "Epoch [67/85] Batch 670/938 Loss D: 0.2486, Loss G: 2.7150\n",
      "Epoch [67/85] Batch 680/938 Loss D: 0.2067, Loss G: 3.2054\n",
      "Epoch [67/85] Batch 690/938 Loss D: 0.2943, Loss G: 3.4592\n",
      "Epoch [67/85] Batch 700/938 Loss D: 0.2998, Loss G: 2.4246\n",
      "Epoch [67/85] Batch 710/938 Loss D: 0.2721, Loss G: 1.9025\n",
      "Epoch [67/85] Batch 720/938 Loss D: 0.3410, Loss G: 2.4642\n",
      "Epoch [67/85] Batch 730/938 Loss D: 0.2059, Loss G: 2.6693\n",
      "Epoch [67/85] Batch 740/938 Loss D: 0.3773, Loss G: 2.4112\n",
      "Epoch [67/85] Batch 750/938 Loss D: 0.3455, Loss G: 2.6022\n",
      "Epoch [67/85] Batch 760/938 Loss D: 0.2243, Loss G: 3.1193\n",
      "Epoch [67/85] Batch 770/938 Loss D: 0.3999, Loss G: 1.8248\n",
      "Epoch [67/85] Batch 780/938 Loss D: 0.2565, Loss G: 2.7379\n",
      "Epoch [67/85] Batch 790/938 Loss D: 0.2458, Loss G: 2.3434\n",
      "Epoch [67/85] Batch 800/938 Loss D: 0.3248, Loss G: 2.5105\n",
      "Epoch [67/85] Batch 810/938 Loss D: 0.1787, Loss G: 2.6275\n",
      "Epoch [67/85] Batch 820/938 Loss D: 0.2925, Loss G: 1.9531\n",
      "Epoch [67/85] Batch 830/938 Loss D: 0.3132, Loss G: 2.0518\n",
      "Epoch [67/85] Batch 840/938 Loss D: 0.3239, Loss G: 2.2535\n",
      "Epoch [67/85] Batch 850/938 Loss D: 0.3060, Loss G: 2.4025\n",
      "Epoch [67/85] Batch 860/938 Loss D: 0.3218, Loss G: 2.4281\n",
      "Epoch [67/85] Batch 870/938 Loss D: 0.3139, Loss G: 2.5181\n",
      "Epoch [67/85] Batch 880/938 Loss D: 0.3330, Loss G: 1.9518\n",
      "Epoch [67/85] Batch 890/938 Loss D: 0.2996, Loss G: 3.2247\n",
      "Epoch [67/85] Batch 900/938 Loss D: 0.2368, Loss G: 2.6636\n",
      "Epoch [67/85] Batch 910/938 Loss D: 0.3012, Loss G: 2.2342\n",
      "Epoch [67/85] Batch 920/938 Loss D: 0.3028, Loss G: 1.9153\n",
      "Epoch [67/85] Batch 930/938 Loss D: 0.2964, Loss G: 2.8259\n",
      "Epoch [68/85] Batch 0/938 Loss D: 0.3081, Loss G: 2.2083\n",
      "Epoch [68/85] Batch 10/938 Loss D: 0.3351, Loss G: 2.2785\n",
      "Epoch [68/85] Batch 20/938 Loss D: 0.4988, Loss G: 1.5461\n",
      "Epoch [68/85] Batch 30/938 Loss D: 0.3750, Loss G: 2.1142\n",
      "Epoch [68/85] Batch 40/938 Loss D: 0.3794, Loss G: 2.2223\n",
      "Epoch [68/85] Batch 50/938 Loss D: 0.2926, Loss G: 2.4862\n",
      "Epoch [68/85] Batch 60/938 Loss D: 0.2943, Loss G: 2.3900\n",
      "Epoch [68/85] Batch 70/938 Loss D: 0.2149, Loss G: 3.2702\n",
      "Epoch [68/85] Batch 80/938 Loss D: 0.3496, Loss G: 2.1299\n",
      "Epoch [68/85] Batch 90/938 Loss D: 0.3447, Loss G: 2.0061\n",
      "Epoch [68/85] Batch 100/938 Loss D: 0.2884, Loss G: 2.2764\n",
      "Epoch [68/85] Batch 110/938 Loss D: 0.2286, Loss G: 2.8633\n",
      "Epoch [68/85] Batch 120/938 Loss D: 0.2609, Loss G: 2.8932\n",
      "Epoch [68/85] Batch 130/938 Loss D: 0.3401, Loss G: 2.2009\n",
      "Epoch [68/85] Batch 140/938 Loss D: 0.3016, Loss G: 2.3386\n",
      "Epoch [68/85] Batch 150/938 Loss D: 0.5190, Loss G: 2.2739\n",
      "Epoch [68/85] Batch 160/938 Loss D: 0.1990, Loss G: 3.4303\n",
      "Epoch [68/85] Batch 170/938 Loss D: 0.3321, Loss G: 2.3161\n",
      "Epoch [68/85] Batch 180/938 Loss D: 0.4617, Loss G: 2.6916\n",
      "Epoch [68/85] Batch 190/938 Loss D: 0.3703, Loss G: 2.4178\n",
      "Epoch [68/85] Batch 200/938 Loss D: 0.2478, Loss G: 2.7923\n",
      "Epoch [68/85] Batch 210/938 Loss D: 0.3336, Loss G: 2.3837\n",
      "Epoch [68/85] Batch 220/938 Loss D: 0.3574, Loss G: 2.3755\n",
      "Epoch [68/85] Batch 230/938 Loss D: 0.2274, Loss G: 2.5651\n",
      "Epoch [68/85] Batch 240/938 Loss D: 0.2418, Loss G: 2.4898\n",
      "Epoch [68/85] Batch 250/938 Loss D: 0.3687, Loss G: 2.4851\n",
      "Epoch [68/85] Batch 260/938 Loss D: 0.3186, Loss G: 3.6153\n",
      "Epoch [68/85] Batch 270/938 Loss D: 0.3176, Loss G: 2.6151\n",
      "Epoch [68/85] Batch 280/938 Loss D: 0.2575, Loss G: 2.5164\n",
      "Epoch [68/85] Batch 290/938 Loss D: 0.3099, Loss G: 1.9169\n",
      "Epoch [68/85] Batch 300/938 Loss D: 0.2370, Loss G: 2.7955\n",
      "Epoch [68/85] Batch 310/938 Loss D: 0.4271, Loss G: 3.1138\n",
      "Epoch [68/85] Batch 320/938 Loss D: 0.2037, Loss G: 3.1358\n",
      "Epoch [68/85] Batch 330/938 Loss D: 0.2870, Loss G: 2.2559\n",
      "Epoch [68/85] Batch 340/938 Loss D: 0.3116, Loss G: 2.2893\n",
      "Epoch [68/85] Batch 350/938 Loss D: 0.2807, Loss G: 2.5536\n",
      "Epoch [68/85] Batch 360/938 Loss D: 0.3443, Loss G: 2.0065\n",
      "Epoch [68/85] Batch 370/938 Loss D: 0.2550, Loss G: 2.6961\n",
      "Epoch [68/85] Batch 380/938 Loss D: 0.2961, Loss G: 1.9435\n",
      "Epoch [68/85] Batch 390/938 Loss D: 0.2133, Loss G: 2.4127\n",
      "Epoch [68/85] Batch 400/938 Loss D: 0.2553, Loss G: 3.1004\n",
      "Epoch [68/85] Batch 410/938 Loss D: 0.2670, Loss G: 2.8668\n",
      "Epoch [68/85] Batch 420/938 Loss D: 0.2796, Loss G: 1.9721\n",
      "Epoch [68/85] Batch 430/938 Loss D: 0.3182, Loss G: 2.1015\n",
      "Epoch [68/85] Batch 440/938 Loss D: 0.3442, Loss G: 2.3666\n",
      "Epoch [68/85] Batch 450/938 Loss D: 0.3859, Loss G: 2.1775\n",
      "Epoch [68/85] Batch 460/938 Loss D: 0.2403, Loss G: 2.0740\n",
      "Epoch [68/85] Batch 470/938 Loss D: 0.2203, Loss G: 2.5695\n",
      "Epoch [68/85] Batch 480/938 Loss D: 0.2984, Loss G: 2.5183\n",
      "Epoch [68/85] Batch 490/938 Loss D: 0.3580, Loss G: 2.1578\n",
      "Epoch [68/85] Batch 500/938 Loss D: 0.4335, Loss G: 2.1773\n",
      "Epoch [68/85] Batch 510/938 Loss D: 0.1918, Loss G: 3.2678\n",
      "Epoch [68/85] Batch 520/938 Loss D: 0.3806, Loss G: 2.3724\n",
      "Epoch [68/85] Batch 530/938 Loss D: 0.3083, Loss G: 2.4275\n",
      "Epoch [68/85] Batch 540/938 Loss D: 0.3412, Loss G: 1.8092\n",
      "Epoch [68/85] Batch 550/938 Loss D: 0.2518, Loss G: 2.4128\n",
      "Epoch [68/85] Batch 560/938 Loss D: 0.3924, Loss G: 1.9838\n",
      "Epoch [68/85] Batch 570/938 Loss D: 0.1606, Loss G: 3.4080\n",
      "Epoch [68/85] Batch 580/938 Loss D: 0.2479, Loss G: 2.6550\n",
      "Epoch [68/85] Batch 590/938 Loss D: 0.2093, Loss G: 3.0543\n",
      "Epoch [68/85] Batch 600/938 Loss D: 0.2670, Loss G: 2.6670\n",
      "Epoch [68/85] Batch 610/938 Loss D: 0.2130, Loss G: 2.1600\n",
      "Epoch [68/85] Batch 620/938 Loss D: 0.2581, Loss G: 2.6332\n",
      "Epoch [68/85] Batch 630/938 Loss D: 0.4017, Loss G: 2.0404\n",
      "Epoch [68/85] Batch 640/938 Loss D: 0.3220, Loss G: 2.0338\n",
      "Epoch [68/85] Batch 650/938 Loss D: 0.2158, Loss G: 2.7191\n",
      "Epoch [68/85] Batch 660/938 Loss D: 0.2563, Loss G: 3.4172\n",
      "Epoch [68/85] Batch 670/938 Loss D: 0.2354, Loss G: 3.7982\n",
      "Epoch [68/85] Batch 680/938 Loss D: 0.3237, Loss G: 2.4672\n",
      "Epoch [68/85] Batch 690/938 Loss D: 0.3438, Loss G: 2.4544\n",
      "Epoch [68/85] Batch 700/938 Loss D: 0.2224, Loss G: 3.0352\n",
      "Epoch [68/85] Batch 710/938 Loss D: 0.3251, Loss G: 2.0008\n",
      "Epoch [68/85] Batch 720/938 Loss D: 0.3173, Loss G: 2.4193\n",
      "Epoch [68/85] Batch 730/938 Loss D: 0.3935, Loss G: 2.6234\n",
      "Epoch [68/85] Batch 740/938 Loss D: 0.2887, Loss G: 2.5834\n",
      "Epoch [68/85] Batch 750/938 Loss D: 0.2598, Loss G: 2.4970\n",
      "Epoch [68/85] Batch 760/938 Loss D: 0.3046, Loss G: 2.1854\n",
      "Epoch [68/85] Batch 770/938 Loss D: 0.2681, Loss G: 2.1083\n",
      "Epoch [68/85] Batch 780/938 Loss D: 0.1074, Loss G: 3.1221\n",
      "Epoch [68/85] Batch 790/938 Loss D: 0.2600, Loss G: 2.8779\n",
      "Epoch [68/85] Batch 800/938 Loss D: 0.2252, Loss G: 2.2948\n",
      "Epoch [68/85] Batch 810/938 Loss D: 0.2819, Loss G: 2.9677\n",
      "Epoch [68/85] Batch 820/938 Loss D: 0.3277, Loss G: 2.1011\n",
      "Epoch [68/85] Batch 830/938 Loss D: 0.3798, Loss G: 2.0887\n",
      "Epoch [68/85] Batch 840/938 Loss D: 0.3778, Loss G: 1.9966\n",
      "Epoch [68/85] Batch 850/938 Loss D: 0.2340, Loss G: 2.4203\n",
      "Epoch [68/85] Batch 860/938 Loss D: 0.2839, Loss G: 2.3817\n",
      "Epoch [68/85] Batch 870/938 Loss D: 0.1768, Loss G: 3.0966\n",
      "Epoch [68/85] Batch 880/938 Loss D: 0.2700, Loss G: 2.6225\n",
      "Epoch [68/85] Batch 890/938 Loss D: 0.3341, Loss G: 2.3851\n",
      "Epoch [68/85] Batch 900/938 Loss D: 0.2387, Loss G: 3.2356\n",
      "Epoch [68/85] Batch 910/938 Loss D: 0.2106, Loss G: 3.2333\n",
      "Epoch [68/85] Batch 920/938 Loss D: 0.2449, Loss G: 2.6203\n",
      "Epoch [68/85] Batch 930/938 Loss D: 0.3469, Loss G: 2.6134\n",
      "Epoch [69/85] Batch 0/938 Loss D: 0.2461, Loss G: 2.5107\n",
      "Epoch [69/85] Batch 10/938 Loss D: 0.2877, Loss G: 2.0159\n",
      "Epoch [69/85] Batch 20/938 Loss D: 0.2147, Loss G: 2.9134\n",
      "Epoch [69/85] Batch 30/938 Loss D: 0.3623, Loss G: 1.9174\n",
      "Epoch [69/85] Batch 40/938 Loss D: 0.3244, Loss G: 2.5393\n",
      "Epoch [69/85] Batch 50/938 Loss D: 0.4079, Loss G: 2.7323\n",
      "Epoch [69/85] Batch 60/938 Loss D: 0.4095, Loss G: 2.2737\n",
      "Epoch [69/85] Batch 70/938 Loss D: 0.2005, Loss G: 2.2222\n",
      "Epoch [69/85] Batch 80/938 Loss D: 0.2363, Loss G: 2.1846\n",
      "Epoch [69/85] Batch 90/938 Loss D: 0.3122, Loss G: 2.2577\n",
      "Epoch [69/85] Batch 100/938 Loss D: 0.4416, Loss G: 2.6162\n",
      "Epoch [69/85] Batch 110/938 Loss D: 0.2185, Loss G: 2.3385\n",
      "Epoch [69/85] Batch 120/938 Loss D: 0.2809, Loss G: 2.2026\n",
      "Epoch [69/85] Batch 130/938 Loss D: 0.2176, Loss G: 3.1254\n",
      "Epoch [69/85] Batch 140/938 Loss D: 0.3187, Loss G: 3.1895\n",
      "Epoch [69/85] Batch 150/938 Loss D: 0.2851, Loss G: 3.3609\n",
      "Epoch [69/85] Batch 160/938 Loss D: 0.2904, Loss G: 2.7282\n",
      "Epoch [69/85] Batch 170/938 Loss D: 0.2544, Loss G: 2.9283\n",
      "Epoch [69/85] Batch 180/938 Loss D: 0.2320, Loss G: 3.2815\n",
      "Epoch [69/85] Batch 190/938 Loss D: 0.2865, Loss G: 3.4747\n",
      "Epoch [69/85] Batch 200/938 Loss D: 0.2355, Loss G: 2.6031\n",
      "Epoch [69/85] Batch 210/938 Loss D: 0.3214, Loss G: 2.2673\n",
      "Epoch [69/85] Batch 220/938 Loss D: 0.2334, Loss G: 2.4617\n",
      "Epoch [69/85] Batch 230/938 Loss D: 0.2697, Loss G: 2.2629\n",
      "Epoch [69/85] Batch 240/938 Loss D: 0.3442, Loss G: 2.3539\n",
      "Epoch [69/85] Batch 250/938 Loss D: 0.3861, Loss G: 2.2614\n",
      "Epoch [69/85] Batch 260/938 Loss D: 0.3351, Loss G: 1.9227\n",
      "Epoch [69/85] Batch 270/938 Loss D: 0.2781, Loss G: 2.0393\n",
      "Epoch [69/85] Batch 280/938 Loss D: 0.2389, Loss G: 2.4948\n",
      "Epoch [69/85] Batch 290/938 Loss D: 0.3185, Loss G: 2.0094\n",
      "Epoch [69/85] Batch 300/938 Loss D: 0.3710, Loss G: 2.9553\n",
      "Epoch [69/85] Batch 310/938 Loss D: 0.2262, Loss G: 2.6981\n",
      "Epoch [69/85] Batch 320/938 Loss D: 0.2399, Loss G: 3.1347\n",
      "Epoch [69/85] Batch 330/938 Loss D: 0.2764, Loss G: 2.0500\n",
      "Epoch [69/85] Batch 340/938 Loss D: 0.2281, Loss G: 2.4159\n",
      "Epoch [69/85] Batch 350/938 Loss D: 0.3070, Loss G: 2.1273\n",
      "Epoch [69/85] Batch 360/938 Loss D: 0.3045, Loss G: 2.5033\n",
      "Epoch [69/85] Batch 370/938 Loss D: 0.2665, Loss G: 3.3322\n",
      "Epoch [69/85] Batch 380/938 Loss D: 0.3879, Loss G: 2.3460\n",
      "Epoch [69/85] Batch 390/938 Loss D: 0.3140, Loss G: 2.2976\n",
      "Epoch [69/85] Batch 400/938 Loss D: 0.2123, Loss G: 2.3663\n",
      "Epoch [69/85] Batch 410/938 Loss D: 0.3041, Loss G: 1.8320\n",
      "Epoch [69/85] Batch 420/938 Loss D: 0.3702, Loss G: 2.4861\n",
      "Epoch [69/85] Batch 430/938 Loss D: 0.2295, Loss G: 2.7365\n",
      "Epoch [69/85] Batch 440/938 Loss D: 0.2718, Loss G: 1.9129\n",
      "Epoch [69/85] Batch 450/938 Loss D: 0.3676, Loss G: 1.9912\n",
      "Epoch [69/85] Batch 460/938 Loss D: 0.2814, Loss G: 2.9254\n",
      "Epoch [69/85] Batch 470/938 Loss D: 0.1790, Loss G: 2.7688\n",
      "Epoch [69/85] Batch 480/938 Loss D: 0.2946, Loss G: 1.9330\n",
      "Epoch [69/85] Batch 490/938 Loss D: 0.4884, Loss G: 1.6529\n",
      "Epoch [69/85] Batch 500/938 Loss D: 0.3250, Loss G: 2.1114\n",
      "Epoch [69/85] Batch 510/938 Loss D: 0.2880, Loss G: 2.2557\n",
      "Epoch [69/85] Batch 520/938 Loss D: 0.3553, Loss G: 3.1965\n",
      "Epoch [69/85] Batch 530/938 Loss D: 0.1774, Loss G: 3.7645\n",
      "Epoch [69/85] Batch 540/938 Loss D: 0.5131, Loss G: 2.6318\n",
      "Epoch [69/85] Batch 550/938 Loss D: 0.3244, Loss G: 1.9138\n",
      "Epoch [69/85] Batch 560/938 Loss D: 0.2236, Loss G: 2.4284\n",
      "Epoch [69/85] Batch 570/938 Loss D: 0.1533, Loss G: 3.3274\n",
      "Epoch [69/85] Batch 580/938 Loss D: 0.2868, Loss G: 2.3276\n",
      "Epoch [69/85] Batch 590/938 Loss D: 0.2500, Loss G: 2.4997\n",
      "Epoch [69/85] Batch 600/938 Loss D: 0.2470, Loss G: 2.2193\n",
      "Epoch [69/85] Batch 610/938 Loss D: 0.2436, Loss G: 2.5123\n",
      "Epoch [69/85] Batch 620/938 Loss D: 0.2576, Loss G: 2.6661\n",
      "Epoch [69/85] Batch 630/938 Loss D: 0.3218, Loss G: 2.0341\n",
      "Epoch [69/85] Batch 640/938 Loss D: 0.4069, Loss G: 1.6427\n",
      "Epoch [69/85] Batch 650/938 Loss D: 0.3145, Loss G: 2.2915\n",
      "Epoch [69/85] Batch 660/938 Loss D: 0.3584, Loss G: 2.0052\n",
      "Epoch [69/85] Batch 670/938 Loss D: 0.2426, Loss G: 2.3614\n",
      "Epoch [69/85] Batch 680/938 Loss D: 0.2861, Loss G: 2.3259\n",
      "Epoch [69/85] Batch 690/938 Loss D: 0.3499, Loss G: 2.1543\n",
      "Epoch [69/85] Batch 700/938 Loss D: 0.3639, Loss G: 2.1690\n",
      "Epoch [69/85] Batch 710/938 Loss D: 0.2911, Loss G: 2.5186\n",
      "Epoch [69/85] Batch 720/938 Loss D: 0.3088, Loss G: 2.3597\n",
      "Epoch [69/85] Batch 730/938 Loss D: 0.1834, Loss G: 3.2456\n",
      "Epoch [69/85] Batch 740/938 Loss D: 0.4818, Loss G: 2.1373\n",
      "Epoch [69/85] Batch 750/938 Loss D: 0.3271, Loss G: 2.8071\n",
      "Epoch [69/85] Batch 760/938 Loss D: 0.2496, Loss G: 2.5795\n",
      "Epoch [69/85] Batch 770/938 Loss D: 0.3531, Loss G: 2.6526\n",
      "Epoch [69/85] Batch 780/938 Loss D: 0.2074, Loss G: 2.8367\n",
      "Epoch [69/85] Batch 790/938 Loss D: 0.3851, Loss G: 2.1551\n",
      "Epoch [69/85] Batch 800/938 Loss D: 0.2698, Loss G: 2.6851\n",
      "Epoch [69/85] Batch 810/938 Loss D: 0.2781, Loss G: 2.7836\n",
      "Epoch [69/85] Batch 820/938 Loss D: 0.2748, Loss G: 3.4176\n",
      "Epoch [69/85] Batch 830/938 Loss D: 0.2552, Loss G: 3.6683\n",
      "Epoch [69/85] Batch 840/938 Loss D: 0.3014, Loss G: 2.6330\n",
      "Epoch [69/85] Batch 850/938 Loss D: 0.1341, Loss G: 3.4630\n",
      "Epoch [69/85] Batch 860/938 Loss D: 0.2493, Loss G: 2.4261\n",
      "Epoch [69/85] Batch 870/938 Loss D: 0.1650, Loss G: 2.6356\n",
      "Epoch [69/85] Batch 880/938 Loss D: 0.3341, Loss G: 2.9258\n",
      "Epoch [69/85] Batch 890/938 Loss D: 0.3265, Loss G: 3.0817\n",
      "Epoch [69/85] Batch 900/938 Loss D: 0.2651, Loss G: 2.5877\n",
      "Epoch [69/85] Batch 910/938 Loss D: 0.2447, Loss G: 2.2460\n",
      "Epoch [69/85] Batch 920/938 Loss D: 0.2304, Loss G: 2.9219\n",
      "Epoch [69/85] Batch 930/938 Loss D: 0.2872, Loss G: 2.4176\n",
      "Epoch [70/85] Batch 0/938 Loss D: 0.1898, Loss G: 2.7964\n",
      "Epoch [70/85] Batch 10/938 Loss D: 0.3185, Loss G: 2.1170\n",
      "Epoch [70/85] Batch 20/938 Loss D: 0.2402, Loss G: 3.5008\n",
      "Epoch [70/85] Batch 30/938 Loss D: 0.3406, Loss G: 2.2627\n",
      "Epoch [70/85] Batch 40/938 Loss D: 0.3833, Loss G: 1.8195\n",
      "Epoch [70/85] Batch 50/938 Loss D: 0.3501, Loss G: 2.3400\n",
      "Epoch [70/85] Batch 60/938 Loss D: 0.2600, Loss G: 2.4864\n",
      "Epoch [70/85] Batch 70/938 Loss D: 0.3458, Loss G: 1.9058\n",
      "Epoch [70/85] Batch 80/938 Loss D: 0.1871, Loss G: 2.4844\n",
      "Epoch [70/85] Batch 90/938 Loss D: 0.3985, Loss G: 2.1829\n",
      "Epoch [70/85] Batch 100/938 Loss D: 0.2129, Loss G: 2.7985\n",
      "Epoch [70/85] Batch 110/938 Loss D: 0.2809, Loss G: 2.0113\n",
      "Epoch [70/85] Batch 120/938 Loss D: 0.2561, Loss G: 2.0059\n",
      "Epoch [70/85] Batch 130/938 Loss D: 0.2544, Loss G: 2.6957\n",
      "Epoch [70/85] Batch 140/938 Loss D: 0.3095, Loss G: 2.3714\n",
      "Epoch [70/85] Batch 150/938 Loss D: 0.3694, Loss G: 1.8705\n",
      "Epoch [70/85] Batch 160/938 Loss D: 0.3340, Loss G: 2.2182\n",
      "Epoch [70/85] Batch 170/938 Loss D: 0.3515, Loss G: 2.4802\n",
      "Epoch [70/85] Batch 180/938 Loss D: 0.4513, Loss G: 2.0676\n",
      "Epoch [70/85] Batch 190/938 Loss D: 0.3322, Loss G: 2.5256\n",
      "Epoch [70/85] Batch 200/938 Loss D: 0.3127, Loss G: 2.7805\n",
      "Epoch [70/85] Batch 210/938 Loss D: 0.3787, Loss G: 2.2539\n",
      "Epoch [70/85] Batch 220/938 Loss D: 0.2200, Loss G: 2.6027\n",
      "Epoch [70/85] Batch 230/938 Loss D: 0.2452, Loss G: 2.3422\n",
      "Epoch [70/85] Batch 240/938 Loss D: 0.4058, Loss G: 2.2071\n",
      "Epoch [70/85] Batch 250/938 Loss D: 0.2442, Loss G: 2.1638\n",
      "Epoch [70/85] Batch 260/938 Loss D: 0.2292, Loss G: 2.8179\n",
      "Epoch [70/85] Batch 270/938 Loss D: 0.2504, Loss G: 2.4049\n",
      "Epoch [70/85] Batch 280/938 Loss D: 0.3908, Loss G: 4.0740\n",
      "Epoch [70/85] Batch 290/938 Loss D: 0.2868, Loss G: 2.6478\n",
      "Epoch [70/85] Batch 300/938 Loss D: 0.3175, Loss G: 2.6795\n",
      "Epoch [70/85] Batch 310/938 Loss D: 0.2093, Loss G: 3.2570\n",
      "Epoch [70/85] Batch 320/938 Loss D: 0.5150, Loss G: 2.4738\n",
      "Epoch [70/85] Batch 330/938 Loss D: 0.4450, Loss G: 3.2128\n",
      "Epoch [70/85] Batch 340/938 Loss D: 0.1955, Loss G: 2.9531\n",
      "Epoch [70/85] Batch 350/938 Loss D: 0.4300, Loss G: 1.7812\n",
      "Epoch [70/85] Batch 360/938 Loss D: 0.2820, Loss G: 2.1815\n",
      "Epoch [70/85] Batch 370/938 Loss D: 0.2192, Loss G: 2.7118\n",
      "Epoch [70/85] Batch 380/938 Loss D: 0.3353, Loss G: 2.1163\n",
      "Epoch [70/85] Batch 390/938 Loss D: 0.3095, Loss G: 2.1280\n",
      "Epoch [70/85] Batch 400/938 Loss D: 0.1718, Loss G: 3.1609\n",
      "Epoch [70/85] Batch 410/938 Loss D: 0.2778, Loss G: 2.9659\n",
      "Epoch [70/85] Batch 420/938 Loss D: 0.2631, Loss G: 2.6469\n",
      "Epoch [70/85] Batch 430/938 Loss D: 0.3189, Loss G: 2.2446\n",
      "Epoch [70/85] Batch 440/938 Loss D: 0.3067, Loss G: 2.3059\n",
      "Epoch [70/85] Batch 450/938 Loss D: 0.1673, Loss G: 2.8240\n",
      "Epoch [70/85] Batch 460/938 Loss D: 0.2750, Loss G: 2.8720\n",
      "Epoch [70/85] Batch 470/938 Loss D: 0.2544, Loss G: 2.4624\n",
      "Epoch [70/85] Batch 480/938 Loss D: 0.2353, Loss G: 2.3315\n",
      "Epoch [70/85] Batch 490/938 Loss D: 0.2922, Loss G: 1.9821\n",
      "Epoch [70/85] Batch 500/938 Loss D: 0.4264, Loss G: 1.8681\n",
      "Epoch [70/85] Batch 510/938 Loss D: 0.3080, Loss G: 2.1805\n",
      "Epoch [70/85] Batch 520/938 Loss D: 0.2955, Loss G: 1.8095\n",
      "Epoch [70/85] Batch 530/938 Loss D: 0.3414, Loss G: 2.6572\n",
      "Epoch [70/85] Batch 540/938 Loss D: 0.2478, Loss G: 2.4003\n",
      "Epoch [70/85] Batch 550/938 Loss D: 0.2759, Loss G: 2.5825\n",
      "Epoch [70/85] Batch 560/938 Loss D: 0.3659, Loss G: 2.8210\n",
      "Epoch [70/85] Batch 570/938 Loss D: 0.2970, Loss G: 2.7909\n",
      "Epoch [70/85] Batch 580/938 Loss D: 0.2955, Loss G: 2.4896\n",
      "Epoch [70/85] Batch 590/938 Loss D: 0.2537, Loss G: 2.9152\n",
      "Epoch [70/85] Batch 600/938 Loss D: 0.2702, Loss G: 2.1522\n",
      "Epoch [70/85] Batch 610/938 Loss D: 0.2591, Loss G: 2.4546\n",
      "Epoch [70/85] Batch 620/938 Loss D: 0.2762, Loss G: 2.6204\n",
      "Epoch [70/85] Batch 630/938 Loss D: 0.2739, Loss G: 2.2401\n",
      "Epoch [70/85] Batch 640/938 Loss D: 0.2458, Loss G: 2.1874\n",
      "Epoch [70/85] Batch 650/938 Loss D: 0.3607, Loss G: 3.1583\n",
      "Epoch [70/85] Batch 660/938 Loss D: 0.3646, Loss G: 3.3347\n",
      "Epoch [70/85] Batch 670/938 Loss D: 0.3179, Loss G: 2.5771\n",
      "Epoch [70/85] Batch 680/938 Loss D: 0.3268, Loss G: 2.0845\n",
      "Epoch [70/85] Batch 690/938 Loss D: 0.3055, Loss G: 1.9009\n",
      "Epoch [70/85] Batch 700/938 Loss D: 0.2587, Loss G: 3.1166\n",
      "Epoch [70/85] Batch 710/938 Loss D: 0.2224, Loss G: 3.0625\n",
      "Epoch [70/85] Batch 720/938 Loss D: 0.4701, Loss G: 3.0134\n",
      "Epoch [70/85] Batch 730/938 Loss D: 0.2404, Loss G: 3.2820\n",
      "Epoch [70/85] Batch 740/938 Loss D: 0.2014, Loss G: 2.4231\n",
      "Epoch [70/85] Batch 750/938 Loss D: 0.1201, Loss G: 3.6248\n",
      "Epoch [70/85] Batch 760/938 Loss D: 0.2347, Loss G: 2.5856\n",
      "Epoch [70/85] Batch 770/938 Loss D: 0.2046, Loss G: 3.4770\n",
      "Epoch [70/85] Batch 780/938 Loss D: 0.2429, Loss G: 2.6163\n",
      "Epoch [70/85] Batch 790/938 Loss D: 0.2390, Loss G: 2.2337\n",
      "Epoch [70/85] Batch 800/938 Loss D: 0.3318, Loss G: 2.0416\n",
      "Epoch [70/85] Batch 810/938 Loss D: 0.2367, Loss G: 3.5400\n",
      "Epoch [70/85] Batch 820/938 Loss D: 0.2453, Loss G: 2.9428\n",
      "Epoch [70/85] Batch 830/938 Loss D: 0.3205, Loss G: 2.5402\n",
      "Epoch [70/85] Batch 840/938 Loss D: 0.3755, Loss G: 2.0209\n",
      "Epoch [70/85] Batch 850/938 Loss D: 0.2669, Loss G: 2.3434\n",
      "Epoch [70/85] Batch 860/938 Loss D: 0.3259, Loss G: 2.0561\n",
      "Epoch [70/85] Batch 870/938 Loss D: 0.3401, Loss G: 2.2832\n",
      "Epoch [70/85] Batch 880/938 Loss D: 0.2412, Loss G: 2.4230\n",
      "Epoch [70/85] Batch 890/938 Loss D: 0.2169, Loss G: 3.0547\n",
      "Epoch [70/85] Batch 900/938 Loss D: 0.2295, Loss G: 3.1257\n",
      "Epoch [70/85] Batch 910/938 Loss D: 0.2230, Loss G: 2.4258\n",
      "Epoch [70/85] Batch 920/938 Loss D: 0.3714, Loss G: 2.1381\n",
      "Epoch [70/85] Batch 930/938 Loss D: 0.2715, Loss G: 2.7857\n",
      "Epoch [71/85] Batch 0/938 Loss D: 0.3133, Loss G: 2.1233\n",
      "Epoch [71/85] Batch 10/938 Loss D: 0.2711, Loss G: 2.4056\n",
      "Epoch [71/85] Batch 20/938 Loss D: 0.2474, Loss G: 1.9207\n",
      "Epoch [71/85] Batch 30/938 Loss D: 0.4131, Loss G: 2.0311\n",
      "Epoch [71/85] Batch 40/938 Loss D: 0.2504, Loss G: 2.9957\n",
      "Epoch [71/85] Batch 50/938 Loss D: 0.2737, Loss G: 2.6738\n",
      "Epoch [71/85] Batch 60/938 Loss D: 0.2728, Loss G: 2.1456\n",
      "Epoch [71/85] Batch 70/938 Loss D: 0.3766, Loss G: 1.9597\n",
      "Epoch [71/85] Batch 80/938 Loss D: 0.3371, Loss G: 2.1057\n",
      "Epoch [71/85] Batch 90/938 Loss D: 0.3348, Loss G: 2.6004\n",
      "Epoch [71/85] Batch 100/938 Loss D: 0.3079, Loss G: 2.1229\n",
      "Epoch [71/85] Batch 110/938 Loss D: 0.2504, Loss G: 2.0122\n",
      "Epoch [71/85] Batch 120/938 Loss D: 0.2452, Loss G: 2.3543\n",
      "Epoch [71/85] Batch 130/938 Loss D: 0.2887, Loss G: 2.5608\n",
      "Epoch [71/85] Batch 140/938 Loss D: 0.2421, Loss G: 2.3037\n",
      "Epoch [71/85] Batch 150/938 Loss D: 0.2026, Loss G: 2.8446\n",
      "Epoch [71/85] Batch 160/938 Loss D: 0.2215, Loss G: 3.3387\n",
      "Epoch [71/85] Batch 170/938 Loss D: 0.3268, Loss G: 2.3373\n",
      "Epoch [71/85] Batch 180/938 Loss D: 0.3741, Loss G: 1.7662\n",
      "Epoch [71/85] Batch 190/938 Loss D: 0.2958, Loss G: 2.2217\n",
      "Epoch [71/85] Batch 200/938 Loss D: 0.2678, Loss G: 2.9096\n",
      "Epoch [71/85] Batch 210/938 Loss D: 0.2506, Loss G: 2.3328\n",
      "Epoch [71/85] Batch 220/938 Loss D: 0.2384, Loss G: 2.6771\n",
      "Epoch [71/85] Batch 230/938 Loss D: 0.3114, Loss G: 2.1297\n",
      "Epoch [71/85] Batch 240/938 Loss D: 0.2536, Loss G: 2.8082\n",
      "Epoch [71/85] Batch 250/938 Loss D: 0.4732, Loss G: 2.1242\n",
      "Epoch [71/85] Batch 260/938 Loss D: 0.2292, Loss G: 3.2493\n",
      "Epoch [71/85] Batch 270/938 Loss D: 0.2692, Loss G: 2.3875\n",
      "Epoch [71/85] Batch 280/938 Loss D: 0.3321, Loss G: 1.7237\n",
      "Epoch [71/85] Batch 290/938 Loss D: 0.2455, Loss G: 2.5551\n",
      "Epoch [71/85] Batch 300/938 Loss D: 0.3480, Loss G: 2.2117\n",
      "Epoch [71/85] Batch 310/938 Loss D: 0.1702, Loss G: 3.1064\n",
      "Epoch [71/85] Batch 320/938 Loss D: 0.2432, Loss G: 2.2086\n",
      "Epoch [71/85] Batch 330/938 Loss D: 0.2929, Loss G: 2.2811\n",
      "Epoch [71/85] Batch 340/938 Loss D: 0.3596, Loss G: 2.1299\n",
      "Epoch [71/85] Batch 350/938 Loss D: 0.3013, Loss G: 1.9654\n",
      "Epoch [71/85] Batch 360/938 Loss D: 0.2523, Loss G: 2.4326\n",
      "Epoch [71/85] Batch 370/938 Loss D: 0.3184, Loss G: 2.8251\n",
      "Epoch [71/85] Batch 380/938 Loss D: 0.3304, Loss G: 2.5284\n",
      "Epoch [71/85] Batch 390/938 Loss D: 0.3696, Loss G: 2.1144\n",
      "Epoch [71/85] Batch 400/938 Loss D: 0.2979, Loss G: 2.8221\n",
      "Epoch [71/85] Batch 410/938 Loss D: 0.3843, Loss G: 2.0379\n",
      "Epoch [71/85] Batch 420/938 Loss D: 0.3550, Loss G: 2.3425\n",
      "Epoch [71/85] Batch 430/938 Loss D: 0.2670, Loss G: 2.2262\n",
      "Epoch [71/85] Batch 440/938 Loss D: 0.2643, Loss G: 3.2612\n",
      "Epoch [71/85] Batch 450/938 Loss D: 0.4032, Loss G: 1.9558\n",
      "Epoch [71/85] Batch 460/938 Loss D: 0.3530, Loss G: 2.3997\n",
      "Epoch [71/85] Batch 470/938 Loss D: 0.3696, Loss G: 2.9952\n",
      "Epoch [71/85] Batch 480/938 Loss D: 0.3714, Loss G: 2.1872\n",
      "Epoch [71/85] Batch 490/938 Loss D: 0.1996, Loss G: 2.3950\n",
      "Epoch [71/85] Batch 500/938 Loss D: 0.2140, Loss G: 2.9721\n",
      "Epoch [71/85] Batch 510/938 Loss D: 0.4291, Loss G: 1.8472\n",
      "Epoch [71/85] Batch 520/938 Loss D: 0.3116, Loss G: 2.2042\n",
      "Epoch [71/85] Batch 530/938 Loss D: 0.2961, Loss G: 2.8528\n",
      "Epoch [71/85] Batch 540/938 Loss D: 0.2510, Loss G: 2.8449\n",
      "Epoch [71/85] Batch 550/938 Loss D: 0.3221, Loss G: 2.2597\n",
      "Epoch [71/85] Batch 560/938 Loss D: 0.2001, Loss G: 2.3353\n",
      "Epoch [71/85] Batch 570/938 Loss D: 0.5390, Loss G: 2.7878\n",
      "Epoch [71/85] Batch 580/938 Loss D: 0.1790, Loss G: 3.5258\n",
      "Epoch [71/85] Batch 590/938 Loss D: 0.3084, Loss G: 3.2554\n",
      "Epoch [71/85] Batch 600/938 Loss D: 0.1361, Loss G: 3.5112\n",
      "Epoch [71/85] Batch 610/938 Loss D: 0.1547, Loss G: 3.2399\n",
      "Epoch [71/85] Batch 620/938 Loss D: 0.3132, Loss G: 2.2554\n",
      "Epoch [71/85] Batch 630/938 Loss D: 0.2494, Loss G: 2.4020\n",
      "Epoch [71/85] Batch 640/938 Loss D: 0.3543, Loss G: 1.7015\n",
      "Epoch [71/85] Batch 650/938 Loss D: 0.2673, Loss G: 2.3766\n",
      "Epoch [71/85] Batch 660/938 Loss D: 0.2506, Loss G: 2.5414\n",
      "Epoch [71/85] Batch 670/938 Loss D: 0.3305, Loss G: 2.1621\n",
      "Epoch [71/85] Batch 680/938 Loss D: 0.2961, Loss G: 2.2804\n",
      "Epoch [71/85] Batch 690/938 Loss D: 0.3025, Loss G: 3.0304\n",
      "Epoch [71/85] Batch 700/938 Loss D: 0.3012, Loss G: 2.7105\n",
      "Epoch [71/85] Batch 710/938 Loss D: 0.4557, Loss G: 1.7975\n",
      "Epoch [71/85] Batch 720/938 Loss D: 0.3715, Loss G: 2.0636\n",
      "Epoch [71/85] Batch 730/938 Loss D: 0.2408, Loss G: 2.5365\n",
      "Epoch [71/85] Batch 740/938 Loss D: 0.3063, Loss G: 2.9278\n",
      "Epoch [71/85] Batch 750/938 Loss D: 0.2230, Loss G: 3.0002\n",
      "Epoch [71/85] Batch 760/938 Loss D: 0.2507, Loss G: 4.8894\n",
      "Epoch [71/85] Batch 770/938 Loss D: 0.3101, Loss G: 2.8536\n",
      "Epoch [71/85] Batch 780/938 Loss D: 0.2035, Loss G: 3.4061\n",
      "Epoch [71/85] Batch 790/938 Loss D: 0.3369, Loss G: 2.2294\n",
      "Epoch [71/85] Batch 800/938 Loss D: 0.3481, Loss G: 1.9080\n",
      "Epoch [71/85] Batch 810/938 Loss D: 0.1864, Loss G: 2.5950\n",
      "Epoch [71/85] Batch 820/938 Loss D: 0.3079, Loss G: 2.3267\n",
      "Epoch [71/85] Batch 830/938 Loss D: 0.2767, Loss G: 2.8610\n",
      "Epoch [71/85] Batch 840/938 Loss D: 0.5332, Loss G: 2.1400\n",
      "Epoch [71/85] Batch 850/938 Loss D: 0.1624, Loss G: 4.2368\n",
      "Epoch [71/85] Batch 860/938 Loss D: 0.3182, Loss G: 2.1687\n",
      "Epoch [71/85] Batch 870/938 Loss D: 0.3180, Loss G: 2.1563\n",
      "Epoch [71/85] Batch 880/938 Loss D: 0.2482, Loss G: 2.4698\n",
      "Epoch [71/85] Batch 890/938 Loss D: 0.3369, Loss G: 1.8247\n",
      "Epoch [71/85] Batch 900/938 Loss D: 0.3085, Loss G: 2.7976\n",
      "Epoch [71/85] Batch 910/938 Loss D: 0.2232, Loss G: 2.8347\n",
      "Epoch [71/85] Batch 920/938 Loss D: 0.2300, Loss G: 2.9162\n",
      "Epoch [71/85] Batch 930/938 Loss D: 0.2702, Loss G: 2.6076\n",
      "Epoch [72/85] Batch 0/938 Loss D: 0.3577, Loss G: 1.9449\n",
      "Epoch [72/85] Batch 10/938 Loss D: 0.3686, Loss G: 1.5527\n",
      "Epoch [72/85] Batch 20/938 Loss D: 0.3496, Loss G: 2.5321\n",
      "Epoch [72/85] Batch 30/938 Loss D: 0.2869, Loss G: 3.8502\n",
      "Epoch [72/85] Batch 40/938 Loss D: 0.2436, Loss G: 2.9266\n",
      "Epoch [72/85] Batch 50/938 Loss D: 0.3125, Loss G: 2.4141\n",
      "Epoch [72/85] Batch 60/938 Loss D: 0.2728, Loss G: 2.6265\n",
      "Epoch [72/85] Batch 70/938 Loss D: 0.2945, Loss G: 2.0638\n",
      "Epoch [72/85] Batch 80/938 Loss D: 0.3059, Loss G: 2.4687\n",
      "Epoch [72/85] Batch 90/938 Loss D: 0.3803, Loss G: 2.0079\n",
      "Epoch [72/85] Batch 100/938 Loss D: 0.3392, Loss G: 2.2453\n",
      "Epoch [72/85] Batch 110/938 Loss D: 0.3357, Loss G: 2.7481\n",
      "Epoch [72/85] Batch 120/938 Loss D: 0.1962, Loss G: 2.9713\n",
      "Epoch [72/85] Batch 130/938 Loss D: 0.3427, Loss G: 2.3675\n",
      "Epoch [72/85] Batch 140/938 Loss D: 0.3779, Loss G: 1.8665\n",
      "Epoch [72/85] Batch 150/938 Loss D: 0.3123, Loss G: 2.1151\n",
      "Epoch [72/85] Batch 160/938 Loss D: 0.3126, Loss G: 1.8853\n",
      "Epoch [72/85] Batch 170/938 Loss D: 0.3677, Loss G: 2.4364\n",
      "Epoch [72/85] Batch 180/938 Loss D: 0.2767, Loss G: 2.4268\n",
      "Epoch [72/85] Batch 190/938 Loss D: 0.4704, Loss G: 2.1153\n",
      "Epoch [72/85] Batch 200/938 Loss D: 0.2389, Loss G: 2.6539\n",
      "Epoch [72/85] Batch 210/938 Loss D: 0.3102, Loss G: 2.7831\n",
      "Epoch [72/85] Batch 220/938 Loss D: 0.2828, Loss G: 2.3277\n",
      "Epoch [72/85] Batch 230/938 Loss D: 0.2950, Loss G: 2.5364\n",
      "Epoch [72/85] Batch 240/938 Loss D: 0.3485, Loss G: 1.8949\n",
      "Epoch [72/85] Batch 250/938 Loss D: 0.2018, Loss G: 3.3042\n",
      "Epoch [72/85] Batch 260/938 Loss D: 0.3125, Loss G: 2.2259\n",
      "Epoch [72/85] Batch 270/938 Loss D: 0.1674, Loss G: 2.8941\n",
      "Epoch [72/85] Batch 280/938 Loss D: 0.3039, Loss G: 2.3401\n",
      "Epoch [72/85] Batch 290/938 Loss D: 0.3017, Loss G: 1.9733\n",
      "Epoch [72/85] Batch 300/938 Loss D: 0.2415, Loss G: 2.6024\n",
      "Epoch [72/85] Batch 310/938 Loss D: 0.1850, Loss G: 2.9132\n",
      "Epoch [72/85] Batch 320/938 Loss D: 0.3482, Loss G: 2.9923\n",
      "Epoch [72/85] Batch 330/938 Loss D: 0.3317, Loss G: 3.0050\n",
      "Epoch [72/85] Batch 340/938 Loss D: 0.2289, Loss G: 2.6938\n",
      "Epoch [72/85] Batch 350/938 Loss D: 0.2239, Loss G: 2.4443\n",
      "Epoch [72/85] Batch 360/938 Loss D: 0.2928, Loss G: 2.1629\n",
      "Epoch [72/85] Batch 370/938 Loss D: 0.3001, Loss G: 2.3391\n",
      "Epoch [72/85] Batch 380/938 Loss D: 0.3966, Loss G: 2.2923\n",
      "Epoch [72/85] Batch 390/938 Loss D: 0.2383, Loss G: 3.1696\n",
      "Epoch [72/85] Batch 400/938 Loss D: 0.3519, Loss G: 2.2993\n",
      "Epoch [72/85] Batch 410/938 Loss D: 0.2778, Loss G: 2.7432\n",
      "Epoch [72/85] Batch 420/938 Loss D: 0.3017, Loss G: 2.7873\n",
      "Epoch [72/85] Batch 430/938 Loss D: 0.2356, Loss G: 2.9578\n",
      "Epoch [72/85] Batch 440/938 Loss D: 0.5325, Loss G: 1.5520\n",
      "Epoch [72/85] Batch 450/938 Loss D: 0.1856, Loss G: 3.0235\n",
      "Epoch [72/85] Batch 460/938 Loss D: 0.2596, Loss G: 2.6390\n",
      "Epoch [72/85] Batch 470/938 Loss D: 0.2044, Loss G: 2.6206\n",
      "Epoch [72/85] Batch 480/938 Loss D: 0.2679, Loss G: 2.0899\n",
      "Epoch [72/85] Batch 490/938 Loss D: 0.2761, Loss G: 2.5678\n",
      "Epoch [72/85] Batch 500/938 Loss D: 0.5055, Loss G: 1.9283\n",
      "Epoch [72/85] Batch 510/938 Loss D: 0.2694, Loss G: 3.0501\n",
      "Epoch [72/85] Batch 520/938 Loss D: 0.5157, Loss G: 3.4862\n",
      "Epoch [72/85] Batch 530/938 Loss D: 0.3145, Loss G: 3.1269\n",
      "Epoch [72/85] Batch 540/938 Loss D: 0.4089, Loss G: 2.5682\n",
      "Epoch [72/85] Batch 550/938 Loss D: 0.3109, Loss G: 2.2170\n",
      "Epoch [72/85] Batch 560/938 Loss D: 0.1882, Loss G: 2.6571\n",
      "Epoch [72/85] Batch 570/938 Loss D: 0.2899, Loss G: 3.2659\n",
      "Epoch [72/85] Batch 580/938 Loss D: 0.2099, Loss G: 2.6618\n",
      "Epoch [72/85] Batch 590/938 Loss D: 0.2782, Loss G: 2.8124\n",
      "Epoch [72/85] Batch 600/938 Loss D: 0.2657, Loss G: 2.3039\n",
      "Epoch [72/85] Batch 610/938 Loss D: 0.2633, Loss G: 2.4861\n",
      "Epoch [72/85] Batch 620/938 Loss D: 0.5335, Loss G: 1.6382\n",
      "Epoch [72/85] Batch 630/938 Loss D: 0.3868, Loss G: 2.1651\n",
      "Epoch [72/85] Batch 640/938 Loss D: 0.3650, Loss G: 2.1639\n",
      "Epoch [72/85] Batch 650/938 Loss D: 0.3108, Loss G: 2.3058\n",
      "Epoch [72/85] Batch 660/938 Loss D: 0.2923, Loss G: 2.4170\n",
      "Epoch [72/85] Batch 670/938 Loss D: 0.3728, Loss G: 1.8348\n",
      "Epoch [72/85] Batch 680/938 Loss D: 0.3362, Loss G: 2.4906\n",
      "Epoch [72/85] Batch 690/938 Loss D: 0.3268, Loss G: 2.7280\n",
      "Epoch [72/85] Batch 700/938 Loss D: 0.3690, Loss G: 2.1405\n",
      "Epoch [72/85] Batch 710/938 Loss D: 0.2983, Loss G: 2.3741\n",
      "Epoch [72/85] Batch 720/938 Loss D: 0.2796, Loss G: 2.1366\n",
      "Epoch [72/85] Batch 730/938 Loss D: 0.3515, Loss G: 2.1499\n",
      "Epoch [72/85] Batch 740/938 Loss D: 0.3265, Loss G: 2.0690\n",
      "Epoch [72/85] Batch 750/938 Loss D: 0.2529, Loss G: 2.4414\n",
      "Epoch [72/85] Batch 760/938 Loss D: 0.2207, Loss G: 2.9967\n",
      "Epoch [72/85] Batch 770/938 Loss D: 0.3306, Loss G: 2.6237\n",
      "Epoch [72/85] Batch 780/938 Loss D: 0.3676, Loss G: 2.3619\n",
      "Epoch [72/85] Batch 790/938 Loss D: 0.2372, Loss G: 2.6436\n",
      "Epoch [72/85] Batch 800/938 Loss D: 0.2844, Loss G: 2.2498\n",
      "Epoch [72/85] Batch 810/938 Loss D: 0.2826, Loss G: 2.4415\n",
      "Epoch [72/85] Batch 820/938 Loss D: 0.3049, Loss G: 2.8602\n",
      "Epoch [72/85] Batch 830/938 Loss D: 0.3949, Loss G: 2.2970\n",
      "Epoch [72/85] Batch 840/938 Loss D: 0.2974, Loss G: 1.7963\n",
      "Epoch [72/85] Batch 850/938 Loss D: 0.3138, Loss G: 2.8568\n",
      "Epoch [72/85] Batch 860/938 Loss D: 0.3260, Loss G: 2.9475\n",
      "Epoch [72/85] Batch 870/938 Loss D: 0.2757, Loss G: 2.6983\n",
      "Epoch [72/85] Batch 880/938 Loss D: 0.4145, Loss G: 1.8431\n",
      "Epoch [72/85] Batch 890/938 Loss D: 0.1513, Loss G: 3.3676\n",
      "Epoch [72/85] Batch 900/938 Loss D: 0.2693, Loss G: 3.1915\n",
      "Epoch [72/85] Batch 910/938 Loss D: 0.3231, Loss G: 2.2416\n",
      "Epoch [72/85] Batch 920/938 Loss D: 0.2403, Loss G: 2.4083\n",
      "Epoch [72/85] Batch 930/938 Loss D: 0.2224, Loss G: 2.7190\n",
      "Epoch [73/85] Batch 0/938 Loss D: 0.3184, Loss G: 2.1716\n",
      "Epoch [73/85] Batch 10/938 Loss D: 0.2926, Loss G: 1.9447\n",
      "Epoch [73/85] Batch 20/938 Loss D: 0.2654, Loss G: 3.1650\n",
      "Epoch [73/85] Batch 30/938 Loss D: 0.4113, Loss G: 2.1482\n",
      "Epoch [73/85] Batch 40/938 Loss D: 0.2856, Loss G: 2.6472\n",
      "Epoch [73/85] Batch 50/938 Loss D: 0.2652, Loss G: 2.1311\n",
      "Epoch [73/85] Batch 60/938 Loss D: 0.2357, Loss G: 2.2211\n",
      "Epoch [73/85] Batch 70/938 Loss D: 0.2682, Loss G: 2.5597\n",
      "Epoch [73/85] Batch 80/938 Loss D: 0.3700, Loss G: 2.3055\n",
      "Epoch [73/85] Batch 90/938 Loss D: 0.2795, Loss G: 2.0538\n",
      "Epoch [73/85] Batch 100/938 Loss D: 0.4068, Loss G: 2.0502\n",
      "Epoch [73/85] Batch 110/938 Loss D: 0.2914, Loss G: 2.7690\n",
      "Epoch [73/85] Batch 120/938 Loss D: 0.2573, Loss G: 2.6233\n",
      "Epoch [73/85] Batch 130/938 Loss D: 0.3613, Loss G: 1.9637\n",
      "Epoch [73/85] Batch 140/938 Loss D: 0.3448, Loss G: 2.3854\n",
      "Epoch [73/85] Batch 150/938 Loss D: 0.2752, Loss G: 2.1068\n",
      "Epoch [73/85] Batch 160/938 Loss D: 0.1767, Loss G: 2.7478\n",
      "Epoch [73/85] Batch 170/938 Loss D: 0.3522, Loss G: 2.2164\n",
      "Epoch [73/85] Batch 180/938 Loss D: 0.3427, Loss G: 2.0410\n",
      "Epoch [73/85] Batch 190/938 Loss D: 0.2708, Loss G: 2.4210\n",
      "Epoch [73/85] Batch 200/938 Loss D: 0.2863, Loss G: 2.9196\n",
      "Epoch [73/85] Batch 210/938 Loss D: 0.2398, Loss G: 2.9028\n",
      "Epoch [73/85] Batch 220/938 Loss D: 0.2888, Loss G: 3.0049\n",
      "Epoch [73/85] Batch 230/938 Loss D: 0.2866, Loss G: 2.3505\n",
      "Epoch [73/85] Batch 240/938 Loss D: 0.1555, Loss G: 2.9074\n",
      "Epoch [73/85] Batch 250/938 Loss D: 0.2295, Loss G: 2.9308\n",
      "Epoch [73/85] Batch 260/938 Loss D: 0.2226, Loss G: 3.5310\n",
      "Epoch [73/85] Batch 270/938 Loss D: 0.2047, Loss G: 2.3062\n",
      "Epoch [73/85] Batch 280/938 Loss D: 0.3093, Loss G: 2.3606\n",
      "Epoch [73/85] Batch 290/938 Loss D: 0.2930, Loss G: 2.6249\n",
      "Epoch [73/85] Batch 300/938 Loss D: 0.1692, Loss G: 3.5926\n",
      "Epoch [73/85] Batch 310/938 Loss D: 0.2694, Loss G: 2.4231\n",
      "Epoch [73/85] Batch 320/938 Loss D: 0.3354, Loss G: 2.0592\n",
      "Epoch [73/85] Batch 330/938 Loss D: 0.2348, Loss G: 3.3411\n",
      "Epoch [73/85] Batch 340/938 Loss D: 0.2804, Loss G: 2.8698\n",
      "Epoch [73/85] Batch 350/938 Loss D: 0.1232, Loss G: 3.8593\n",
      "Epoch [73/85] Batch 360/938 Loss D: 0.2387, Loss G: 2.6615\n",
      "Epoch [73/85] Batch 370/938 Loss D: 0.3459, Loss G: 2.1469\n",
      "Epoch [73/85] Batch 380/938 Loss D: 0.3258, Loss G: 1.8761\n",
      "Epoch [73/85] Batch 390/938 Loss D: 0.3109, Loss G: 2.5963\n",
      "Epoch [73/85] Batch 400/938 Loss D: 0.2778, Loss G: 2.3711\n",
      "Epoch [73/85] Batch 410/938 Loss D: 0.2230, Loss G: 2.4293\n",
      "Epoch [73/85] Batch 420/938 Loss D: 0.2805, Loss G: 1.8168\n",
      "Epoch [73/85] Batch 430/938 Loss D: 0.2897, Loss G: 2.1972\n",
      "Epoch [73/85] Batch 440/938 Loss D: 0.3978, Loss G: 2.4627\n",
      "Epoch [73/85] Batch 450/938 Loss D: 0.3077, Loss G: 3.0897\n",
      "Epoch [73/85] Batch 460/938 Loss D: 0.2730, Loss G: 2.5995\n",
      "Epoch [73/85] Batch 470/938 Loss D: 0.2434, Loss G: 2.5396\n",
      "Epoch [73/85] Batch 480/938 Loss D: 0.2106, Loss G: 2.2365\n",
      "Epoch [73/85] Batch 490/938 Loss D: 0.2295, Loss G: 2.5423\n",
      "Epoch [73/85] Batch 500/938 Loss D: 0.2779, Loss G: 2.7403\n",
      "Epoch [73/85] Batch 510/938 Loss D: 0.2499, Loss G: 2.1966\n",
      "Epoch [73/85] Batch 520/938 Loss D: 0.2194, Loss G: 2.2167\n",
      "Epoch [73/85] Batch 530/938 Loss D: 0.2397, Loss G: 3.2839\n",
      "Epoch [73/85] Batch 540/938 Loss D: 0.3077, Loss G: 2.4304\n",
      "Epoch [73/85] Batch 550/938 Loss D: 0.3891, Loss G: 2.1202\n",
      "Epoch [73/85] Batch 560/938 Loss D: 0.1809, Loss G: 2.3191\n",
      "Epoch [73/85] Batch 570/938 Loss D: 0.3172, Loss G: 1.7875\n",
      "Epoch [73/85] Batch 580/938 Loss D: 0.2293, Loss G: 2.9217\n",
      "Epoch [73/85] Batch 590/938 Loss D: 0.4217, Loss G: 2.8573\n",
      "Epoch [73/85] Batch 600/938 Loss D: 0.2568, Loss G: 2.8750\n",
      "Epoch [73/85] Batch 610/938 Loss D: 0.2381, Loss G: 2.6704\n",
      "Epoch [73/85] Batch 620/938 Loss D: 0.1486, Loss G: 2.5184\n",
      "Epoch [73/85] Batch 630/938 Loss D: 0.1940, Loss G: 3.3802\n",
      "Epoch [73/85] Batch 640/938 Loss D: 0.3069, Loss G: 2.8664\n",
      "Epoch [73/85] Batch 650/938 Loss D: 0.2290, Loss G: 2.9319\n",
      "Epoch [73/85] Batch 660/938 Loss D: 0.2238, Loss G: 3.5980\n",
      "Epoch [73/85] Batch 670/938 Loss D: 0.1546, Loss G: 3.9651\n",
      "Epoch [73/85] Batch 680/938 Loss D: 0.2324, Loss G: 3.1893\n",
      "Epoch [73/85] Batch 690/938 Loss D: 0.2899, Loss G: 2.6713\n",
      "Epoch [73/85] Batch 700/938 Loss D: 0.3214, Loss G: 2.5640\n",
      "Epoch [73/85] Batch 710/938 Loss D: 0.2669, Loss G: 2.3250\n",
      "Epoch [73/85] Batch 720/938 Loss D: 0.5223, Loss G: 1.5690\n",
      "Epoch [73/85] Batch 730/938 Loss D: 0.3473, Loss G: 2.6087\n",
      "Epoch [73/85] Batch 740/938 Loss D: 0.2419, Loss G: 2.5708\n",
      "Epoch [73/85] Batch 750/938 Loss D: 0.2982, Loss G: 3.0120\n",
      "Epoch [73/85] Batch 760/938 Loss D: 0.3381, Loss G: 1.9817\n",
      "Epoch [73/85] Batch 770/938 Loss D: 0.3071, Loss G: 2.3203\n",
      "Epoch [73/85] Batch 780/938 Loss D: 0.2803, Loss G: 3.2837\n",
      "Epoch [73/85] Batch 790/938 Loss D: 0.2519, Loss G: 2.4546\n",
      "Epoch [73/85] Batch 800/938 Loss D: 0.2698, Loss G: 3.0022\n",
      "Epoch [73/85] Batch 810/938 Loss D: 0.3065, Loss G: 2.7624\n",
      "Epoch [73/85] Batch 820/938 Loss D: 0.3454, Loss G: 2.5433\n",
      "Epoch [73/85] Batch 830/938 Loss D: 0.2370, Loss G: 2.3631\n",
      "Epoch [73/85] Batch 840/938 Loss D: 0.3372, Loss G: 2.3899\n",
      "Epoch [73/85] Batch 850/938 Loss D: 0.2518, Loss G: 3.3245\n",
      "Epoch [73/85] Batch 860/938 Loss D: 0.2481, Loss G: 3.0130\n",
      "Epoch [73/85] Batch 870/938 Loss D: 0.2748, Loss G: 2.3997\n",
      "Epoch [73/85] Batch 880/938 Loss D: 0.3624, Loss G: 1.9179\n",
      "Epoch [73/85] Batch 890/938 Loss D: 0.3234, Loss G: 1.8465\n",
      "Epoch [73/85] Batch 900/938 Loss D: 0.1877, Loss G: 3.0270\n",
      "Epoch [73/85] Batch 910/938 Loss D: 0.4167, Loss G: 3.2006\n",
      "Epoch [73/85] Batch 920/938 Loss D: 0.2440, Loss G: 3.3231\n",
      "Epoch [73/85] Batch 930/938 Loss D: 0.3274, Loss G: 2.7152\n",
      "Epoch [74/85] Batch 0/938 Loss D: 0.3798, Loss G: 1.5539\n",
      "Epoch [74/85] Batch 10/938 Loss D: 0.3225, Loss G: 2.1586\n",
      "Epoch [74/85] Batch 20/938 Loss D: 0.2501, Loss G: 3.6362\n",
      "Epoch [74/85] Batch 30/938 Loss D: 0.2111, Loss G: 2.9383\n",
      "Epoch [74/85] Batch 40/938 Loss D: 0.2509, Loss G: 2.7014\n",
      "Epoch [74/85] Batch 50/938 Loss D: 0.2236, Loss G: 2.5532\n",
      "Epoch [74/85] Batch 60/938 Loss D: 0.3636, Loss G: 2.3875\n",
      "Epoch [74/85] Batch 70/938 Loss D: 0.2273, Loss G: 3.1324\n",
      "Epoch [74/85] Batch 80/938 Loss D: 0.3098, Loss G: 3.1642\n",
      "Epoch [74/85] Batch 90/938 Loss D: 0.2682, Loss G: 2.2958\n",
      "Epoch [74/85] Batch 100/938 Loss D: 0.1988, Loss G: 2.7411\n",
      "Epoch [74/85] Batch 110/938 Loss D: 0.5076, Loss G: 2.0148\n",
      "Epoch [74/85] Batch 120/938 Loss D: 0.3561, Loss G: 2.7450\n",
      "Epoch [74/85] Batch 130/938 Loss D: 0.3153, Loss G: 2.1967\n",
      "Epoch [74/85] Batch 140/938 Loss D: 0.5098, Loss G: 2.2702\n",
      "Epoch [74/85] Batch 150/938 Loss D: 0.4171, Loss G: 2.2650\n",
      "Epoch [74/85] Batch 160/938 Loss D: 0.2808, Loss G: 3.0831\n",
      "Epoch [74/85] Batch 170/938 Loss D: 0.2036, Loss G: 3.2235\n",
      "Epoch [74/85] Batch 180/938 Loss D: 0.2386, Loss G: 2.3742\n",
      "Epoch [74/85] Batch 190/938 Loss D: 0.2184, Loss G: 2.6960\n",
      "Epoch [74/85] Batch 200/938 Loss D: 0.1889, Loss G: 3.4632\n",
      "Epoch [74/85] Batch 210/938 Loss D: 0.2814, Loss G: 2.5996\n",
      "Epoch [74/85] Batch 220/938 Loss D: 0.3771, Loss G: 2.2039\n",
      "Epoch [74/85] Batch 230/938 Loss D: 0.2376, Loss G: 2.5106\n",
      "Epoch [74/85] Batch 240/938 Loss D: 0.2788, Loss G: 2.3066\n",
      "Epoch [74/85] Batch 250/938 Loss D: 0.1287, Loss G: 3.0056\n",
      "Epoch [74/85] Batch 260/938 Loss D: 0.2468, Loss G: 2.5630\n",
      "Epoch [74/85] Batch 270/938 Loss D: 0.3653, Loss G: 2.4403\n",
      "Epoch [74/85] Batch 280/938 Loss D: 0.4584, Loss G: 2.1819\n",
      "Epoch [74/85] Batch 290/938 Loss D: 0.2848, Loss G: 2.5237\n",
      "Epoch [74/85] Batch 300/938 Loss D: 0.2860, Loss G: 2.2788\n",
      "Epoch [74/85] Batch 310/938 Loss D: 0.3936, Loss G: 1.9860\n",
      "Epoch [74/85] Batch 320/938 Loss D: 0.2912, Loss G: 2.5449\n",
      "Epoch [74/85] Batch 330/938 Loss D: 0.2932, Loss G: 2.1236\n",
      "Epoch [74/85] Batch 340/938 Loss D: 0.2553, Loss G: 2.9406\n",
      "Epoch [74/85] Batch 350/938 Loss D: 0.3781, Loss G: 2.1359\n",
      "Epoch [74/85] Batch 360/938 Loss D: 0.2389, Loss G: 2.2012\n",
      "Epoch [74/85] Batch 370/938 Loss D: 0.2930, Loss G: 2.1144\n",
      "Epoch [74/85] Batch 380/938 Loss D: 0.2985, Loss G: 3.1433\n",
      "Epoch [74/85] Batch 390/938 Loss D: 0.2103, Loss G: 3.2790\n",
      "Epoch [74/85] Batch 400/938 Loss D: 0.2789, Loss G: 3.6054\n",
      "Epoch [74/85] Batch 410/938 Loss D: 0.2314, Loss G: 2.4870\n",
      "Epoch [74/85] Batch 420/938 Loss D: 0.2143, Loss G: 2.6199\n",
      "Epoch [74/85] Batch 430/938 Loss D: 0.1690, Loss G: 3.7670\n",
      "Epoch [74/85] Batch 440/938 Loss D: 0.2122, Loss G: 3.5131\n",
      "Epoch [74/85] Batch 450/938 Loss D: 0.3456, Loss G: 2.3025\n",
      "Epoch [74/85] Batch 460/938 Loss D: 0.3378, Loss G: 2.0012\n",
      "Epoch [74/85] Batch 470/938 Loss D: 0.3422, Loss G: 3.1487\n",
      "Epoch [74/85] Batch 480/938 Loss D: 0.4150, Loss G: 2.2457\n",
      "Epoch [74/85] Batch 490/938 Loss D: 0.2886, Loss G: 2.1696\n",
      "Epoch [74/85] Batch 500/938 Loss D: 0.4543, Loss G: 1.9723\n",
      "Epoch [74/85] Batch 510/938 Loss D: 0.2808, Loss G: 2.1276\n",
      "Epoch [74/85] Batch 520/938 Loss D: 0.4785, Loss G: 1.4747\n",
      "Epoch [74/85] Batch 530/938 Loss D: 0.3216, Loss G: 2.0449\n",
      "Epoch [74/85] Batch 540/938 Loss D: 0.2988, Loss G: 2.5063\n",
      "Epoch [74/85] Batch 550/938 Loss D: 0.2919, Loss G: 2.4389\n",
      "Epoch [74/85] Batch 560/938 Loss D: 0.2187, Loss G: 2.7275\n",
      "Epoch [74/85] Batch 570/938 Loss D: 0.1877, Loss G: 2.8099\n",
      "Epoch [74/85] Batch 580/938 Loss D: 0.3089, Loss G: 2.9251\n",
      "Epoch [74/85] Batch 590/938 Loss D: 0.2113, Loss G: 2.6890\n",
      "Epoch [74/85] Batch 600/938 Loss D: 0.3024, Loss G: 1.8570\n",
      "Epoch [74/85] Batch 610/938 Loss D: 0.3567, Loss G: 1.8666\n",
      "Epoch [74/85] Batch 620/938 Loss D: 0.1445, Loss G: 2.9955\n",
      "Epoch [74/85] Batch 630/938 Loss D: 0.2148, Loss G: 2.7666\n",
      "Epoch [74/85] Batch 640/938 Loss D: 0.3804, Loss G: 1.8836\n",
      "Epoch [74/85] Batch 650/938 Loss D: 0.4229, Loss G: 2.4746\n",
      "Epoch [74/85] Batch 660/938 Loss D: 0.2521, Loss G: 2.4525\n",
      "Epoch [74/85] Batch 670/938 Loss D: 0.2183, Loss G: 2.1195\n",
      "Epoch [74/85] Batch 680/938 Loss D: 0.2487, Loss G: 3.2580\n",
      "Epoch [74/85] Batch 690/938 Loss D: 0.3285, Loss G: 3.3445\n",
      "Epoch [74/85] Batch 700/938 Loss D: 0.2124, Loss G: 2.6312\n",
      "Epoch [74/85] Batch 710/938 Loss D: 0.3650, Loss G: 2.1809\n",
      "Epoch [74/85] Batch 720/938 Loss D: 0.3426, Loss G: 1.6876\n",
      "Epoch [74/85] Batch 730/938 Loss D: 0.2380, Loss G: 2.8325\n",
      "Epoch [74/85] Batch 740/938 Loss D: 0.2556, Loss G: 2.4771\n",
      "Epoch [74/85] Batch 750/938 Loss D: 0.3134, Loss G: 2.1201\n",
      "Epoch [74/85] Batch 760/938 Loss D: 0.2858, Loss G: 2.2185\n",
      "Epoch [74/85] Batch 770/938 Loss D: 0.1993, Loss G: 2.9232\n",
      "Epoch [74/85] Batch 780/938 Loss D: 0.3317, Loss G: 2.4543\n",
      "Epoch [74/85] Batch 790/938 Loss D: 0.2040, Loss G: 4.0835\n",
      "Epoch [74/85] Batch 800/938 Loss D: 0.3432, Loss G: 2.0551\n",
      "Epoch [74/85] Batch 810/938 Loss D: 0.2426, Loss G: 2.9399\n",
      "Epoch [74/85] Batch 820/938 Loss D: 0.3165, Loss G: 2.9620\n",
      "Epoch [74/85] Batch 830/938 Loss D: 0.2654, Loss G: 2.7899\n",
      "Epoch [74/85] Batch 840/938 Loss D: 0.4086, Loss G: 2.5591\n",
      "Epoch [74/85] Batch 850/938 Loss D: 0.1952, Loss G: 2.6111\n",
      "Epoch [74/85] Batch 860/938 Loss D: 0.1915, Loss G: 2.9613\n",
      "Epoch [74/85] Batch 870/938 Loss D: 0.2060, Loss G: 3.9535\n",
      "Epoch [74/85] Batch 880/938 Loss D: 0.2721, Loss G: 2.3582\n",
      "Epoch [74/85] Batch 890/938 Loss D: 0.2812, Loss G: 2.0054\n",
      "Epoch [74/85] Batch 900/938 Loss D: 0.3495, Loss G: 2.0290\n",
      "Epoch [74/85] Batch 910/938 Loss D: 0.2881, Loss G: 2.4907\n",
      "Epoch [74/85] Batch 920/938 Loss D: 0.2937, Loss G: 2.6637\n",
      "Epoch [74/85] Batch 930/938 Loss D: 0.2638, Loss G: 2.5415\n",
      "Epoch [75/85] Batch 0/938 Loss D: 0.2949, Loss G: 1.6397\n",
      "Epoch [75/85] Batch 10/938 Loss D: 0.2716, Loss G: 2.5905\n",
      "Epoch [75/85] Batch 20/938 Loss D: 0.3442, Loss G: 2.6572\n",
      "Epoch [75/85] Batch 30/938 Loss D: 0.2336, Loss G: 2.3001\n",
      "Epoch [75/85] Batch 40/938 Loss D: 0.2492, Loss G: 2.1461\n",
      "Epoch [75/85] Batch 50/938 Loss D: 0.3060, Loss G: 2.3591\n",
      "Epoch [75/85] Batch 60/938 Loss D: 0.3476, Loss G: 2.5134\n",
      "Epoch [75/85] Batch 70/938 Loss D: 0.4257, Loss G: 1.9408\n",
      "Epoch [75/85] Batch 80/938 Loss D: 0.2432, Loss G: 3.5986\n",
      "Epoch [75/85] Batch 90/938 Loss D: 0.3412, Loss G: 2.4401\n",
      "Epoch [75/85] Batch 100/938 Loss D: 0.2026, Loss G: 2.8659\n",
      "Epoch [75/85] Batch 110/938 Loss D: 0.2719, Loss G: 2.8170\n",
      "Epoch [75/85] Batch 120/938 Loss D: 0.3119, Loss G: 2.5997\n",
      "Epoch [75/85] Batch 130/938 Loss D: 0.2068, Loss G: 3.8503\n",
      "Epoch [75/85] Batch 140/938 Loss D: 0.1720, Loss G: 3.9333\n",
      "Epoch [75/85] Batch 150/938 Loss D: 0.2007, Loss G: 3.4857\n",
      "Epoch [75/85] Batch 160/938 Loss D: 0.1638, Loss G: 3.9627\n",
      "Epoch [75/85] Batch 170/938 Loss D: 0.4551, Loss G: 2.0408\n",
      "Epoch [75/85] Batch 180/938 Loss D: 0.2691, Loss G: 2.0872\n",
      "Epoch [75/85] Batch 190/938 Loss D: 0.3067, Loss G: 2.1475\n",
      "Epoch [75/85] Batch 200/938 Loss D: 0.2037, Loss G: 2.1916\n",
      "Epoch [75/85] Batch 210/938 Loss D: 0.3092, Loss G: 2.4714\n",
      "Epoch [75/85] Batch 220/938 Loss D: 0.1399, Loss G: 3.7954\n",
      "Epoch [75/85] Batch 230/938 Loss D: 0.2076, Loss G: 2.7425\n",
      "Epoch [75/85] Batch 240/938 Loss D: 0.3052, Loss G: 2.4099\n",
      "Epoch [75/85] Batch 250/938 Loss D: 0.2821, Loss G: 1.9845\n",
      "Epoch [75/85] Batch 260/938 Loss D: 0.2900, Loss G: 1.9569\n",
      "Epoch [75/85] Batch 270/938 Loss D: 0.3373, Loss G: 2.4994\n",
      "Epoch [75/85] Batch 280/938 Loss D: 0.3775, Loss G: 2.6377\n",
      "Epoch [75/85] Batch 290/938 Loss D: 0.1534, Loss G: 3.4102\n",
      "Epoch [75/85] Batch 300/938 Loss D: 0.2771, Loss G: 2.3069\n",
      "Epoch [75/85] Batch 310/938 Loss D: 0.3228, Loss G: 2.3706\n",
      "Epoch [75/85] Batch 320/938 Loss D: 0.2998, Loss G: 3.2455\n",
      "Epoch [75/85] Batch 330/938 Loss D: 0.2262, Loss G: 2.6658\n",
      "Epoch [75/85] Batch 340/938 Loss D: 0.3519, Loss G: 1.9057\n",
      "Epoch [75/85] Batch 350/938 Loss D: 0.3927, Loss G: 2.4209\n",
      "Epoch [75/85] Batch 360/938 Loss D: 0.3281, Loss G: 2.6968\n",
      "Epoch [75/85] Batch 370/938 Loss D: 0.2524, Loss G: 2.5905\n",
      "Epoch [75/85] Batch 380/938 Loss D: 0.2646, Loss G: 2.5941\n",
      "Epoch [75/85] Batch 390/938 Loss D: 0.2881, Loss G: 1.9633\n",
      "Epoch [75/85] Batch 400/938 Loss D: 0.1572, Loss G: 3.6468\n",
      "Epoch [75/85] Batch 410/938 Loss D: 0.2662, Loss G: 2.6713\n",
      "Epoch [75/85] Batch 420/938 Loss D: 0.5061, Loss G: 2.0008\n",
      "Epoch [75/85] Batch 430/938 Loss D: 0.2086, Loss G: 2.9948\n",
      "Epoch [75/85] Batch 440/938 Loss D: 0.3993, Loss G: 1.9434\n",
      "Epoch [75/85] Batch 450/938 Loss D: 0.3661, Loss G: 2.5324\n",
      "Epoch [75/85] Batch 460/938 Loss D: 0.2890, Loss G: 2.6638\n",
      "Epoch [75/85] Batch 470/938 Loss D: 0.2960, Loss G: 2.6748\n",
      "Epoch [75/85] Batch 480/938 Loss D: 0.2202, Loss G: 4.1094\n",
      "Epoch [75/85] Batch 490/938 Loss D: 0.2078, Loss G: 3.5436\n",
      "Epoch [75/85] Batch 500/938 Loss D: 0.1656, Loss G: 3.8237\n",
      "Epoch [75/85] Batch 510/938 Loss D: 0.2680, Loss G: 3.0052\n",
      "Epoch [75/85] Batch 520/938 Loss D: 0.2166, Loss G: 3.2211\n",
      "Epoch [75/85] Batch 530/938 Loss D: 0.2072, Loss G: 2.9983\n",
      "Epoch [75/85] Batch 540/938 Loss D: 0.3008, Loss G: 2.6621\n",
      "Epoch [75/85] Batch 550/938 Loss D: 0.3045, Loss G: 3.3512\n",
      "Epoch [75/85] Batch 560/938 Loss D: 0.2935, Loss G: 2.2743\n",
      "Epoch [75/85] Batch 570/938 Loss D: 0.4243, Loss G: 2.2487\n",
      "Epoch [75/85] Batch 580/938 Loss D: 0.3437, Loss G: 1.8226\n",
      "Epoch [75/85] Batch 590/938 Loss D: 0.2865, Loss G: 2.4145\n",
      "Epoch [75/85] Batch 600/938 Loss D: 0.2657, Loss G: 1.9330\n",
      "Epoch [75/85] Batch 610/938 Loss D: 0.2626, Loss G: 2.9581\n",
      "Epoch [75/85] Batch 620/938 Loss D: 0.2798, Loss G: 2.8813\n",
      "Epoch [75/85] Batch 630/938 Loss D: 0.2472, Loss G: 3.2366\n",
      "Epoch [75/85] Batch 640/938 Loss D: 0.3511, Loss G: 2.0777\n",
      "Epoch [75/85] Batch 650/938 Loss D: 0.3530, Loss G: 2.1359\n",
      "Epoch [75/85] Batch 660/938 Loss D: 0.3025, Loss G: 2.6074\n",
      "Epoch [75/85] Batch 670/938 Loss D: 0.2401, Loss G: 1.9243\n",
      "Epoch [75/85] Batch 680/938 Loss D: 0.2095, Loss G: 2.6268\n",
      "Epoch [75/85] Batch 690/938 Loss D: 0.2111, Loss G: 3.4682\n",
      "Epoch [75/85] Batch 700/938 Loss D: 0.1025, Loss G: 4.5581\n",
      "Epoch [75/85] Batch 710/938 Loss D: 0.2128, Loss G: 3.3016\n",
      "Epoch [75/85] Batch 720/938 Loss D: 0.4155, Loss G: 3.0538\n",
      "Epoch [75/85] Batch 730/938 Loss D: 0.2334, Loss G: 2.9074\n",
      "Epoch [75/85] Batch 740/938 Loss D: 0.4096, Loss G: 2.8176\n",
      "Epoch [75/85] Batch 750/938 Loss D: 0.3404, Loss G: 2.0973\n",
      "Epoch [75/85] Batch 760/938 Loss D: 0.2799, Loss G: 2.8521\n",
      "Epoch [75/85] Batch 770/938 Loss D: 0.2338, Loss G: 2.3427\n",
      "Epoch [75/85] Batch 780/938 Loss D: 0.2989, Loss G: 2.3875\n",
      "Epoch [75/85] Batch 790/938 Loss D: 0.3113, Loss G: 2.0260\n",
      "Epoch [75/85] Batch 800/938 Loss D: 0.2272, Loss G: 2.5264\n",
      "Epoch [75/85] Batch 810/938 Loss D: 0.2833, Loss G: 3.1859\n",
      "Epoch [75/85] Batch 820/938 Loss D: 0.2948, Loss G: 2.4042\n",
      "Epoch [75/85] Batch 830/938 Loss D: 0.3114, Loss G: 2.1839\n",
      "Epoch [75/85] Batch 840/938 Loss D: 0.2815, Loss G: 2.3909\n",
      "Epoch [75/85] Batch 850/938 Loss D: 0.1862, Loss G: 2.8901\n",
      "Epoch [75/85] Batch 860/938 Loss D: 0.2801, Loss G: 2.0059\n",
      "Epoch [75/85] Batch 870/938 Loss D: 0.3367, Loss G: 2.0580\n",
      "Epoch [75/85] Batch 880/938 Loss D: 0.1772, Loss G: 3.1669\n",
      "Epoch [75/85] Batch 890/938 Loss D: 0.3828, Loss G: 2.6189\n",
      "Epoch [75/85] Batch 900/938 Loss D: 0.2819, Loss G: 2.6433\n",
      "Epoch [75/85] Batch 910/938 Loss D: 0.4106, Loss G: 2.2130\n",
      "Epoch [75/85] Batch 920/938 Loss D: 0.1812, Loss G: 3.4837\n",
      "Epoch [75/85] Batch 930/938 Loss D: 0.2681, Loss G: 2.5290\n",
      "Epoch [76/85] Batch 0/938 Loss D: 0.1724, Loss G: 2.5480\n",
      "Epoch [76/85] Batch 10/938 Loss D: 0.2792, Loss G: 2.6636\n",
      "Epoch [76/85] Batch 20/938 Loss D: 0.3981, Loss G: 1.9719\n",
      "Epoch [76/85] Batch 30/938 Loss D: 0.1843, Loss G: 3.2717\n",
      "Epoch [76/85] Batch 40/938 Loss D: 0.1823, Loss G: 3.5254\n",
      "Epoch [76/85] Batch 50/938 Loss D: 0.2272, Loss G: 3.3240\n",
      "Epoch [76/85] Batch 60/938 Loss D: 0.3204, Loss G: 2.0568\n",
      "Epoch [76/85] Batch 70/938 Loss D: 0.2829, Loss G: 2.6807\n",
      "Epoch [76/85] Batch 80/938 Loss D: 0.2902, Loss G: 2.7040\n",
      "Epoch [76/85] Batch 90/938 Loss D: 0.3258, Loss G: 2.8080\n",
      "Epoch [76/85] Batch 100/938 Loss D: 0.1332, Loss G: 3.6818\n",
      "Epoch [76/85] Batch 110/938 Loss D: 0.3880, Loss G: 2.2274\n",
      "Epoch [76/85] Batch 120/938 Loss D: 0.2562, Loss G: 2.4929\n",
      "Epoch [76/85] Batch 130/938 Loss D: 0.2880, Loss G: 2.9372\n",
      "Epoch [76/85] Batch 140/938 Loss D: 0.2595, Loss G: 2.5231\n",
      "Epoch [76/85] Batch 150/938 Loss D: 0.2762, Loss G: 2.3197\n",
      "Epoch [76/85] Batch 160/938 Loss D: 0.3321, Loss G: 2.4514\n",
      "Epoch [76/85] Batch 170/938 Loss D: 0.2259, Loss G: 2.8354\n",
      "Epoch [76/85] Batch 180/938 Loss D: 0.2423, Loss G: 2.6686\n",
      "Epoch [76/85] Batch 190/938 Loss D: 0.2632, Loss G: 2.3140\n",
      "Epoch [76/85] Batch 200/938 Loss D: 0.2411, Loss G: 2.4831\n",
      "Epoch [76/85] Batch 210/938 Loss D: 0.2968, Loss G: 2.2548\n",
      "Epoch [76/85] Batch 220/938 Loss D: 0.3829, Loss G: 1.9796\n",
      "Epoch [76/85] Batch 230/938 Loss D: 0.3226, Loss G: 2.4667\n",
      "Epoch [76/85] Batch 240/938 Loss D: 0.2242, Loss G: 2.5974\n",
      "Epoch [76/85] Batch 250/938 Loss D: 0.2869, Loss G: 2.9015\n",
      "Epoch [76/85] Batch 260/938 Loss D: 0.2558, Loss G: 2.8762\n",
      "Epoch [76/85] Batch 270/938 Loss D: 0.2643, Loss G: 2.6797\n",
      "Epoch [76/85] Batch 280/938 Loss D: 0.2219, Loss G: 2.4978\n",
      "Epoch [76/85] Batch 290/938 Loss D: 0.2955, Loss G: 2.3069\n",
      "Epoch [76/85] Batch 300/938 Loss D: 0.4581, Loss G: 2.3862\n",
      "Epoch [76/85] Batch 310/938 Loss D: 0.2747, Loss G: 2.0541\n",
      "Epoch [76/85] Batch 320/938 Loss D: 0.1973, Loss G: 2.7406\n",
      "Epoch [76/85] Batch 330/938 Loss D: 0.2777, Loss G: 2.4188\n",
      "Epoch [76/85] Batch 340/938 Loss D: 0.2258, Loss G: 2.5969\n",
      "Epoch [76/85] Batch 350/938 Loss D: 0.3741, Loss G: 1.8935\n",
      "Epoch [76/85] Batch 360/938 Loss D: 0.2349, Loss G: 3.1050\n",
      "Epoch [76/85] Batch 370/938 Loss D: 0.3491, Loss G: 2.3982\n",
      "Epoch [76/85] Batch 380/938 Loss D: 0.3985, Loss G: 2.1011\n",
      "Epoch [76/85] Batch 390/938 Loss D: 0.2649, Loss G: 2.9529\n",
      "Epoch [76/85] Batch 400/938 Loss D: 0.1914, Loss G: 2.3608\n",
      "Epoch [76/85] Batch 410/938 Loss D: 0.1636, Loss G: 3.7582\n",
      "Epoch [76/85] Batch 420/938 Loss D: 0.2840, Loss G: 2.4060\n",
      "Epoch [76/85] Batch 430/938 Loss D: 0.2850, Loss G: 2.7114\n",
      "Epoch [76/85] Batch 440/938 Loss D: 0.2103, Loss G: 3.1992\n",
      "Epoch [76/85] Batch 450/938 Loss D: 0.3183, Loss G: 2.4659\n",
      "Epoch [76/85] Batch 460/938 Loss D: 0.2601, Loss G: 2.4557\n",
      "Epoch [76/85] Batch 470/938 Loss D: 0.2464, Loss G: 3.3537\n",
      "Epoch [76/85] Batch 480/938 Loss D: 0.3303, Loss G: 2.9307\n",
      "Epoch [76/85] Batch 490/938 Loss D: 0.3038, Loss G: 2.2523\n",
      "Epoch [76/85] Batch 500/938 Loss D: 0.3940, Loss G: 1.9292\n",
      "Epoch [76/85] Batch 510/938 Loss D: 0.2734, Loss G: 2.7064\n",
      "Epoch [76/85] Batch 520/938 Loss D: 0.3416, Loss G: 2.0242\n",
      "Epoch [76/85] Batch 530/938 Loss D: 0.4042, Loss G: 1.6854\n",
      "Epoch [76/85] Batch 540/938 Loss D: 0.2278, Loss G: 2.5253\n",
      "Epoch [76/85] Batch 550/938 Loss D: 0.3565, Loss G: 2.1109\n",
      "Epoch [76/85] Batch 560/938 Loss D: 0.2196, Loss G: 3.0053\n",
      "Epoch [76/85] Batch 570/938 Loss D: 0.3212, Loss G: 2.2204\n",
      "Epoch [76/85] Batch 580/938 Loss D: 0.4213, Loss G: 2.8020\n",
      "Epoch [76/85] Batch 590/938 Loss D: 0.2791, Loss G: 2.6103\n",
      "Epoch [76/85] Batch 600/938 Loss D: 0.3495, Loss G: 1.9798\n",
      "Epoch [76/85] Batch 610/938 Loss D: 0.2774, Loss G: 2.4795\n",
      "Epoch [76/85] Batch 620/938 Loss D: 0.3620, Loss G: 2.3008\n",
      "Epoch [76/85] Batch 630/938 Loss D: 0.3179, Loss G: 2.5893\n",
      "Epoch [76/85] Batch 640/938 Loss D: 0.1961, Loss G: 3.1042\n",
      "Epoch [76/85] Batch 650/938 Loss D: 0.2110, Loss G: 2.5235\n",
      "Epoch [76/85] Batch 660/938 Loss D: 0.3879, Loss G: 1.9712\n",
      "Epoch [76/85] Batch 670/938 Loss D: 0.2241, Loss G: 2.5076\n",
      "Epoch [76/85] Batch 680/938 Loss D: 0.3618, Loss G: 1.9188\n",
      "Epoch [76/85] Batch 690/938 Loss D: 0.2955, Loss G: 2.2394\n",
      "Epoch [76/85] Batch 700/938 Loss D: 0.3441, Loss G: 2.6900\n",
      "Epoch [76/85] Batch 710/938 Loss D: 0.2894, Loss G: 2.6814\n",
      "Epoch [76/85] Batch 720/938 Loss D: 0.3776, Loss G: 2.8758\n",
      "Epoch [76/85] Batch 730/938 Loss D: 0.2913, Loss G: 2.9877\n",
      "Epoch [76/85] Batch 740/938 Loss D: 0.1322, Loss G: 3.5439\n",
      "Epoch [76/85] Batch 750/938 Loss D: 0.2755, Loss G: 2.7904\n",
      "Epoch [76/85] Batch 760/938 Loss D: 0.2793, Loss G: 2.2603\n",
      "Epoch [76/85] Batch 770/938 Loss D: 0.3795, Loss G: 1.9531\n",
      "Epoch [76/85] Batch 780/938 Loss D: 0.2621, Loss G: 2.4931\n",
      "Epoch [76/85] Batch 790/938 Loss D: 0.2939, Loss G: 2.1094\n",
      "Epoch [76/85] Batch 800/938 Loss D: 0.3060, Loss G: 2.0754\n",
      "Epoch [76/85] Batch 810/938 Loss D: 0.2192, Loss G: 2.7033\n",
      "Epoch [76/85] Batch 820/938 Loss D: 0.2091, Loss G: 3.0360\n",
      "Epoch [76/85] Batch 830/938 Loss D: 0.2309, Loss G: 2.7608\n",
      "Epoch [76/85] Batch 840/938 Loss D: 0.2172, Loss G: 3.2203\n",
      "Epoch [76/85] Batch 850/938 Loss D: 0.2571, Loss G: 2.5044\n",
      "Epoch [76/85] Batch 860/938 Loss D: 0.2392, Loss G: 2.9324\n",
      "Epoch [76/85] Batch 870/938 Loss D: 0.3292, Loss G: 2.5244\n",
      "Epoch [76/85] Batch 880/938 Loss D: 0.2667, Loss G: 2.5253\n",
      "Epoch [76/85] Batch 890/938 Loss D: 0.3358, Loss G: 2.3312\n",
      "Epoch [76/85] Batch 900/938 Loss D: 0.3749, Loss G: 1.9194\n",
      "Epoch [76/85] Batch 910/938 Loss D: 0.2083, Loss G: 3.6525\n",
      "Epoch [76/85] Batch 920/938 Loss D: 0.3133, Loss G: 3.7803\n",
      "Epoch [76/85] Batch 930/938 Loss D: 0.3541, Loss G: 2.3819\n",
      "Epoch [77/85] Batch 0/938 Loss D: 0.2787, Loss G: 2.0255\n",
      "Epoch [77/85] Batch 10/938 Loss D: 0.1435, Loss G: 2.7655\n",
      "Epoch [77/85] Batch 20/938 Loss D: 0.1836, Loss G: 3.8061\n",
      "Epoch [77/85] Batch 30/938 Loss D: 0.2063, Loss G: 3.0093\n",
      "Epoch [77/85] Batch 40/938 Loss D: 0.2808, Loss G: 2.4197\n",
      "Epoch [77/85] Batch 50/938 Loss D: 0.2450, Loss G: 2.8053\n",
      "Epoch [77/85] Batch 60/938 Loss D: 0.0718, Loss G: 3.9440\n",
      "Epoch [77/85] Batch 70/938 Loss D: 0.2353, Loss G: 3.2538\n",
      "Epoch [77/85] Batch 80/938 Loss D: 0.1885, Loss G: 2.6150\n",
      "Epoch [77/85] Batch 90/938 Loss D: 0.2409, Loss G: 2.8152\n",
      "Epoch [77/85] Batch 100/938 Loss D: 0.1587, Loss G: 3.6964\n",
      "Epoch [77/85] Batch 110/938 Loss D: 0.2482, Loss G: 2.2306\n",
      "Epoch [77/85] Batch 120/938 Loss D: 0.2773, Loss G: 2.5863\n",
      "Epoch [77/85] Batch 130/938 Loss D: 0.2383, Loss G: 2.5537\n",
      "Epoch [77/85] Batch 140/938 Loss D: 0.3164, Loss G: 2.0019\n",
      "Epoch [77/85] Batch 150/938 Loss D: 0.2666, Loss G: 2.6475\n",
      "Epoch [77/85] Batch 160/938 Loss D: 0.3117, Loss G: 2.6523\n",
      "Epoch [77/85] Batch 170/938 Loss D: 0.3251, Loss G: 2.4660\n",
      "Epoch [77/85] Batch 180/938 Loss D: 0.3063, Loss G: 2.5030\n",
      "Epoch [77/85] Batch 190/938 Loss D: 0.2220, Loss G: 2.5027\n",
      "Epoch [77/85] Batch 200/938 Loss D: 0.3580, Loss G: 2.0070\n",
      "Epoch [77/85] Batch 210/938 Loss D: 0.2877, Loss G: 2.1222\n",
      "Epoch [77/85] Batch 220/938 Loss D: 0.2888, Loss G: 2.2320\n",
      "Epoch [77/85] Batch 230/938 Loss D: 0.5025, Loss G: 2.3530\n",
      "Epoch [77/85] Batch 240/938 Loss D: 0.3202, Loss G: 2.1223\n",
      "Epoch [77/85] Batch 250/938 Loss D: 0.3094, Loss G: 2.9933\n",
      "Epoch [77/85] Batch 260/938 Loss D: 0.2123, Loss G: 2.8100\n",
      "Epoch [77/85] Batch 270/938 Loss D: 0.2705, Loss G: 2.5431\n",
      "Epoch [77/85] Batch 280/938 Loss D: 0.2623, Loss G: 2.7244\n",
      "Epoch [77/85] Batch 290/938 Loss D: 0.2157, Loss G: 2.8888\n",
      "Epoch [77/85] Batch 300/938 Loss D: 0.3647, Loss G: 2.5613\n",
      "Epoch [77/85] Batch 310/938 Loss D: 0.3351, Loss G: 2.4956\n",
      "Epoch [77/85] Batch 320/938 Loss D: 0.2752, Loss G: 2.3267\n",
      "Epoch [77/85] Batch 330/938 Loss D: 0.2806, Loss G: 3.1116\n",
      "Epoch [77/85] Batch 340/938 Loss D: 0.3905, Loss G: 2.1843\n",
      "Epoch [77/85] Batch 350/938 Loss D: 0.2492, Loss G: 3.0785\n",
      "Epoch [77/85] Batch 360/938 Loss D: 0.2157, Loss G: 2.6566\n",
      "Epoch [77/85] Batch 370/938 Loss D: 0.2947, Loss G: 2.4209\n",
      "Epoch [77/85] Batch 380/938 Loss D: 0.2694, Loss G: 3.1607\n",
      "Epoch [77/85] Batch 390/938 Loss D: 0.3099, Loss G: 2.3821\n",
      "Epoch [77/85] Batch 400/938 Loss D: 0.3838, Loss G: 2.6989\n",
      "Epoch [77/85] Batch 410/938 Loss D: 0.2463, Loss G: 2.5346\n",
      "Epoch [77/85] Batch 420/938 Loss D: 0.3168, Loss G: 2.0306\n",
      "Epoch [77/85] Batch 430/938 Loss D: 0.4072, Loss G: 2.0289\n",
      "Epoch [77/85] Batch 440/938 Loss D: 0.2553, Loss G: 2.3090\n",
      "Epoch [77/85] Batch 450/938 Loss D: 0.3057, Loss G: 2.8763\n",
      "Epoch [77/85] Batch 460/938 Loss D: 0.2225, Loss G: 2.9090\n",
      "Epoch [77/85] Batch 470/938 Loss D: 0.3175, Loss G: 2.0616\n",
      "Epoch [77/85] Batch 480/938 Loss D: 0.3430, Loss G: 1.9261\n",
      "Epoch [77/85] Batch 490/938 Loss D: 0.2777, Loss G: 2.3494\n",
      "Epoch [77/85] Batch 500/938 Loss D: 0.2960, Loss G: 2.7365\n",
      "Epoch [77/85] Batch 510/938 Loss D: 0.3770, Loss G: 2.5834\n",
      "Epoch [77/85] Batch 520/938 Loss D: 0.2384, Loss G: 3.1775\n",
      "Epoch [77/85] Batch 530/938 Loss D: 0.2037, Loss G: 3.1056\n",
      "Epoch [77/85] Batch 540/938 Loss D: 0.2385, Loss G: 2.8343\n",
      "Epoch [77/85] Batch 550/938 Loss D: 0.2005, Loss G: 3.1088\n",
      "Epoch [77/85] Batch 560/938 Loss D: 0.4140, Loss G: 1.7097\n",
      "Epoch [77/85] Batch 570/938 Loss D: 0.3117, Loss G: 2.5706\n",
      "Epoch [77/85] Batch 580/938 Loss D: 0.1836, Loss G: 3.7688\n",
      "Epoch [77/85] Batch 590/938 Loss D: 0.1425, Loss G: 4.1444\n",
      "Epoch [77/85] Batch 600/938 Loss D: 0.1630, Loss G: 3.3877\n",
      "Epoch [77/85] Batch 610/938 Loss D: 0.0746, Loss G: 3.8238\n",
      "Epoch [77/85] Batch 620/938 Loss D: 0.1564, Loss G: 3.9792\n",
      "Epoch [77/85] Batch 630/938 Loss D: 0.2731, Loss G: 2.7764\n",
      "Epoch [77/85] Batch 640/938 Loss D: 0.2819, Loss G: 2.9519\n",
      "Epoch [77/85] Batch 650/938 Loss D: 0.2711, Loss G: 2.5515\n",
      "Epoch [77/85] Batch 660/938 Loss D: 0.4072, Loss G: 2.1776\n",
      "Epoch [77/85] Batch 670/938 Loss D: 0.3886, Loss G: 2.1299\n",
      "Epoch [77/85] Batch 680/938 Loss D: 0.3112, Loss G: 2.1633\n",
      "Epoch [77/85] Batch 690/938 Loss D: 0.3039, Loss G: 2.0233\n",
      "Epoch [77/85] Batch 700/938 Loss D: 0.2846, Loss G: 2.4396\n",
      "Epoch [77/85] Batch 710/938 Loss D: 0.1971, Loss G: 3.1475\n",
      "Epoch [77/85] Batch 720/938 Loss D: 0.2684, Loss G: 2.7588\n",
      "Epoch [77/85] Batch 730/938 Loss D: 0.3557, Loss G: 2.5357\n",
      "Epoch [77/85] Batch 740/938 Loss D: 0.2509, Loss G: 2.3443\n",
      "Epoch [77/85] Batch 750/938 Loss D: 0.3837, Loss G: 2.0241\n",
      "Epoch [77/85] Batch 760/938 Loss D: 0.3602, Loss G: 3.2561\n",
      "Epoch [77/85] Batch 770/938 Loss D: 0.2657, Loss G: 2.7071\n",
      "Epoch [77/85] Batch 780/938 Loss D: 0.2718, Loss G: 2.7447\n",
      "Epoch [77/85] Batch 790/938 Loss D: 0.4721, Loss G: 2.0132\n",
      "Epoch [77/85] Batch 800/938 Loss D: 0.2312, Loss G: 2.4611\n",
      "Epoch [77/85] Batch 810/938 Loss D: 0.3830, Loss G: 1.9725\n",
      "Epoch [77/85] Batch 820/938 Loss D: 0.3385, Loss G: 2.1355\n",
      "Epoch [77/85] Batch 830/938 Loss D: 0.2449, Loss G: 2.6740\n",
      "Epoch [77/85] Batch 840/938 Loss D: 0.2316, Loss G: 3.0147\n",
      "Epoch [77/85] Batch 850/938 Loss D: 0.3656, Loss G: 1.7763\n",
      "Epoch [77/85] Batch 860/938 Loss D: 0.4192, Loss G: 1.8047\n",
      "Epoch [77/85] Batch 870/938 Loss D: 0.2071, Loss G: 2.5603\n",
      "Epoch [77/85] Batch 880/938 Loss D: 0.1889, Loss G: 2.5687\n",
      "Epoch [77/85] Batch 890/938 Loss D: 0.1355, Loss G: 3.3913\n",
      "Epoch [77/85] Batch 900/938 Loss D: 0.2124, Loss G: 3.9780\n",
      "Epoch [77/85] Batch 910/938 Loss D: 0.2033, Loss G: 3.1113\n",
      "Epoch [77/85] Batch 920/938 Loss D: 0.3736, Loss G: 1.6333\n",
      "Epoch [77/85] Batch 930/938 Loss D: 0.2325, Loss G: 3.5194\n",
      "Epoch [78/85] Batch 0/938 Loss D: 0.2377, Loss G: 3.7931\n",
      "Epoch [78/85] Batch 10/938 Loss D: 0.2625, Loss G: 2.1448\n",
      "Epoch [78/85] Batch 20/938 Loss D: 0.3186, Loss G: 1.9677\n",
      "Epoch [78/85] Batch 30/938 Loss D: 0.1963, Loss G: 2.8669\n",
      "Epoch [78/85] Batch 40/938 Loss D: 0.2527, Loss G: 2.3648\n",
      "Epoch [78/85] Batch 50/938 Loss D: 0.2313, Loss G: 2.1030\n",
      "Epoch [78/85] Batch 60/938 Loss D: 0.3289, Loss G: 2.2248\n",
      "Epoch [78/85] Batch 70/938 Loss D: 0.2378, Loss G: 3.3315\n",
      "Epoch [78/85] Batch 80/938 Loss D: 0.2994, Loss G: 2.4543\n",
      "Epoch [78/85] Batch 90/938 Loss D: 0.2371, Loss G: 2.4537\n",
      "Epoch [78/85] Batch 100/938 Loss D: 0.3332, Loss G: 2.3005\n",
      "Epoch [78/85] Batch 110/938 Loss D: 0.2618, Loss G: 2.7991\n",
      "Epoch [78/85] Batch 120/938 Loss D: 0.2331, Loss G: 3.2252\n",
      "Epoch [78/85] Batch 130/938 Loss D: 0.1052, Loss G: 3.7262\n",
      "Epoch [78/85] Batch 140/938 Loss D: 0.1837, Loss G: 3.2526\n",
      "Epoch [78/85] Batch 150/938 Loss D: 0.2606, Loss G: 3.7954\n",
      "Epoch [78/85] Batch 160/938 Loss D: 0.2323, Loss G: 2.9299\n",
      "Epoch [78/85] Batch 170/938 Loss D: 0.4985, Loss G: 1.6967\n",
      "Epoch [78/85] Batch 180/938 Loss D: 0.3304, Loss G: 1.8296\n",
      "Epoch [78/85] Batch 190/938 Loss D: 0.3875, Loss G: 1.9600\n",
      "Epoch [78/85] Batch 200/938 Loss D: 0.3327, Loss G: 2.1703\n",
      "Epoch [78/85] Batch 210/938 Loss D: 0.2203, Loss G: 2.4950\n",
      "Epoch [78/85] Batch 220/938 Loss D: 0.3013, Loss G: 2.5144\n",
      "Epoch [78/85] Batch 230/938 Loss D: 0.3465, Loss G: 2.2337\n",
      "Epoch [78/85] Batch 240/938 Loss D: 0.2158, Loss G: 3.3006\n",
      "Epoch [78/85] Batch 250/938 Loss D: 0.2049, Loss G: 3.3121\n",
      "Epoch [78/85] Batch 260/938 Loss D: 0.2639, Loss G: 2.0962\n",
      "Epoch [78/85] Batch 270/938 Loss D: 0.3696, Loss G: 1.8002\n",
      "Epoch [78/85] Batch 280/938 Loss D: 0.2576, Loss G: 2.2939\n",
      "Epoch [78/85] Batch 290/938 Loss D: 0.2233, Loss G: 3.5941\n",
      "Epoch [78/85] Batch 300/938 Loss D: 0.2471, Loss G: 2.6500\n",
      "Epoch [78/85] Batch 310/938 Loss D: 0.2686, Loss G: 2.0417\n",
      "Epoch [78/85] Batch 320/938 Loss D: 0.1823, Loss G: 2.8869\n",
      "Epoch [78/85] Batch 330/938 Loss D: 0.3479, Loss G: 2.2689\n",
      "Epoch [78/85] Batch 340/938 Loss D: 0.1115, Loss G: 3.7895\n",
      "Epoch [78/85] Batch 350/938 Loss D: 0.3056, Loss G: 1.8481\n",
      "Epoch [78/85] Batch 360/938 Loss D: 0.2291, Loss G: 3.1914\n",
      "Epoch [78/85] Batch 370/938 Loss D: 0.2121, Loss G: 3.0387\n",
      "Epoch [78/85] Batch 380/938 Loss D: 0.2622, Loss G: 2.3771\n",
      "Epoch [78/85] Batch 390/938 Loss D: 0.3030, Loss G: 2.5596\n",
      "Epoch [78/85] Batch 400/938 Loss D: 0.1998, Loss G: 2.7058\n",
      "Epoch [78/85] Batch 410/938 Loss D: 0.2825, Loss G: 3.3011\n",
      "Epoch [78/85] Batch 420/938 Loss D: 0.2164, Loss G: 3.0345\n",
      "Epoch [78/85] Batch 430/938 Loss D: 0.3613, Loss G: 1.7076\n",
      "Epoch [78/85] Batch 440/938 Loss D: 0.3821, Loss G: 1.7257\n",
      "Epoch [78/85] Batch 450/938 Loss D: 0.3161, Loss G: 2.2230\n",
      "Epoch [78/85] Batch 460/938 Loss D: 0.3213, Loss G: 2.4000\n",
      "Epoch [78/85] Batch 470/938 Loss D: 0.2059, Loss G: 3.4924\n",
      "Epoch [78/85] Batch 480/938 Loss D: 0.3366, Loss G: 2.2453\n",
      "Epoch [78/85] Batch 490/938 Loss D: 0.2321, Loss G: 2.1294\n",
      "Epoch [78/85] Batch 500/938 Loss D: 0.4731, Loss G: 2.7847\n",
      "Epoch [78/85] Batch 510/938 Loss D: 0.3103, Loss G: 1.9276\n",
      "Epoch [78/85] Batch 520/938 Loss D: 0.3751, Loss G: 2.4775\n",
      "Epoch [78/85] Batch 530/938 Loss D: 0.3939, Loss G: 2.3360\n",
      "Epoch [78/85] Batch 540/938 Loss D: 0.3411, Loss G: 2.6869\n",
      "Epoch [78/85] Batch 550/938 Loss D: 0.2827, Loss G: 2.5743\n",
      "Epoch [78/85] Batch 560/938 Loss D: 0.3615, Loss G: 2.2776\n",
      "Epoch [78/85] Batch 570/938 Loss D: 0.2856, Loss G: 2.2249\n",
      "Epoch [78/85] Batch 580/938 Loss D: 0.1310, Loss G: 3.4220\n",
      "Epoch [78/85] Batch 590/938 Loss D: 0.1934, Loss G: 2.9122\n",
      "Epoch [78/85] Batch 600/938 Loss D: 0.1933, Loss G: 3.4597\n",
      "Epoch [78/85] Batch 610/938 Loss D: 0.3453, Loss G: 2.3949\n",
      "Epoch [78/85] Batch 620/938 Loss D: 0.1745, Loss G: 2.9850\n",
      "Epoch [78/85] Batch 630/938 Loss D: 0.2293, Loss G: 2.8418\n",
      "Epoch [78/85] Batch 640/938 Loss D: 0.2974, Loss G: 2.6452\n",
      "Epoch [78/85] Batch 650/938 Loss D: 0.2854, Loss G: 2.0314\n",
      "Epoch [78/85] Batch 660/938 Loss D: 0.3515, Loss G: 2.6192\n",
      "Epoch [78/85] Batch 670/938 Loss D: 0.3272, Loss G: 2.8925\n",
      "Epoch [78/85] Batch 680/938 Loss D: 0.1956, Loss G: 3.7948\n",
      "Epoch [78/85] Batch 690/938 Loss D: 0.2808, Loss G: 2.5325\n",
      "Epoch [78/85] Batch 700/938 Loss D: 0.3221, Loss G: 2.8502\n",
      "Epoch [78/85] Batch 710/938 Loss D: 0.2397, Loss G: 2.6431\n",
      "Epoch [78/85] Batch 720/938 Loss D: 0.4620, Loss G: 1.5702\n",
      "Epoch [78/85] Batch 730/938 Loss D: 0.3012, Loss G: 2.4790\n",
      "Epoch [78/85] Batch 740/938 Loss D: 0.2850, Loss G: 2.1943\n",
      "Epoch [78/85] Batch 750/938 Loss D: 0.2423, Loss G: 2.3533\n",
      "Epoch [78/85] Batch 760/938 Loss D: 0.3338, Loss G: 2.3459\n",
      "Epoch [78/85] Batch 770/938 Loss D: 0.3279, Loss G: 2.0007\n",
      "Epoch [78/85] Batch 780/938 Loss D: 0.2802, Loss G: 2.4104\n",
      "Epoch [78/85] Batch 790/938 Loss D: 0.3336, Loss G: 2.5643\n",
      "Epoch [78/85] Batch 800/938 Loss D: 0.3254, Loss G: 2.1825\n",
      "Epoch [78/85] Batch 810/938 Loss D: 0.2730, Loss G: 2.5707\n",
      "Epoch [78/85] Batch 820/938 Loss D: 0.3179, Loss G: 2.4867\n",
      "Epoch [78/85] Batch 830/938 Loss D: 0.2870, Loss G: 2.4016\n",
      "Epoch [78/85] Batch 840/938 Loss D: 0.2117, Loss G: 2.9548\n",
      "Epoch [78/85] Batch 850/938 Loss D: 0.5007, Loss G: 1.6133\n",
      "Epoch [78/85] Batch 860/938 Loss D: 0.2446, Loss G: 2.3558\n",
      "Epoch [78/85] Batch 870/938 Loss D: 0.3030, Loss G: 2.4244\n",
      "Epoch [78/85] Batch 880/938 Loss D: 0.3499, Loss G: 2.7667\n",
      "Epoch [78/85] Batch 890/938 Loss D: 0.2690, Loss G: 3.3150\n",
      "Epoch [78/85] Batch 900/938 Loss D: 0.2154, Loss G: 2.8835\n",
      "Epoch [78/85] Batch 910/938 Loss D: 0.4887, Loss G: 2.3947\n",
      "Epoch [78/85] Batch 920/938 Loss D: 0.1525, Loss G: 2.8856\n",
      "Epoch [78/85] Batch 930/938 Loss D: 0.3194, Loss G: 2.1994\n",
      "Epoch [79/85] Batch 0/938 Loss D: 0.1803, Loss G: 3.4050\n",
      "Epoch [79/85] Batch 10/938 Loss D: 0.2357, Loss G: 2.4791\n",
      "Epoch [79/85] Batch 20/938 Loss D: 0.1791, Loss G: 3.2476\n",
      "Epoch [79/85] Batch 30/938 Loss D: 0.2729, Loss G: 3.1886\n",
      "Epoch [79/85] Batch 40/938 Loss D: 0.2092, Loss G: 2.4254\n",
      "Epoch [79/85] Batch 50/938 Loss D: 0.3151, Loss G: 2.5520\n",
      "Epoch [79/85] Batch 60/938 Loss D: 0.3601, Loss G: 1.8142\n",
      "Epoch [79/85] Batch 70/938 Loss D: 0.2129, Loss G: 3.0592\n",
      "Epoch [79/85] Batch 80/938 Loss D: 0.1816, Loss G: 3.5422\n",
      "Epoch [79/85] Batch 90/938 Loss D: 0.3644, Loss G: 1.9665\n",
      "Epoch [79/85] Batch 100/938 Loss D: 0.3718, Loss G: 2.0180\n",
      "Epoch [79/85] Batch 110/938 Loss D: 0.2503, Loss G: 2.1585\n",
      "Epoch [79/85] Batch 120/938 Loss D: 0.1327, Loss G: 3.0268\n",
      "Epoch [79/85] Batch 130/938 Loss D: 0.2489, Loss G: 2.5335\n",
      "Epoch [79/85] Batch 140/938 Loss D: 0.2952, Loss G: 2.0371\n",
      "Epoch [79/85] Batch 150/938 Loss D: 0.3396, Loss G: 2.6245\n",
      "Epoch [79/85] Batch 160/938 Loss D: 0.2445, Loss G: 3.0310\n",
      "Epoch [79/85] Batch 170/938 Loss D: 0.3108, Loss G: 2.9441\n",
      "Epoch [79/85] Batch 180/938 Loss D: 0.2686, Loss G: 2.5154\n",
      "Epoch [79/85] Batch 190/938 Loss D: 0.3804, Loss G: 1.7435\n",
      "Epoch [79/85] Batch 200/938 Loss D: 0.4527, Loss G: 1.8185\n",
      "Epoch [79/85] Batch 210/938 Loss D: 0.3004, Loss G: 2.8995\n",
      "Epoch [79/85] Batch 220/938 Loss D: 0.2531, Loss G: 2.7097\n",
      "Epoch [79/85] Batch 230/938 Loss D: 0.3291, Loss G: 2.1612\n",
      "Epoch [79/85] Batch 240/938 Loss D: 0.2290, Loss G: 2.4034\n",
      "Epoch [79/85] Batch 250/938 Loss D: 0.1521, Loss G: 3.5486\n",
      "Epoch [79/85] Batch 260/938 Loss D: 0.3176, Loss G: 2.2982\n",
      "Epoch [79/85] Batch 270/938 Loss D: 0.2979, Loss G: 2.1239\n",
      "Epoch [79/85] Batch 280/938 Loss D: 0.2624, Loss G: 2.5331\n",
      "Epoch [79/85] Batch 290/938 Loss D: 0.1870, Loss G: 3.6638\n",
      "Epoch [79/85] Batch 300/938 Loss D: 0.2394, Loss G: 3.6855\n",
      "Epoch [79/85] Batch 310/938 Loss D: 0.1454, Loss G: 2.8926\n",
      "Epoch [79/85] Batch 320/938 Loss D: 0.2195, Loss G: 3.0272\n",
      "Epoch [79/85] Batch 330/938 Loss D: 0.2679, Loss G: 3.3358\n",
      "Epoch [79/85] Batch 340/938 Loss D: 0.2087, Loss G: 2.8437\n",
      "Epoch [79/85] Batch 350/938 Loss D: 0.1773, Loss G: 3.2510\n",
      "Epoch [79/85] Batch 360/938 Loss D: 0.1708, Loss G: 4.1191\n",
      "Epoch [79/85] Batch 370/938 Loss D: 0.2521, Loss G: 2.9333\n",
      "Epoch [79/85] Batch 380/938 Loss D: 0.2073, Loss G: 2.7235\n",
      "Epoch [79/85] Batch 390/938 Loss D: 0.2237, Loss G: 2.2737\n",
      "Epoch [79/85] Batch 400/938 Loss D: 0.4078, Loss G: 2.2056\n",
      "Epoch [79/85] Batch 410/938 Loss D: 0.2624, Loss G: 2.8280\n",
      "Epoch [79/85] Batch 420/938 Loss D: 0.3311, Loss G: 2.8180\n",
      "Epoch [79/85] Batch 430/938 Loss D: 0.2619, Loss G: 2.3181\n",
      "Epoch [79/85] Batch 440/938 Loss D: 0.2646, Loss G: 2.2058\n",
      "Epoch [79/85] Batch 450/938 Loss D: 0.3057, Loss G: 2.4007\n",
      "Epoch [79/85] Batch 460/938 Loss D: 0.1920, Loss G: 4.2416\n",
      "Epoch [79/85] Batch 470/938 Loss D: 0.3268, Loss G: 2.5258\n",
      "Epoch [79/85] Batch 480/938 Loss D: 0.4196, Loss G: 1.8725\n",
      "Epoch [79/85] Batch 490/938 Loss D: 0.2466, Loss G: 2.5683\n",
      "Epoch [79/85] Batch 500/938 Loss D: 0.1677, Loss G: 3.7438\n",
      "Epoch [79/85] Batch 510/938 Loss D: 0.1885, Loss G: 3.4634\n",
      "Epoch [79/85] Batch 520/938 Loss D: 0.2890, Loss G: 2.3240\n",
      "Epoch [79/85] Batch 530/938 Loss D: 0.1928, Loss G: 3.4207\n",
      "Epoch [79/85] Batch 540/938 Loss D: 0.4240, Loss G: 1.6428\n",
      "Epoch [79/85] Batch 550/938 Loss D: 0.2573, Loss G: 3.1523\n",
      "Epoch [79/85] Batch 560/938 Loss D: 0.2922, Loss G: 3.7429\n",
      "Epoch [79/85] Batch 570/938 Loss D: 0.3461, Loss G: 2.6453\n",
      "Epoch [79/85] Batch 580/938 Loss D: 0.2561, Loss G: 2.1552\n",
      "Epoch [79/85] Batch 590/938 Loss D: 0.3381, Loss G: 1.7260\n",
      "Epoch [79/85] Batch 600/938 Loss D: 0.2225, Loss G: 2.8219\n",
      "Epoch [79/85] Batch 610/938 Loss D: 0.2351, Loss G: 2.9871\n",
      "Epoch [79/85] Batch 620/938 Loss D: 0.3022, Loss G: 2.0646\n",
      "Epoch [79/85] Batch 630/938 Loss D: 0.2342, Loss G: 2.3512\n",
      "Epoch [79/85] Batch 640/938 Loss D: 0.2499, Loss G: 2.8508\n",
      "Epoch [79/85] Batch 650/938 Loss D: 0.3103, Loss G: 2.4678\n",
      "Epoch [79/85] Batch 660/938 Loss D: 0.2569, Loss G: 2.3219\n",
      "Epoch [79/85] Batch 670/938 Loss D: 0.1553, Loss G: 3.5749\n",
      "Epoch [79/85] Batch 680/938 Loss D: 0.2316, Loss G: 3.4590\n",
      "Epoch [79/85] Batch 690/938 Loss D: 0.2971, Loss G: 2.6992\n",
      "Epoch [79/85] Batch 700/938 Loss D: 0.1868, Loss G: 2.5439\n",
      "Epoch [79/85] Batch 710/938 Loss D: 0.2370, Loss G: 2.6122\n",
      "Epoch [79/85] Batch 720/938 Loss D: 0.3055, Loss G: 2.4871\n",
      "Epoch [79/85] Batch 730/938 Loss D: 0.3760, Loss G: 1.8242\n",
      "Epoch [79/85] Batch 740/938 Loss D: 0.2151, Loss G: 2.6779\n",
      "Epoch [79/85] Batch 750/938 Loss D: 0.2952, Loss G: 2.8985\n",
      "Epoch [79/85] Batch 760/938 Loss D: 0.4308, Loss G: 2.4503\n",
      "Epoch [79/85] Batch 770/938 Loss D: 0.3104, Loss G: 2.4996\n",
      "Epoch [79/85] Batch 780/938 Loss D: 0.2883, Loss G: 2.5967\n",
      "Epoch [79/85] Batch 790/938 Loss D: 0.2091, Loss G: 2.6661\n",
      "Epoch [79/85] Batch 800/938 Loss D: 0.3316, Loss G: 2.3648\n",
      "Epoch [79/85] Batch 810/938 Loss D: 0.1144, Loss G: 4.8829\n",
      "Epoch [79/85] Batch 820/938 Loss D: 0.2667, Loss G: 3.3895\n",
      "Epoch [79/85] Batch 830/938 Loss D: 0.2305, Loss G: 3.2518\n",
      "Epoch [79/85] Batch 840/938 Loss D: 0.2351, Loss G: 2.4071\n",
      "Epoch [79/85] Batch 850/938 Loss D: 0.2981, Loss G: 2.7623\n",
      "Epoch [79/85] Batch 860/938 Loss D: 0.2841, Loss G: 2.1634\n",
      "Epoch [79/85] Batch 870/938 Loss D: 0.3137, Loss G: 2.5338\n",
      "Epoch [79/85] Batch 880/938 Loss D: 0.3011, Loss G: 3.0278\n",
      "Epoch [79/85] Batch 890/938 Loss D: 0.4108, Loss G: 2.3535\n",
      "Epoch [79/85] Batch 900/938 Loss D: 0.3040, Loss G: 2.5231\n",
      "Epoch [79/85] Batch 910/938 Loss D: 0.4170, Loss G: 2.1586\n",
      "Epoch [79/85] Batch 920/938 Loss D: 0.3366, Loss G: 1.9563\n",
      "Epoch [79/85] Batch 930/938 Loss D: 0.1045, Loss G: 3.4232\n",
      "Epoch [80/85] Batch 0/938 Loss D: 0.2708, Loss G: 3.1138\n",
      "Epoch [80/85] Batch 10/938 Loss D: 0.3341, Loss G: 2.6985\n",
      "Epoch [80/85] Batch 20/938 Loss D: 0.3289, Loss G: 2.4684\n",
      "Epoch [80/85] Batch 30/938 Loss D: 0.3235, Loss G: 2.1192\n",
      "Epoch [80/85] Batch 40/938 Loss D: 0.2365, Loss G: 3.8928\n",
      "Epoch [80/85] Batch 50/938 Loss D: 0.1238, Loss G: 3.1795\n",
      "Epoch [80/85] Batch 60/938 Loss D: 0.2468, Loss G: 2.4229\n",
      "Epoch [80/85] Batch 70/938 Loss D: 0.3461, Loss G: 2.1164\n",
      "Epoch [80/85] Batch 80/938 Loss D: 0.4318, Loss G: 1.7151\n",
      "Epoch [80/85] Batch 90/938 Loss D: 0.3318, Loss G: 3.7743\n",
      "Epoch [80/85] Batch 100/938 Loss D: 0.2979, Loss G: 3.6145\n",
      "Epoch [80/85] Batch 110/938 Loss D: 0.2600, Loss G: 2.8467\n",
      "Epoch [80/85] Batch 120/938 Loss D: 0.1829, Loss G: 3.0479\n",
      "Epoch [80/85] Batch 130/938 Loss D: 0.2125, Loss G: 2.3357\n",
      "Epoch [80/85] Batch 140/938 Loss D: 0.1656, Loss G: 3.1958\n",
      "Epoch [80/85] Batch 150/938 Loss D: 0.2371, Loss G: 2.4132\n",
      "Epoch [80/85] Batch 160/938 Loss D: 0.4078, Loss G: 1.9665\n",
      "Epoch [80/85] Batch 170/938 Loss D: 0.2918, Loss G: 2.4712\n",
      "Epoch [80/85] Batch 180/938 Loss D: 0.2563, Loss G: 2.5713\n",
      "Epoch [80/85] Batch 190/938 Loss D: 0.2847, Loss G: 2.5260\n",
      "Epoch [80/85] Batch 200/938 Loss D: 0.2155, Loss G: 2.7317\n",
      "Epoch [80/85] Batch 210/938 Loss D: 0.2830, Loss G: 2.6855\n",
      "Epoch [80/85] Batch 220/938 Loss D: 0.3756, Loss G: 2.4425\n",
      "Epoch [80/85] Batch 230/938 Loss D: 0.3055, Loss G: 2.4194\n",
      "Epoch [80/85] Batch 240/938 Loss D: 0.3908, Loss G: 2.6503\n",
      "Epoch [80/85] Batch 250/938 Loss D: 0.3524, Loss G: 2.3009\n",
      "Epoch [80/85] Batch 260/938 Loss D: 0.3889, Loss G: 1.8790\n",
      "Epoch [80/85] Batch 270/938 Loss D: 0.2507, Loss G: 2.9168\n",
      "Epoch [80/85] Batch 280/938 Loss D: 0.2929, Loss G: 2.4107\n",
      "Epoch [80/85] Batch 290/938 Loss D: 0.2488, Loss G: 2.5933\n",
      "Epoch [80/85] Batch 300/938 Loss D: 0.2700, Loss G: 3.1292\n",
      "Epoch [80/85] Batch 310/938 Loss D: 0.3271, Loss G: 3.1600\n",
      "Epoch [80/85] Batch 320/938 Loss D: 0.2392, Loss G: 2.2272\n",
      "Epoch [80/85] Batch 330/938 Loss D: 0.2435, Loss G: 2.0933\n",
      "Epoch [80/85] Batch 340/938 Loss D: 0.5316, Loss G: 1.7804\n",
      "Epoch [80/85] Batch 350/938 Loss D: 0.4114, Loss G: 2.7408\n",
      "Epoch [80/85] Batch 360/938 Loss D: 0.2934, Loss G: 3.0629\n",
      "Epoch [80/85] Batch 370/938 Loss D: 0.3135, Loss G: 2.8902\n",
      "Epoch [80/85] Batch 380/938 Loss D: 0.3139, Loss G: 3.4450\n",
      "Epoch [80/85] Batch 390/938 Loss D: 0.2869, Loss G: 2.4314\n",
      "Epoch [80/85] Batch 400/938 Loss D: 0.1636, Loss G: 3.5767\n",
      "Epoch [80/85] Batch 410/938 Loss D: 0.3248, Loss G: 2.3051\n",
      "Epoch [80/85] Batch 420/938 Loss D: 0.3171, Loss G: 2.0312\n",
      "Epoch [80/85] Batch 430/938 Loss D: 0.3952, Loss G: 2.3175\n",
      "Epoch [80/85] Batch 440/938 Loss D: 0.2000, Loss G: 3.0471\n",
      "Epoch [80/85] Batch 450/938 Loss D: 0.3919, Loss G: 2.1471\n",
      "Epoch [80/85] Batch 460/938 Loss D: 0.2725, Loss G: 2.7665\n",
      "Epoch [80/85] Batch 470/938 Loss D: 0.1826, Loss G: 3.0468\n",
      "Epoch [80/85] Batch 480/938 Loss D: 0.3341, Loss G: 3.2516\n",
      "Epoch [80/85] Batch 490/938 Loss D: 0.5736, Loss G: 1.8910\n",
      "Epoch [80/85] Batch 500/938 Loss D: 0.4330, Loss G: 1.6955\n",
      "Epoch [80/85] Batch 510/938 Loss D: 0.4246, Loss G: 2.5155\n",
      "Epoch [80/85] Batch 520/938 Loss D: 0.3285, Loss G: 3.2346\n",
      "Epoch [80/85] Batch 530/938 Loss D: 0.2495, Loss G: 2.6588\n",
      "Epoch [80/85] Batch 540/938 Loss D: 0.4182, Loss G: 2.5336\n",
      "Epoch [80/85] Batch 550/938 Loss D: 0.3782, Loss G: 1.8785\n",
      "Epoch [80/85] Batch 560/938 Loss D: 0.2311, Loss G: 3.0388\n",
      "Epoch [80/85] Batch 570/938 Loss D: 0.2634, Loss G: 3.0228\n",
      "Epoch [80/85] Batch 580/938 Loss D: 0.2240, Loss G: 2.4502\n",
      "Epoch [80/85] Batch 590/938 Loss D: 0.2149, Loss G: 2.3679\n",
      "Epoch [80/85] Batch 600/938 Loss D: 0.1769, Loss G: 3.9793\n",
      "Epoch [80/85] Batch 610/938 Loss D: 0.3939, Loss G: 2.2519\n",
      "Epoch [80/85] Batch 620/938 Loss D: 0.3805, Loss G: 2.0408\n",
      "Epoch [80/85] Batch 630/938 Loss D: 0.2640, Loss G: 2.6296\n",
      "Epoch [80/85] Batch 640/938 Loss D: 0.3115, Loss G: 2.7032\n",
      "Epoch [80/85] Batch 650/938 Loss D: 0.3150, Loss G: 2.8064\n",
      "Epoch [80/85] Batch 660/938 Loss D: 0.2849, Loss G: 2.7240\n",
      "Epoch [80/85] Batch 670/938 Loss D: 0.3336, Loss G: 2.2063\n",
      "Epoch [80/85] Batch 680/938 Loss D: 0.2946, Loss G: 2.2397\n",
      "Epoch [80/85] Batch 690/938 Loss D: 0.2984, Loss G: 2.8165\n",
      "Epoch [80/85] Batch 700/938 Loss D: 0.4049, Loss G: 2.3938\n",
      "Epoch [80/85] Batch 710/938 Loss D: 0.3939, Loss G: 2.0802\n",
      "Epoch [80/85] Batch 720/938 Loss D: 0.3467, Loss G: 2.0574\n",
      "Epoch [80/85] Batch 730/938 Loss D: 0.3172, Loss G: 2.2059\n",
      "Epoch [80/85] Batch 740/938 Loss D: 0.4574, Loss G: 2.1222\n",
      "Epoch [80/85] Batch 750/938 Loss D: 0.2043, Loss G: 3.1541\n",
      "Epoch [80/85] Batch 760/938 Loss D: 0.2790, Loss G: 2.6988\n",
      "Epoch [80/85] Batch 770/938 Loss D: 0.2716, Loss G: 2.1374\n",
      "Epoch [80/85] Batch 780/938 Loss D: 0.3412, Loss G: 2.3972\n",
      "Epoch [80/85] Batch 790/938 Loss D: 0.2328, Loss G: 2.8462\n",
      "Epoch [80/85] Batch 800/938 Loss D: 0.2361, Loss G: 3.3164\n",
      "Epoch [80/85] Batch 810/938 Loss D: 0.2617, Loss G: 3.0296\n",
      "Epoch [80/85] Batch 820/938 Loss D: 0.3239, Loss G: 2.5233\n",
      "Epoch [80/85] Batch 830/938 Loss D: 0.3679, Loss G: 2.5030\n",
      "Epoch [80/85] Batch 840/938 Loss D: 0.2878, Loss G: 2.4503\n",
      "Epoch [80/85] Batch 850/938 Loss D: 0.2090, Loss G: 2.9871\n",
      "Epoch [80/85] Batch 860/938 Loss D: 0.2208, Loss G: 2.5732\n",
      "Epoch [80/85] Batch 870/938 Loss D: 0.4004, Loss G: 2.0676\n",
      "Epoch [80/85] Batch 880/938 Loss D: 0.3521, Loss G: 2.3068\n",
      "Epoch [80/85] Batch 890/938 Loss D: 0.3676, Loss G: 2.1703\n",
      "Epoch [80/85] Batch 900/938 Loss D: 0.2132, Loss G: 3.0733\n",
      "Epoch [80/85] Batch 910/938 Loss D: 0.2938, Loss G: 2.3698\n",
      "Epoch [80/85] Batch 920/938 Loss D: 0.2951, Loss G: 2.1856\n",
      "Epoch [80/85] Batch 930/938 Loss D: 0.2775, Loss G: 2.5099\n",
      "Epoch [81/85] Batch 0/938 Loss D: 0.1632, Loss G: 3.2327\n",
      "Epoch [81/85] Batch 10/938 Loss D: 0.3205, Loss G: 2.9161\n",
      "Epoch [81/85] Batch 20/938 Loss D: 0.3273, Loss G: 2.7348\n",
      "Epoch [81/85] Batch 30/938 Loss D: 0.3494, Loss G: 1.7324\n",
      "Epoch [81/85] Batch 40/938 Loss D: 0.1400, Loss G: 2.8112\n",
      "Epoch [81/85] Batch 50/938 Loss D: 0.3155, Loss G: 2.1962\n",
      "Epoch [81/85] Batch 60/938 Loss D: 0.2652, Loss G: 2.6089\n",
      "Epoch [81/85] Batch 70/938 Loss D: 0.3642, Loss G: 2.0457\n",
      "Epoch [81/85] Batch 80/938 Loss D: 0.2326, Loss G: 2.5625\n",
      "Epoch [81/85] Batch 90/938 Loss D: 0.2417, Loss G: 2.6413\n",
      "Epoch [81/85] Batch 100/938 Loss D: 0.3205, Loss G: 2.3570\n",
      "Epoch [81/85] Batch 110/938 Loss D: 0.1999, Loss G: 2.3381\n",
      "Epoch [81/85] Batch 120/938 Loss D: 0.2604, Loss G: 2.1171\n",
      "Epoch [81/85] Batch 130/938 Loss D: 0.4647, Loss G: 2.2069\n",
      "Epoch [81/85] Batch 140/938 Loss D: 0.2541, Loss G: 2.0745\n",
      "Epoch [81/85] Batch 150/938 Loss D: 0.1469, Loss G: 4.5274\n",
      "Epoch [81/85] Batch 160/938 Loss D: 0.2823, Loss G: 2.5499\n",
      "Epoch [81/85] Batch 170/938 Loss D: 0.3115, Loss G: 2.7075\n",
      "Epoch [81/85] Batch 180/938 Loss D: 0.3780, Loss G: 2.2318\n",
      "Epoch [81/85] Batch 190/938 Loss D: 0.3438, Loss G: 2.1675\n",
      "Epoch [81/85] Batch 200/938 Loss D: 0.1762, Loss G: 3.0684\n",
      "Epoch [81/85] Batch 210/938 Loss D: 0.2520, Loss G: 2.1827\n",
      "Epoch [81/85] Batch 220/938 Loss D: 0.1651, Loss G: 2.9373\n",
      "Epoch [81/85] Batch 230/938 Loss D: 0.3669, Loss G: 2.2711\n",
      "Epoch [81/85] Batch 240/938 Loss D: 0.2238, Loss G: 3.5080\n",
      "Epoch [81/85] Batch 250/938 Loss D: 0.2679, Loss G: 2.8712\n",
      "Epoch [81/85] Batch 260/938 Loss D: 0.2156, Loss G: 3.3898\n",
      "Epoch [81/85] Batch 270/938 Loss D: 0.1956, Loss G: 2.8934\n",
      "Epoch [81/85] Batch 280/938 Loss D: 0.4304, Loss G: 1.9246\n",
      "Epoch [81/85] Batch 290/938 Loss D: 0.2859, Loss G: 2.8263\n",
      "Epoch [81/85] Batch 300/938 Loss D: 0.2733, Loss G: 2.2596\n",
      "Epoch [81/85] Batch 310/938 Loss D: 0.1552, Loss G: 3.2637\n",
      "Epoch [81/85] Batch 320/938 Loss D: 0.1481, Loss G: 3.6786\n",
      "Epoch [81/85] Batch 330/938 Loss D: 0.1239, Loss G: 3.5565\n",
      "Epoch [81/85] Batch 340/938 Loss D: 0.1818, Loss G: 3.0698\n",
      "Epoch [81/85] Batch 350/938 Loss D: 0.3694, Loss G: 2.9673\n",
      "Epoch [81/85] Batch 360/938 Loss D: 0.2697, Loss G: 3.8547\n",
      "Epoch [81/85] Batch 370/938 Loss D: 0.2644, Loss G: 2.7397\n",
      "Epoch [81/85] Batch 380/938 Loss D: 0.1140, Loss G: 4.0383\n",
      "Epoch [81/85] Batch 390/938 Loss D: 0.2880, Loss G: 2.2749\n",
      "Epoch [81/85] Batch 400/938 Loss D: 0.2167, Loss G: 2.6714\n",
      "Epoch [81/85] Batch 410/938 Loss D: 0.3123, Loss G: 2.8966\n",
      "Epoch [81/85] Batch 420/938 Loss D: 0.3108, Loss G: 2.9054\n",
      "Epoch [81/85] Batch 430/938 Loss D: 0.2690, Loss G: 2.7465\n",
      "Epoch [81/85] Batch 440/938 Loss D: 0.1790, Loss G: 2.7424\n",
      "Epoch [81/85] Batch 450/938 Loss D: 0.1864, Loss G: 3.0399\n",
      "Epoch [81/85] Batch 460/938 Loss D: 0.3520, Loss G: 3.0441\n",
      "Epoch [81/85] Batch 470/938 Loss D: 0.2057, Loss G: 2.8610\n",
      "Epoch [81/85] Batch 480/938 Loss D: 0.2165, Loss G: 2.4407\n",
      "Epoch [81/85] Batch 490/938 Loss D: 0.2603, Loss G: 2.5717\n",
      "Epoch [81/85] Batch 500/938 Loss D: 0.1459, Loss G: 4.1044\n",
      "Epoch [81/85] Batch 510/938 Loss D: 0.2716, Loss G: 2.4891\n",
      "Epoch [81/85] Batch 520/938 Loss D: 0.2781, Loss G: 3.3528\n",
      "Epoch [81/85] Batch 530/938 Loss D: 0.3608, Loss G: 2.2987\n",
      "Epoch [81/85] Batch 540/938 Loss D: 0.1744, Loss G: 3.0051\n",
      "Epoch [81/85] Batch 550/938 Loss D: 0.1917, Loss G: 3.0082\n",
      "Epoch [81/85] Batch 560/938 Loss D: 0.2314, Loss G: 2.4863\n",
      "Epoch [81/85] Batch 570/938 Loss D: 0.2150, Loss G: 3.3170\n",
      "Epoch [81/85] Batch 580/938 Loss D: 0.3180, Loss G: 2.7034\n",
      "Epoch [81/85] Batch 590/938 Loss D: 0.2876, Loss G: 2.2811\n",
      "Epoch [81/85] Batch 600/938 Loss D: 0.2239, Loss G: 2.3293\n",
      "Epoch [81/85] Batch 610/938 Loss D: 0.2209, Loss G: 2.8009\n",
      "Epoch [81/85] Batch 620/938 Loss D: 0.3326, Loss G: 2.1930\n",
      "Epoch [81/85] Batch 630/938 Loss D: 0.3130, Loss G: 2.4932\n",
      "Epoch [81/85] Batch 640/938 Loss D: 0.2921, Loss G: 2.8301\n",
      "Epoch [81/85] Batch 650/938 Loss D: 0.2976, Loss G: 2.6296\n",
      "Epoch [81/85] Batch 660/938 Loss D: 0.4695, Loss G: 1.8974\n",
      "Epoch [81/85] Batch 670/938 Loss D: 0.3083, Loss G: 2.3643\n",
      "Epoch [81/85] Batch 680/938 Loss D: 0.3108, Loss G: 2.1180\n",
      "Epoch [81/85] Batch 690/938 Loss D: 0.2033, Loss G: 3.2591\n",
      "Epoch [81/85] Batch 700/938 Loss D: 0.3135, Loss G: 2.0940\n",
      "Epoch [81/85] Batch 710/938 Loss D: 0.2532, Loss G: 1.9219\n",
      "Epoch [81/85] Batch 720/938 Loss D: 0.2158, Loss G: 2.4597\n",
      "Epoch [81/85] Batch 730/938 Loss D: 0.3121, Loss G: 2.3310\n",
      "Epoch [81/85] Batch 740/938 Loss D: 0.2825, Loss G: 2.4799\n",
      "Epoch [81/85] Batch 750/938 Loss D: 0.3909, Loss G: 1.6624\n",
      "Epoch [81/85] Batch 760/938 Loss D: 0.3191, Loss G: 2.1940\n",
      "Epoch [81/85] Batch 770/938 Loss D: 0.4258, Loss G: 1.9497\n",
      "Epoch [81/85] Batch 780/938 Loss D: 0.2669, Loss G: 2.1541\n",
      "Epoch [81/85] Batch 790/938 Loss D: 0.2504, Loss G: 3.3569\n",
      "Epoch [81/85] Batch 800/938 Loss D: 0.2700, Loss G: 3.2679\n",
      "Epoch [81/85] Batch 810/938 Loss D: 0.3348, Loss G: 2.0000\n",
      "Epoch [81/85] Batch 820/938 Loss D: 0.3413, Loss G: 2.5334\n",
      "Epoch [81/85] Batch 830/938 Loss D: 0.1692, Loss G: 3.4036\n",
      "Epoch [81/85] Batch 840/938 Loss D: 0.4501, Loss G: 2.7378\n",
      "Epoch [81/85] Batch 850/938 Loss D: 0.2586, Loss G: 2.4845\n",
      "Epoch [81/85] Batch 860/938 Loss D: 0.2094, Loss G: 2.1816\n",
      "Epoch [81/85] Batch 870/938 Loss D: 0.2790, Loss G: 2.8079\n",
      "Epoch [81/85] Batch 880/938 Loss D: 0.3325, Loss G: 2.4693\n",
      "Epoch [81/85] Batch 890/938 Loss D: 0.2238, Loss G: 2.8017\n",
      "Epoch [81/85] Batch 900/938 Loss D: 0.4257, Loss G: 1.8627\n",
      "Epoch [81/85] Batch 910/938 Loss D: 0.3535, Loss G: 2.8170\n",
      "Epoch [81/85] Batch 920/938 Loss D: 0.3430, Loss G: 2.8939\n",
      "Epoch [81/85] Batch 930/938 Loss D: 0.5051, Loss G: 1.1086\n",
      "Epoch [82/85] Batch 0/938 Loss D: 0.2073, Loss G: 4.7618\n",
      "Epoch [82/85] Batch 10/938 Loss D: 0.2436, Loss G: 2.9338\n",
      "Epoch [82/85] Batch 20/938 Loss D: 0.2800, Loss G: 2.3120\n",
      "Epoch [82/85] Batch 30/938 Loss D: 0.3186, Loss G: 2.8411\n",
      "Epoch [82/85] Batch 40/938 Loss D: 0.2818, Loss G: 2.4310\n",
      "Epoch [82/85] Batch 50/938 Loss D: 0.2260, Loss G: 2.6836\n",
      "Epoch [82/85] Batch 60/938 Loss D: 0.4447, Loss G: 2.1347\n",
      "Epoch [82/85] Batch 70/938 Loss D: 0.5399, Loss G: 2.4873\n",
      "Epoch [82/85] Batch 80/938 Loss D: 0.2989, Loss G: 2.1923\n",
      "Epoch [82/85] Batch 90/938 Loss D: 0.5309, Loss G: 1.4078\n",
      "Epoch [82/85] Batch 100/938 Loss D: 0.1920, Loss G: 2.6631\n",
      "Epoch [82/85] Batch 110/938 Loss D: 0.3033, Loss G: 4.0613\n",
      "Epoch [82/85] Batch 120/938 Loss D: 0.1939, Loss G: 3.5694\n",
      "Epoch [82/85] Batch 130/938 Loss D: 0.2359, Loss G: 2.3615\n",
      "Epoch [82/85] Batch 140/938 Loss D: 0.2083, Loss G: 2.6005\n",
      "Epoch [82/85] Batch 150/938 Loss D: 0.1802, Loss G: 3.0767\n",
      "Epoch [82/85] Batch 160/938 Loss D: 0.4224, Loss G: 2.1675\n",
      "Epoch [82/85] Batch 170/938 Loss D: 0.2606, Loss G: 2.6980\n",
      "Epoch [82/85] Batch 180/938 Loss D: 0.3897, Loss G: 1.8892\n",
      "Epoch [82/85] Batch 190/938 Loss D: 0.2036, Loss G: 2.2162\n",
      "Epoch [82/85] Batch 200/938 Loss D: 0.3492, Loss G: 2.6747\n",
      "Epoch [82/85] Batch 210/938 Loss D: 0.3186, Loss G: 2.2627\n",
      "Epoch [82/85] Batch 220/938 Loss D: 0.1715, Loss G: 2.4954\n",
      "Epoch [82/85] Batch 230/938 Loss D: 0.1950, Loss G: 2.7387\n",
      "Epoch [82/85] Batch 240/938 Loss D: 0.3532, Loss G: 2.6307\n",
      "Epoch [82/85] Batch 250/938 Loss D: 0.2155, Loss G: 2.8156\n",
      "Epoch [82/85] Batch 260/938 Loss D: 0.2476, Loss G: 2.9381\n",
      "Epoch [82/85] Batch 270/938 Loss D: 0.3061, Loss G: 2.5489\n",
      "Epoch [82/85] Batch 280/938 Loss D: 0.2788, Loss G: 2.1398\n",
      "Epoch [82/85] Batch 290/938 Loss D: 0.4369, Loss G: 1.6491\n",
      "Epoch [82/85] Batch 300/938 Loss D: 0.2287, Loss G: 3.0253\n",
      "Epoch [82/85] Batch 310/938 Loss D: 0.3287, Loss G: 4.4095\n",
      "Epoch [82/85] Batch 320/938 Loss D: 0.1991, Loss G: 3.6204\n",
      "Epoch [82/85] Batch 330/938 Loss D: 0.3668, Loss G: 2.3893\n",
      "Epoch [82/85] Batch 340/938 Loss D: 0.1813, Loss G: 2.6925\n",
      "Epoch [82/85] Batch 350/938 Loss D: 0.3327, Loss G: 2.6397\n",
      "Epoch [82/85] Batch 360/938 Loss D: 0.3992, Loss G: 3.1724\n",
      "Epoch [82/85] Batch 370/938 Loss D: 0.3163, Loss G: 2.7761\n",
      "Epoch [82/85] Batch 380/938 Loss D: 0.2986, Loss G: 2.1930\n",
      "Epoch [82/85] Batch 390/938 Loss D: 0.3041, Loss G: 2.1663\n",
      "Epoch [82/85] Batch 400/938 Loss D: 0.2493, Loss G: 3.1174\n",
      "Epoch [82/85] Batch 410/938 Loss D: 0.2200, Loss G: 3.5491\n",
      "Epoch [82/85] Batch 420/938 Loss D: 0.3047, Loss G: 2.3767\n",
      "Epoch [82/85] Batch 430/938 Loss D: 0.2262, Loss G: 2.2973\n",
      "Epoch [82/85] Batch 440/938 Loss D: 0.3445, Loss G: 1.7448\n",
      "Epoch [82/85] Batch 450/938 Loss D: 0.3058, Loss G: 2.9306\n",
      "Epoch [82/85] Batch 460/938 Loss D: 0.1800, Loss G: 3.2560\n",
      "Epoch [82/85] Batch 470/938 Loss D: 0.1742, Loss G: 3.1674\n",
      "Epoch [82/85] Batch 480/938 Loss D: 0.2020, Loss G: 2.7585\n",
      "Epoch [82/85] Batch 490/938 Loss D: 0.1799, Loss G: 2.7201\n",
      "Epoch [82/85] Batch 500/938 Loss D: 0.1786, Loss G: 3.0424\n",
      "Epoch [82/85] Batch 510/938 Loss D: 0.1524, Loss G: 3.5626\n",
      "Epoch [82/85] Batch 520/938 Loss D: 0.2838, Loss G: 1.8262\n",
      "Epoch [82/85] Batch 530/938 Loss D: 0.3362, Loss G: 2.4323\n",
      "Epoch [82/85] Batch 540/938 Loss D: 0.3252, Loss G: 1.8107\n",
      "Epoch [82/85] Batch 550/938 Loss D: 0.3738, Loss G: 1.7325\n",
      "Epoch [82/85] Batch 560/938 Loss D: 0.2145, Loss G: 2.8810\n",
      "Epoch [82/85] Batch 570/938 Loss D: 0.2356, Loss G: 3.5322\n",
      "Epoch [82/85] Batch 580/938 Loss D: 0.3712, Loss G: 2.5139\n",
      "Epoch [82/85] Batch 590/938 Loss D: 0.3619, Loss G: 2.1349\n",
      "Epoch [82/85] Batch 600/938 Loss D: 0.3708, Loss G: 2.1048\n",
      "Epoch [82/85] Batch 610/938 Loss D: 0.3548, Loss G: 2.0383\n",
      "Epoch [82/85] Batch 620/938 Loss D: 0.3742, Loss G: 2.0921\n",
      "Epoch [82/85] Batch 630/938 Loss D: 0.2543, Loss G: 2.4778\n",
      "Epoch [82/85] Batch 640/938 Loss D: 0.1916, Loss G: 3.5966\n",
      "Epoch [82/85] Batch 650/938 Loss D: 0.2156, Loss G: 3.3133\n",
      "Epoch [82/85] Batch 660/938 Loss D: 0.2008, Loss G: 2.8447\n",
      "Epoch [82/85] Batch 670/938 Loss D: 0.4444, Loss G: 2.3912\n",
      "Epoch [82/85] Batch 680/938 Loss D: 0.1686, Loss G: 3.6707\n",
      "Epoch [82/85] Batch 690/938 Loss D: 0.2316, Loss G: 2.9448\n",
      "Epoch [82/85] Batch 700/938 Loss D: 0.3713, Loss G: 2.1190\n",
      "Epoch [82/85] Batch 710/938 Loss D: 0.2424, Loss G: 2.7520\n",
      "Epoch [82/85] Batch 720/938 Loss D: 0.2674, Loss G: 2.3287\n",
      "Epoch [82/85] Batch 730/938 Loss D: 0.1952, Loss G: 2.8231\n",
      "Epoch [82/85] Batch 740/938 Loss D: 0.2861, Loss G: 3.6309\n",
      "Epoch [82/85] Batch 750/938 Loss D: 0.3316, Loss G: 2.0547\n",
      "Epoch [82/85] Batch 760/938 Loss D: 0.2961, Loss G: 1.9597\n",
      "Epoch [82/85] Batch 770/938 Loss D: 0.3370, Loss G: 2.2704\n",
      "Epoch [82/85] Batch 780/938 Loss D: 0.3717, Loss G: 2.5093\n",
      "Epoch [82/85] Batch 790/938 Loss D: 0.3567, Loss G: 2.4756\n",
      "Epoch [82/85] Batch 800/938 Loss D: 0.3046, Loss G: 2.4025\n",
      "Epoch [82/85] Batch 810/938 Loss D: 0.1847, Loss G: 3.1816\n",
      "Epoch [82/85] Batch 820/938 Loss D: 0.2791, Loss G: 2.2577\n",
      "Epoch [82/85] Batch 830/938 Loss D: 0.2770, Loss G: 2.4341\n",
      "Epoch [82/85] Batch 840/938 Loss D: 0.2812, Loss G: 2.8145\n",
      "Epoch [82/85] Batch 850/938 Loss D: 0.2158, Loss G: 3.1391\n",
      "Epoch [82/85] Batch 860/938 Loss D: 0.1509, Loss G: 3.2004\n",
      "Epoch [82/85] Batch 870/938 Loss D: 0.3693, Loss G: 2.3829\n",
      "Epoch [82/85] Batch 880/938 Loss D: 0.2209, Loss G: 3.0264\n",
      "Epoch [82/85] Batch 890/938 Loss D: 0.2687, Loss G: 2.4425\n",
      "Epoch [82/85] Batch 900/938 Loss D: 0.1869, Loss G: 2.5654\n",
      "Epoch [82/85] Batch 910/938 Loss D: 0.2028, Loss G: 2.9627\n",
      "Epoch [82/85] Batch 920/938 Loss D: 0.2134, Loss G: 2.6754\n",
      "Epoch [82/85] Batch 930/938 Loss D: 0.1877, Loss G: 3.8052\n",
      "Epoch [83/85] Batch 0/938 Loss D: 0.2195, Loss G: 2.7323\n",
      "Epoch [83/85] Batch 10/938 Loss D: 0.1957, Loss G: 3.3842\n",
      "Epoch [83/85] Batch 20/938 Loss D: 0.1131, Loss G: 4.9913\n",
      "Epoch [83/85] Batch 30/938 Loss D: 0.2718, Loss G: 4.4919\n",
      "Epoch [83/85] Batch 40/938 Loss D: 0.2031, Loss G: 3.4940\n",
      "Epoch [83/85] Batch 50/938 Loss D: 0.2487, Loss G: 2.4403\n",
      "Epoch [83/85] Batch 60/938 Loss D: 0.2243, Loss G: 2.6790\n",
      "Epoch [83/85] Batch 70/938 Loss D: 0.2425, Loss G: 2.8195\n",
      "Epoch [83/85] Batch 80/938 Loss D: 0.1193, Loss G: 4.3434\n",
      "Epoch [83/85] Batch 90/938 Loss D: 0.2157, Loss G: 4.4606\n",
      "Epoch [83/85] Batch 100/938 Loss D: 0.2117, Loss G: 3.7313\n",
      "Epoch [83/85] Batch 110/938 Loss D: 0.4252, Loss G: 2.0429\n",
      "Epoch [83/85] Batch 120/938 Loss D: 0.2428, Loss G: 2.5142\n",
      "Epoch [83/85] Batch 130/938 Loss D: 0.2801, Loss G: 2.8893\n",
      "Epoch [83/85] Batch 140/938 Loss D: 0.1170, Loss G: 3.4790\n",
      "Epoch [83/85] Batch 150/938 Loss D: 0.2342, Loss G: 4.4681\n",
      "Epoch [83/85] Batch 160/938 Loss D: 0.1383, Loss G: 3.1516\n",
      "Epoch [83/85] Batch 170/938 Loss D: 0.1739, Loss G: 2.8616\n",
      "Epoch [83/85] Batch 180/938 Loss D: 0.1849, Loss G: 4.1510\n",
      "Epoch [83/85] Batch 190/938 Loss D: 0.2491, Loss G: 3.8268\n",
      "Epoch [83/85] Batch 200/938 Loss D: 0.1181, Loss G: 3.2329\n",
      "Epoch [83/85] Batch 210/938 Loss D: 0.2357, Loss G: 3.6725\n",
      "Epoch [83/85] Batch 220/938 Loss D: 0.3973, Loss G: 2.0526\n",
      "Epoch [83/85] Batch 230/938 Loss D: 0.2376, Loss G: 2.4478\n",
      "Epoch [83/85] Batch 240/938 Loss D: 0.1683, Loss G: 3.1052\n",
      "Epoch [83/85] Batch 250/938 Loss D: 0.2760, Loss G: 2.6726\n",
      "Epoch [83/85] Batch 260/938 Loss D: 0.3255, Loss G: 3.1621\n",
      "Epoch [83/85] Batch 270/938 Loss D: 0.2727, Loss G: 2.2300\n",
      "Epoch [83/85] Batch 280/938 Loss D: 0.2981, Loss G: 2.3264\n",
      "Epoch [83/85] Batch 290/938 Loss D: 0.3357, Loss G: 2.6802\n",
      "Epoch [83/85] Batch 300/938 Loss D: 0.2579, Loss G: 2.4727\n",
      "Epoch [83/85] Batch 310/938 Loss D: 0.2171, Loss G: 2.9880\n",
      "Epoch [83/85] Batch 320/938 Loss D: 0.1894, Loss G: 2.9736\n",
      "Epoch [83/85] Batch 330/938 Loss D: 0.3001, Loss G: 2.1124\n",
      "Epoch [83/85] Batch 340/938 Loss D: 0.3635, Loss G: 2.8163\n",
      "Epoch [83/85] Batch 350/938 Loss D: 0.1693, Loss G: 2.7246\n",
      "Epoch [83/85] Batch 360/938 Loss D: 0.1039, Loss G: 3.9014\n",
      "Epoch [83/85] Batch 370/938 Loss D: 0.1796, Loss G: 3.5182\n",
      "Epoch [83/85] Batch 380/938 Loss D: 0.1968, Loss G: 3.0310\n",
      "Epoch [83/85] Batch 390/938 Loss D: 0.1948, Loss G: 2.7349\n",
      "Epoch [83/85] Batch 400/938 Loss D: 0.2162, Loss G: 3.3858\n",
      "Epoch [83/85] Batch 410/938 Loss D: 0.2519, Loss G: 3.0569\n",
      "Epoch [83/85] Batch 420/938 Loss D: 0.2965, Loss G: 2.1329\n",
      "Epoch [83/85] Batch 430/938 Loss D: 0.1164, Loss G: 3.6753\n",
      "Epoch [83/85] Batch 440/938 Loss D: 0.1467, Loss G: 3.3866\n",
      "Epoch [83/85] Batch 450/938 Loss D: 0.3479, Loss G: 2.6815\n",
      "Epoch [83/85] Batch 460/938 Loss D: 0.3115, Loss G: 2.2887\n",
      "Epoch [83/85] Batch 470/938 Loss D: 0.3105, Loss G: 2.0282\n",
      "Epoch [83/85] Batch 480/938 Loss D: 0.2545, Loss G: 3.2570\n",
      "Epoch [83/85] Batch 490/938 Loss D: 0.3246, Loss G: 1.9865\n",
      "Epoch [83/85] Batch 500/938 Loss D: 0.2836, Loss G: 2.7265\n",
      "Epoch [83/85] Batch 510/938 Loss D: 0.3903, Loss G: 2.7158\n",
      "Epoch [83/85] Batch 520/938 Loss D: 0.2462, Loss G: 2.5952\n",
      "Epoch [83/85] Batch 530/938 Loss D: 0.2153, Loss G: 2.5442\n",
      "Epoch [83/85] Batch 540/938 Loss D: 0.3433, Loss G: 1.9381\n",
      "Epoch [83/85] Batch 550/938 Loss D: 0.2702, Loss G: 3.5965\n",
      "Epoch [83/85] Batch 560/938 Loss D: 0.2155, Loss G: 3.0356\n",
      "Epoch [83/85] Batch 570/938 Loss D: 0.3052, Loss G: 2.2854\n",
      "Epoch [83/85] Batch 580/938 Loss D: 0.2386, Loss G: 2.4856\n",
      "Epoch [83/85] Batch 590/938 Loss D: 0.2746, Loss G: 2.1525\n",
      "Epoch [83/85] Batch 600/938 Loss D: 0.3470, Loss G: 1.9260\n",
      "Epoch [83/85] Batch 610/938 Loss D: 0.1927, Loss G: 3.0082\n",
      "Epoch [83/85] Batch 620/938 Loss D: 0.3705, Loss G: 1.9613\n",
      "Epoch [83/85] Batch 630/938 Loss D: 0.2286, Loss G: 2.5856\n",
      "Epoch [83/85] Batch 640/938 Loss D: 0.1639, Loss G: 3.4183\n",
      "Epoch [83/85] Batch 650/938 Loss D: 0.3123, Loss G: 4.4347\n",
      "Epoch [83/85] Batch 660/938 Loss D: 0.2643, Loss G: 2.9120\n",
      "Epoch [83/85] Batch 670/938 Loss D: 0.2716, Loss G: 2.6494\n",
      "Epoch [83/85] Batch 680/938 Loss D: 0.1903, Loss G: 2.5221\n",
      "Epoch [83/85] Batch 690/938 Loss D: 0.3036, Loss G: 3.0049\n",
      "Epoch [83/85] Batch 700/938 Loss D: 0.2321, Loss G: 4.1188\n",
      "Epoch [83/85] Batch 710/938 Loss D: 0.3270, Loss G: 2.8532\n",
      "Epoch [83/85] Batch 720/938 Loss D: 0.2936, Loss G: 2.6636\n",
      "Epoch [83/85] Batch 730/938 Loss D: 0.2435, Loss G: 2.4765\n",
      "Epoch [83/85] Batch 740/938 Loss D: 0.4928, Loss G: 3.0784\n",
      "Epoch [83/85] Batch 750/938 Loss D: 0.2505, Loss G: 2.9623\n",
      "Epoch [83/85] Batch 760/938 Loss D: 0.4330, Loss G: 2.1355\n",
      "Epoch [83/85] Batch 770/938 Loss D: 0.3967, Loss G: 2.4976\n",
      "Epoch [83/85] Batch 780/938 Loss D: 0.3408, Loss G: 2.4603\n",
      "Epoch [83/85] Batch 790/938 Loss D: 0.1589, Loss G: 3.8716\n",
      "Epoch [83/85] Batch 800/938 Loss D: 0.4365, Loss G: 2.2705\n",
      "Epoch [83/85] Batch 810/938 Loss D: 0.2705, Loss G: 2.6025\n",
      "Epoch [83/85] Batch 820/938 Loss D: 0.3848, Loss G: 1.9202\n",
      "Epoch [83/85] Batch 830/938 Loss D: 0.3482, Loss G: 2.0421\n",
      "Epoch [83/85] Batch 840/938 Loss D: 0.3498, Loss G: 2.3129\n",
      "Epoch [83/85] Batch 850/938 Loss D: 0.2520, Loss G: 3.0164\n",
      "Epoch [83/85] Batch 860/938 Loss D: 0.1669, Loss G: 2.7502\n",
      "Epoch [83/85] Batch 870/938 Loss D: 0.2557, Loss G: 3.0188\n",
      "Epoch [83/85] Batch 880/938 Loss D: 0.3440, Loss G: 3.1057\n",
      "Epoch [83/85] Batch 890/938 Loss D: 0.4201, Loss G: 2.7046\n",
      "Epoch [83/85] Batch 900/938 Loss D: 0.2823, Loss G: 3.2615\n",
      "Epoch [83/85] Batch 910/938 Loss D: 0.3736, Loss G: 2.4497\n",
      "Epoch [83/85] Batch 920/938 Loss D: 0.2031, Loss G: 3.5891\n",
      "Epoch [83/85] Batch 930/938 Loss D: 0.2280, Loss G: 3.1856\n",
      "Epoch [84/85] Batch 0/938 Loss D: 0.1993, Loss G: 3.3102\n",
      "Epoch [84/85] Batch 10/938 Loss D: 0.4322, Loss G: 1.7137\n",
      "Epoch [84/85] Batch 20/938 Loss D: 0.2666, Loss G: 3.6291\n",
      "Epoch [84/85] Batch 30/938 Loss D: 0.1669, Loss G: 3.6792\n",
      "Epoch [84/85] Batch 40/938 Loss D: 0.2082, Loss G: 2.8343\n",
      "Epoch [84/85] Batch 50/938 Loss D: 0.4980, Loss G: 2.1916\n",
      "Epoch [84/85] Batch 60/938 Loss D: 0.1666, Loss G: 3.2201\n",
      "Epoch [84/85] Batch 70/938 Loss D: 0.1661, Loss G: 3.2423\n",
      "Epoch [84/85] Batch 80/938 Loss D: 0.2342, Loss G: 3.0059\n",
      "Epoch [84/85] Batch 90/938 Loss D: 0.3056, Loss G: 3.0647\n",
      "Epoch [84/85] Batch 100/938 Loss D: 0.3514, Loss G: 2.2766\n",
      "Epoch [84/85] Batch 110/938 Loss D: 0.2873, Loss G: 3.4437\n",
      "Epoch [84/85] Batch 120/938 Loss D: 0.3342, Loss G: 2.5874\n",
      "Epoch [84/85] Batch 130/938 Loss D: 0.2358, Loss G: 2.8495\n",
      "Epoch [84/85] Batch 140/938 Loss D: 0.2276, Loss G: 2.8644\n",
      "Epoch [84/85] Batch 150/938 Loss D: 0.2460, Loss G: 2.4124\n",
      "Epoch [84/85] Batch 160/938 Loss D: 0.3654, Loss G: 1.9351\n",
      "Epoch [84/85] Batch 170/938 Loss D: 0.5073, Loss G: 1.7397\n",
      "Epoch [84/85] Batch 180/938 Loss D: 0.3008, Loss G: 2.2113\n",
      "Epoch [84/85] Batch 190/938 Loss D: 0.2744, Loss G: 2.0064\n",
      "Epoch [84/85] Batch 200/938 Loss D: 0.3490, Loss G: 1.8642\n",
      "Epoch [84/85] Batch 210/938 Loss D: 0.1502, Loss G: 3.3320\n",
      "Epoch [84/85] Batch 220/938 Loss D: 0.4009, Loss G: 2.5834\n",
      "Epoch [84/85] Batch 230/938 Loss D: 0.2981, Loss G: 2.4877\n",
      "Epoch [84/85] Batch 240/938 Loss D: 0.1247, Loss G: 3.9127\n",
      "Epoch [84/85] Batch 250/938 Loss D: 0.1764, Loss G: 3.2638\n",
      "Epoch [84/85] Batch 260/938 Loss D: 0.2272, Loss G: 2.6563\n",
      "Epoch [84/85] Batch 270/938 Loss D: 0.2045, Loss G: 3.2769\n",
      "Epoch [84/85] Batch 280/938 Loss D: 0.2131, Loss G: 2.6844\n",
      "Epoch [84/85] Batch 290/938 Loss D: 0.3188, Loss G: 2.4153\n",
      "Epoch [84/85] Batch 300/938 Loss D: 0.3140, Loss G: 2.3136\n",
      "Epoch [84/85] Batch 310/938 Loss D: 0.2906, Loss G: 2.7583\n",
      "Epoch [84/85] Batch 320/938 Loss D: 0.3046, Loss G: 2.5971\n",
      "Epoch [84/85] Batch 330/938 Loss D: 0.2646, Loss G: 3.1316\n",
      "Epoch [84/85] Batch 340/938 Loss D: 0.2905, Loss G: 3.3499\n",
      "Epoch [84/85] Batch 350/938 Loss D: 0.3610, Loss G: 2.8458\n",
      "Epoch [84/85] Batch 360/938 Loss D: 0.2920, Loss G: 2.8079\n",
      "Epoch [84/85] Batch 370/938 Loss D: 0.1754, Loss G: 3.4023\n",
      "Epoch [84/85] Batch 380/938 Loss D: 0.2622, Loss G: 3.6125\n",
      "Epoch [84/85] Batch 390/938 Loss D: 0.1822, Loss G: 3.3104\n",
      "Epoch [84/85] Batch 400/938 Loss D: 0.2646, Loss G: 2.0036\n",
      "Epoch [84/85] Batch 410/938 Loss D: 0.4105, Loss G: 1.8794\n",
      "Epoch [84/85] Batch 420/938 Loss D: 0.2284, Loss G: 2.6644\n",
      "Epoch [84/85] Batch 430/938 Loss D: 0.1842, Loss G: 2.9570\n",
      "Epoch [84/85] Batch 440/938 Loss D: 0.2753, Loss G: 2.1496\n",
      "Epoch [84/85] Batch 450/938 Loss D: 0.2247, Loss G: 2.8034\n",
      "Epoch [84/85] Batch 460/938 Loss D: 0.3414, Loss G: 2.5866\n",
      "Epoch [84/85] Batch 470/938 Loss D: 0.2799, Loss G: 2.2237\n",
      "Epoch [84/85] Batch 480/938 Loss D: 0.2495, Loss G: 2.4312\n",
      "Epoch [84/85] Batch 490/938 Loss D: 0.3202, Loss G: 2.2520\n",
      "Epoch [84/85] Batch 500/938 Loss D: 0.2619, Loss G: 2.8443\n",
      "Epoch [84/85] Batch 510/938 Loss D: 0.3965, Loss G: 2.4321\n",
      "Epoch [84/85] Batch 520/938 Loss D: 0.4012, Loss G: 2.4866\n",
      "Epoch [84/85] Batch 530/938 Loss D: 0.2847, Loss G: 2.8331\n",
      "Epoch [84/85] Batch 540/938 Loss D: 0.2997, Loss G: 2.1649\n",
      "Epoch [84/85] Batch 550/938 Loss D: 0.3732, Loss G: 2.6506\n",
      "Epoch [84/85] Batch 560/938 Loss D: 0.4202, Loss G: 2.5098\n",
      "Epoch [84/85] Batch 570/938 Loss D: 0.3481, Loss G: 2.3421\n",
      "Epoch [84/85] Batch 580/938 Loss D: 0.3104, Loss G: 2.3662\n",
      "Epoch [84/85] Batch 590/938 Loss D: 0.3395, Loss G: 3.0433\n",
      "Epoch [84/85] Batch 600/938 Loss D: 0.2450, Loss G: 3.1918\n",
      "Epoch [84/85] Batch 610/938 Loss D: 0.3218, Loss G: 2.2921\n",
      "Epoch [84/85] Batch 620/938 Loss D: 0.2764, Loss G: 2.3090\n",
      "Epoch [84/85] Batch 630/938 Loss D: 0.4227, Loss G: 1.8972\n",
      "Epoch [84/85] Batch 640/938 Loss D: 0.2392, Loss G: 2.9585\n",
      "Epoch [84/85] Batch 650/938 Loss D: 0.2630, Loss G: 2.6761\n",
      "Epoch [84/85] Batch 660/938 Loss D: 0.3843, Loss G: 2.2863\n",
      "Epoch [84/85] Batch 670/938 Loss D: 0.1918, Loss G: 3.4723\n",
      "Epoch [84/85] Batch 680/938 Loss D: 0.1365, Loss G: 3.5835\n",
      "Epoch [84/85] Batch 690/938 Loss D: 0.0941, Loss G: 4.4437\n",
      "Epoch [84/85] Batch 700/938 Loss D: 0.1000, Loss G: 4.4423\n",
      "Epoch [84/85] Batch 710/938 Loss D: 0.3301, Loss G: 3.1075\n",
      "Epoch [84/85] Batch 720/938 Loss D: 0.2480, Loss G: 2.4386\n",
      "Epoch [84/85] Batch 730/938 Loss D: 0.1981, Loss G: 3.1194\n",
      "Epoch [84/85] Batch 740/938 Loss D: 0.2962, Loss G: 2.6748\n",
      "Epoch [84/85] Batch 750/938 Loss D: 0.1835, Loss G: 3.1719\n",
      "Epoch [84/85] Batch 760/938 Loss D: 0.2245, Loss G: 2.5672\n",
      "Epoch [84/85] Batch 770/938 Loss D: 0.3075, Loss G: 2.0719\n",
      "Epoch [84/85] Batch 780/938 Loss D: 0.2953, Loss G: 1.9518\n",
      "Epoch [84/85] Batch 790/938 Loss D: 0.2020, Loss G: 2.4994\n",
      "Epoch [84/85] Batch 800/938 Loss D: 0.2928, Loss G: 1.7704\n",
      "Epoch [84/85] Batch 810/938 Loss D: 0.2552, Loss G: 2.1060\n",
      "Epoch [84/85] Batch 820/938 Loss D: 0.2465, Loss G: 3.0072\n",
      "Epoch [84/85] Batch 830/938 Loss D: 0.2012, Loss G: 4.4453\n",
      "Epoch [84/85] Batch 840/938 Loss D: 0.3422, Loss G: 2.3592\n",
      "Epoch [84/85] Batch 850/938 Loss D: 0.1569, Loss G: 2.8459\n",
      "Epoch [84/85] Batch 860/938 Loss D: 0.2627, Loss G: 2.5908\n",
      "Epoch [84/85] Batch 870/938 Loss D: 0.3379, Loss G: 2.1321\n",
      "Epoch [84/85] Batch 880/938 Loss D: 0.1800, Loss G: 3.2053\n",
      "Epoch [84/85] Batch 890/938 Loss D: 0.1960, Loss G: 4.0368\n",
      "Epoch [84/85] Batch 900/938 Loss D: 0.2564, Loss G: 2.8092\n",
      "Epoch [84/85] Batch 910/938 Loss D: 0.3902, Loss G: 1.4265\n",
      "Epoch [84/85] Batch 920/938 Loss D: 0.2205, Loss G: 2.3733\n",
      "Epoch [84/85] Batch 930/938 Loss D: 0.1789, Loss G: 3.5113\n",
      "Epoch [85/85] Batch 0/938 Loss D: 0.2553, Loss G: 2.3523\n",
      "Epoch [85/85] Batch 10/938 Loss D: 0.2972, Loss G: 1.9835\n",
      "Epoch [85/85] Batch 20/938 Loss D: 0.3099, Loss G: 2.5663\n",
      "Epoch [85/85] Batch 30/938 Loss D: 0.2757, Loss G: 3.5385\n",
      "Epoch [85/85] Batch 40/938 Loss D: 0.3055, Loss G: 2.8181\n",
      "Epoch [85/85] Batch 50/938 Loss D: 0.2742, Loss G: 2.5689\n",
      "Epoch [85/85] Batch 60/938 Loss D: 0.3205, Loss G: 2.7665\n",
      "Epoch [85/85] Batch 70/938 Loss D: 0.3008, Loss G: 2.8522\n",
      "Epoch [85/85] Batch 80/938 Loss D: 0.1912, Loss G: 2.7286\n",
      "Epoch [85/85] Batch 90/938 Loss D: 0.2231, Loss G: 2.7144\n",
      "Epoch [85/85] Batch 100/938 Loss D: 0.2990, Loss G: 2.4203\n",
      "Epoch [85/85] Batch 110/938 Loss D: 0.2440, Loss G: 2.9844\n",
      "Epoch [85/85] Batch 120/938 Loss D: 0.3093, Loss G: 2.6680\n",
      "Epoch [85/85] Batch 130/938 Loss D: 0.2273, Loss G: 2.8617\n",
      "Epoch [85/85] Batch 140/938 Loss D: 0.2261, Loss G: 2.7277\n",
      "Epoch [85/85] Batch 150/938 Loss D: 0.3018, Loss G: 2.5516\n",
      "Epoch [85/85] Batch 160/938 Loss D: 0.2806, Loss G: 2.5949\n",
      "Epoch [85/85] Batch 170/938 Loss D: 0.2595, Loss G: 2.4519\n",
      "Epoch [85/85] Batch 180/938 Loss D: 0.3884, Loss G: 1.8694\n",
      "Epoch [85/85] Batch 190/938 Loss D: 0.2919, Loss G: 3.0353\n",
      "Epoch [85/85] Batch 200/938 Loss D: 0.3845, Loss G: 2.9585\n",
      "Epoch [85/85] Batch 210/938 Loss D: 0.3427, Loss G: 2.0054\n",
      "Epoch [85/85] Batch 220/938 Loss D: 0.2052, Loss G: 2.7201\n",
      "Epoch [85/85] Batch 230/938 Loss D: 0.1387, Loss G: 2.6834\n",
      "Epoch [85/85] Batch 240/938 Loss D: 0.2095, Loss G: 3.5198\n",
      "Epoch [85/85] Batch 250/938 Loss D: 0.2998, Loss G: 3.0671\n",
      "Epoch [85/85] Batch 260/938 Loss D: 0.1279, Loss G: 3.4677\n",
      "Epoch [85/85] Batch 270/938 Loss D: 0.2550, Loss G: 2.4641\n",
      "Epoch [85/85] Batch 280/938 Loss D: 0.2268, Loss G: 3.0348\n",
      "Epoch [85/85] Batch 290/938 Loss D: 0.1176, Loss G: 4.4468\n",
      "Epoch [85/85] Batch 300/938 Loss D: 0.3633, Loss G: 1.9332\n",
      "Epoch [85/85] Batch 310/938 Loss D: 0.2348, Loss G: 2.7253\n",
      "Epoch [85/85] Batch 320/938 Loss D: 0.2940, Loss G: 2.0929\n",
      "Epoch [85/85] Batch 330/938 Loss D: 0.2156, Loss G: 2.7106\n",
      "Epoch [85/85] Batch 340/938 Loss D: 0.2193, Loss G: 2.2613\n",
      "Epoch [85/85] Batch 350/938 Loss D: 0.2368, Loss G: 2.6094\n",
      "Epoch [85/85] Batch 360/938 Loss D: 0.3864, Loss G: 2.8542\n",
      "Epoch [85/85] Batch 370/938 Loss D: 0.2747, Loss G: 2.8196\n",
      "Epoch [85/85] Batch 380/938 Loss D: 0.3568, Loss G: 2.1821\n",
      "Epoch [85/85] Batch 390/938 Loss D: 0.2061, Loss G: 2.6943\n",
      "Epoch [85/85] Batch 400/938 Loss D: 0.2450, Loss G: 2.6996\n",
      "Epoch [85/85] Batch 410/938 Loss D: 0.2321, Loss G: 3.0762\n",
      "Epoch [85/85] Batch 420/938 Loss D: 0.2894, Loss G: 3.1848\n",
      "Epoch [85/85] Batch 430/938 Loss D: 0.2707, Loss G: 2.5037\n",
      "Epoch [85/85] Batch 440/938 Loss D: 0.1558, Loss G: 3.3774\n",
      "Epoch [85/85] Batch 450/938 Loss D: 0.2105, Loss G: 2.6518\n",
      "Epoch [85/85] Batch 460/938 Loss D: 0.1185, Loss G: 3.4634\n",
      "Epoch [85/85] Batch 470/938 Loss D: 0.3352, Loss G: 2.5695\n",
      "Epoch [85/85] Batch 480/938 Loss D: 0.2260, Loss G: 2.7736\n",
      "Epoch [85/85] Batch 490/938 Loss D: 0.3011, Loss G: 2.7347\n",
      "Epoch [85/85] Batch 500/938 Loss D: 0.3891, Loss G: 2.2931\n",
      "Epoch [85/85] Batch 510/938 Loss D: 0.3093, Loss G: 2.1405\n",
      "Epoch [85/85] Batch 520/938 Loss D: 0.3255, Loss G: 2.2510\n",
      "Epoch [85/85] Batch 530/938 Loss D: 0.2133, Loss G: 2.5759\n",
      "Epoch [85/85] Batch 540/938 Loss D: 0.3316, Loss G: 2.3556\n",
      "Epoch [85/85] Batch 550/938 Loss D: 0.2518, Loss G: 2.4041\n",
      "Epoch [85/85] Batch 560/938 Loss D: 0.2221, Loss G: 2.9034\n",
      "Epoch [85/85] Batch 570/938 Loss D: 0.3945, Loss G: 2.9863\n",
      "Epoch [85/85] Batch 580/938 Loss D: 0.2704, Loss G: 2.4997\n",
      "Epoch [85/85] Batch 590/938 Loss D: 0.1902, Loss G: 3.4247\n",
      "Epoch [85/85] Batch 600/938 Loss D: 0.2317, Loss G: 4.0045\n",
      "Epoch [85/85] Batch 610/938 Loss D: 0.3236, Loss G: 2.5428\n",
      "Epoch [85/85] Batch 620/938 Loss D: 0.1317, Loss G: 3.6017\n",
      "Epoch [85/85] Batch 630/938 Loss D: 0.2352, Loss G: 2.4127\n",
      "Epoch [85/85] Batch 640/938 Loss D: 0.3229, Loss G: 2.8675\n",
      "Epoch [85/85] Batch 650/938 Loss D: 0.2987, Loss G: 2.8303\n",
      "Epoch [85/85] Batch 660/938 Loss D: 0.1487, Loss G: 3.4199\n",
      "Epoch [85/85] Batch 670/938 Loss D: 0.4158, Loss G: 2.4004\n",
      "Epoch [85/85] Batch 680/938 Loss D: 0.2534, Loss G: 2.7710\n",
      "Epoch [85/85] Batch 690/938 Loss D: 0.3024, Loss G: 2.8157\n",
      "Epoch [85/85] Batch 700/938 Loss D: 0.3565, Loss G: 2.5762\n",
      "Epoch [85/85] Batch 710/938 Loss D: 0.2990, Loss G: 2.3610\n",
      "Epoch [85/85] Batch 720/938 Loss D: 0.2474, Loss G: 2.7085\n",
      "Epoch [85/85] Batch 730/938 Loss D: 0.2073, Loss G: 3.2555\n",
      "Epoch [85/85] Batch 740/938 Loss D: 0.1414, Loss G: 2.9598\n",
      "Epoch [85/85] Batch 750/938 Loss D: 0.2626, Loss G: 2.5032\n",
      "Epoch [85/85] Batch 760/938 Loss D: 0.2978, Loss G: 2.5947\n",
      "Epoch [85/85] Batch 770/938 Loss D: 0.2032, Loss G: 2.8417\n",
      "Epoch [85/85] Batch 780/938 Loss D: 0.3717, Loss G: 2.4613\n",
      "Epoch [85/85] Batch 790/938 Loss D: 0.2547, Loss G: 3.0723\n",
      "Epoch [85/85] Batch 800/938 Loss D: 0.2454, Loss G: 3.3508\n",
      "Epoch [85/85] Batch 810/938 Loss D: 0.2818, Loss G: 2.8080\n",
      "Epoch [85/85] Batch 820/938 Loss D: 0.3284, Loss G: 3.5443\n",
      "Epoch [85/85] Batch 830/938 Loss D: 0.3661, Loss G: 2.0947\n",
      "Epoch [85/85] Batch 840/938 Loss D: 0.2552, Loss G: 2.6339\n",
      "Epoch [85/85] Batch 850/938 Loss D: 0.3503, Loss G: 2.5406\n",
      "Epoch [85/85] Batch 860/938 Loss D: 0.2244, Loss G: 2.9105\n",
      "Epoch [85/85] Batch 870/938 Loss D: 0.2814, Loss G: 1.8235\n",
      "Epoch [85/85] Batch 880/938 Loss D: 0.2411, Loss G: 2.5245\n",
      "Epoch [85/85] Batch 890/938 Loss D: 0.2829, Loss G: 2.4644\n",
      "Epoch [85/85] Batch 900/938 Loss D: 0.1893, Loss G: 3.9680\n",
      "Epoch [85/85] Batch 910/938 Loss D: 0.2368, Loss G: 3.0971\n",
      "Epoch [85/85] Batch 920/938 Loss D: 0.2389, Loss G: 2.3873\n",
      "Epoch [85/85] Batch 930/938 Loss D: 0.3332, Loss G: 2.3935\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "class CustomMNISTDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir # data directory\n",
    "        self.transform = transform #    \n",
    "        self.image_paths = []\n",
    "\n",
    "        for i in range(10):\n",
    "            label_dir = os.path.join(root_dir, str(i))\n",
    "            for img_file in glob.glob(os.path.join(label_dir, '*.png')):\n",
    "                self.image_paths.append(img_file) # data     \n",
    "\n",
    "        print(f'Found {len(self.image_paths)} images')        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index): #   \n",
    "        img_path = self.image_paths[index]\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, img_channels=1, feature_g=64):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.ConvTranspose2d(z_dim, feature_g*4, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.InstanceNorm2d(feature_g*4)\n",
    "        self.r1 = nn.ReLU(True)\n",
    "\n",
    "        self.conv2 = nn.ConvTranspose2d(feature_g*4, feature_g, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.InstanceNorm2d(feature_g)\n",
    "        self.r2 = nn.ReLU(True)\n",
    "\n",
    "        self.conv3 = nn.ConvTranspose2d(feature_g, img_channels, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.t = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.r1(self.bn1(self.conv1(x)))\n",
    "        x = self.r2(self.bn2(self.conv2(x)))\n",
    "        x = self.t(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_channels=1, feature_d=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(img_channels, feature_d, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(feature_d)\n",
    "        self.r1 = nn.LeakyReLU(True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(feature_d, feature_d*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(feature_d*4)\n",
    "        self.r2 = nn.ReLU(True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(feature_d*4, 1, kernel_size=3, stride=2, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.r1(self.bn1(self.conv1(x)))\n",
    "        x = self.r2(self.bn2(self.conv2(x)))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "data_dir = './data/train/'\n",
    "result_dir = './result/'\n",
    "os.makedirs(result_dir, exist_ok=True)\n",
    "\n",
    "# 4.  \n",
    "batch_size = 64\n",
    "lr = 0.0005\n",
    "z_dim = 100\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "epochs = 100  #   \n",
    "\n",
    "print(f\"Using Device: {device}\")\n",
    "\n",
    "# 5.   \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((16, 16)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# 6.    \n",
    "\n",
    "train_dataset = CustomMNISTDataset(root_dir=data_dir, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# 7.  \n",
    "\n",
    "gen = Generator(z_dim=z_dim, img_channels=1, feature_g=32).to(device)\n",
    "disc = Discriminator(img_channels=1, feature_d=32).to(device)\n",
    "\n",
    "# 8.      \n",
    "\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr*0.75)\n",
    "bce_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# 9.     \n",
    "\n",
    "def show_generated_images(generator, num_images=64, epoch=0):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_images, z_dim, 1, 1).to(device)  # CNN 4D   \n",
    "        fake_images = generator(noise)\n",
    "        fake_images = fake_images.cpu()\n",
    "        grid = vutils.make_grid(fake_images, nrow=8, normalize=True)\n",
    "        plt.clf()\n",
    "        plt.imshow(grid.permute(1, 2, 0).squeeze(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Generated Images at Epoch {epoch}')\n",
    "        plt.savefig(f'{result_dir}image_lr_mod.png', pad_inches=0.1, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    generator.train()\n",
    "\n",
    "# 10. GAN  \n",
    "losses_g = []\n",
    "losses_d = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, real in enumerate(train_dataloader):\n",
    "        real = real.to(device)\n",
    "        batch_size = real.shape[0]\n",
    "        ### (a)   ( )\n",
    "        noise = torch.randn(batch_size, z_dim, 1, 1).to(device)\n",
    "        fake = gen(noise)\n",
    "        \n",
    "        #  (1) \n",
    "        disc_real = disc(real).view(-1) #   \n",
    "        loss_disc_real = bce_loss(disc_real, torch.ones_like(disc_real))\n",
    "\n",
    "        #  (0) \n",
    "        disc_fake = disc(fake.detach()).view(-1)\n",
    "        loss_disc_fake = bce_loss(disc_fake, torch.zeros_like(disc_fake))\n",
    "        \n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        opt_disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### (b)   ( )\n",
    "        output = disc(fake).view(-1)\n",
    "        loss_gen = bce_loss(output, torch.ones_like(output))\n",
    "        \n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        losses_g.append(loss_gen.item())\n",
    "        losses_d.append(loss_disc.item())\n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Batch {batch_idx}/{len(train_dataloader)} \"\n",
    "                  f\"Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\")\n",
    "            show_generated_images(gen, num_images=16, epoch=epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#   \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses_g, label=\"Generator Loss\", color='blue')\n",
    "plt.plot(losses_d, label=\"Discriminator Loss\", color='red')\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"GAN Loss\")\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UR",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
